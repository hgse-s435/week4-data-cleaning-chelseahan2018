{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the graphs inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This week we are going to work with some text data. In this folder, you should a text file called 'fullpapers.txt'. This file was generated by converting the proceedings of the EDM (Educational Data Mining) conference of 2018. You can find the proceedings here: http://educationaldatamining.org/EDM2017/proc_files/fullpapers.pdf\n",
    "We are going to explore the different terms that are used by authors of the papers in this conference, which will require some data cleaning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is compare the different papers in terms of the vocabulary used. \n",
    "* open the pdf of the proceedings (fullpapers.pdf); \n",
    "* open the txt of the proceedigs (fullpapers.txt)\n",
    "\n",
    "1) we want to split the data into different papers. Brainstorm a few ideas on how to do that:\n",
    "* Look at Abstract\n",
    "* Look at Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2) First we are going to read the fullpapers.txt file \n",
    "# and assign its content to a variable called \"data\"\n",
    "# hint: https://stackoverflow.com/questions/3758147/easiest-way-to-read-write-a-files-content-in-python\n",
    "data = None\n",
    "with open('./fullpapers.txt', encoding='utf8') as f:\n",
    "    data = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x0cZone out no more: Mitigating mind wandering during\\ncomputerized reading\\nSidney K. D’Mello, Caitlin Mills, Robert Bixler, & Nigel Bosch\\nUniversity of Notre Dame\\n118 Haggar Hall\\nNotre Dame, IN 46556, U'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\f",
      "Z\n"
     ]
    }
   ],
   "source": [
    "delimiter = data[:2]\n",
    "print (delimiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3) To facilitate data processing, we want to split this file\n",
    "# into different pages. Create a list called \"pages\" that \n",
    "# stores the text presented on each page of the pdf\n",
    "# Look into the .split() function, what string are we going to want to split by?\n",
    "pages = data.split('Proceedings of the 10th International Conference on Educational Data Mining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages = data.split(delimiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one out no more: mitigating mind wandering during\n",
      "computerized reading\n",
      "sidney k. d’mello, caitlin mills, robert bixler, & nigel bosch\n",
      "university of notre dame\n",
      "118 haggar hall\n",
      "notre dame, in 46556, usa\n",
      "sdmello@nd.edu\n",
      "\n",
      "abstract\n",
      "mind wandering, defined as shifts in attention from task-related\n",
      "processing to task-unrelated thoughts, is a ubiquitous\n",
      "phenomenon that has a negative influence on performance and\n",
      "productivity in many contexts, including learning. we propose\n",
      "that next-generation learning technologies should have some\n",
      "mechanism to detect and respond to mind wandering in real-time.\n",
      "towards this end, we developed a technology that automatically\n",
      "detects mind wandering from eye-gaze during learning from\n",
      "instructional texts. when mind wandering is detected, the\n",
      "technology intervenes by posing just-in-time questions and\n",
      "encouraging re-reading as needed. after multiple rounds of\n",
      "iterative refinement, we summatively compared the technology to\n",
      "a yoked-control in an experiment with 104 participants. the key\n",
      "dependent variable was performance on a post-reading\n",
      "comprehension assessment. our results suggest that the\n",
      "technology was successful in correcting comprehension deficits\n",
      "attributed to mind wandering (d = .47 sigma) under specific\n",
      "conditions, thereby highlighting the potential to improve learning\n",
      "by “attending to attention.”\n",
      "\n",
      "keywords\n",
      "mind wandering; gaze tracking; student modeling; attentionaware.\n",
      "\n",
      "1. introduction\n",
      "despite our best efforts to write a clear and engaging paper,\n",
      "chances are high that within the next 10 pages you might fall prey\n",
      "to what is referred to as zoning out, daydreaming, or mind\n",
      "wandering [45]. despite your best intention to concentrate on our\n",
      "paper, at some point your attention might drift away to unrelated\n",
      "thoughts of lunch, childcare, or an upcoming trip. this prediction\n",
      "is not based on some negative or cynical opinion of the\n",
      "reader/reviewer (we read and review papers too), but on what is\n",
      "known about attentional control, vigilance, and concentration\n",
      "while individuals are engaged in complex comprehension\n",
      "activities, such as reading for understanding.\n",
      "one recent study tracked mind wandering of 5,000 individuals\n",
      "from 83 countries with a smartphone app that prompted people\n",
      "with thought-probes at random intervals throughout the day [24].\n",
      "people reported mind wandering for 46.9% of the prompts, which\n",
      "confirmed lab studies on the pervasiveness of mind wandering\n",
      "(see [45] for a review). mind wandering is more than merely\n",
      "incidental; a recent meta-analysis of 88 samples indicated a\n",
      "negative correlation between mind wandering and performance\n",
      "across a variety of tasks [34], a correlation which increases with\n",
      "task complexity. when compounded with its high frequency,\n",
      "mind wandering can have serious consequences on the\n",
      "performance and productivity of society at large.\n",
      "\n",
      "of learning with technology. traditional learning technologies\n",
      "rely on the assumption that students are attending to the learning\n",
      "session, although this is not always the case. for example, it has\n",
      "been estimated that students mind wander approximately 40% of\n",
      "the time when engaging with online lectures [38], which are an\n",
      "important component of moocs. some advanced technologies\n",
      "do aim to detect and respond to affective states like boredom, but\n",
      "evidence for their effectiveness is still equivocal (see [9] for a\n",
      "review). further, boredom is related to but not the same as\n",
      "attention [12]. there are technologies that aim to prevent mind\n",
      "wandering by engendering a highly immersive learning\n",
      "experience and have achieved some success in this regard [40,\n",
      "41]. but what is to be done when attentional focus inevitably\n",
      "wanes as the session progresses and the novelty of the system and\n",
      "content fades?\n",
      "our central thesis is that next-generation learning technologies\n",
      "should include mechanisms to model and respond to learners’\n",
      "attention in real-time [8]. such attention-aware technologies can\n",
      "model various aspects of learner attention (e.g., divided attention,\n",
      "alternating attention). here, we focus on detecting and mitigating\n",
      "mind wandering, a quintessential signal of waning engagement.\n",
      "we situate our work in the context of reading because reading is\n",
      "a common activity shared across multiple learning technologies,\n",
      "thereby increasing the generalizability of our results. further,\n",
      "students mind wander approximately 30% of the time during\n",
      "computerized reading [44]. and although mind wandering can\n",
      "facilitate certain cognitive processes like future planning and\n",
      "divergent thinking [2, 28], it negatively correlates with\n",
      "comprehension and learning (reviewed in [31, 45]), suggesting\n",
      "that it is important to address mind wandering during learning.\n",
      "towards this end, we developed and validated a closed-loop\n",
      "attention-aware learning technology that combines a machinelearned mind wandering detector with a real-time interpolated\n",
      "testing and re-study intervention. our attention-aware technology\n",
      "works as follows. learners read a text on a computer screen using\n",
      "a self-paced screen-by-screen (also called page-by-page) reading\n",
      "paradigm. we track eye-gaze during reading using a remote eye\n",
      "tracker that does not restrict head movements. we focus on eyegaze for mind wandering detection due to decades of research\n",
      "suggesting a tight coupling between attentional focus and eye\n",
      "movements during reading [36]. when mind wandering is\n",
      "detected, the system intervenes in an attempt to redirect\n",
      "attentional focus and correct any comprehension deficits that\n",
      "might arise due to mind wandering. the interventions consist of\n",
      "asking comprehension question on pages where mind wandering\n",
      "was detected and providing opportunities to re-read based on\n",
      "learners’ responses. in this paper, we discuss the mind wandering\n",
      "\n",
      "mind wandering is also unfortunately an under-addressed\n",
      "problem in education and is yet to be deeply studied in the context\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "8\n",
      "\n",
      "\f",
      "detector, intervention approach, and results of a summative\n",
      "evaluation study 1.\n",
      "\n",
      "1.1 related work\n",
      "the idea of attention-aware user interfaces is not new, but was\n",
      "proposed almost a decade ago by roda and thomas [39]. there\n",
      "was even an article on futuristic applications of attention-aware\n",
      "systems in educational contexts [35]. prior to this, gluck, et al.\n",
      "[15] discussed the use of eye tracking to increase the bandwidth\n",
      "of information available to an intelligent tutoring system (its).\n",
      "similarly, anderson [1] followed up on some of these ideas by\n",
      "demonstrating how particular beneficial instructional strategies\n",
      "could only be launched via a real-time analysis of eye gaze.\n",
      "most of the recent work has been on leveraging eye gaze to\n",
      "increase the bandwidth of learner models [22, 23, 29]. conati, et\n",
      "al. [5] provide an excellent review of much of the existing work\n",
      "in this area. we can group the research into three categories: (1)\n",
      "offline-analyses of eye gaze to study attentional processes, (2)\n",
      "computational modeling of attentional states, and (3) closed-loop\n",
      "systems that respond to attention in real-time. offline-analysis of\n",
      "eye movements has received considerable attention in cognitive\n",
      "and educational psychology for several decades [e.g., 16, 19], so\n",
      "this area of research is relatively healthy. online computational\n",
      "models of learner attention are just beginning to emerge [e.g., 6,\n",
      "11], while closed-loop attention-aware systems are few and far\n",
      "between (see [7, 15, 42, 48] for a more or less exhaustive list).\n",
      "two known examples, gazetutor and attentivereview, are\n",
      "discussed below.\n",
      "gazetutor [7] is a learning technology for biology. it has an\n",
      "animated conversational agent that provides spoken explanations\n",
      "on biology topics which are synchronized with images. the\n",
      "system uses a tobii t60 eye tracker to detect inattention, which\n",
      "is assumed to occur when learners’ gaze is not on the tutor agent\n",
      "or image for at least five consecutive seconds. when this occurs,\n",
      "the system interrupts its speech mid utterance, directs learners to\n",
      "reorient their attention (e.g., “i’m over here you know”), and\n",
      "repeats speaking from the start of the current utterance. in an\n",
      "evaluation study, 48 learners (undergraduate students) completed\n",
      "a learning session on four biology topics with the attention-aware\n",
      "components enabled (experimental group) or disabled (control\n",
      "group). the results indicated that gazetutor was successful in\n",
      "dynamically reorienting learners’ attentional patterns towards the\n",
      "interface. importantly, learning gains for deep reasoning\n",
      "questions were significantly higher for the experimental vs.\n",
      "control group, but only for high aptitude learners. the results\n",
      "suggest that even the most basic attention-aware technology can\n",
      "be effective in improving learning, at least for a subset of learners.\n",
      "however, a key limitation is that the researchers simply assumed\n",
      "that off-screen gaze corresponded to inattention, but did not test\n",
      "this assumption (e.g., students could have been concentrating\n",
      "with their eyes closed and this would have been perceived as\n",
      "being inattentive).\n",
      "attentivereview [32] is a closed-loop system for mooc learning\n",
      "on mobile phones. the system uses video-based\n",
      "photoplethysmography (ppg) to detect a learners’ heart rate from\n",
      "the back camera of a smartphone while they view mooc-like\n",
      "lectures on the phone. attentivereview ranks the lectures based\n",
      "1\n",
      "\n",
      "on its estimates of learners’ “perceived difficulty,” selecting the\n",
      "most difficult lecture for subsequent review (called adaptive\n",
      "review). in a 32-participant between-subjects evaluation study,\n",
      "the authors found that learning gains obtained from the adaptive\n",
      "review condition were statistically on par with a full review\n",
      "condition, but were achieved in 66.7% less review time. although\n",
      "this result suggests that attentivereview increased learning\n",
      "efficiency, there is the question as to whether the system should\n",
      "even be considered to be an “attention-aware” technology. this is\n",
      "because it is arguable if the system has anything to do with\n",
      "attention (except for “attention” appearing in its name) as it\n",
      "selects items for review based on a model of “perceived\n",
      "difficulty” and not on learners’ “attentional state.” the two might\n",
      "be related, but are clearly not the same.\n",
      "\n",
      "1.2 novelty\n",
      "our paper focuses on closing the loop between research on\n",
      "educational data and learning outcomes by developing and\n",
      "validating the first (in our view) real-time learning technology\n",
      "that detects and mitigates mind wandering during computerized\n",
      "reading. although automated detection of complex mental states\n",
      "with the goal of developing intelligent learning technologies that\n",
      "respond to the sensed states is an active research area (see reviews\n",
      "by [9, 18]), mind wandering has rarely been explored as an aspect\n",
      "of a learner’s mental state that warrants detection and corrective\n",
      "action. and while there has been some work on modeling the\n",
      "locus of learner attention (see review by [5]), mind wandering is\n",
      "inherently different than more commonly studied forms of\n",
      "attention (e.g., selective attention, distraction), because it involves\n",
      "more covert forms of involuntary attentional lapses spawned by\n",
      "self-generated internal thought [45]. simply put, mind wandering\n",
      "is a form of “looking without seeing” because the eyes might be\n",
      "fixated on the appropriate external stimulus, but very little is\n",
      "being processed as the mind is consumed by stimulusindependent internal thoughts. offline automated approaches to\n",
      "detect mind wandering have been developed (e.g., [3, 11, 27, 33]),\n",
      "but these detectors have not yet been used to trigger online\n",
      "interventions. here, we adapt an offline gaze-based automated\n",
      "mind wandering detector [13] to trigger real-time interventions to\n",
      "address mind wandering during reading. we conduct a\n",
      "randomized control trial to evaluate the efficacy of our attentionaware learning technology in improving learning.\n",
      "\n",
      "2. mind wandering detection\n",
      "we adopted a supervised learning approach for mind wandering\n",
      "detection. below we provide a high-level overview of the\n",
      "approach; readers are directed to [3, 13] for a detailed discussion\n",
      "of the general approach used to build gaze-based detectors of\n",
      "mind wandering.\n",
      "\n",
      "2.1 training data\n",
      "we obtained training data from a previous study [26] that\n",
      "involved 98 undergraduate students reading a 57-page text on the\n",
      "surface tension of liquids [4] on a computer screen for an average\n",
      "of 28 minutes. the text contained around 6500 words, with an\n",
      "average of 115 words per page, and was displayed on a computer\n",
      "screen with courier new typeface. we recorded eye-gaze with a\n",
      "tobii tx300 eye tracker set to a sampling frequency of 120 hz.\n",
      "\n",
      "this paper reports updated results of an earlier version [10] presented\n",
      "as a “late-breaking work” (lbw) poster at the 2016 acm chi\n",
      "conference. lbw “extended abstracts” are not included in the main\n",
      "conference proceedings and copyright is retained by the authors.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "9\n",
      "\n",
      "\f",
      "participants could read normally and were free to move or gesture\n",
      "as they pleased.\n",
      "participants were instructed to report mind wandering (during\n",
      "reading) by pressing a predetermined key when they found\n",
      "themselves “thinking about the task itself but not the actual\n",
      "content of the text” or when they were “thinking about anything\n",
      "else besides the task.” this is consistent with contemporary\n",
      "approaches (see [45]) that rely on self-reporting because mind\n",
      "wandering is an internal conscious phenomena. further, selfreports of mind wandering have been linked to predictable\n",
      "patterns in physiology [43], pupillometry [14], eye-gaze [37], and\n",
      "task performance [34], providing validity for this approach.\n",
      "\n",
      "on the page, we classified the page as a positive instance of mind\n",
      "wandering. this was done because analyses indicated that\n",
      "participants were more likely to be mind wandering in those cases\n",
      "(but see [13] for alternate strategies to handle missing instances).\n",
      "\n",
      "on average, we received mind wandering reports for 32% of the\n",
      "pages (sd = 20%), although there was considerable variability\n",
      "among participants (ranging from 0% to 82%). self-reported\n",
      "mind wandering negatively correlated (r = -.23, p < .05) with\n",
      "scores on a subsequent comprehension assessment [26], which\n",
      "provides evidence for the predictive validity of the self-reports.\n",
      "\n",
      "2.2 model building\n",
      "the stream of eye-gaze data was filtered to produce a series of\n",
      "fixations, saccades, and blinks, from which global eye gaze\n",
      "features were extracted (see figure 1). global features are\n",
      "independent of the words being read and are therefore more\n",
      "generalizable than so-called local features. a full list of 62 global\n",
      "features along with detailed descriptions is provided in [13], but\n",
      "briefly the features can be grouped into the following four\n",
      "categories: (1) eye movement descriptive features (n = 48) were\n",
      "statistical functionals (e.g., min, median) for fixation duration,\n",
      "saccade duration, saccade amplitude, saccade velocity, and\n",
      "relative and absolute saccade angle distributions; (2) pupil\n",
      "diameter descriptive features were statistical functionals (n = 8)\n",
      "computed from participant-level z-score standardized estimates\n",
      "of pupil diameter; (3) blink features (n = 2) consisted of the\n",
      "number of blinks and the mean blink duration; (4) miscellaneous\n",
      "gaze features (n = 4) consisted of the number of saccades,\n",
      "horizontal saccade proportion, fixation dispersion, and the\n",
      "fixation duration/saccade duration ratio. we proceeded with a\n",
      "subset of 32 features after eliminating features exhibiting\n",
      "multicollinearity.\n",
      "features were calculated from only a certain amount of gaze data\n",
      "from each page, called the window. the end of the window was\n",
      "positioned 3 seconds before a self-report so as to not overlap with\n",
      "the key-press. the average amount of time between self-reports\n",
      "and the beginning of the page was 16 seconds. we used this time\n",
      "point as the end of the window for pages with no self-report.\n",
      "pages that were shorter than the target window size were\n",
      "discarded, as were pages with windows that contained fewer than\n",
      "five gaze fixations as there was insufficient data to compute some\n",
      "of the features. there were a total of 4,225 windows with\n",
      "sufficient data for supervised classification.\n",
      "we experimented with a number of supervised classifiers on\n",
      "window sizes of 4, 8, and 12 seconds to discriminate positive\n",
      "(pages with a self-report = 32%) from negative (pages without a\n",
      "self-report) instances of mind wandering. the training data were\n",
      "downsampled to achieve a 50% base rate; testing data were\n",
      "unaltered. a leave-one-participant-out validation approach was\n",
      "adopted where models were built on data from n-1 participants\n",
      "and evaluated on the held-out participant. the process was\n",
      "repeated for all participants. model validation was conducted in a\n",
      "way to simulate a real-time system by analyzing data from every\n",
      "page. when classification was not possible due to a lack of valid\n",
      "gaze data and/or because participants did not spend enough time\n",
      "\n",
      "figure 1: gaze fixations during mind wandering (top)\n",
      "and normal reading (bottom)\n",
      "\n",
      "2.3 detector accuracy\n",
      "the best model was a support vector machine that used global\n",
      "features and operated on a window size of 8-seconds. the area\n",
      "under the roc curve (auc or auroc or a’) was .66, which\n",
      "exceeds the 0.5 chance threshold [17].\n",
      "we assigned each instance as mind wandering or not mind\n",
      "wandering based on whether the detector’s predicted likelihood\n",
      "of mind wandering (ranges from 0 to 1) was below or above 0.5\n",
      "we adopted the default 0.5 threshold as it led to a higher rate of\n",
      "true positives while maintaining a moderate rate of true negatives.\n",
      "this resulted in the following confusion matrix shown in table 1.\n",
      "the model had a weighted precision of 72.2% and a weighted\n",
      "recall of 67.4%, which we deemed to be sufficiently accurate for\n",
      "intervention.\n",
      "table 1: proportionalized confusion matrix for mind\n",
      "wandering detection\n",
      "predicted mind wandering (mw)\n",
      "actual mw\n",
      "\n",
      "yes\n",
      "\n",
      "no\n",
      "\n",
      "yes\n",
      "\n",
      "0.715 (hit)\n",
      "\n",
      "0.285 (miss)\n",
      "\n",
      "no\n",
      "\n",
      "0.346 (false positive)\n",
      "\n",
      "0.654 (correct rejection)\n",
      "\n",
      "3. intervention to address mind wandering\n",
      "our intervention approach is grounded in the basic idea that\n",
      "learning of conceptual information involves creating and\n",
      "maintaining an internal model (mental model) by integrating\n",
      "information from the text with prior knowledge from memory\n",
      "[25]. this integration process relies on attentional focus and\n",
      "breaks down during mind wandering because information from\n",
      "the external environment is no longer being integrated into the\n",
      "internal mental model. this results in an impaired model which\n",
      "leads to less effective suppression of off-task thoughts. this\n",
      "increase in mind wandering further impairs the mental model,\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "10\n",
      "\n",
      "\f",
      "resulting in a vicious cycle. our intervention targets this vicious\n",
      "cycle by redirecting attention to the primary task and attempting\n",
      "to correct for comprehension deficits attributed to mind\n",
      "wandering. based on research demonstrating the effectiveness of\n",
      "interpolated testing [47], we propose that asking questions on\n",
      "pages where mind wandering is detected and encouraging rereading in response to incorrect responses will aid in re-directing\n",
      "attention to the text and correct knowledge deficits.\n",
      "\n",
      "page regardless of whether the second question was answered\n",
      "correctly, so as not to be overly burdensome.\n",
      "\n",
      "3.1 intervention implementation\n",
      "our initial intervention was implemented for the same text used\n",
      "to create the mind wandering detector (although it could be\n",
      "applied to any text). the text was integrated into the computer\n",
      "reading interface. mind wandering detection occurred when the\n",
      "learner navigated to the next page using the right arrow key. in\n",
      "order to address ambiguity in mind wandering detection, we used\n",
      "the detector’s mind wandering likelihood to probabilistically\n",
      "determine when to intervene. for example, if the mind wandering\n",
      "likelihood was 70%, then there was a 70% chance of intervention\n",
      "on any given page (all else being equal). we did not intervene for\n",
      "the first three pages in order to allow the learner to become\n",
      "familiar with the text and interface. to reduce disruption, there\n",
      "was a 50% reduced probability of intervening on adjacent pages,\n",
      "and the maximum number of interventions was capped at 1/3 ×\n",
      "the number of pages (19 for the present 57-page text). table 2\n",
      "presents pseudo code for when to launch an intervention.\n",
      "table 2: pseudo code for intervention strategy\n",
      "launch_intervention:\n",
      "if current_page >= waitpages\n",
      "and\n",
      "total_interventions < maxintrv)\n",
      "and\n",
      "gaze_likelihood > random(0,1)\n",
      "and\n",
      "(!has_intervened(previous_page)\n",
      "or 0.5 < random (0,1)):\n",
      "do_intervention()\n",
      "else:\n",
      "show_next_page()\n",
      "do_intervention:\n",
      "answer1 = show_question1()\n",
      "if answer1 is correct:\n",
      "show_positive_feedback()\n",
      "show_next_page()\n",
      "else:\n",
      "show_neg_feedback()\n",
      "suggest_rereading()\n",
      "if page advance detected:\n",
      "answer2 = show_question2();\n",
      "show_next_page()\n",
      "\n",
      "figure 2 presents an outline of the intervention strategy. the\n",
      "intervention itself relied on two multiple choice questions for\n",
      "each page (screen) of the text. when the system decided to\n",
      "intervene, one of the questions (randomly selected) was presented\n",
      "to the learner. if the learner answered this online question\n",
      "correctly, positive feedback was provided, and the learner could\n",
      "advance to the next page. if the learner answered incorrectly,\n",
      "negative feedback was provided, and the system encouraged the\n",
      "learner to re-read the page. the learner was then provided with a\n",
      "second (randomly selected) online question, which could either\n",
      "be the same or the alternate question for that page. feedback was\n",
      "not provided and the learner was allowed to advance to the next\n",
      "\n",
      "figure 2: outline of intervention strategy\n",
      "\n",
      "3.2 iterative refinement\n",
      "the technology was refined through multiple rounds of formative\n",
      "testing with 67 participants, recruited from the same institution\n",
      "used to build the detector. participants were observed while\n",
      "interacting with the technology, their responses were analyzed,\n",
      "and they were interviewed about their experience. we used the\n",
      "feedback gleaned from these tests to refine the intervention\n",
      "parameters (i.e., when to launch, how many interventions to\n",
      "launch, whether to launch interventions on subsequent pages),\n",
      "intervention questions themselves, and instructions on how to\n",
      "attend to the intervention. for example, earlier versions of the\n",
      "intervention used a fixed threshold (instead of the aforementioned\n",
      "probabilistic approach) to trigger an intervention. despite many\n",
      "attempts to set this threshold, the end result was that some\n",
      "participants received many interventions while others received\n",
      "almost no interventions. this issue was corrected by\n",
      "probabilistically rather than deterministically launching the\n",
      "intervention. additional testing/refinement of the comprehension\n",
      "questions used in the intervention was done using crowdsourcing\n",
      "platforms, specifically amazon’s mechanical turk (mturk).\n",
      "\n",
      "4. evaluation study\n",
      "we conducted a randomized controlled trial to evaluate the\n",
      "technology. the experiment had two conditions: an intervention\n",
      "condition and a yoked control condition (as described below). the\n",
      "yoked control was needed to verify that any learning benefits are\n",
      "attributed to the technology being sensitive to mind wandering\n",
      "and not merely to the added opportunities to answer online\n",
      "questions and re-read. this is because we know that interpolated\n",
      "testing itself has beneficial comprehension effects [47].\n",
      "\n",
      "4.1 method\n",
      "participants (n = 104) were a new set of undergraduate students\n",
      "who participated to fulfill research credit requirements. they\n",
      "were recruited from the same university used to build the mw\n",
      "detector and for the iterative testing and refinement cycles.\n",
      "we did not use a pretest because we expected participants to be\n",
      "unfamiliar with the topic. participants were not informed that the\n",
      "interface would be tracking their mind wandering (until the\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "11\n",
      "\n",
      "\f",
      "debriefing at the end), instead, they were instructed as follows:\n",
      "“while reading the text, you will occasionally be asked some\n",
      "questions about the page you just read. depending on your\n",
      "answer, you will re-read the same page and you will be asked\n",
      "another question that may or may not be the same question.”\n",
      "participants in the intervention condition received the\n",
      "intervention as described above (i.e., based on detected mind\n",
      "wandering likelihoods). each participant in the yoked control\n",
      "condition was paired with a participant in the intervention\n",
      "condition. he or she received an intervention question on the\n",
      "same pages as their paired intervention participant regardless of\n",
      "mind wandering likelihood. for example, if participant a (i.e.,\n",
      "intervention condition) received questions on pages 5, 7, 10, and\n",
      "25, participant b (i.e., yoked control condition) would receive\n",
      "intervention questions on the same pages. however, if the yoked\n",
      "participant answered incorrectly, then (s)he had the opportunity\n",
      "to re-read and answer another question regardless of the outcome\n",
      "of their intervention-condition partner.\n",
      "after reading, participants completed a 38-item multiple choice\n",
      "comprehension assessment to measure learning. the questions\n",
      "were randomly selected from the 57 pages (one per page) with the\n",
      "exception that a higher selection priority was given to pages that\n",
      "were re-read on account of the intervention. participants in the\n",
      "yoked control condition received the same posttest questions as\n",
      "their intervention condition counterparts.\n",
      "\n",
      "4.2 results\n",
      "participants received an average of 16 (min of 7 and max of 19)\n",
      "interventions. they spent an average of 27.5 seconds on each\n",
      "screen prior to receiving an intervention. there was no significant\n",
      "difference across conditions (p = .998), suggesting that reading\n",
      "time was not a confound. in what follows, we compared each\n",
      "intervention participant to his/her yoked control with a two-tailed\n",
      "paired-samples t-test and a 0.05 criteria for statistical\n",
      "significance.\n",
      "mind wandering detection. the detector’s likelihood of mind\n",
      "wandering was slightly higher for participants in the yokedcontrol condition (m = .431; sd = .170) compared to the\n",
      "intervention condition (m = .404; sd = .112), but the difference\n",
      "was not statistically significant (p = .348). this was unsurprising\n",
      "as participants in both groups received the same interventions,\n",
      "which itself was expected to reduce mind wandering. importantly,\n",
      "mind wandering likelihoods were negatively correlated with\n",
      "performance on the online questions (r = -.296, p = .033) as well\n",
      "as on posttest questions (r = -.319, p = .021). this provides\n",
      "evidence for the validity of the mind wandering detector when\n",
      "applied to a new set of learners and under different conditions\n",
      "(i.e., reading interspersed with online questions compared to\n",
      "uninterrupted reading).\n",
      "comprehension assessment. there was some overlap between\n",
      "the online questions and the posttest questions. to obtain an\n",
      "unbiased estimate of learning, we only analyzed performance on\n",
      "previously unseen posttest questions. that is, questions that were\n",
      "used as part of the intervention were first removed before\n",
      "computing posttest scores.\n",
      "there were no significant condition differences on overall\n",
      "posttest scores (p = .846). the intervention condition answered\n",
      "57.6% (sd = .157) of the questions correctly while the yoked\n",
      "control condition answered 58.1% (sd = .129) correctly. this\n",
      "finding was not surprising as both conditions received the exact\n",
      "same treatment except that the interventions were triggered based\n",
      "\n",
      "on detected mind wandering in the intervention condition but not\n",
      "the control condition.\n",
      "next, we examined posttest performance as a function of mind\n",
      "wandering during reading. each page was designated as a low or\n",
      "high mind wandering page based on a median split of mind\n",
      "wandering likelihoods (medians = .35 and .36 on a 0 to 1 scale for\n",
      "intervention and control conditions, respectively). we then\n",
      "analyzed performance on posttest questions corresponding to\n",
      "pages with low vs. high likelihoods of mind wandering (during\n",
      "reading). the results are shown in table 3.\n",
      "we found no significant posttest differences on pages where both\n",
      "the intervention and control participants had low (p = .759) or\n",
      "high (p = .922) mind wandering likelihoods (first and last rows in\n",
      "table 3, respectively). there was also no significant posttest\n",
      "difference (p = .630) for pages where the intervention condition\n",
      "had high mind wandering likelihoods but the control condition\n",
      "had low mind wandering likelihoods (row 3). however, the\n",
      "intervention condition significantly (p = .003, d = .47 sigma)\n",
      "outperformed the control condition for pages where the\n",
      "intervention participants had low likelihoods of mind wandering\n",
      "but control participants had high mind wandering likelihoods\n",
      "(row 2). these last two finding suggests that the intervention had\n",
      "the intended effect of reducing comprehension deficits\n",
      "attributable to mind wandering because it led to equitable\n",
      "performance when mind wandering was high and improved\n",
      "performance when it was low.\n",
      "table 3: posttest performance (proportion of correct\n",
      "responses) as a function of mind wandering during reading.\n",
      "standard deviations in parenthesis.\n",
      "mind\n",
      "wandering\n",
      "\n",
      "posttest\n",
      "\n",
      "n\n",
      "\n",
      "int.\n",
      "\n",
      "cntrl.\n",
      "\n",
      "int.\n",
      "\n",
      "cntrl.\n",
      "\n",
      "43\n",
      "\n",
      "low\n",
      "\n",
      "low\n",
      "\n",
      ".604 (.288)\n",
      "\n",
      ".623 (.287)\n",
      "\n",
      "40\n",
      "\n",
      "low\n",
      "\n",
      "high\n",
      "\n",
      ".643 (.263)\n",
      "\n",
      ".489 (.298)\n",
      "\n",
      "43\n",
      "\n",
      "high\n",
      "\n",
      "low\n",
      "\n",
      ".535 (.295)\n",
      "\n",
      ".566 (.305)\n",
      "\n",
      "45\n",
      "\n",
      "high\n",
      "\n",
      "high\n",
      "\n",
      ".522 (.312)\n",
      "\n",
      ".515 (.291)\n",
      "\n",
      "scores\n",
      "\n",
      "note. int. = intervention. cntrl. = control. bolded cells represent a\n",
      "statistically significant difference. n = number of pairs (out of 52) in each\n",
      "analysis. it differs slightly across analyses as not all participants were\n",
      "assigned to each mind wandering group.\n",
      "\n",
      "after-task interview. we interviewed a subset of the participants\n",
      "in order to gauge their subjective experience with the\n",
      "intervention. a few key themes emerged. participants reported\n",
      "paying closer attention to the text after realizing they would be\n",
      "periodically answering multiple-choice questions. this was good.\n",
      "however, participants also reported that they adapted their\n",
      "reading strategies in one of two ways in response to the questions.\n",
      "since the questions targeted factual information (sometimes\n",
      "verbatim) from the text, some participants paid more attention to\n",
      "details and precise wordings instead of the broader concepts being\n",
      "discussed in the text. more discouragingly, some participants\n",
      "reported adopting a preemptive skimming strategy in that they\n",
      "would only look for keywords that they expected to appear in a\n",
      "subsequent question.\n",
      "participants were encouraged to re-read text when they answered\n",
      "incorrectly before receiving another question (or the same\n",
      "question in some cases). many participants reported simply\n",
      "scanning the text (when re-reading) to locate keywords from the\n",
      "question before moving on. since the scanning strategy was often\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "12\n",
      "\n",
      "\f",
      "successful to answer the subsequent question, participants\n",
      "reported that the questions were too easy and it took relatively\n",
      "little effort to locate the correct answer compared to re-reading.\n",
      "they suggested that it may have been better if the questions had\n",
      "targeted key concepts rather than facts.\n",
      "finally, participants reported difficulties with re-engaging with\n",
      "the text after answering an online question because the text was\n",
      "cleared when an intervention question was displayed; an item that\n",
      "can be easily corrected in subsequent versions.\n",
      "\n",
      "5. discussion\n",
      "we developed the first educational technology capable of realtime mind wandering detection and dynamic intervention during\n",
      "computerized reading. in the remainder of this section, we discuss\n",
      "the significance of our main findings, limitations, and avenues for\n",
      "future work.\n",
      "\n",
      "5.1 significance of main findings\n",
      "we have three main findings. first, we demonstrated that a\n",
      "machine-learned mind wandering detector built in one context\n",
      "can be applied to a different (albeit related) interaction context.\n",
      "specifically, the detector was trained on a data set involving\n",
      "participants silently reading and self-reporting mind wandering,\n",
      "but was applied to an interactive context involving interpolated\n",
      "assessments, which engendered different reading strategies.\n",
      "further, self-reports of mind wandering were not collected in this\n",
      "interactive context, which might have influenced mind wandering\n",
      "rates in and of itself. despite these differences, we were able to\n",
      "demonstrate the predictive validity of the detector by showing\n",
      "that it negatively correlated with both online and offline\n",
      "comprehension scores when evaluated on new participants.\n",
      "second, we showed promising effects for our intervention\n",
      "approach despite a very conservative experimental design, which\n",
      "ensured that the intervention and control groups were equated\n",
      "along all respects, except that the intervention was triggered based\n",
      "on the mind wandering detector (key manipulation). further, we\n",
      "used a probabilistic approach to trigger an intervention, because\n",
      "the detector is inherently imperfect. as a result, participants could\n",
      "have received an intervention when they were not mind\n",
      "wandering and/or could have failed to receive one when they were\n",
      "mind wandering. therefore, it was essential to compare the two\n",
      "groups under conditions when the mind wandering levels\n",
      "differed. this more nuanced analysis revealed that although the\n",
      "intervention itself did not lead to a boost in overall comprehension\n",
      "(because it is remedial), it equated comprehension scores when\n",
      "mind wandering was high (i.e., scores for the intervention group\n",
      "were comparable when the control group was low on mind\n",
      "wandering). it also demonstrated the cost of not intervening\n",
      "during mind wandering (i.e., scores for the intervention group\n",
      "were greater when the control group was high on mind\n",
      "wandering). in other words, the intervention was successful in\n",
      "mitigating the negative effects of mind wandering.\n",
      "third, despite the advantages articulated above, the intervention\n",
      "itself was reactive and engendered several unintended (and\n",
      "presumably suboptimal) behaviors. in particular, students altered\n",
      "their reading strategies in response to the interpolated questions,\n",
      "which were a critical part of the intervention. in a sense, they\n",
      "attempted to “game the intervention” by attempting to proactively\n",
      "predict the types of questions they might receive and then\n",
      "adopting a complementary reading strategy consisting of\n",
      "skimming and/or focusing on factual information. this reliance\n",
      "on surface- rather than deeper-levels of processing was\n",
      "incongruent with our goal of promoting deep comprehension.\n",
      "\n",
      "5.2 limitations\n",
      "there are a number of methodological limitations with this work\n",
      "that go beyond limitations with the intervention (as discussed\n",
      "above). first, we focused on a single text that is perceived as\n",
      "being quite dull and consequently triggers rather high levels of\n",
      "mind wandering [26]. this raises the question of whether the\n",
      "detector will generalize to different texts. we expect some level\n",
      "of generalizability in terms of features used because the detector\n",
      "only used content- and position- (on the screen) free global gaze\n",
      "features. however, given that several supervised classifiers are\n",
      "very sensitive to differences in base rates, the detector might overor under- predict mind wandering when applied to texts that\n",
      "engender different rates of mind wandering. therefore, retraining\n",
      "the detector with a more diverse set of texts is warranted.\n",
      "another limitation is the scalability of our learning technology.\n",
      "the eye tracker we used was a cost-prohibitive tobii tx300 that\n",
      "will not scale beyond the laboratory. fortunately, commercialoff-the-shelf (cots) eye trackers, such as eye tribe and tobii\n",
      "eyex, can be used to surpass this limitation. it is an open question\n",
      "as to whether the mind wandering detector can operate with\n",
      "similar fidelity with these cots eye trackers. our use of global\n",
      "gaze features which do not require high-precision eye tracking\n",
      "holds considerable promise in this regard. nevertheless,\n",
      "replication with scalable eye trackers and/or scalable alternatives\n",
      "to eye tracking (e.g., facial-feature tracking [46] or monitoring\n",
      "reading patterns [27]) is an important next step (see section 5.3).\n",
      "our use of surface-level questions for both the intervention and\n",
      "the subsequent comprehension assessment is also a limitation as\n",
      "is the lack of a delayed comprehension assessment. it might be\n",
      "the case that the intervention effects manifest as richer encodings\n",
      "in long-term memory, a possibility that cannot be addressed in the\n",
      "current experiment that only assessed immediate learning.\n",
      "other limitations include a limited student sample (i.e.\n",
      "undergraduates from a private midwestern college) and a\n",
      "laboratory setup. it is possible that the results would not\n",
      "generalize to a more diverse student population or in more\n",
      "ecological environments (but see below for evidence of\n",
      "generalizability of the detector in classroom environments).\n",
      "replication with data from more diverse populations and\n",
      "environments would be a necessary next step to increase the\n",
      "ecological validity of this work.\n",
      "\n",
      "5.3 future work\n",
      "our future work is progressing along two main fronts. one is to\n",
      "address limitations in the intervention and design of the\n",
      "experimental evaluation as discussed above. accordingly, we are\n",
      "exploring alternative intervention strategies, such as: (a) tagging\n",
      "items for future re-study rather than interrupting participants\n",
      "during reading; (b) highlighting specific portions of the text as an\n",
      "overt cue to facilitate comprehension of critical information; (c)\n",
      "asking fewer intervention questions, but selecting inference\n",
      "questions that target deeper levels of comprehension and that span\n",
      "multiple pages of the text; and (d) asking learners to engage in\n",
      "reflection by providing written self-explanations of the textual\n",
      "content. we are currently evaluating one such redesigned\n",
      "intervention – open-ended questions targeting deeper levels of\n",
      "comprehension (item c). our revised experimental design taps\n",
      "both surface- and inference-level comprehension and assesses\n",
      "comprehension immediately after reading (to measure learning)\n",
      "and after a one-week delay (to measure retention).\n",
      "we are also developing attention-aware versions of more\n",
      "interactive interfaces, such as learning with an intelligent tutoring\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "13\n",
      "\n",
      "\f",
      "system called gurututor [30]. this project also addresses some\n",
      "of the scalability concerns by replacing expensive research-grade\n",
      "eye tracking with cost-effective cots eye tracking (e.g., the eye\n",
      "tribe or tobii eyex) and provides evidence for real-world\n",
      "generalizability by collecting data in classrooms rather than the\n",
      "lab. we recently tested our implementation on 135 students (total)\n",
      "in a noisy computer-enabled high-school classroom where eyegaze of entire classes of students was collected during their\n",
      "normal class periods [20]. using a similar approach to the present\n",
      "work, we used the data to build and validate a studentindependent gaze-based mind wandering detector. the resultant\n",
      "mind wandering detection accuracy (f1 of 0.59) was substantially\n",
      "greater than chance (f1 of 0.24) and outperformed earlier work on\n",
      "the same domain [21]. the next step is to develop interventions\n",
      "that redirect attention and correct learning deficiencies\n",
      "attributable to mind wandering and to test the interventions in\n",
      "real-world environments. by doing so, we hope to advance our\n",
      "foundational vision of developing next-generation technologies\n",
      "that enhance the process and products of learning by “attending\n",
      "to attention.”\n",
      "\n",
      "[6]\n",
      "\n",
      "[7]\n",
      "\n",
      "[8]\n",
      "\n",
      "[9]\n",
      "\n",
      "[10]\n",
      "\n",
      "[11]\n",
      "\n",
      "[12]\n",
      "figure 3: guru tutor interface overlaid with eye-gaze\n",
      "obtained via the eyetribe\n",
      "\n",
      "[13]\n",
      "\n",
      "6. acknowledgements\n",
      "this research was supported by the national science foundation\n",
      "(nsf) (drl 1235958 and iis 1523091). the authors are grateful\n",
      "to kris kopp and jenny wu for their contributions to the study.\n",
      "any opinions, findings and conclusions, or recommendations\n",
      "expressed in this paper are those of the authors and do not\n",
      "necessarily reflect the views of nsf.\n",
      "\n",
      "[14]\n",
      "\n",
      "[15]\n",
      "\n",
      "7. references\n",
      "[1] anderson, j.r. 2002. spanning seven orders of magnitude:\n",
      "a challenge for cognitive modeling. cognitive science, 26\n",
      "(1), 85-112.\n",
      "[2] baird, b., smallwood, j., mrazek, m.d., kam, j.w.,\n",
      "franklin, m.s. and schooler, j.w. 2012. inspired by\n",
      "distraction mind wandering facilitates creative incubation.\n",
      "psychological science, 23 (10), 1117-1122.\n",
      "[3] bixler, r. and d'mello, s.k. 2016. automatic gaze-based\n",
      "user-independent detection of mind wandering during\n",
      "computerized reading. user modeling & user-adapted\n",
      "interaction, 26, 33-68.\n",
      "[4] boys, c.v. 1895. soap bubbles, their colours and the forces\n",
      "which mold them. society for promoting christian\n",
      "knowledge.\n",
      "[5] conati, c., aleven, v. and mitrovic, a. 2013. eye-tracking\n",
      "for student modelling in intelligent tutoring systems. in\n",
      "sottilare, r., graesser, a., hu, x. and holden, h. eds.\n",
      "design recommendations for intelligent tutoring systems -\n",
      "\n",
      "[16]\n",
      "\n",
      "[17]\n",
      "\n",
      "[18]\n",
      "\n",
      "[19]\n",
      "\n",
      "volume 1: learner modeling, army research laboratory,\n",
      "orlando, fl.\n",
      "conati, c. and merten, c. 2007. eye-tracking for user\n",
      "modeling in exploratory learning environments: an\n",
      "empirical evaluation. knowledge-based systems, 20 (6),\n",
      "557-574.\n",
      "d'mello, s., olney, a., williams, c. and hays, p. 2012.\n",
      "gaze tutor: a gaze-reactive intelligent tutoring system.\n",
      "international journal of human-computer studies, 70 (5),\n",
      "377-398.\n",
      "d'mello, s.k. 2016. giving eyesight to the blind: towards\n",
      "attention-aware aied. international journal of artificial\n",
      "intelligence in education, 26 (2), 645-659.\n",
      "d'mello, s.k., blanchard, n., baker, r., ocumpaugh, j. and\n",
      "brawner, k. 2014. i feel your pain: a selective review of\n",
      "affect-sensitive instructional strategies. in sottilare, r.,\n",
      "graesser, a., hu, x. and goldberg, b. eds. design\n",
      "recommendations for adaptive intelligent tutoring\n",
      "systems: adaptive instructional strategies (volume 2), us\n",
      "army research laboratory, orlando, fl.\n",
      "d'mello, s.k., kopp, k., bixler, r. and bosch, n. 2016.\n",
      "attending to attention: detecting and combating mind\n",
      "wandering during computerized reading in extended\n",
      "abstracts of the acm sigchi conference on human\n",
      "factors in computing systems (chi 2016), acm, new\n",
      "york.\n",
      "drummond, j. and litman, d. 2010. in the zone: towards\n",
      "detecting student zoning out using supervised machine\n",
      "learning. in aleven, v., kay, j. and mostow, j. eds.\n",
      "intelligent tutoring systems., springer-verlag, berlin /\n",
      "heidelberg.\n",
      "eastwood, j.d., frischen, a., fenske, m.j. and smilek, d.\n",
      "2012. the unengaged mind: defining boredom in terms of\n",
      "attention. perspectives on psychological science, 7 (5), 482495.\n",
      "faber, m., bixler, r. and d'mello, s.k. in press. an\n",
      "automated behavioral measure of mind wandering during\n",
      "computerized reading. behavior research methods.\n",
      "franklin, m.s., broadway, j.m., mrazek, m.d., smallwood,\n",
      "j. and schooler, j.w. 2013. window to the wandering mind:\n",
      "pupillometry of spontaneous thought while reading. the\n",
      "quarterly journal of experimental psychology, 66 (12),\n",
      "2289-2294.\n",
      "gluck, k.a., anderson, j.r. and douglass, s.a. 2000.\n",
      "broader bandwidth in student modeling: what if its were\n",
      "“eye” ts? in gauthier, c., frasson, c. and vanlehn, k. eds.\n",
      "proceedings of the 5th international conference on\n",
      "intelligent tutoring systems, springer, berlin.\n",
      "graesser, a., lu, s., olde, b., cooper-pye, e. and whitten,\n",
      "s. 2005. question asking and eye tracking during cognitive\n",
      "disequilibrium: comprehending illustrated texts on devices\n",
      "when the devices break down. memory and cognition, 33,\n",
      "1235-1247.\n",
      "hanley, j.a. and mcneil, b.j. 1982. the meaning and use\n",
      "of the area under a receiver operating characteristic (roc)\n",
      "curve. radiology, 143 (1), 29-36.\n",
      "harley, j.m., lajoie, s.p., frasson, c. and hall, n.c. in\n",
      "press. developing emotion-aware, advanced learning\n",
      "technologies: a taxonomy of approaches and features.\n",
      "international journal of artificial intelligence in education.\n",
      "hegarty, m. and just, m. 1993. constructing mental models\n",
      "of machines from text and diagrams. journal of memory and\n",
      "language, 32 (6), 717-742.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "14\n",
      "\n",
      "\f",
      "[20] hutt, s., mills, c., bosch, n., krasich, k., brockmole, j.r.\n",
      "and d'mello, s.k. in review. out of the fr-eye- ing pan:\n",
      "towards gaze-based models of attention during learning\n",
      "with technology in the classroom.\n",
      "[21] hutt, s., mills, c., white, s., donnelly, p.j. and d’mello,\n",
      "s.k. 2016. the eyes have it: gaze-based detection of mind\n",
      "wandering during learning with an intelligent tutoring\n",
      "system. in proceedings of the 9th international conference\n",
      "on educational data mining (edm 2016), international\n",
      "educational data mining society.\n",
      "[22] jaques, n., conati, c., harley, j.m. and azevedo, r. year.\n",
      "predicting affect from gaze data during interaction with an\n",
      "intelligent tutoring system. in intelligent tutoring systems,\n",
      "(2014), springer, 29-38.\n",
      "[23] kardan, s. and conati, c. 2012. exploring gaze data for\n",
      "determining user learning with an interactive simulation. in\n",
      "carberry, s., weibelzahl, s., micarelli, a. and semeraro, g.\n",
      "eds. proceedings of the 20th international conference on\n",
      "user modeling, adaptation, and personalization (umap\n",
      "2012), springer, berlin.\n",
      "[24] killingsworth, m.a. and gilbert, d.t. 2010. a wandering\n",
      "mind is an unhappy mind. science, 330 (6006), 932-932.\n",
      "[25] kintsch, w. 1998. comprehension: a paradigm for\n",
      "cognition. cambridge university press, new york.\n",
      "[26] kopp, k., d’mello, s. and mills, c. 2015. influencing the\n",
      "occurrence of mind wandering while reading. consciousness\n",
      "and cognition, 34 (1), 52-62.\n",
      "[27] mills, c. and d’mello, s.k. 2015. toward a real-time (day)\n",
      "dreamcatcher: detecting mind wandering episodes during\n",
      "online reading. in romero, c., pechenizkiy, m., boticario,\n",
      "j. and santos, o. eds. proceedings of the 8th international\n",
      "conference on educational data mining (edm 2015),\n",
      "international educational data mining society.\n",
      "[28] mooneyham, b.w. and schooler, j.w. 2013. the costs and\n",
      "benefits of mind-wandering: a review. canadian journal of\n",
      "experimental psychology/revue canadienne de psychologie\n",
      "expérimentale, 67 (1), 11.\n",
      "[29] muir, m. and conati, c. 2012. an analysis of attention to\n",
      "student–adaptive hints in an educational game. in cerri,\n",
      "s.a., clancey, w.j., papadourakis, g. and panourgia, k.\n",
      "eds. proceedings of the international conference on\n",
      "intelligent tutoring systems, springer, berlin.\n",
      "[30] olney, a., d'mello, a., person, n., cade, w., hays, p.,\n",
      "williams, c., lehman, b. and graesser, a. 2012. guru: a\n",
      "computer tutor that models expert human tutors. in cerri, s.,\n",
      "clancey, w., papadourakis, g. and panourgia, k. eds.\n",
      "proceedings of the 11th international conference on\n",
      "intelligent\n",
      "tutoring\n",
      "systems,\n",
      "springer-verlag,\n",
      "berlin/heidelberg.\n",
      "[31] olney, a., risko, e.f., d'mello, s.k. and graesser, a.c.\n",
      "2015. attention in educational contexts: the role of the\n",
      "learning task in guiding attention. in fawcett, j., risko, e.f.\n",
      "and kingstone, a. eds. the handbook of attention, mit\n",
      "press, cambridge, ma.\n",
      "[32] pham, p. and wang, j. 2016. adaptive review for mobile\n",
      "mooc learning via implicit physiological signal sensing.\n",
      "in proceedings of the 18th acm international conference\n",
      "on multimodal interaction (icmi 2016), acm, new york,\n",
      "ny.\n",
      "[33] pham, p. and wang, j. 2015. attentivelearner: improving\n",
      "mobile mooc learning via implicit heart rate tracking. in\n",
      "international conference on artificial intelligence in\n",
      "education, springer, berlin heidelberg.\n",
      "\n",
      "[34] randall, j.g., oswald, f.l. and beier, m.e. 2014. mindwandering, cognition, and performance: a theory-driven\n",
      "meta-analysis of attention regulation. psychological\n",
      "bulletin, 140 (6), 1411-1431.\n",
      "[35] rapp, d.n. 2006. the value of attention aware systems in\n",
      "educational settings. computers in human behavior, 22 (4),\n",
      "603-614.\n",
      "[36] rayner, k. 1998. eye movements in reading and information\n",
      "processing: 20 years of research. psychological bulletin, 124\n",
      "(3), 372-422.\n",
      "[37] reichle, e.d., reineberg, a.e. and schooler, j.w. 2010. eye\n",
      "movements during mindless reading. psychological science,\n",
      "21 (9), 1300.\n",
      "[38] risko, e.f., buchanan, d., medimorec, s. and kingstone, a.\n",
      "2013. everyday attention: mind wandering and computer\n",
      "use during lectures. computers & education, 68 (1), 275283.\n",
      "[39] roda, c. and thomas, j. 2006. attention aware systems:\n",
      "theories, applications, and research agenda. computers in\n",
      "human behavior, 22 (4), 557-587.\n",
      "[40] rowe, j., mott, b., mcquiggan, s., robison, j., lee, s. and\n",
      "lester, j. year. crystal island: a narrative-centered learning\n",
      "environment for eighth grade microbiology. in workshop on\n",
      "intelligent educational games at the 14th international\n",
      "conference on artificial intelligence in education,\n",
      "brighton, uk, (2009), 11-20.\n",
      "[41] shute, v.j., ventura, m., bauer, m. and zapata-rivera, d.\n",
      "2009. melding the power of serious games and embedded\n",
      "assessment to monitor and foster learning: flow and grow.\n",
      "in ritterfeld, u., cody, m. and vorderer, p. eds. serious\n",
      "games: mechanisms and effects, routledge, taylor and\n",
      "francis, mahwah, nj.\n",
      "[42] sibert, j.l., gokturk, m. and lavine, r.a. 2000. the reading\n",
      "assistant: eye gaze triggered auditory prompting for reading\n",
      "remediation. in proceedings of the 13th annual acm\n",
      "symposium on user interface software and technology,\n",
      "acm, new york, ny.\n",
      "[43] smallwood, j., davies, j.b., heim, d., finnigan, f.,\n",
      "sudberry, m., o'connor, r. and obonsawin, m. 2004.\n",
      "subjective experience and the attentional lapse: task\n",
      "engagement and disengagement during sustained attention.\n",
      "consciousness and cognition, 13 (4), 657-690.\n",
      "[44] smallwood, j., fishman, d.j. and schooler, j.w. 2007.\n",
      "counting the cost of an absent mind: mind wandering as an\n",
      "underrecognized influence on educational performance.\n",
      "psychonomic bulletin & review, 14 (2), 230-236.\n",
      "[45] smallwood, j. and schooler, j.w. 2015. the science of mind\n",
      "wandering: empirically navigating the stream of\n",
      "consciousness. annu. rev. psychol, 66, 487-518.\n",
      "[46] stewart, a., bosch, p., chen, h., donnelly, p.j. and\n",
      "d’mello, s.k. 2016. where's your mind at? video-based\n",
      "mind wandering detection during film viewing. in aroyo,\n",
      "l., d'mello, s., vassileva, j. and blustein, j. eds.\n",
      "proceedings of the 2016 acm on international conference\n",
      "on user modeling, adaptation, & personalization (acm\n",
      "umap 2016), acm, new york.\n",
      "[47] szpunar, k.k., khan, n.y. and schacter, d.l. 2013.\n",
      "interpolated memory tests reduce mind wandering and\n",
      "improve learning of online lectures. proceedings of the\n",
      "national academy of sciences, 110 (16), 6313-6317.\n",
      "[48] wang, h., chignell, m. and ishizuka, m. 2006. empathic\n",
      "tutoring software agents using real-time eye tracking. in\n",
      "proceedings of the 2006 symposium on eye tracking\n",
      "research &applications, acm, new york.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "15\n",
      "\n",
      "\f",
      "measuring similarity of educational items using data on\n",
      "learners’ performance\n",
      "jiří řihák\n",
      "\n",
      "faculty of informatics\n",
      "masaryk university\n",
      "brno, czech republic\n",
      "\n",
      "thran@mail.muni.cz\n",
      "abstract\n",
      "educational systems typically contain a large pool of items\n",
      "(questions, problems). using data mining techniques we can\n",
      "group these items into knowledge components, detect duplicated items and outliers, and identify missing items. to\n",
      "these ends, it is useful to analyze item similarities, which can\n",
      "be used as input to clustering or visualization techniques.\n",
      "we describe and evaluate different measures of item similarity that are based only on learners’ performance data, which\n",
      "makes them widely applicable. we provide evaluation using\n",
      "both simulated data and real data from several educational\n",
      "systems. the results show that pearson correlation is a suitable similarity measure and that response times are useful\n",
      "for improving stability of similarity measures when the scope\n",
      "of available data is small.\n",
      "\n",
      "1. introduction\n",
      "interactive educational systems offer learners items (problems, questions) for solving. realistic educational systems\n",
      "typically contain a large number of such items. this is particularly true for adaptive systems, which try to present suitable items for different kinds of learners. the management\n",
      "of a large pool of items is difficult. however, educational\n",
      "systems collect data about learners’ performance and the\n",
      "data can be used to get insight into item properties. in this\n",
      "work we focus on methods for computing item similarities\n",
      "based on learners’ performance data, which consists of binary information about the answers (correct/incorrect).\n",
      "automatically detected item similarities are the first and\n",
      "necessary step in further analysis such as clustering of the\n",
      "items, which is useful in several ways, with one particular\n",
      "application being learner modeling [9]. learner models estimate knowledge and skills of learners and are the basis\n",
      "of adaptive behavior of educational systems. a learner’s\n",
      "models requires a mapping of items into knowledge components [17]. item clusters can serve as a basis for knowledge\n",
      "component definition or refinement. the specified knowledge components are relevant not only for modeling, but\n",
      "\n",
      "radek pelánek\n",
      "\n",
      "faculty of informatics\n",
      "masaryk university\n",
      "brno, czech republic\n",
      "\n",
      "pelanek@mail.muni.cz\n",
      "they are typically directly visible to\n",
      "terface of a system, e.g., in a form\n",
      "visualizing the estimated knowledge\n",
      "ized overview of mistakes, which is\n",
      "components.\n",
      "\n",
      "learners in the user inof open learner model\n",
      "state, or in a personalgrouped by knowledge\n",
      "\n",
      "information about items is also very useful for management\n",
      "of the content of educational systems – preparation of new\n",
      "items, filtering of unsuitable items, preparation of explanations, and hint messages. information about item similarities and clusters can be also relevant for teachers as it can\n",
      "provide them an inspiration for “live” discussions in class.\n",
      "this type of applications is in line with baker’s argument [1]\n",
      "for focusing on the use of learning analytics for “leveraging\n",
      "human intelligence” instead of its use for automatic intelligent methods.\n",
      "item similarities and clusters are studied not only in educational data mining but also in a closely related area of\n",
      "recommender systems. the setting of recommender systems\n",
      "is in many aspects very similar to educational systems – in\n",
      "both cases we have users and items, just instead of “performance” (the correctness of answers, the speed of answers)\n",
      "recommender systems consider “ratings” (how much a user\n",
      "likes an item). item similarities and clustering techniques\n",
      "have thus been also considered in the recommender systems\n",
      "research (we mention specific techniques below). there is a\n",
      "slight, but important difference between the two areas. in\n",
      "recommender systems item similarities and clusterings are\n",
      "typically only auxiliary techniques hidden within a “recommendation black box”. in educational system, it is useful to\n",
      "make these results explicitly available to system developers,\n",
      "curriculum production teams, or teachers.\n",
      "there are two basic approaches to dealing with item similarities and knowledge components: a “model based approach”\n",
      "and an “item similarity approach”. the basic idea of the\n",
      "model based approach is to construct a simplified model that\n",
      "explains the observed data. based on a matrix of learners’\n",
      "answers to items we construct a model that predicts these\n",
      "answers. typically, the model assigns several latent skills to\n",
      "learners and uses a mapping of items to corresponding latent\n",
      "factors. this kind of models can often be naturally expressed\n",
      "using matrix multiplication, i.e., fitting a model leads to matrix factorization. once we fit the model to data, items that\n",
      "have the same value of a latent factor can be denoted as\n",
      "“similar”. this approach leads naturally to multiple knowledge components per skill. the model is typically computed\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "16\n",
      "\n",
      "\f",
      "using some optimization technique that leads only to local\n",
      "optima (e.g., gradient descent). it is thus necessary to address the role of initialization, and parameter setting of the\n",
      "search procedure. in recommender systems this approach is\n",
      "used for implementation of collaborative filtering; it is often\n",
      "called “singular value decomposition” (svd) [18]. in educational context many variants of this approach have been\n",
      "proposed under different names and terminology, e.g., qmatrix [3], non-negative matrix factorization techniques [8],\n",
      "sparse factor analysis [19], or matrix refinement [10].\n",
      "\n",
      "syntactic\n",
      "similarity\n",
      "of items\n",
      "\n",
      "learner\n",
      "data\n",
      "\n",
      "expert\n",
      "input\n",
      "\n",
      "item similarity\n",
      "matrix\n",
      "visualization\n",
      "\n",
      "clusters\n",
      "\n",
      "with the item similarity approach we do not construct an\n",
      "explicit model of learners’ behavior, but we compute directly\n",
      "a similarity measure for each pairs of items. these similarities are then used to compute clusters of items, to project\n",
      "items into a plane, or for other analysis (e.g., for each item\n",
      "listing the 3 most similar items). this approach naturally\n",
      "leads to a mapping with a single knowledge component per\n",
      "item (i.e., different kind of output from most model based\n",
      "methods). one advantage of this approach is easier interpretability. in recommender system research this approach\n",
      "is called neighborhood-based methods [11] or item-item collaborative filtering [7]. similarity has been used for clustering of items [23, 24] and also for clustering of users [29].\n",
      "in educational setting item similarity has been analyzed using correlation of learners’ answers [22] and problem solving\n",
      "times [21], and also using learners’ wrong answers [25].\n",
      "\n",
      "figure 1: high-level illustration of the general approach to item analysis based on item similarities.\n",
      "\n",
      "so far we have discussed methods that are based only on\n",
      "data about learners’ answers. often we have some additional\n",
      "information about items and their similarities, e.g., a manual labeling or data based on syntactic similarity of items\n",
      "(text of questions). for both model based and item similarity approaches previous research has studied techniques for\n",
      "combination of these different types of inputs [10, 21].\n",
      "\n",
      "in this work we focus on computing item similarities using\n",
      "learners’ performance data. as figure 1 shows, the similarity computation can also utilize information from domain\n",
      "experts or automatically determined information based on\n",
      "the inner structure of items (e.g., text of questions or some\n",
      "available meta-data).\n",
      "\n",
      "in this work we focus on the item similarity approach, because in the educational setting this approach is less explored than the model based approach. we discuss specific\n",
      "techniques, clarify details of their usage, and provide evaluation using both data from real learners and simulated data.\n",
      "simulated data are useful for evaluation of the considered\n",
      "unsupervised machine learning tasks, because in the case of\n",
      "real-world data we do not know the “ground truth”.\n",
      "the specific contributions of this work are the following. we\n",
      "provide guidelines for the choice of item similarity measures\n",
      "– we discuss different options and provide results identifying\n",
      "suitable measures (pearson, yule, cohen); we also demonstrate the usefulness of “two step similarity measures”. we\n",
      "explore benefits of the use of response time information as\n",
      "supplement to usual information of correctness of answer.\n",
      "we use and discuss several evaluation methods for the considered tasks. we specifically consider the issue of “how\n",
      "much data do we need”. this is often practically more important than the exact choice of a used technique, but the\n",
      "issue is rather neglected in previous work.\n",
      "\n",
      "2.\n",
      "\n",
      "measures of item similarity\n",
      "\n",
      "figure 1 provides a high-level illustration of the item similarity approach. this approach consist of two steps that\n",
      "are to a large degree independent. at first, we compute an\n",
      "item similarity matrix, i.e., for each pair of items i, j we\n",
      "\n",
      "compute similarity sij of these items. at second, we can\n",
      "construct clusters or visualizations of items using only the\n",
      "item similarity matrix.\n",
      "experience with clustering algorithms suggests that the appropriate choice of similarity measure is more important\n",
      "than choice of clustering algorithm [13]. the choice of similarity measure is domain specific and it is typically not explored in general research on clustering. therefore, we focus\n",
      "on the first step – the choice of similarity measure – and explore it for the case of educational data.\n",
      "\n",
      "2.1 basic setting\n",
      "\n",
      "we discuss different possibilities for computation of item\n",
      "similarities. note that in our discussion we consistently use\n",
      "“similarity measures” (higher values correspond to higher\n",
      "similarity), some related works provide formulas for dissimilarity measures (distance of items; lower values correspond\n",
      "to higher similarity). this is just a technical issue, as we can\n",
      "easily transform similarity into dissimilarity by subtraction.\n",
      "the input to item similarity computation are data about\n",
      "learner performance, i.e., a matrix l × i, where l is the\n",
      "number of learners and i is the number of items. the matrix values specify learners’ performance. the matrix is typically very sparse (many missing values). the output of the\n",
      "computation is an item similarity matrix, which specifies\n",
      "similarity for each pair of items.\n",
      "note that in our discussion we mostly ignore the issue of\n",
      "learning (change of learners skill as they progress through\n",
      "items). when learning is relatively slow and items are presented in a randomized order, learning is just a reasonably\n",
      "small source of noise and does not have a fundamental impact on the computation of item similarities. in cases where\n",
      "learning is fast or items are presented in a fixed order, it\n",
      "may be necessary to take learning explicitly into account.\n",
      "\n",
      "2.2 correctness of answers\n",
      "the basic type of information available in educational systems is the correctness of learners’ answers. so we start with\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "17\n",
      "\n",
      "\f",
      "similarity measures that utilize only this type of information, i.e., dichotomous data (correct/incorrect) on learners’\n",
      "answers on items. the advantage of these measures is that\n",
      "they are applicable in wide variety of settings.\n",
      "with dichotomous data we can summarize learners’ performance on items i and j using an agreement matrix with\n",
      "just four values (table 1). although we have just four values to quantify the similarity of items i and j, previous research has identified large number of different measures for\n",
      "dichotomous data and analyzed their relations [5, 12, 20].\n",
      "for example choi et al. [5] discuss 76 different measures, albeit many of them are only slight variations on one theme.\n",
      "similarity measures over dichotomous data are often used in\n",
      "biology (co-occurrence of species) [14]. a more directly relevant application is the use of similarity measures for recommendations [30]. recommender systems typically use either\n",
      "pearson correlation or cosine similarity for computation of\n",
      "item similarities [11], but they consider richer than binary\n",
      "data.\n",
      "table 1: an agreement matrix for two items and definitions of similarity measures based on the agreement matrix (n = a + b + c + d is the total number of\n",
      "observations).\n",
      "item i\n",
      "incorrect correct\n",
      "item j\n",
      "\n",
      "incorrect\n",
      "correct\n",
      "\n",
      "a\n",
      "c\n",
      "\n",
      "b\n",
      "d\n",
      "\n",
      "cohen\n",
      "\n",
      "sy = (ad − bc)/(ad + bc)\n",
      "p\n",
      "sp = (ad − bc)/ (a + b)(a + c)(b + d)(c + d)\n",
      "\n",
      "sokal\n",
      "\n",
      "ss = (a + d)/(a + b + c + d)\n",
      "\n",
      "jaccard\n",
      "\n",
      "sj = a/(a + b + c)\n",
      "p\n",
      "so = a/ (a + b)(a + c)\n",
      "\n",
      "yule\n",
      "pearson\n",
      "\n",
      "ochiai\n",
      "\n",
      "sc = (po − pe )/(1 − pe )\n",
      "po = (a + d)/n\n",
      "pe = ((a + b)(a + c) + (b + d)(c + d))/n2\n",
      "\n",
      "table 1 provides definitions of 6 measures that we have chosen for our comparison. in accordance with previous research (e.g., [5, 14]) we call measures by names of researchers\n",
      "who proposed them. the choice of measures was done in\n",
      "such a way as to cover measures used in the most closely related work and measures which achieved good results (even\n",
      "if the previous work was in other domains). we also tried\n",
      "to cover different types of measures.\n",
      "pearson measure is the standard pearson correlation coefficient evaluated over the dichotomous data. in the context of dichotomous data it is also called phi coefficient or\n",
      "matthews correlation coefficient. yule measure is similar\n",
      "measure, which achieved good results in previous work [30].\n",
      "cohen measure is typically used as a measure of inter-rater\n",
      "agreement (it is more commonly called “cohen’s kappa”).\n",
      "in our setting it makes sense to consider this measure when\n",
      "\n",
      "we view learners’ answers as “ratings” of items. relations\n",
      "between these three measures are discussed in [32].\n",
      "ochiai coefficient is typically used in biology [14]. it is also\n",
      "equivalent to cosine similarity evaluated over dichotomous\n",
      "data; cosine similarity is often used in recommender systems for computing item similarity, albeit typically over interval data [7]. sokal measure is also called sokal-michener\n",
      "or “simple matching”. it is equivalent to accuracy measure\n",
      "used in information retrieval. together with jaccard measure they are often used in biology, but they have also been\n",
      "used for clustering of educational data [12].\n",
      "note that some similarity measures are asymmetric with respect to 0 and 1 values. these measures are typically used\n",
      "in contexts where the interpretation of binary values is presence/absence of a specific feature (or observation). in the\n",
      "educational context it is more natural to use measures which\n",
      "treat correct and incorrect answers symmetrically. nevertheless, for completeness we have included also some of the\n",
      "commonly used asymmetric measures (ochiai and jaccard).\n",
      "in these cases we focus on incorrect answers (value a as opposed to d) as these are typically less frequent and thus bear\n",
      "more information.\n",
      "\n",
      "2.3\n",
      "\n",
      "other data sources\n",
      "\n",
      "the correctness of answers is the basic source of information about item similarities, but not the only one. we\n",
      "can also use other data. the second major type of performance data is response time (time taken to answer an\n",
      "item). the basic approach to utilization of response time\n",
      "is to combine it with the correctness of an answer. given\n",
      "the correctness value c ∈ {0, 1}, a response time t ∈ r+ ,\n",
      "and the median of all response times τ , we combine them\n",
      "into a single score r. examples of such transformations\n",
      "are: linear transformation for correct answers only (r =\n",
      "c · max(1 − t/2τ, 0)); exponential discounting used in matmat [28] (r = c · min(1, 0.9t/τ −1 )); linear transformation\n",
      "inspired by high speed, high stakes scoring rule used in math\n",
      "garden [16] (r = (2c − 1) · max(1 − t/2τ, 0)). the first\n",
      "approach was used in our experiment due to its simplicity\n",
      "and high influence of response time information.\n",
      "the scores obtained in this way are real numbers. given the\n",
      "scores it is natural to compute similarity of two items using\n",
      "pearson correlation coefficient of scores (over learners who\n",
      "answered both items). it is also possible to utilize specific\n",
      "wrong answers for computation of item similarity [25].\n",
      "it is also possible to combine performance based measures\n",
      "with other types of data. for example we may estimate\n",
      "item similarity based on analysis of the content of items\n",
      "(syntactical similarity of texts), or collect expert opinion\n",
      "(manual categorization of items into several groups). the\n",
      "advantage of the similarity approach (compared to model\n",
      "based approach) is that different similarity measures can be\n",
      "usually combined in straightforward way by using a weighted\n",
      "average of different measures.\n",
      "\n",
      "2.4 second level of item similarity\n",
      "the basic computation of item similarities computes similarity of items i and j using only data about these two items.\n",
      "to improve a similarity measure, it is possible to employ a\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "18\n",
      "\n",
      "\f",
      "“second of level of item similarity” that is based on the computed item similarity matrix and uses information on all\n",
      "items. examples of such a second step is euclidean distance\n",
      "or correlation. similarity of items i and j is given by the\n",
      "euclidean distance or pearson correlation of rows i and j\n",
      "in the similarity matrix. note that euclidean distance may\n",
      "be used implicitly when we use standard implementation of\n",
      "some clustering algorithms (e.g., k-means).\n",
      "with the basic approach to item similarity, we consider\n",
      "items similar when performance of learners on these items is\n",
      "similar. with the second step of item similarity, we consider\n",
      "two items similar when they behave similarly with respect\n",
      "to other items. the main reason for using this second step\n",
      "is the reduction of noise in data by using more information. this may be useful particularly to deal with learning.\n",
      "two very similar items may have rather low direct similarity, because getting a feedback on the first item can strongly\n",
      "influence the performance on the second item. however, we\n",
      "expect both items to have similar similarities to other items.\n",
      "a more technical reason to using the second step (particularly the euclidean distance) is to obtain a measure that\n",
      "is a distance metric. the measures described above mostly\n",
      "do not satisfy triangle inequality and thus do not satisfy\n",
      "the requirements on distance metric; this property may be\n",
      "important for some clustering algorithms.\n",
      "\n",
      "3. evaluation\n",
      "in this work we focus on item similarity, but we keep the\n",
      "overall context depicted in figure 1 in mind. the quality of\n",
      "a visualization is to a certain degree subjective and difficult\n",
      "to quantify, but the quality of clusters can be quantified and\n",
      "thus we can use it to compare similarity measures. from\n",
      "the large pool of existing clustering algorithms [15] we consider k-means, which is the most common implementation\n",
      "of centroid-based clustering, and hierarchical clustering. we\n",
      "used agglomerative or “bottom up” approach where items\n",
      "are successively merged to clusters using ward’s method as\n",
      "linkage criteria.\n",
      "\n",
      "3.1\n",
      "\n",
      "data\n",
      "\n",
      "we use data from real educational systems as well as simulated learner data. real-world data provide information\n",
      "about the realistic performance of techniques, but the evaluation is complicated by the fact that we do not know the\n",
      "“ground truth” (the “correct” similarity or clusters of items).\n",
      "simulated data provide a setting that is in many aspects\n",
      "simplified but allows easier evaluation thanks to the access\n",
      "to the ground truth.\n",
      "for generating simulated data we use a simple approach\n",
      "with minimal number of assumptions and ad hoc parameters. each item belongs to one of k knowledge components. each knowledge component contains n items. each\n",
      "item has a difficulty generated from the standard normal\n",
      "distribution di ∼ n (0, 1). skills of learners with respect to\n",
      "individual knowledge components are independent. skill of\n",
      "a learner l with respect to knowledge component j is generated from the standard normal distribution θlj ∼ n (0, 1).\n",
      "we assume no learning (constant skills). answers are generated as bernoulli trials with the probability of a correct\n",
      "answer given by the logistic function of the difference of a\n",
      "\n",
      "table 2: data used for analysis.\n",
      "learners items\n",
      "answers\n",
      "czech 1 (adjectives)\n",
      "czech 2\n",
      "matmat: numbers\n",
      "matmat: addition\n",
      "math garden: addition\n",
      "math garden: multiplic.\n",
      "\n",
      "1 134\n",
      "4 567\n",
      "6 434\n",
      "3 580\n",
      "83 297\n",
      "97 842\n",
      "\n",
      "108\n",
      "210\n",
      "60\n",
      "135\n",
      "30\n",
      "30\n",
      "\n",
      "62 613\n",
      "336 382\n",
      "67 753\n",
      "20 337\n",
      "881 994\n",
      "1 233 024\n",
      "\n",
      "relevant skill and an item difficulty (a rasch model): p =\n",
      "exp(θlj − di )−1 . this approach is rather standard, for example piech at al. [26] use very similar procedure and also\n",
      "other works use closely related procedures [4, 12]. in the\n",
      "experiment reported below the basic setting is 100 learners,\n",
      "5 knowledge components with 20 items each.\n",
      "to evaluate techniques on realistic educational data, we use\n",
      "data from three educational systems. table 2 describes the\n",
      "size of the used data sets.\n",
      "umı́me česky (umimecesky.cz) is a system for practice of\n",
      "czech spelling and grammar. we use data only from one exercise from the system – simple “fill-in-the-blank” questions\n",
      "with two options. we use only data on the correctness of\n",
      "answers (response time is available, but since it depends on\n",
      "the text of a particular item its utilization is difficult). we\n",
      "focus particularly on one subset of items: questions about\n",
      "the choice between i/y in suffixes of czech adjectives. for\n",
      "this subset we have manually determined 7 groups of items\n",
      "corresponding to czech grammar rules.\n",
      "matmat (matmat.cz) is a system for practice of basic arithmetic (e.g., counting, addition, multiplication). for each\n",
      "item we know the underlying construct (e.g., “13” or “7 +\n",
      "8”) and also the specific form of questions (e.g., what type of\n",
      "visualization has been used). we use data on both correctness and response time. we selected the two largest subsets:\n",
      "multiplication and numbers (practice of number sens, counting).\n",
      "math garden is another system for practice of basic arithmetic [16]. this system is more widely used than matmat,\n",
      "but we do not have direct access to the system and detailed\n",
      "data. for the analysis we reuse publicly available data from\n",
      "previous research [6]. the available data contain both correctness of answers and response times, but they contain\n",
      "information only about 30 items without any identification\n",
      "of these items.\n",
      "\n",
      "3.2 comparison of similarity measures\n",
      "to evaluate similarity measures we consider several types\n",
      "of analysis. with simulated data, we analyze the similarity\n",
      "measures with respect to the ground truth while for realworld data we evaluate correlations among similarity measures. we also compare the quality of subsequent clusterings using adjusted rand index (ari) [27, 31], which measures the agreement of two clusterings (with a correction for\n",
      "agreement due to chance). typically, we use the adjusted\n",
      "rand index to compare the clustering with a ground truth\n",
      "(available for simulated data) or with a manually provided\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "19\n",
      "\n",
      "\f",
      "pearson\n",
      "\n",
      "pearson → pearson\n",
      "\n",
      "within-cluster\n",
      "\n",
      "within-cluster\n",
      "\n",
      "between-cluster\n",
      "\n",
      "between-cluster\n",
      "\n",
      "yule\n",
      "\n",
      "czech 1 (adjectives)\n",
      "\n",
      "matmat: numbers\n",
      "\n",
      "yule → pearson\n",
      "\n",
      "within-cluster\n",
      "\n",
      "within-cluster\n",
      "\n",
      "between-cluster\n",
      "\n",
      "between-cluster\n",
      "\n",
      "jaccard\n",
      "\n",
      "sokal\n",
      "\n",
      "within-cluster\n",
      "\n",
      "within-cluster\n",
      "\n",
      "between-cluster\n",
      "\n",
      "between-cluster\n",
      "\n",
      "figure 3: correlations of similarity measures.\n",
      "\n",
      "figure 2: differences between similarity values\n",
      "inside knowledge components and between them.\n",
      "simulated data set with the basic setting were used.\n",
      "\n",
      "classification (available for the czech 1 data set). it can be\n",
      "also used to compare two detected clusterings (clusterings\n",
      "based on two different algorithms or clusterings based on\n",
      "two independent halves of data).\n",
      "as a first step in the evaluation of similarity measures, we\n",
      "consider experiments with simulated data where we can utilize the ground truth. in clustering we expect high withincluster similarity values and low between-cluster similarity\n",
      "values. figure 2 shows distribution of the similarity values\n",
      "for selected measures and suggest which measures separate\n",
      "within-cluster and between-cluster values better and therefore which measures will be more useful in clustering. the\n",
      "results show that for jaccard and sokal measures the values overlap to a large degree, whereas pearson and yule\n",
      "measures provide better results. adding the second step –\n",
      "pearson correlation in this example – to the similarity measure separates within-cluster and between-cluster values better. that suggests that extending similarities in this way is\n",
      "not only necessary step for some subsequent algorithms such\n",
      "as k-means but also a useful technique with better performance.\n",
      "for data coming from real systems we do not know the\n",
      "ground truth and thus we can only compare the similarity measures to each other. to evaluate how similar two\n",
      "measures are we take all similarity values for all item pairs\n",
      "and computed correlation coefficient. figure 3 shows results\n",
      "for two data sets which are good representatives of overall results. pearson and cohen measures are highly correlated (> 0.98) across all data sets and have nearly the same\n",
      "values (although not exactly the same). larger differences\n",
      "(but only up to 0.1) can be found typically when one of the\n",
      "values in the agreement matrix is small and that happens\n",
      "only for poorly correlated items with the resulting similarity value around 0. the second pair of highly correlated\n",
      "measures is ochiai and jaccard, which are both asymmetric\n",
      "with respect to the agreement matrix. the correlation between these two pairs of measures vary depending on data\n",
      "set and in some cases drops up to 0.5. because of this high\n",
      "correlation within these pairs we further report results only\n",
      "\n",
      "for pearson and jaccard measures. yule measure is usually\n",
      "similar to pearson measure (correlation usually around 0.9).\n",
      "the main difference is that the yule measure spreads values\n",
      "more evenly across the interval [-1, 1]. sokal is the most\n",
      "outlying measure with no correlation or small correlation\n",
      "(usually < 0.6) with all other measures.\n",
      "figure 4 shows the effect of the second levels of item similarity on the pearson measure (results for other measures\n",
      "are analogical). the euclid distance as second level similarity brings larger differences (lower correlation) than pearson\n",
      "correlation. the correlations for large data sets such as math\n",
      "garden are usually high (> 0.9) and conversely the lowest\n",
      "correlations are found in results for small data sets. this\n",
      "suggests that the second level of similarity is more significant, and thus potentially more useful, where only limited\n",
      "amount of data is available.\n",
      "czech 1 (adjectives)\n",
      "\n",
      "czech 2\n",
      "\n",
      "matmat: numbers\n",
      "\n",
      "6\n",
      "matmat: addition\n",
      "\n",
      "math garden: addition\n",
      "\n",
      "math garden: multiplic.\n",
      "\n",
      "figure 4: correlations of pearson measure and pearson with different second levels.\n",
      "finally, we evaluate the quality of the similarity measures\n",
      "according to the performance of the subsequent clustering.\n",
      "from the two considered clustering methods we used the hierarchical clustering in this comparison because it naturally\n",
      "works with similarity measure and does not require metric\n",
      "space. the other two methods have similar result with same\n",
      "conclusions. table 3 and figure 5 show results. although\n",
      "the results are dependent on the specific data set and the\n",
      "used clustering algorithm, there is quite clear general conclusion. pearson and yule measures provide better results\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "20\n",
      "\n",
      "\f",
      "1223\n",
      "\n",
      "correlation\n",
      "\n",
      "882\n",
      "\n",
      "data set\n",
      "czech 1 (adjectives)\n",
      "czech 2\n",
      "matmat: numbers\n",
      "matmat: addition\n",
      "math garden: addition\n",
      "math garden: multiplic.\n",
      "\n",
      "336\n",
      "63\n",
      "68\n",
      "\n",
      "20\n",
      "\n",
      "sample size\n",
      "\n",
      "figure 6: stability of similarity measure (yule) for\n",
      "real-world data sets. data set was sampled, split\n",
      "to halves and pearson correlation was computed for\n",
      "similarity values. numbers on the right side indicate\n",
      "thousands of answers in data sets.\n",
      "\n",
      "figure 5: the quality of clustering for different measures used in the second step of item similarity. top:\n",
      "simulated data with 5 correlated skills. bottom:\n",
      "czech grammar with 7 manually determined clusters.\n",
      "than jaccard and sokal, i.e., for the considered task the\n",
      "later two measures are not suitable. the pearson is usually\n",
      "slightly better than yule but the choice between them seems\n",
      "not to be fundamental (which is not surprising given that\n",
      "they are highly correlated). the results also show that the\n",
      "“second step” is always useful. the result for simulated data\n",
      "favor euclidean distance over pearson but there are almost\n",
      "no differences for real-world data.\n",
      "\n",
      "3.3\n",
      "\n",
      "do we have enough data?\n",
      "\n",
      "in machine learning the amount of available data often is\n",
      "more important than the choice of a specific algorithm [2].\n",
      "our results suggest that once we choose a suitable type of\n",
      "similarity measure (e.g., pearson, cohen, or yule), the differences between these measures are not fundamental, the\n",
      "more important issue becomes the size of available data.\n",
      "specifically, for a given data set we want to know whether\n",
      "the data are sufficiently large so that the computed item\n",
      "similarities are meaningful and stable. this issue can be explored by analyzing confidence intervals for computed similarity values. as a simple approach to analysis of similarity stability we propose the following approach: we split\n",
      "the available data into two independent halves (in a learner\n",
      "stratified manner), for each half we compute the item similarities, and we compute the correlation of the resulting item\n",
      "similarities.\n",
      "\n",
      "we can also perform this computation for artificially reduced\n",
      "data sets – this shows how the stability of results increases\n",
      "with the size of data. figure 6 shows this kind of analysis\n",
      "for our data (real-world data sets). we clearly see large differences among individual data sets. math garden data set\n",
      "contains large number of answers and only a few items, the\n",
      "results show excellent stability, clearly in this case we have\n",
      "enough data to analyze item similarities. for the czech\n",
      "grammar data set we have large number of answers, but\n",
      "these are divided among relatively large number of items.\n",
      "the results show a reasonably good stability, the data are\n",
      "usable for analysis, but clearly more data can bring improvement. for matmat data the stability is poor, to draw solid\n",
      "conclusions about item similarities we need more data.\n",
      "\n",
      "3.4 response time utilization\n",
      "the incorporation of response time information to similarity measure can change the meaning of similarity. figure 7\n",
      "gives such example and shows projection of items from matmat practicing number sense. similar items according to\n",
      "measures using only correctness of answers tend to be items\n",
      "with the same graphical representation in the system. on\n",
      "the other hand, similar items according to measures using\n",
      "also response time are usually items practicing close numbers.\n",
      "we used this method also on data sets from math garden,\n",
      "which are much larger. in this case the use of response\n",
      "times has only small impact on the computed item similarities (correlations between 0.9 and 0.95). however, the use of\n",
      "response times influences how quickly does the computation\n",
      "converge, i.e., how much data do we need. to explore this\n",
      "we consider as the ground truth the average of computed\n",
      "similarity matrices with and without response times for the\n",
      "whole data set. then we used smaller samples of the data\n",
      "set, used them to compute item similarities and checked the\n",
      "agreement with this ground truth. figure 8 shows the difference between speed of convergence of measure with and\n",
      "without response time utilization. results shows that the\n",
      "measure which use addition information from response time\n",
      "converges to ground truth much faster. this result suggests\n",
      "that the use of response time can improve clustering or visualizations when only small number of answers are available.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "21\n",
      "\n",
      "\f",
      "table 3: comparison of similarity measures for one real-world data (with sampled students) set and simulated\n",
      "data sets with c knowledge components and l learners. the values provide the adjusted rand index (with\n",
      "0.95 confidence interval) for a hierarchical clustering computed based on the specific similarity measure. the\n",
      "top result for every data set is highlighted.\n",
      "czech 1 (c=7)\n",
      "\n",
      "l = 50, c = 5\n",
      "\n",
      "l = 100, c = 5\n",
      "\n",
      "l = 200, c = 5\n",
      "\n",
      "l = 100, c = 2\n",
      "\n",
      "l = 100, c = 10\n",
      "\n",
      "0.32 ± 0.02\n",
      "0.31 ± 0.03\n",
      "0.31 ± 0.03\n",
      "0.15 ± 0.06\n",
      "0.43 ± 0.01\n",
      "0.32 ± 0.02\n",
      "0.41 ± 0.03\n",
      "0.32 ± 0.03\n",
      "\n",
      "0.26 ± 0.04\n",
      "0.06 ± 0.03\n",
      "0.19 ± 0.04\n",
      "0.11 ± 0.02\n",
      "0.45 ± 0.05\n",
      "0.36 ± 0.05\n",
      "0.39 ± 0.05\n",
      "0.38 ± 0.05\n",
      "\n",
      "0.48 ± 0.05\n",
      "0.15 ± 0.04\n",
      "0.43 ± 0.05\n",
      "0.18 ± 0.03\n",
      "0.80 ± 0.06\n",
      "0.65 ± 0.07\n",
      "0.73 ± 0.06\n",
      "0.72 ± 0.06\n",
      "\n",
      "0.84 ± 0.05\n",
      "0.29 ± 0.08\n",
      "0.77 ± 0.07\n",
      "0.25 ± 0.05\n",
      "0.98 ± 0.01\n",
      "0.94 ± 0.04\n",
      "0.96 ± 0.02\n",
      "0.97 ± 0.02\n",
      "\n",
      "0.77 ± 0.12\n",
      "0.32 ± 0.18\n",
      "0.60 ± 0.15\n",
      "0.12 ± 0.11\n",
      "0.95 ± 0.03\n",
      "0.89 ± 0.11\n",
      "0.92 ± 0.03\n",
      "0.94 ± 0.04\n",
      "\n",
      "0.34 ± 0.04\n",
      "0.09 ± 0.02\n",
      "0.31 ± 0.03\n",
      "0.14 ± 0.02\n",
      "0.67 ± 0.04\n",
      "0.43 ± 0.03\n",
      "0.55 ± 0.04\n",
      "0.55 ± 0.05\n",
      "\n",
      "correlation with ground truth\n",
      "\n",
      "pearson\n",
      "jaccard\n",
      "yule\n",
      "sokal\n",
      "pearson → euclid\n",
      "yule → euclid\n",
      "pearson → pearson\n",
      "yule → pearson\n",
      "\n",
      "without\n",
      "response times\n",
      "with\n",
      "\n",
      "sample size\n",
      "\n",
      "figure 7: projection of items practicing number\n",
      "sense from matmat system. left: measure based\n",
      "only correctness. right: measure using response\n",
      "time. opacity corresponds to the number value of\n",
      "the item and color corresponds to the graphical representation of the task.\n",
      "\n",
      "4. discussion\n",
      "our focus is the automatic computation of item similarities\n",
      "based on learners’ performance data. these similarities can\n",
      "be then used in further analysis of an item relations such as\n",
      "an item clustering or a visualization. this outlines direction\n",
      "for future work in which methods using the item similarities\n",
      "should be studied in more detail. compared to alternative\n",
      "approaches that have been proposed for the task (e.g., matrix factorizations, neural networks), the item similarity approach is rather straightforward, easy to realize, and it can\n",
      "be easily combined with other sources of information about\n",
      "items (text of items, expert opinion). for these reasons the\n",
      "item similarity approach should be used at least as a baseline\n",
      "in proposals for more complex methods like deep knowledge\n",
      "tracing [26].\n",
      "the most difficult step in this approach is the choice of a\n",
      "similarity measure. once we make a specific choice, the realization of the approach is easy. our results provide some\n",
      "guidelines for this choice. pearson, yule, and cohen measures lead to significantly better results than ochiai, sokal,\n",
      "and jaccard measures. it is also beneficial to use the second\n",
      "step of item similarity (e.g., the euclidean distance over vec-\n",
      "\n",
      "figure 8: the speed of convergence to ground truth\n",
      "for measures with and without response time on\n",
      "math garden addition data set.\n",
      "\n",
      "tors of item similarities). the exact choice of details does not\n",
      "seem to make fundamental difference (e.g., pearson versus\n",
      "yule in the first step, the euclidean distance versus pearson correlation in the second step). the pearson correlation coefficient is a good “default choice”, since it provides\n",
      "quite robust results and is applicable in several settings and\n",
      "steps. it also has the pragmatic advantage of having fast,\n",
      "readily available implementation in nearly all computational\n",
      "environments, whereas measures like yule may require additional implementation effort.\n",
      "the amount of data available is the critical factor for the success of automatic analysis of item relations. a key question\n",
      "for practical applications is thus: “do we have enough data\n",
      "to use automated techniques?” in this work we used several\n",
      "specific methods for analysis of this question, but the issue\n",
      "requires more attention – not just for the item similarity\n",
      "approach, but also for other methods proposed in previous\n",
      "work. for example previous work on deep knowledge tracing [26], which studies closely related issues, states only that\n",
      "deep neural networks require large data without providing\n",
      "any specific quantification what ‘large’ means. the necesssary quantity of data is, of course, connected to the quality\n",
      "of data – some data sources are more noisy than other, e.g.,\n",
      "answers from voluntary practice contain more noise than answers from high-stakes testing. an important direction for\n",
      "future work is thus to compare model based and item simi-\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "22\n",
      "\n",
      "\f",
      "larity approaches while taking into account the ‘amount and\n",
      "quality of data available’ issue.\n",
      "\n",
      "5.\n",
      "\n",
      "references\n",
      "\n",
      "[1] r. s. baker. stupid tutoring systems, intelligent\n",
      "humans. international journal of artificial\n",
      "intelligence in education, 26(2):600–614, 2016.\n",
      "[2] m. banko and e. brill. scaling to very very large\n",
      "corpora for natural language disambiguation. in proc.\n",
      "of association for computational linguistics, pages\n",
      "26–33, 2001.\n",
      "[3] t. barnes. the q-matrix method: mining student\n",
      "response data for knowledge. in educational data\n",
      "mining workshop, 2005.\n",
      "[4] w.-h. chen and d. thissen. local dependence\n",
      "indexes for item pairs using item response theory.\n",
      "journal of educational and behavioral statistics,\n",
      "22(3):265–289, 1997.\n",
      "[5] s.-s. choi, s.-h. cha, and c. c. tappert. a survey of\n",
      "binary similarity and distance measures. journal of\n",
      "systemics, cybernetics and informatics, 8(1):43–48,\n",
      "2010.\n",
      "[6] f. coomans, a. hofman, m. brinkhuis, h. l. van der\n",
      "maas, and g. maris. distinguishing fast and slow\n",
      "processes in accuracy-response time data. plos one,\n",
      "11(5):e0155149, 2016.\n",
      "[7] m. deshpande and g. karypis. item-based top-n\n",
      "recommendation algorithms. acm transactions on\n",
      "information systems (tois), 22(1):143–177, 2004.\n",
      "[8] m. c. desmarais. mapping question items to skills\n",
      "with non-negative matrix factorization. acm\n",
      "sigkdd explorations newsletter, 13(2):30–36, 2012.\n",
      "[9] m. c. desmarais and r. s. baker. a review of recent\n",
      "advances in learner and skill modeling in intelligent\n",
      "learning environments. user modeling and\n",
      "user-adapted interaction, 22(1-2):9–38, 2012.\n",
      "[10] m. c. desmarais, b. beheshti, and p. xu. the\n",
      "refinement of a q-matrix: assessing methods to\n",
      "validate tasks to skills mapping. in proc. of\n",
      "educational data mining, pages 308–311, 2014.\n",
      "[11] c. desrosiers and g. karypis. a comprehensive survey\n",
      "of neighborhood-based recommendation methods. in\n",
      "recommender systems handbook, pages 107–144.\n",
      "springer, 2011.\n",
      "[12] h. finch. comparison of distance measures in cluster\n",
      "analysis with dichotomous data. journal of data\n",
      "science, 3(1):85–100, 2005.\n",
      "[13] j. friedman, t. hastie, and r. tibshirani. the\n",
      "elements of statistical learning, volume 1. springer\n",
      "series in statistics springer, berlin, 2001.\n",
      "[14] d. a. jackson, k. m. somers, and h. h. harvey.\n",
      "similarity coefficients: measures of co-occurrence and\n",
      "association or simply measures of occurrence?\n",
      "american naturalist, pages 436–453, 1989.\n",
      "[15] a. k. jain. data clustering: 50 years beyond k-means.\n",
      "pattern recognition letters, 31(8):651–666, 2010.\n",
      "[16] s. klinkenberg, m. straatemeier, and h. van der\n",
      "maas. computer adaptive practice of maths ability\n",
      "using a new item response model for on the fly ability\n",
      "and difficulty estimation. computers & education,\n",
      "57(2):1813–1824, 2011.\n",
      "\n",
      "[17] k. r. koedinger, a. t. corbett, and c. perfetti. the\n",
      "knowledge-learning-instruction framework: bridging\n",
      "the science-practice chasm to enhance robust student\n",
      "learning. cognitive science, 36(5):757–798, 2012.\n",
      "[18] y. koren and r. bell. advances in collaborative\n",
      "filtering. recommender systems handbook, pages\n",
      "145–186, 2011.\n",
      "[19] a. s. lan, a. e. waters, c. studer, and r. g.\n",
      "baraniuk. sparse factor analysis for learning and\n",
      "content analytics. journal of machine learning\n",
      "research, 15(1):1959–2008, 2014.\n",
      "[20] s.-f. m. liang and l.-w. tzeng. assessing suitability\n",
      "of similarity coefficients in measuring human mental\n",
      "models. in network of ergonomics societies\n",
      "conference, pages 1–5. ieee, 2012.\n",
      "[21] j. nižnan, r. pelánek, and j. řihák. using problem\n",
      "solving times and expert opinion to detect skills. in\n",
      "proc. of educational data mining, pages 434–434,\n",
      "2014.\n",
      "[22] j. nižnan, r. pelánek, and j. řihák. student models\n",
      "for prior knowledge estimation. in proc. of\n",
      "educational data mining, pages 109–116, 2015.\n",
      "[23] m. o’connor and j. herlocker. clustering items for\n",
      "collaborative filtering. in proc. of the acm sigir\n",
      "workshop on recommender systems, volume 128. uc\n",
      "berkeley, 1999.\n",
      "[24] y.-j. park and a. tuzhilin. the long tail of\n",
      "recommender systems and how to leverage it. in proc.\n",
      "of recommender systems, pages 11–18. acm, 2008.\n",
      "[25] r. pelánek and j. řihák. properties and applications\n",
      "of wrong answers in online educational systems. in\n",
      "proc. of educational data mining, 2016.\n",
      "[26] c. piech, j. bassen, j. huang, s. ganguli, m. sahami,\n",
      "l. j. guibas, and j. sohl-dickstein. deep knowledge\n",
      "tracing. in advances in neural information processing\n",
      "systems, pages 505–513, 2015.\n",
      "[27] w. m. rand. objective criteria for the evaluation of\n",
      "clustering methods. journal of the american\n",
      "statistical association, 66(336):846–850, 1971.\n",
      "[28] j. rihák. use of time information in models behind\n",
      "adaptive system for building fluency in mathematics.\n",
      "in proc. of educational data mining, 2015.\n",
      "[29] b. m. sarwar, g. karypis, j. konstan, and j. riedl.\n",
      "recommender systems for large-scale e-commerce:\n",
      "scalable neighborhood formation using clustering. in\n",
      "proc. of computer and information technology,\n",
      "volume 1, 2002.\n",
      "[30] e. şenyürek and h. polat. effects of binary similarity\n",
      "measures on top-n recommendations. anadolu\n",
      "university journal of science and technology – a\n",
      "applied sciences and engineering, 14(1):55–65, 2013.\n",
      "[31] n. x. vinh, j. epps, and j. bailey. information\n",
      "theoretic measures for clusterings comparison: is a\n",
      "correction for chance necessary? in proc. of machine\n",
      "learning, pages 1073–1080. acm, 2009.\n",
      "[32] m. j. warrens. on association coefficients for 2× 2\n",
      "tables and properties that do not depend on the\n",
      "marginal distributions. psychometrika, 73(4):777–789,\n",
      "2008.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "23\n",
      "\n",
      "\f",
      "adaptive sequential recommendation for discussion\n",
      "forums on moocs using context trees\n",
      "fei mi\n",
      "boi faltings\n",
      "artificial intelligence lab\n",
      "école polytechnique fédérale de lausanne, switzerland\n",
      "firstname.lastname@epfl.ch\n",
      "abstract\n",
      "\n",
      "massive open online courses (moocs) have demonstrated growing popularity and rapid development in recent years. discussion\n",
      "forums have become crucial components for students and instructors to widely exchange ideas and propagate knowledge. it is important to recommend helpful information from forums to students\n",
      "for the benefit of the learning process. however, students or instructors update discussion forums very often, and the student preferences over forum contents shift rapidly as a mooc progresses.\n",
      "so, mooc forum recommendations need to be adaptive to these\n",
      "evolving forum contents and drifting student interests. these frequent changes pose a challenge to most standard recommendation\n",
      "methods as they have difficulty adapting to new and drifting observations. we formalize the discussion forum recommendation\n",
      "problem as a sequence prediction problem. then we compare different methods, including a new method called context tree (ct),\n",
      "which can be effectively applied to online sequential recommendation tasks. the results show that the ct recommender performs\n",
      "better than other methods for moocs forum recommendation task.\n",
      "we analyze the reasons for this and demonstrate that it is because\n",
      "of better adaptation to changes in the domain. this highlights the\n",
      "importance of considering the adaptation aspect when building recommender system with drifting preferences, as well as using machine learning in general.\n",
      "\n",
      "keywords\n",
      "\n",
      "moocs forum recommendation, context tree, model adaptation\n",
      "\n",
      "1. introduction\n",
      "\n",
      "with the increased availability of data, machine learning has become the method of choice for knowledge acquisition in intelligent\n",
      "systems and various applications. however, data and the knowledge derived from it have a timeliness, such that in a dynamic environment not all the knowledge acquired in the past remains valid.\n",
      "therefore, machine learning models should acquire new knowledge incrementally and adapt to the dynamic environments. today, many intelligent systems deal with dynamic environments: information on websites, social networks, and applications in com-\n",
      "\n",
      "mercial markets. in such evolving environments, knowledge needs\n",
      "to adapt to the changes very frequently. many statistical machine\n",
      "learning techniques interpolate between input data and thus their\n",
      "models can adapt only slowly to new situations. in this paper,\n",
      "we consider the dynamic environments for recommendation task.\n",
      "drifting user interests and preferences [3, 11] are important in building personal assistance systems, such as recommendation systems\n",
      "for social networks or for news websites where recommendations\n",
      "need be adaptive to drifting trends rather than recommending obsolete or well-known information. we focus on the application\n",
      "of recommending forum contents for massive open online courses\n",
      "(moocs) where we found that the adaptation issue is a crucial aspect for providing useful and trendy information to students.\n",
      "the rapid emergence of some mooc platforms and many moocs\n",
      "provided on them has opened up a new era of education by pushing\n",
      "the boundaries of education to the general public. in this special online classroom setting, sharing with your classmates or asking help\n",
      "from instructors is not as easy as in traditional brick-and-mortar\n",
      "classrooms. so discussion forums there have become one of the\n",
      "most important components for students to widely exchange ideas\n",
      "and to obtain instructors’ supplementary information. mooc forums play the role of social learning media for knowledge propagation with increasing number of students and interactions as a course\n",
      "progresses. every member in the forum can talk about course content with each other, and the intensive interaction between them\n",
      "supports the knowledge propagation between members of the learning community.\n",
      "the online discussion forums are usually well structured via the\n",
      "different threads which are created by students or instructors; they\n",
      "can contain several posts and comments within the topic. an example of the discussion forum from a famous “machine learning”\n",
      "course by andre ng on coursera1 is shown in figure 1. the left\n",
      "figure shows various threads and the right figure illustrates some\n",
      "replies within the last thread (\"having a problem with the collaborative filtering cost\"). in general, the replies within a thread are\n",
      "related to the topic of the thread and they can also refer to some\n",
      "other threads for supplementary information, like the link in the\n",
      "second reply. our goal is to point the students towards useful forum threads through effectively mining forum visit patterns.\n",
      "two aspects set forum recommendation system for moocs apart\n",
      "from other recommendation scenarios. first, student interests and\n",
      "preferences drift fast during the span of a course, which is influenced by the dynamics in forums and the content of the course;\n",
      "second, the pool of items to be recommended and the items them1\n",
      "\n",
      "https://www.coursera.org/\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "24\n",
      "\n",
      "\f",
      "figure 1: an sample discussion forum. left: sample threads. right: replies within the last thread (\"having a problem with the collaborative filtering cost\").\n",
      "selves are evolving over time because forum threads can be edited\n",
      "very frequently by either students or instructors. so the recommendations provided to students need to be adaptive to these drifting\n",
      "preferences and evolving items. traditional recommendation techniques, such as collaborative filtering and methods based on matrix factorization, only adapt slowly, as they build an increasingly\n",
      "complex model of users and items. therefore, when a new item is\n",
      "superseded by a newer version or a new preference pattern appears,\n",
      "it takes time for recommendations to adapt. to better address the\n",
      "dynamic nature of recommendation in moocs, we model the recommendation problem as a dynamic and sequential machine learning problem for the task of predicting the next item in a sequence of\n",
      "items consumed by a user. during the sequential process, the challenge is combining old knowledge with new knowledge such that\n",
      "both old and new patterns can be identified fast and accurately. we\n",
      "use algorithms for sequential recommendation based on variableorder markov models. more specifically, we use a structure called\n",
      "context tree (ct) [21] which was originally proposed for lossless\n",
      "data compression. we apply the ct method for recommending\n",
      "discussion forum contents for moocs, where adapting to drifting preferences and dynamic items is crucial. in experiments, it is\n",
      "compared with various sequential and non-sequential methods. we\n",
      "show that both old knowledge and new patterns can be captured effectively through context activation using ct, and that this is why\n",
      "it is particularly strong at adapting to drifting user preferences and\n",
      "performs extremely well for mooc forum recommendation tasks.\n",
      "the main contribution of this paper is fourfold:\n",
      "• we applied the context tree structure to a sequential recommendation tasks where dynamic item sets and drifting user\n",
      "preferences are of great concern.\n",
      "• analyze how the dynamic changes in user preferences are\n",
      "followed in different recommendation techniques.\n",
      "• extensive experiments are conducted for both sequential and\n",
      "non-sequential recommendation settings. through the experimental analysis, we validate our hypothesis that the ct\n",
      "recommender adapts well to drifting preferences.\n",
      "\n",
      "• partial context matching (pct) technique, built on top of the\n",
      "standard ct method, is proposed and tested to generalize to\n",
      "new sequence patterns, and it further boosts the recommendation performance.\n",
      "\n",
      "2.\n",
      "\n",
      "related work\n",
      "\n",
      "typical recommender systems adopt a static view of the recommendation process and treat it as a prediction problem over all historical\n",
      "preference data. from the perspective of generating adaptive recommendations,we contend that it is more appropriate to view the\n",
      "recommendation problem as a sequential decision problem. next,\n",
      "we mainly review some techniques developed for recommender\n",
      "systems with temporal or sequential considerations.\n",
      "the most well-known class of recommender system is based on\n",
      "collaborative filtering (cf) [19]. several attempts have been made\n",
      "to incorporate temporal components into the collaborative filtering\n",
      "setting to model users’ drifting preferences over time. a common\n",
      "way to deal with the temporal nature is to give higher weights to\n",
      "events that happened recently. [6, 7, 15] introduced algorithms\n",
      "for item-based cf that compute the time weightings for different\n",
      "items by adding a tailored decay factor according to the user’s own\n",
      "purchase behavior. for low dimensional linear factor models, [11]\n",
      "proposed a model called “timesvd” to predict movie ratings for\n",
      "netflix by modeling temporal dynamics, including periodic effects,\n",
      "via matrix factorization. as retraining latent factor models is costly,\n",
      "one alternative is to learn the parameters and update the decision\n",
      "function online for each new observation [1, 16]. [10] applied the\n",
      "online cf method, coupled with an item popularity-aware weighting scheme on missing data, to recommending social web contents\n",
      "with implicit feedbacks.\n",
      "markov models are also applied to recommender systems to learn\n",
      "the transition function over items. [24] treated recommendation as\n",
      "a univariate time series problem and described a sequential model\n",
      "with a fixed history. predictions are made by learning a forest of\n",
      "decision trees, one for each item. when the number of items is big,\n",
      "this approach does not scale. [17] viewed the problem of generating\n",
      "recommendations as a sequential decision problem and they con-\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "25\n",
      "\n",
      "\f",
      "sidered a finite mixture of markov models with fixed weights. [4]\n",
      "applied markov models to recommendation tasks using skipping\n",
      "and weighting techniques for modeling long-distance relationships\n",
      "within a sequence. a major drawback of these markov models is\n",
      "that it is not clear how to choose the order of markov chain.\n",
      "online algorithms for recommendation are also proposed in several literatures. in [18], a q-learning-based travel recommender is\n",
      "proposed, where trips are ranked using a linear function of several\n",
      "attributes and the weights are updated according to user feedback.\n",
      "a multi-armed bandit model called linucb is proposed by [13]\n",
      "for news recommendation to learn the weights of the linear reward\n",
      "function, in which news articles are represented as feature vectors;\n",
      "click-through rates of articles are treated as the payoffs. [20] proposed a similar recommender for music recommendation with rating feedback, called bayes-ucb, that optimizes the nonlinear reward function using bayesian inference. [14] used a markov decision process (mdp) to model the sequential user preferences for\n",
      "recommending music playlists. however, the exploration phase of\n",
      "these methods makes them adapt slowly. as user preferences drift\n",
      "fast in many recommendation setting, it is not effective to explore\n",
      "all options before generating useful ones.\n",
      "within the context of recommendation for moocs, [23] proposed\n",
      "an adaptive feature-based matrix factorization framework for course\n",
      "forum recommendation, and the adaptation is achieved by utilizing\n",
      "only recent features. [22] designed a context-aware matrix factorization model to predict student preferences for forum contents, and\n",
      "the context considered includes only supplementary statistical features about students and forum contents. in this paper, we focus on\n",
      "a class of recommender systems based on a structure, called context tree [21], which was originally used to estimate variable-order\n",
      "markov models (vmms) for lossless data compression. then, [2,\n",
      "12, 5] applied this structure to various discrete sequence prediction tasks. recently it was applied to news recommendation by\n",
      "[8, 9]. the most important property of online algorithms is the noregret property, meaning that the model learned online is eventually\n",
      "as good as the best model that could be learned offline. according to [21], the no-regret property is achieved by context trees for\n",
      "the data compression problem. regret analysis for ct was conducted through simulation by [5] for stochastically generated hidden markov models with small state space. they show that ct\n",
      "achieves the no-regret property when the environment is stationary.\n",
      "as we focus on dynamic recommendation environments with timevarying preferences and limited observations, the no-regret property can be hardly achieved while the model adaptation is a bigger\n",
      "issue for better performance.\n",
      "\n",
      "3.\n",
      "\n",
      "context tree recommender\n",
      "\n",
      "due to the sequential item consumption process, user preferences\n",
      "can be summarized by the last several items visited. when modeling the process as a fixed-order markov process [17], it is difficult\n",
      "to select the order. a variable-order markov model (vmm), like a\n",
      "context tree, alleviates this problem by using a context-dependent\n",
      "order. the context tree is a space efficient structure to keep track\n",
      "of the history in a variable-order markov chain so that the data\n",
      "structure is built incrementally for sequences that actually occur. a\n",
      "local prediction model, called expert, is assigned to each tree node,\n",
      "it only gives predictions for users who have consumed the sequence\n",
      "of items corresponding to the node. in this section, we first introduce how to use the ct structure and the local prediction model for\n",
      "sequential recommendation. then, we discuss adaptation properties and the model complexity of the ct recommender.\n",
      "\n",
      "3.1 the context tree data structure\n",
      "\n",
      "in ct, a sequence s = hn1 , . . . , nl i is an ordered list of items\n",
      "ni ∈ n consumed by a user. the sequence of items viewed until\n",
      "time t is st and the set of all possible sequences s.\n",
      "a context s = {s ∈ s : ξ ≺ s} is the set of all possible sequences\n",
      "in s ending with the suffix ξ. ξ is the suffix (≺) of s if last elements\n",
      "of s are equal to ξ. for example, one suffix ξ of the sequence\n",
      "s = hn2 , n3 , n1 i is given by ξ = hn3 , n1 i.\n",
      "a context tree t = (v, e) with nodes v and edges e is a partition\n",
      "tree over all contexts of s. each node i ∈ v in the context tree\n",
      "corresponds to a context si . if node i is the ancestor of node j then\n",
      "sj ⊂ si . initially the context tree t only contains a root node\n",
      "with the most general context. every time a new item is consumed,\n",
      "the active leaf node is split into a number of subsets, which then\n",
      "become nodes in the tree. this construction results in a variableorder markov model. figure 2 illustrates a simple ct with some\n",
      "sequences over an item set hn1 , n2 , n3 i. each node in the ct corresponds to a context. for instance, the node hn1 i represents the\n",
      "context with all sequences end with item n1 .\n",
      "\n",
      "figure 2: an example context tree. for the sequence s = hn2 , n3 , n1 i,\n",
      "nodes in red-dashed are activated.\n",
      "\n",
      "3.2 context tree for recommendation\n",
      "\n",
      "for each context si , an expert µi is associated in order to compute\n",
      "the estimated probability p(nt+1 |st ) of the next item nt+1 under\n",
      "this context. a user’s browsing history st is matched to the ct and\n",
      "identifies a path of matching nodes (see figure 2). all the experts\n",
      "associated with these nodes are called active. the set of active\n",
      "experts a(st ) = {µi : ξi ≺ st } is the set of experts µi associated\n",
      "to contexts si = {s : ξi ≺ st } such that ξi are suffix of st . a(st )\n",
      "is responsible for the prediction for st .\n",
      "\n",
      "3.2.1\n",
      "\n",
      "expert model\n",
      "\n",
      "the standard way for estimating the probability p(nt+1 |st ), as proposed by [5], is to use a dirichlet-multinomial prior for each expert\n",
      "µi . the probability of viewing an item x depends on the number of\n",
      "times αxt the item x has been consumed when the expert is active\n",
      "until time t. the corresponding marginal probability is:\n",
      "pi (nt+1 = x|st ) = p\n",
      "\n",
      "αxt + α0\n",
      "αjt + α0\n",
      "\n",
      "(1)\n",
      "\n",
      "j ∈n\n",
      "\n",
      "where α0 is the initial count of the dirichlet prior\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "26\n",
      "\n",
      "\f",
      "3.2.2\n",
      "\n",
      "combining experts to prediction\n",
      "\n",
      "when making recommendation for a sequence st , we first identify\n",
      "the set of contexts and active experts that match the sequence. the\n",
      "predictions given by all the active experts are combined by mixing\n",
      "the recommendations given by them:\n",
      "x\n",
      "p(nt+1 = x|st ) =\n",
      "ui (st )pi (nt+1 = x|st )\n",
      "(2)\n",
      "\n",
      "in their old contexts. it allows the model to make predictions using more complex contexts as more data is acquired so that old and\n",
      "new knowledge can be elegantly combined. for new knowledge\n",
      "or patterns added to an established ct, they can immediately be\n",
      "identified through context matching. this context organization and\n",
      "context matching mechanism help new patterns to be recognized to\n",
      "adapt to changing environments.\n",
      "\n",
      "i∈a(st )\n",
      "\n",
      "the mixture coefficient ui (st ) of expert µi is computed in eq. 3\n",
      "using the weight wi ∈ [0, 1]. weight wi is the probability that\n",
      "the chosen recommendation stops at node i given that the it can be\n",
      "generated by the first i experts, and it can be updated in using eq.5.\n",
      "( q\n",
      "wi j:sj ⊂si (1 − wj ), if st ∈ si\n",
      "(3)\n",
      "ui (st ) =\n",
      "0,\n",
      "otherwise\n",
      "the combined prediction of the first i experts is defined as qi and\n",
      "it can be computed using the recursion in eq. 4. the recursive\n",
      "construction that estimates, for each context at a certain depth i,\n",
      "whether it makes better prediction than the combined prediction\n",
      "qi−1 from depth i − 1.\n",
      "qi = wi pi (nt+1 = x|st ) + (1 − wi )qi−1\n",
      "\n",
      "(4)\n",
      "\n",
      "the weights are updated by taking into account the success of a\n",
      "recommendation. when a user consumes a new item x, we update\n",
      "the weights of the active experts corresponding to the suffix ending\n",
      "before x according to the probability qi (x) of predicting x sequentially via bayes’ theorem. the weights are updated in closed form\n",
      "in eq. 5, and a detailed derivation can be found in [5].\n",
      "wi0 =\n",
      "\n",
      "3.2.3\n",
      "\n",
      "wi pi (nt+1 = x|st )\n",
      "qi (x)\n",
      "\n",
      "(5)\n",
      "\n",
      "ct recommender algorithm\n",
      "\n",
      "the whole recommendation process first goes through all users’ activity sequences over time incrementally to build the ct; the local\n",
      "experts and weights updated using equations 1 and 5 respectively.\n",
      "as users browse more contents, more contexts and paths are added\n",
      "and updated, thus building a deeper, more complete ct. the recommendation for an activity or context in a sequence is generated\n",
      "using eq. 2 continuously as experts and weights are updated. at\n",
      "the same time, a pool of candidate items is maintained through a\n",
      "dynamically evolving context tree. as new items are added, new\n",
      "branches are created. at the same time, nodes corresponding to old\n",
      "items are removed as soon as they disappear from the current pool.\n",
      "the ct recommender is a mixture model. on the one hand, the\n",
      "prediction p(nt+1 = x|st ) is a mixture of the predictions given\n",
      "by all the activated experts along the activated path so that it’s a\n",
      "mixtures of local experts or a mixture of variable order markov\n",
      "models whose oder are defined by context depths. on the other\n",
      "hand, one path in a ct can be constructed or updated by multiple\n",
      "users so that it’s a mixture of users’ preferences.\n",
      "\n",
      "3.3\n",
      "\n",
      "adaptation analysis\n",
      "\n",
      "our hypothesis, which is validated in later experiments, is that the\n",
      "ct recommender can be applied elegantly to domains where adaptation and timeliness are of concern. two properties of the ct\n",
      "methods are crucial to the goal. first, the model parameter learning process and recommendations generated are online such that\n",
      "the model adapts continuously to a dynamic environment. second,\n",
      "adaptability can be achieved by the ct structure itself as knowledge is organized and activated by context. new items or paths are\n",
      "recognized in new contexts, whereas old items can still be accessed\n",
      "\n",
      "3.4 complexity analysis\n",
      "\n",
      "learning ct uses the recursive update defined in eq. 4 and recommendations are generated by weighting the experts’ predictions\n",
      "along the activated path given by eq. 2. for trees of depth d, the\n",
      "time complexity of model learning and prediction for a new observation are both o(d). for input sequence of length t , the updating and recommending complexity are o(m 2 ), where m =\n",
      "min(d, t ). space complexity in the worst case is exponential to\n",
      "the depth of the tree. however, as we do not generate branches\n",
      "unless the sequence occurs in the input, we achieve a much lower\n",
      "bound determined by the total size of the input. so the space complexity is o(n ), where n is the total number of observations.\n",
      "compared with the way that markov models are learned, in which\n",
      "the whole transition matrix needs to be learned simultaneously, the\n",
      "space efficiency of ct offers us an advantage for model learning.\n",
      "for tasks that involve very long sequences, we can limit the depth\n",
      "d of the ct for space and time efficiency.\n",
      "\n",
      "4.\n",
      "\n",
      "dataset and problem analysis\n",
      "\n",
      "4.1 dataset description\n",
      "\n",
      "in this paper, we work with recommending discussion forum threads\n",
      "to mooc students. a forum thread can be updated frequently and\n",
      "it contains multiple posts and comments within the topic. as we\n",
      "mentioned before that the challenge is adapting to drifting user\n",
      "preferences and evolving forum threads as a course progresses. for\n",
      "the experiments elaborated in the following section, we use forum\n",
      "viewing data from three courses offered by école polytechnique\n",
      "fédérale de lausanne on coursera. these three courses include\n",
      "the first offering of “digital signal processing”, the third offering of “functional program design in scala”, and the first offering of “’reactive programming’. they are referred to course 1,\n",
      "course 2 and course 3. some discussion forum statistics for the\n",
      "three courses are given in table 1. from the number of forum\n",
      "participants, forum threads, and thread views, we can see that the\n",
      "course scale increase from course 1 to course 3. a student on\n",
      "moocs often accesses course forums many times during the span\n",
      "of a mooc. each time the threads she views are tracked as one\n",
      "visit session by the web browser. the total number of visit sessions\n",
      "and the average session lengths for three courses are presented in\n",
      "table 1. the length of a session is the number of threads she viewed\n",
      "within a visit session. the thread viewing sequences corresponding to these regular visit sessions are called separated sequences\n",
      "in our later experiments and they treat threads in one visit session\n",
      "as one sequence. models built using separated sequences try to\n",
      "catch short-term patterns within one visit session and we do not\n",
      "differentiate the patterns from different students. another setting,\n",
      "called combined sequences, concatenates all of a student’s visit sessions into one longer sequence so that models built using combined\n",
      "sequences try to learn long-term patterns across students. the average length of combined sequences is the average session length\n",
      "times the average number of sessions per student. from course 1\n",
      "to course 3, average lengths for separated and combined sequences\n",
      "both increase.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "27\n",
      "\n",
      "\f",
      "# of forum participants\n",
      "# of forum threads\n",
      "# of thread views\n",
      "# of sessions\n",
      "avg. session length\n",
      "avg. # of sessions per student\n",
      "\n",
      "course 1 course 2 course 3\n",
      "5,399\n",
      "12,384\n",
      "13,914\n",
      "1,116\n",
      "1,646\n",
      "2,404\n",
      "130,093 379,456 777,304\n",
      "19,892\n",
      "40,764\n",
      "30,082\n",
      "6.5\n",
      "9\n",
      "25.8\n",
      "3.7\n",
      "3.3\n",
      "2.2\n",
      "\n",
      "table 1: course forum statistics for three datasets.\n",
      "another important issue that we can discover from the statistics is\n",
      "that thread viewing data available for sequential recommendation is\n",
      "very sparse. for example in course 1, the average session length is\n",
      "6.5 and the number of threads is around 1116. then the complete\n",
      "space to be explored will be 11166.5 , which is much larger than\n",
      "the size of observations (130,093 thread views). the similar data\n",
      "sparsity issue is even more severe in the other two datasets.\n",
      "\n",
      "4.2\n",
      "\n",
      "forum thread view pattern\n",
      "\n",
      "next, we study the thread viewing pattern which highlights the significance of adaptation issues for thread recommendation. figure\n",
      "3 illustrates the distribution of thread views against freshness for\n",
      "three courses. the freshness of an item is defined as the relative\n",
      "creation order of all items that have been created so far. for example, when a student views a thread tm which is the m-th thread\n",
      "created in the currently existing pool of n threads, then freshness\n",
      "of tm is defined as:\n",
      "m\n",
      "(6)\n",
      "f reshness =\n",
      "n\n",
      "we can see from figure 3 that there is a sharp trend that the new\n",
      "forum threads are viewed much more frequently than the old ones\n",
      "for all three courses. it is mainly due to the fact that fresh threads\n",
      "are closely relevant to the current course progress. moreover, fresh\n",
      "threads can also supersede the contents in some old ones to be\n",
      "viewed. this tendency to view fresh items leads to drifting user\n",
      "preferences. such drifting preferences, coupled with the evolving nature of forum contents, requires recommendations adaptive\n",
      "to drifting or recent preferences.\n",
      "\n",
      "old. in general, sequential patterns are observed more often within\n",
      "specific threads as some specific follow-up threads might be related\n",
      "and useful to the one that you are viewing. so the patterns learned\n",
      "could be used to guide your forum browsing process. on the contrary, sequential patterns on general threads are relatively random\n",
      "and imperceptible.\n",
      "general threads\n",
      "“using gnu octave”\n",
      "“any one from india??”\n",
      "“where is everyone from?\n",
      "“numerical examples in pdf”\n",
      "“how to get a certificate”\n",
      "\n",
      "specific threads\n",
      "“homework day 1 / question 9”\n",
      "“quiz for module 4.2”\n",
      "“quiz -1 question 04”\n",
      "‘homework 3, question 11”\n",
      "“week 1: q10 gema problem”\n",
      "\n",
      "table 2: sample thread titles of general and specific threads.\n",
      "\n",
      "5. results and evaluation\n",
      "\n",
      "in this section, we compare the proposed ct method against various baseline methods in both non-sequential and sequential settings. the results show that the ct recommender performs better\n",
      "than other methods under different setting for all three moocs\n",
      "considered. through the adaptation analysis, we validate our hypothesis that the superior performance of ct recommender comes\n",
      "from the adaptation power to drifting preferences and trendy patterns in the domain. in the end, a regularization technique for ct,\n",
      "called partial context matching (pct), is introduced. it is demonstrated that pct helps better generalize among sequence patterns\n",
      "and further boost performance.\n",
      "\n",
      "5.1 baseline methods\n",
      "\n",
      "5.1.1 non-sequential methods\n",
      "\n",
      "figure 3: thread viewing activities against freshness\n",
      "\n",
      "matrix factorization methods proposed by [23, 22] are the state-ofthe-art for moocs course content recommendation. besides the\n",
      "user-based mf given in [23], we also consider item-based mf that\n",
      "generates recommendations based on the similarity of the latent\n",
      "item features learned from standard mf. in our case, each entry in\n",
      "the user-item matrix of mf contains the number of times a student\n",
      "views a thread. we also test a version where the matrix had a 1 for\n",
      "any number of views, but the performance was not as good, so the\n",
      "development of this version was not taken any further. mf models considered here are updated periodically (week-by-week). to\n",
      "enable a fair comparison against non-sequential matrix factorization techniques, we implemented versions where the ct model is\n",
      "updated at fixed time intervals, equal to those of the mf models.\n",
      "in the “one-shot ct” version, we compute the ct recommendations for each user based on the data available at the time of the\n",
      "model update, and the user then receives these same recommendations at every future time step until the next update. this mirrors\n",
      "the conditions of user-based mf. to compare with item-based mf,\n",
      "the “slow-update ct” version updates the recommendations, but\n",
      "not the model, at each time point based on the sequential forum\n",
      "viewing information available at that time.\n",
      "\n",
      "a further investigation through those views on old threads leads us\n",
      "to a classification of threads into two categories: general threads\n",
      "and specific threads. some titles of the general and specific threads\n",
      "are listed in table 2. we could see the clear difference between\n",
      "these two classes of threads as the general ones corresponds to\n",
      "broad topics and specific ones are related to detailed course contents or exercises. we also found that only a very small part of the\n",
      "old threads are still rather active to be viewed and they are mostly\n",
      "general ones. different from general threads, specific threads that\n",
      "subject to a fine timeliness are viewed very few times after they get\n",
      "\n",
      "sequential methods update model parameters and recommendations continuously as items are consumed. the first two simple\n",
      "methods are based on the observation and heuristic that fresh threads\n",
      "are viewed much frequently than old ones. fresh_1 recommends\n",
      "the last 5 updated threads, and fresh_2 recommends the last 5 created threads. another baseline method, referred as popular, recommends the top 5 threads among the last 100 threads viewed before\n",
      "the current one. we also consider an online version of mf [10] that\n",
      "\n",
      "distribution of thread views against freshness\n",
      "\n",
      "0.3\n",
      "\n",
      "probability\n",
      "\n",
      "0.25\n",
      "\n",
      "course 1\n",
      "course 2\n",
      "course 3\n",
      "\n",
      "0.2\n",
      "0.15\n",
      "0.1\n",
      "0.05\n",
      "0\n",
      "0\n",
      "\n",
      "0.2\n",
      "\n",
      "0.4\n",
      "\n",
      "0.6\n",
      "\n",
      "0.8\n",
      "\n",
      "1\n",
      "\n",
      "freshness\n",
      "\n",
      "5.1.2 sequential methods\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "28\n",
      "\n",
      "\f",
      "40%\n",
      "\n",
      "60%\n",
      "\n",
      "30%\n",
      "20%\n",
      "10%\n",
      "0%\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "50%\n",
      "40%\n",
      "\n",
      "overall perforamance (course 2)\n",
      "\n",
      "60%\n",
      "\n",
      "ct\n",
      "slow-update ct\n",
      "one-shot ct\n",
      "item-base mf\n",
      "user-based mf\n",
      "\n",
      "succ@5ahead\n",
      "\n",
      "50%\n",
      "\n",
      "overall perforamance (course 1)\n",
      "ct\n",
      "slow-update ct\n",
      "one-shot ct\n",
      "item-base mf\n",
      "user-based mf\n",
      "\n",
      "succ@5ahead\n",
      "\n",
      "succ@5ahead\n",
      "\n",
      "60%\n",
      "\n",
      "30%\n",
      "20%\n",
      "10%\n",
      "0%\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "week\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "50%\n",
      "40%\n",
      "\n",
      "overall perforamance (course 3)\n",
      "ct\n",
      "slow-update ct\n",
      "one-shot ct\n",
      "item-base mf\n",
      "user-based mf\n",
      "\n",
      "30%\n",
      "20%\n",
      "10%\n",
      "0%\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "week\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "week\n",
      "\n",
      "figure 4: overall performance comparison of ct and non-sequential methods\n",
      "is currently the state-of-the-art sequential recommendation method,\n",
      "referred to “online-mf”, in which the corresponding latent factor\n",
      "of the item i and user u are updated when a new observation rui\n",
      "arrive. the model optimization is implemented based on elementwise alternating least squares. the number of latent factors is\n",
      "tuned to be 15, 20, 25 for three datasets, and the regularization parameter is set as 0.01. moreover, the weight of a new observation is\n",
      "the same as old ones during optimization for achieving the best performance. furthermore, the proposed ct recommender refers to\n",
      "the full context tree algorithm with a continuously updated model.\n",
      "\n",
      "5.2\n",
      "\n",
      "5.2.1\n",
      "\n",
      "performance and adaptation analysis\n",
      "evaluation metrics\n",
      "\n",
      "in our case, all methods recommend top-5 threads each time. two\n",
      "evaluation metrics are adopted in the following experiments:\n",
      "• succ@5: the mean average precision (map) of predicting\n",
      "the immediately next thread view in a sequence.\n",
      "• succ@5ahead: the map of predicting the future thread\n",
      "views within a sequence. in this case, a recommendation\n",
      "is successful even if it is viewed later in a sequence.\n",
      "\n",
      "5.2.2\n",
      "\n",
      "comparison of non-sequential methods\n",
      "\n",
      "figure 4 shows the performance comparison between different versions of methods based on mf and ct on three datasets. “ct”\n",
      "is the sequential method with a continuously updated model, and\n",
      "all other methods figure 4 are non-sequential versions. combined\n",
      "sequences are used for the ct methods here to have a parallel comparison against mf. we found that a small value of the depth limit\n",
      "of the cts hurts performances, yet a very large depth limit does\n",
      "not increase performance at the cost of computation and memory.\n",
      "through experiments, we tune depths empirically and set them as\n",
      "15, 20, 30 for three datasets.\n",
      "among non-sequential methods, one-shot ct and user-based mf\n",
      "perform the worst for all three courses, which means that recommending the same content for the next week without any sequence\n",
      "consideration is ineffective. slow-update ct performs consistently\n",
      "the best among non-sequential methods, and it proves that adapting\n",
      "recommendations through context tree helps boost performance although the model itself is not updated continuously. compared\n",
      "to slow-update ct, item-based mf performs much worse. they\n",
      "both update model parameters periodically and the recommendations are adjusted given the current observation. however, using\n",
      "the contextual information within a sequence and the corresponding prediction experts of slow-update ct are much more powerful\n",
      "than just using latent item features of item-base mf. moreover, we\n",
      "can clearly see that the normal ct with continuous update outperforms all other non-sequential methods by a large margin for three\n",
      "datasets. it means that drifting preferences need to be followed\n",
      "though continuous and adaptive model update, so sequential methods are better choices. next, we focus on sequential methods, and\n",
      "\n",
      "we validate our hypothesis that the ct model has superior performances because it better handles drifting user preferences.\n",
      "\n",
      "5.2.3\n",
      "\n",
      "comparison of sequential methods\n",
      "\n",
      "the results presented in table 3 show the performance of the full\n",
      "ct recommender compared with other sequential baseline methods under different settings and evaluation metrics. each result\n",
      "tuple contains the performance on the three datasets. we also consider a tail performance metric, referred to personalized evaluation,\n",
      "where the most popular threads (20, 30, and 40 for three courses)\n",
      "are excluded from recommendations. the depth limits of cts using separated sequences are set to 8, 10, and 15 for three courses.\n",
      "we notice that the online-mf method, with continuous model update, performs much worse compared with the ct recommender\n",
      "for all three datasets. this result shows that matrix factorization,\n",
      "which is based on interpolation over the user-item matrix, is not\n",
      "sensitive enough to rapidly drifting preferences with limited observations. the performances of two versions of the fresh recommender are comparable with online-mf, and fresh_1 even outperforms online-mf in many cases, especially for succ@5ahead.\n",
      "it means that simply recommending fresh items even does a better job than online-mf for this recommendation task with drifting\n",
      "preferences. we can see that the ct recommender outperforms\n",
      "all other sequential methods under various settings, except for using non-personalized succ@5ahead for course 2. the popular\n",
      "recommender is indeed a very strong contender when using nonpersonalized evaluation since there is a bias that students can click a\n",
      "“top threads” tag from user interface to view popular threads which\n",
      "are similar to the ones given by popular recommender. from the\n",
      "educational perspective, the setting using separated sequences and\n",
      "personalized evaluation is the most interesting as it reflects shotterm visiting patterns within a session over those specific and less\n",
      "popular forum threads. we could see from the upper right part of\n",
      "table 3 that the ct recommender outperforms all other methods by\n",
      "a large margin under this setting.\n",
      "\n",
      "ct\n",
      "online-mf\n",
      "popular\n",
      "fresh_1\n",
      "fresh_2\n",
      "ct\n",
      "online-mf\n",
      "popular\n",
      "fresh_1\n",
      "fresh_2\n",
      "\n",
      "non-personalized\n",
      "personalized\n",
      "succ@5 succ@5ahead succ@5 succ@5ahead\n",
      "separated sequences\n",
      "[25, 23, 21]% [48, 53, 52]% [19, 14, 16]% [41, 37, 42]%\n",
      "[15, 12, 8]% [33, 29, 23]% [10, 7 ,6 ]% [27, 25, 20]%\n",
      "[15, 20, 16]% [40, 61, 51]% [9, 8 ,8 ]% [34, 31, 36]%\n",
      "[12, 14, 10]% [37, 43, 41]% [10, 10, 8]% [33, 31, 37]%\n",
      "[9, 8, 6]% [31, 31, 29]% [8, 7, 6 ]% [30, 30, 28]%\n",
      "combined sequences\n",
      "[21, 20, 20]% [55, 55, 56]% [16, 13, 14]% [46, 39, 46]%\n",
      "[9, 8, 7]% [34, 27, 23]%\n",
      "[7,6,6]%\n",
      "[29, 24, 20]%\n",
      "[13, 14, 14]% [52, 62, 58]% [9, 8, 7]% [45, 36, 43]%\n",
      "[10, 12, 9]% [48, 44, 44]% [8, 9, 8]% [44, 34, 42]%\n",
      "[7, 6, 6]% [43, 34, 32]% [6, 6, 6]% [42, 32, 31]%\n",
      "\n",
      "table 3: performance comparison of sequential methods\n",
      "\n",
      "5.2.4\n",
      "\n",
      "adaptation comparison\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "29\n",
      "\n",
      "\f",
      "ct\n",
      "online-mf\n",
      "\n",
      "0.8\n",
      "0.6\n",
      "0.4\n",
      "0.2\n",
      "0\n",
      "0\n",
      "\n",
      "0.2\n",
      "\n",
      "average cdf of recommendation freshness (course 2)\n",
      "\n",
      "0.4\n",
      "\n",
      "0.6\n",
      "\n",
      "0.8\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "average cdf of recommendation freshness (course 3)\n",
      "\n",
      "ct\n",
      "online-mf\n",
      "\n",
      "recommended probability\n",
      "\n",
      "1\n",
      "\n",
      "recommended probability\n",
      "\n",
      "recommended probability\n",
      "\n",
      "average cdf of recommendation freshness (course 1)\n",
      "\n",
      "0.8\n",
      "0.6\n",
      "0.4\n",
      "0.2\n",
      "0\n",
      "0\n",
      "\n",
      "0.2\n",
      "\n",
      "freshness\n",
      "\n",
      "0.4\n",
      "\n",
      "0.6\n",
      "\n",
      "0.8\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "ct\n",
      "online-mf\n",
      "\n",
      "0.8\n",
      "0.6\n",
      "0.4\n",
      "0.2\n",
      "0\n",
      "0\n",
      "\n",
      "0.2\n",
      "\n",
      "freshness\n",
      "\n",
      "0.4\n",
      "\n",
      "0.6\n",
      "\n",
      "0.8\n",
      "\n",
      "1\n",
      "\n",
      "freshness\n",
      "\n",
      "figure 5: distribution of recommendation freshness of ct and online-mf\n",
      "0.4\n",
      "\n",
      "ct\n",
      "online-mf\n",
      "\n",
      "0.2\n",
      "0.1\n",
      "0\n",
      "0\n",
      "\n",
      "0.4\n",
      "\n",
      "0.3\n",
      "\n",
      "probability\n",
      "\n",
      "probability\n",
      "\n",
      "0.3\n",
      "\n",
      "p (success|f reshness) for course 2\n",
      "ct\n",
      "online-mf\n",
      "\n",
      "0.2\n",
      "0.1\n",
      "\n",
      "0.2\n",
      "\n",
      "0.4\n",
      "\n",
      "0.6\n",
      "\n",
      "0.8\n",
      "\n",
      "1\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "freshness\n",
      "\n",
      "p (success|f reshness) for course 3\n",
      "ct\n",
      "online-mf\n",
      "\n",
      "0.3\n",
      "\n",
      "probability\n",
      "\n",
      "0.4\n",
      "\n",
      "p (success|f reshness) for course 1\n",
      "\n",
      "0.2\n",
      "0.1\n",
      "\n",
      "0.2\n",
      "\n",
      "0.4\n",
      "\n",
      "0.6\n",
      "\n",
      "0.8\n",
      "\n",
      "1\n",
      "\n",
      "0\n",
      "0\n",
      "\n",
      "freshness\n",
      "\n",
      "0.2\n",
      "\n",
      "0.4\n",
      "\n",
      "0.6\n",
      "\n",
      "0.8\n",
      "\n",
      "1\n",
      "\n",
      "freshness\n",
      "\n",
      "figure 6: conditional success rate of ct and online-mf\n",
      "after seeing the superior performance of the ct recommender, we\n",
      "move to an insight analysis of the results. to be specific, we compare ct and online-mf in terms of their adaptation capabilities\n",
      "to new items. figure 5 illustrates the cumulative density function (cdf) of the threads recommended by different methods against\n",
      "thread freshness. we can see that the cdfs of ct increase sharply\n",
      "when thread freshness increases, which means that the probability\n",
      "of recommending fresh items is high compared to online-mf. in\n",
      "other words, ct recommends more fresh items than online-mf. as\n",
      "we mentioned before that a large portion of fresh threads are specific ones, instead of general ones, so ct recommends more specific and trendy threads to students while methods based on matrix\n",
      "factorization recommend more popular and general threads.\n",
      "other than the quantity of recommending fresh and specific threads,\n",
      "the quality is crucial as well. figure 6 shows the conditional success rate p (success|f reshness) across different degrees of freshness for three courses. p (success|f reshness) is defined as the\n",
      "fraction of the items successfully recommended given the item freshness. for instance, if an item with freshness 0.5 is viewed 100 times\n",
      "throughout a course, then p (success|f reshness = 0.5) = 0.25\n",
      "means it is among the top 5 recommended items 25 times. as\n",
      "the freshness increases, the conditional success rate of online-mf\n",
      "drops speedily while the ct method keeps a solid and stable performance. it is significant that ct outperforms online-mf by a\n",
      "large margin when freshness is high, in other words, it is particularly strong for recommending fresh items. fresh items are often\n",
      "not popular in terms of the total number of views at the time point\n",
      "of recommendation. so identifying fresh items accurately implies\n",
      "a strong adaptation power to new and evolving forum visiting patterns. the analysis above validates our hypothesis that the ct recommender can adapt well to drifting user preferences. another\n",
      "conclusion drawn from figure 6 is that the performance of ct is as\n",
      "good as online-mf for items with low freshness. this is because\n",
      "that the context organization and context matching mechanism help\n",
      "old items to be identifiable though old contexts. to conclude, ct is\n",
      "flexible at combining old knowledge and new knowledge so that it\n",
      "performances well for items with various freshness, especially for\n",
      "fresh ones with drifting preferences.\n",
      "\n",
      "5.3\n",
      "\n",
      "partial context matching (pct)\n",
      "\n",
      "at last, we introduce another technique, built on top of the standard ct, to generalize to new sequence patterns and further boost\n",
      "the recommendation performance. the standard ct recommender\n",
      "adopts a complete context matching mechanism to identify active\n",
      "experts for a sequence s. that is, active experts of s come exactly\n",
      "from the set of suffixes of s. we design a partial context matching (pct) mechanism where active experts of a sequence are not\n",
      "constrained by exact suffixes, yet they can be those very similar\n",
      "ones. two reasons bring us to design the pct mechanism for context tree learning. first, pct mechanism is a way of adding regularization. sequential item consumption process does not have to\n",
      "follow exactly the same order, and slightly different sequences are\n",
      "also relevant for both model learning and recommendation generation. second, the data sparsity issue we discussed before for sequential recommendation setting can be solved to some extent by\n",
      "considering similar contexts for learning model experts. the way\n",
      "pct does aims to activate more experts to train the model, and to\n",
      "generate recommendations from a mixture of similar contexts.\n",
      "we will focus on a skip operation that we add on top of the standard\n",
      "ct recommender. some complex operations, like swapping item\n",
      "orders, are also tested, but they do not generate better performance.\n",
      "for a sequence hsp , . . . , s1 i with length p, the skip operation generates p candidate partially matched contexts that skip one sk for\n",
      "k ∈ [1 . . . p]. all the contexts on the paths from root to partially\n",
      "matched contexts are activated. for example, the path to context\n",
      "hn2 , n1 i can be activated from the context hn2 , n3 , n1 i by the skipping n3 . however, for each partially matched context, there may\n",
      "not exist a fully matched path in the current context tree. in this\n",
      "case, for each partially matched context, we identify the longest\n",
      "path that corresponds it with length q. if q/p is larger than some\n",
      "threshold t, we update experts on this paths and use them to generate recommendations for the current observation. predictions from\n",
      "multiple paths are combined by averaging the probabilities.\n",
      "\n",
      "pct-0.5\n",
      "pct-0.6\n",
      "pct-0.7\n",
      "pct-0.8\n",
      "pct-0.9\n",
      "\n",
      "success@5\n",
      "[+0.4, +0.6, +0.2]%\n",
      "[+0.5, +0.8, +0.3]%\n",
      "[+0.7, +0.9, +0.5]%\n",
      "[+0.8, +1.1, +0.6]%\n",
      "[+1.0, +1.4, +0.7]%\n",
      "\n",
      "success@5ahead\n",
      "[+0.8, +0.9, +0.4]%\n",
      "[+1.1, +1.3, +0.5]%\n",
      "[+1.6, +1.9, +0.7]%\n",
      "[+1.9, +2.4, +1.0]%\n",
      "[+2.0, +2.7, +1.3]%\n",
      "\n",
      "ratio\n",
      "[4.9, 4.5, 3.3]\n",
      "[4.4, 4.1, 2.9]\n",
      "[3.7, 3.2, 2.5]\n",
      "[3.2, 2.9, 2.1]\n",
      "[2.4, 2.2, 1.4]\n",
      "\n",
      "table 4: performance comparison of pct against ct for three courses\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "30\n",
      "\n",
      "\f",
      "table 4 shows the performance of applying pct for both model\n",
      "update and recommendation with threshold t (pct-t). results are\n",
      "compared with the full ct recommender with separated sequences\n",
      "and non-personalized evaluation. for cases where the threshold is\n",
      "smaller than 0.5, we sometimes obtain negative results since partially matched contexts are too short to be relevant. the “ratio”\n",
      "column is the ratio of the number of updated paths in pct compared with standard ct. we can see that pct updates more paths\n",
      "and it offers us consistent performance boosts at the cost of computation.\n",
      "\n",
      "6. conclusion and future work\n",
      "\n",
      "in this paper, we formulate the mooc forum recommendation\n",
      "problem as a sequential decision problem. through experimental\n",
      "analysis, both performance boost and adaptation to drifting preferences are achieved using a new method called context tree. furthermore, a partial context matching mechanism is studied to allow a\n",
      "mixture of different but similar paths. as a future work, exploratory\n",
      "algorithms are interesting to be tried. as exploring all options for\n",
      "all contexts are not feasible, we consider to explore only those top\n",
      "options from similar contexts. deploying the ct recommender in\n",
      "some moocs for online evaluation would be precious to obtain\n",
      "more realistic evaluation.\n",
      "\n",
      "7. references\n",
      "\n",
      "[1] j. abernethy, k. canini, j. langford, and a. simma. online\n",
      "collaborative filtering. university of california at berkeley,\n",
      "tech. rep, 2007.\n",
      "[2] r. begleiter, r. el-yaniv, and g. yona. on prediction using\n",
      "variable order markov models. journal of artificial\n",
      "intelligence research, pages 385–421, 2004.\n",
      "[3] r. m. bell, y. koren, and c. volinsky. the bellkor 2008\n",
      "solution to the netflix prize. statistics research department\n",
      "at at&t research, 2008.\n",
      "[4] g. bonnin, a. brun, and a. boyer. a low-order markov\n",
      "model integrating long-distance histories for collaborative\n",
      "recommender systems. in international conference on\n",
      "intelligent user interfaces, pages 57–66. acm, 2009.\n",
      "[5] c. dimitrakakis. bayesian variable order markov models. in\n",
      "international conference on artificial intelligence and\n",
      "statistics, pages 161–168, 2010.\n",
      "[6] y. ding and x. li. time weight collaborative filtering. in\n",
      "acm international conference on information and\n",
      "knowledge management, pages 485–492. acm, 2005.\n",
      "[7] y. ding, x. li, and m. e. orlowska. recency-based\n",
      "collaborative filtering. in australasian database conference,\n",
      "pages 99–107. australian computer society, inc., 2006.\n",
      "[8] f. garcin, c. dimitrakakis, and b. faltings. personalized\n",
      "news recommendation with context trees. in acm\n",
      "conference on recommender systems, pages 105–112.\n",
      "acm, 2013.\n",
      "[9] f. garcin, b. faltings, o. donatsch, a. alazzawi, c. bruttin,\n",
      "and a. huber. offline and online evaluation of news\n",
      "recommender systems at swissinfo.ch. in acm conference\n",
      "on recommender systems, pages 169–176. acm, 2014.\n",
      "[10] x. he, h. zhang, m.-y. kan, and t.-s. chua. fast matrix\n",
      "factorization for online recommendation with implicit\n",
      "feedback. in international acm conference on research and\n",
      "development in information retrieval, volume 16, 2016.\n",
      "[11] y. koren. collaborative filtering with temporal dynamics.\n",
      "communications of the acm, 53(4):89–97, 2010.\n",
      "\n",
      "[12] s. s. kozat, a. c. singer, and g. c. zeitler. universal\n",
      "piecewise linear prediction via context trees. ieee\n",
      "transactions on signal processing, 55(7):3730–3745, 2007.\n",
      "[13] l. li, w. chu, j. langford, and r. e. schapire. a\n",
      "contextual-bandit approach to personalized news article\n",
      "recommendation. in international conference on world\n",
      "wide web, pages 661–670. acm, 2010.\n",
      "[14] e. liebman, m. saar-tsechansky, and p. stone. dj-mc: a\n",
      "reinforcement-learning agent for music playlist\n",
      "recommendation. in international conference on\n",
      "autonomous agents and multiagent systems, pages 591–599.\n",
      "ifaamas, 2015.\n",
      "[15] n. n. liu, m. zhao, e. xiang, and q. yang. online\n",
      "evolutionary collaborative filtering. in acm conference on\n",
      "recommender systems, pages 95–102. acm, 2010.\n",
      "[16] j. mairal, f. bach, j. ponce, and g. sapiro. online learning\n",
      "for matrix factorization and sparse coding. journal of\n",
      "machine learning research, 11(jan):19–60, 2010.\n",
      "[17] g. shani, r. i. brafman, and d. heckerman. an mdp-based\n",
      "recommender system. in conference on uncertainty in\n",
      "artificial intelligence, pages 453–460. morgan kaufmann\n",
      "publishers inc., 2002.\n",
      "[18] a. srivihok and p. sukonmanee. e-commerce intelligent\n",
      "agent: personalization travel support agent using\n",
      "q-learning. in international conference on electronic\n",
      "commerce, pages 287–292. acm, 2005.\n",
      "[19] x. su and t. m. khoshgoftaar. a survey of collaborative\n",
      "filtering techniques. advances in artificial intelligence,\n",
      "2009:4, 2009.\n",
      "[20] x. wang, y. wang, d. hsu, and y. wang. exploration in\n",
      "interactive personalized music recommendation: a\n",
      "reinforcement learning approach. acm transactions on\n",
      "multimedia computing, communications, and applications,\n",
      "11(1):7, 2014.\n",
      "[21] f. m. willems, y. m. shtarkov, and t. j. tjalkens. the\n",
      "context-tree weighting method: basic properties. ieee\n",
      "transactions on information theory, 41(3):653–664, 1995.\n",
      "[22] d. yang, d. adamson, and c. p. rosé. question\n",
      "recommendation with constraints for massive open online\n",
      "courses. in acm conference on recommender systems,\n",
      "pages 49–56. acm, 2014.\n",
      "[23] d. yang, m. piergallini, i. howley, and c. rose. forum\n",
      "thread recommendation for massive open online courses. in\n",
      "educational data mining, 2014.\n",
      "[24] a. zimdars, d. m. chickering, and c. meek. using temporal\n",
      "data for making recommendations. in conference on\n",
      "uncertainty in artificial intelligence, pages 580–588.\n",
      "morgan kaufmann publishers inc., 2001.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "31\n",
      "\n",
      "\f",
      "analysis of problem-solving behavior in open-ended\n",
      "scientific-discovery game challenges\n",
      "aaron bauer\n",
      "\n",
      "awb@cs.washington.edu\n",
      "\n",
      "jeff flatten\n",
      "\n",
      "jflat06@cs.washington.edu\n",
      "\n",
      "zoran popović\n",
      "\n",
      "zoran@cs.washington.edu\n",
      "\n",
      "center for game science, computer science and engineering\n",
      "university of washington\n",
      "seattle, wa 98195, usa\n",
      "\n",
      "abstract\n",
      "\n",
      "problem-solving skills in creative, open-ended domains are both\n",
      "important and little understood. these domains are generally illstructured, have extremely large exploration spaces, and require\n",
      "high levels of specialized skill in order to produce quality solutions.\n",
      "we investigate problem-solving behavior in one such domain, the\n",
      "scientific-discovery game foldit. our goal is to discover differentiating patterns and understand what distinguishes high and low levels\n",
      "of problem-solving skill. to address the challenges posed by the\n",
      "scale, complexity, and ill-structuredness of foldit solver behavior\n",
      "data, we devise an iterative visualization-based methodology and use\n",
      "this methodology to design a concise, meaning-rich visualization of\n",
      "the problem-solving process in foldit. we use this visualization to\n",
      "identify key patterns in problem-solving approaches, and report how\n",
      "these patterns distinguish high-performing solvers in this domain.\n",
      "\n",
      "keywords\n",
      "\n",
      "problem solving; scientific-discovery games; visualization\n",
      "\n",
      "1.\n",
      "\n",
      "introduction\n",
      "\n",
      "as efforts in scalable online education expand, interest continues\n",
      "to increase in moving beyond small, highly constrained tasks, such\n",
      "as multiple choice or short answer questions, and incorporating\n",
      "creative, open-ended activities [7, 14]. existing research supports\n",
      "this move, showing that problem-based learning can enhance students’ problem-solving and metacognitive skills [11]. scaling such\n",
      "activities poses significant challenges, however, in terms of both assessment and feedback. it will be vital to devise scalable techniques\n",
      "not only to assess students’ final products, but also to understand\n",
      "their progress through complex and heterogeneous problem-solving\n",
      "spaces. these techniques will apply to a broad range of education\n",
      "settings, from purely online programs like udacity’s nanodegrees\n",
      "to more traditional settings where new standards like the common\n",
      "core emphasize strategic problem solving.\n",
      "a growing body of work has found that educational and serious\n",
      "games are fertile ground for assessing students’ capabilities and\n",
      "problem-solving skills [6, 10]. our work continues this general\n",
      "line of inquiry by examining creative, problem-solving behavior\n",
      "among players in the scientific-discovery game foldit. by modeling\n",
      "the functions of proteins, the workhorses of living cells, foldit\n",
      "challenges players, hereafter referred to as solvers, to resolve the\n",
      "shape of proteins as a 3d puzzle. these puzzles are completely\n",
      "open and often under-specified, making it a highly suitable setting\n",
      "in which to gain insight into student progress through complex\n",
      "solution spaces. in the foldit scientific-discovery community, the\n",
      "focus is on developing people from novices to experts that are\n",
      "eventually capable of solving protein structure problems that are\n",
      "\n",
      "currently unsolved by the scientific community. in fact, solutions\n",
      "produced in foldit have led to three results published in nature [3,\n",
      "5, 16]. foldit is an attractive learning space domain because its\n",
      "solvers are capable of contributing to state-of-the-art biochemistry\n",
      "results, and the vast majority of best performing solvers had no\n",
      "exposure to biochemistry prior to joining foldit community. hence,\n",
      "solver behavior in foldit represents development of highly effective\n",
      "problem-solving in an open-ended domain over long time horizons.\n",
      "in this work, we identify six strategic patterns employed by foldit\n",
      "solvers and show how these patterns differentiate between successful\n",
      "and less successful solvers. these patterns cover instances where\n",
      "solvers investigate multiple hypotheses, explore more greedily or\n",
      "more inquisitively, try to escape local optima, and make structured\n",
      "use of the manual or automated tools available in foldit.\n",
      "the aspects of the foldit environment that make it an attractive\n",
      "setting in which to study problem solving also present significant\n",
      "challenges. problems in foldit share many of the properties jonassen\n",
      "attributes to design problems, which they describe as “among the\n",
      "most complex and ill-structured kinds of problems that are encountered in practice” [13]. these properties include a vague goal with\n",
      "few constraints (in foldit, the goal is often entirely open-ended:\n",
      "find a good configuration of the protein), answers that are neither\n",
      "right or wrong, only better or worse, and limited feedback (in foldit,\n",
      "real-time feedback and solution evaluation are limited to a single\n",
      "numerical score corresponding to the protein’s current energy state,\n",
      "and solvers frequently must progress through many low-scoring\n",
      "states to reach a good configuration; more nuanced feedback from\n",
      "biochemists is sometimes available, but on a timescale of weeks).\n",
      "the ill-structured nature of problems posed in foldit necessarily\n",
      "deprives us of the structures, such as clear goal states and straightforward relationships between intermediate states and goal states,\n",
      "that typically form the basis of existing detailed and quantitative\n",
      "analyses of problem-solving behavior.\n",
      "the size and complexity of foldit’s problem space presents another\n",
      "major challenge. even though the logs of solver interactions consist\n",
      "only of regular snapshots of a solver’s current solution (along with\n",
      "attendant metadata), the record of a single solver’s performance on\n",
      "a given problem frequently consists of thousands of such snapshots\n",
      "(which in turn are just a sparse sampling of the actual solving process). furthermore, the nature of the solution state, the configuration\n",
      "of hundreds of components in continuous three-dimensional space,\n",
      "renders collapsing the state space by directly comparing solution\n",
      "states impractical. compounding the size of the problem space is\n",
      "the complexity of the actions available to foldit solvers. in addition\n",
      "to manual manipulation of the protein configuration, solvers can\n",
      "invoke various low-level automated optimization routines (some\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "32\n",
      "\n",
      "\f",
      "of which run until the solver terminates them) and place different\n",
      "kinds of constraints on the protein configuration (rubber bands in\n",
      "foldit parlance) that restrict its modification in a variety of ways.\n",
      "solvers can also deploy many of these tools programmatically via\n",
      "lua scripts called recipes. taken together these challenges of illstructuredness, size, and complexity threaten to make analysis of\n",
      "high-level problem-solving behavior in foldit intractable.\n",
      "to overcome these obstacles, we devise a visualization-based methodology capable of producing tractable representations of foldit solvers’\n",
      "problem-solving behavior while maintaining the key encodings necessary for analysis of high-level strategic behavior. a process of\n",
      "iterative summarization forms the core of this methodology, and\n",
      "ensures that the transformations applied to the raw data do not\n",
      "elide structures potentially relevant to understanding solvers’ unique\n",
      "strategic behavior. using this methodology, we examine solver activity logs from 11 foldit puzzles, representing 970 distinct solvers and\n",
      "nearly 3 million solution snapshots. leveraging metadata present\n",
      "in the solution snapshots, we represent solving behavior as a tree,\n",
      "and apply our methodology to visualize a summarized tree showing\n",
      "where they branched off to investigate multiple hypotheses, how\n",
      "they employed some of the automated tools available to them, and\n",
      "other salient problem-solving behavior. we use these depictions to\n",
      "determine key distinguishing features of this exploration process.\n",
      "we subsequently use these features to better understand the patterns\n",
      "of expert-level problem solving.\n",
      "our work focuses on the following research questions: (1) how\n",
      "can we visually represent an open-ended exploration towards a\n",
      "high-quality solution in a large, ill-structured problem space? (2)\n",
      "what are the key patterns of problem-solving behavior exhibited\n",
      "by individuals?, and (3) what are the key differences along these\n",
      "patterns between high-performing and lower-performing solvers in\n",
      "an open-ended domain like foldit? in addressing these questions we\n",
      "find that high-performing solvers explore the solution space more\n",
      "broadly. in particular, they pursue more hypotheses and actively\n",
      "avoid getting stuck in local minima. we also found that both highand lower-performing solvers have similar proportion of manual and\n",
      "automated tool actions, indicating that better performance on openended challenges stems from the quality of the action intermixing\n",
      "rather than aggregate quantity.\n",
      "\n",
      "2.\n",
      "\n",
      "related work\n",
      "\n",
      "while automated grading has mostly been explored for well-specified\n",
      "tasks where the correct answer has a straightforward and concise\n",
      "description, some previous work has developed techniques for more\n",
      "complex activities. some achieve scalability through a crowdsourcing framework such as udacity’s system for hiring external\n",
      "experts as project reviewers [14]. other work has demonstrated\n",
      "automated approaches that leverage machine learning to enable scalable grading of more complex assignments. for example, geigle et\n",
      "al. describe an application of online active learning to minimize the\n",
      "training set a human grader must produce [7] when automatically\n",
      "grading an assignment where students must analyze medical cases.\n",
      "our work does not focus on grading problem-solving behavior, but\n",
      "instead approaches the issue of scalability at a more fundamental\n",
      "level: understanding fine-grained problem-solving strategies and\n",
      "how they contribute to success in an open-ended domain.\n",
      "a robust body of prior work has addressed the challenge of both\n",
      "visualizing and gleaning insight from player activity in educational\n",
      "and serious games. andersen et al. developed playtracer, a general method for visualizing players’ progress through a game’s\n",
      "\n",
      "state space when a spatial relationship between the player and the\n",
      "virtual environment is not available [1]. wallner and kriglstein provide a thorough review of visualization-based analysis of gameplay\n",
      "data [21]. prior work has analyzed gameplay data without visualization as well. falakmasir et al. propose a data analysis pipeline\n",
      "for modeling player behavior in educational games. this system\n",
      "can produce a simple, interpretable model of in-game actions that\n",
      "can predict learning outcomes [6]. our work differs in its aims from\n",
      "this prior work. we do not seek to develop a general visualization\n",
      "technique, but instead to design and leverage a domain-specific\n",
      "visualization to analyze problem-solving behavior. we are also\n",
      "not predicting player behavior, nor modeling players in terms of\n",
      "low-level actions, but rather identifying higher-level strategy use.\n",
      "the work most similar to ours is that which focuses on problemsolving behavior, including both the long-running efforts in educational psychology to develop general theories and more recent\n",
      "work data-driven on understanding the problem-solving process.\n",
      "our formulation of solving behavior in foldit as a search through\n",
      "a problem space follows from classic information-processing theories of problem solving (e.g., [9, 19]). gick reviews research on\n",
      "both problem-solving strategies and the differences in strategy use\n",
      "between experts and novices [8]. our work complements the existing literature by focusing on understanding problem solving in\n",
      "the little-studied domain of scientific-discovery games, and on the\n",
      "ill-structured problems present in foldit. our findings on the differences in strategy use between high- and lower-performing solvers in\n",
      "foldit are consistent with the consensus in the literature that expert’s\n",
      "knowledge allows them to effectively use strategies that are poorly\n",
      "or infrequently used by less-skilled solvers. we also contribute a\n",
      "granular understanding of the specific strategies and differences at\n",
      "work in the foldit domain.\n",
      "significant recent work has investigated problem-solving behavior\n",
      "in educational games and intelligent tutoring systems using a variety\n",
      "of techniques. tóth et al. used clustering to characterize problemsolving behavior on tasks related to understanding a system of linear\n",
      "structural equations. the clusters distinguished between students\n",
      "that used a vary-one-thing-at-a-time strategy (both more and less\n",
      "efficiently) and those that used other strategies [20]. through a\n",
      "combination of automated detectors, path analysis, and classroom\n",
      "studies, rowe et al. investigated the relationship between a set\n",
      "of six strategic moves in a newtonian physics simulation game\n",
      "and performance on pre- and post-assessments. they found that\n",
      "the use of some moves mediated the relationship between prior\n",
      "achievement and post scores [18]. eagle et al. discuss several applications of using interaction networks to visualize and categorize\n",
      "problem-solving behavior in education games and intelligent tutoring systems. these networks offer insight for hint generation\n",
      "and a flexible method for visualizing student work in rule-using\n",
      "problem solving environments [4] . using decision trees to build\n",
      "separate models for optimal and non-optimal student performance,\n",
      "malkiewich et al. gained insight into how learning environments\n",
      "can encourage elegant problem solving [17]. our primary contribution is to extend analysis of problem-solving behavior to a more\n",
      "complex and open-ended domain that those studied in similar previous work. the size and complexity of foldit’s problem space,\n",
      "the volume of data necessary to capture exploration in this space,\n",
      "and the ill-structured nature of the foldit problems all pose unique\n",
      "challenges. we devise a visualization-based methodology focused\n",
      "on iterative summarization, and successfully apply it to identify key\n",
      "problem-solving patterns exhibited by foldit solvers.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "33\n",
      "\n",
      "\f",
      "3.\n",
      "\n",
      "foldit\n",
      "\n",
      "foldit is a scientific-discovery game that crowdsources protein folding. it presents solvers with a 3d representation of a protein and\n",
      "tasks them with manipulating it into the lowest energy configuration. each protein posed to the solvers is called a puzzle. solvers’\n",
      "solutions to each puzzle are scored according to their energy configuration, and solvers compete to produce the highest scoring results.\n",
      "\n",
      "figure 1: the foldit interface. foldit solvers use a variety of\n",
      "tools to interactively reshape proteins. in this figure, a solver\n",
      "uses rubber bands to pull together two sheets, long flat regions\n",
      "of the protein.\n",
      "solvers have many tools at their disposal when solving foldit puzzles. they can manipulate and constrain the structure in various\n",
      "ways, employ low-level automated optimization (e.g., a wiggle tool\n",
      "makes small, rapid, local adjustments to try and improve the score),\n",
      "and trigger solver-created automated scripts called recipes that can\n",
      "programmatically use the other tools. there is, however, a subset of\n",
      "the basic actions that cannot be used by recipes. we will call these\n",
      "manual-only actions. previous work analyzing solver behavior in\n",
      "foldit has focused primarily on recipe use and dissemination [2] and\n",
      "recipe authoring [15].\n",
      "foldit has several different types of puzzles for solvers to solve. in\n",
      "this work, we focus on the most common type of puzzle, prediction\n",
      "puzzles. these are puzzles in which biochemists know the amino\n",
      "acids that compose the protein in question, but do not know how\n",
      "the particular protein folds up in 3d space. this is in contrast to\n",
      "design puzzles in which solvers insert and delete which amino acids\n",
      "compose the protein to satisfy a variety of scientific goals, including\n",
      "designing new materials and targeting problematic molecules in\n",
      "diseases. we focus on prediction puzzles in this work to simplify\n",
      "our analysis by having a consistent objective (i.e., maximize score)\n",
      "across the problem-solving behavior we analyze.\n",
      "\n",
      "4.\n",
      "\n",
      "methodology\n",
      "\n",
      "prior work has demonstrated the power of visualization to support\n",
      "understanding of problem-solving behavior (e.g., [12]). hence, we\n",
      "devise a methodology capable of producing concise, meaning-rich\n",
      "visualizations of the problem-solving process in foldit, and then\n",
      "leverage these visualizations to identify key patterns of solver behavior. we are specifically interested in how solvers navigate from\n",
      "a puzzle’s start state to a high-quality solution, what states they\n",
      "pass through in between, and what other avenues they explored.\n",
      "\n",
      "since solving a foldit puzzle can be represented as a directed search\n",
      "through a problem space, the clear encoding of parent-child relationships between nodes offered by a tree make it well-suited for\n",
      "visualizing these aspects of the solving process.\n",
      "the scale of the foldit data necessitates significant transformation\n",
      "of the raw data in order to render concise visualizations. without\n",
      "any transformation, meaningful patterns are overwhelmed by sparse,\n",
      "repetitive data and would be far more challenging to identify. while\n",
      "there are many existing techniques for large-scale tree visualization,\n",
      "we find clear benefits to developing a visualization tailored to the\n",
      "foldit domain. specifically, preserving the semantics of our visual\n",
      "encoding is crucial for allowing us to connect patterns in the visualization to concrete strategic behavior in foldit. to accomplish this,\n",
      "the process by which concise visualization are constructed must\n",
      "be carefully designed to maintain these links. hence, we devise a\n",
      "design methodology focused on iterative summarization.\n",
      "this process begins by visualizing the raw data. this is followed\n",
      "by iteratively building and refining a set of transformations to summarize the raw data while preserving meaning. the design of these\n",
      "transformations should be guided by frequently occurring structures.\n",
      "that is, those structures that the transformations can condense without eliding structures corresponding to unique strategic behavior.\n",
      "in parallel to this iterative design, a set of visual encodings are developed to represent the solving process as richly as possible. key\n",
      "to this entire process is frequent consultation with domain experts,\n",
      "in our case experts on foldit and its community. by applying this\n",
      "iterative methodology for several cycles, we designed a domainspecific visualization that we use to identify patterns of strategic\n",
      "behavior among foldit solvers. we follow up on these patterns with\n",
      "computational investigation, and quantify their application by highand lower-performing solvers.\n",
      "\n",
      "4.1\n",
      "\n",
      "data\n",
      "\n",
      "for our analysis, we selected 11 prediction puzzles spanning the\n",
      "range of time for which the necessary data is available. though\n",
      "foldit has been in continuous use since 2010, the data necessary to\n",
      "track a solver’s progress through the problem space has only been\n",
      "collected since mid-2015. our chosen dataset represents 970 unique\n",
      "solvers and nearly 3 million solution snapshots. these 11 puzzles are\n",
      "just a small subset of the available foldit data. we chose a subset of\n",
      "similar puzzles (i.e., a subtype of relatively less complex prediction\n",
      "puzzles) in order to make common solving-behavior patterns easier\n",
      "to identify. the size of the subset was also guided by practical\n",
      "constraints, as each puzzle constitutes a large amount of data (20-60\n",
      "gb for the data from all players on a single puzzle).\n",
      "the data logged by foldit primarily consists of snapshots of solver\n",
      "solutions as they play, stored as text files using the protein data\n",
      "bank (pdb) format. these snapshots include the current protein\n",
      "pose, a timestamp, the solution’s score, the number of times the\n",
      "solver has invoked each action and recipe, and a record of the intermediate states that led up to the solution at the time of the snapshot.\n",
      "this record, or solution history, is a list of unique identifiers each\n",
      "corresponding to a previous solution state. this list is extended\n",
      "every time the solver undoes an action or reloads a previous solution.\n",
      "hence, by comparing the histories of two snapshots from the same\n",
      "solver, we can answer questions about their relationship (e.g., does\n",
      "one snapshot represent the predecessor of another; where did two\n",
      "related snapshots diverge). the key relationship for the purposes of\n",
      "this analysis is the direct parent-child relationship, which we use to\n",
      "generate trees that represent a solver’s solving process.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "34\n",
      "\n",
      "\f",
      "4.2\n",
      "\n",
      "visualizing solution trees\n",
      "\n",
      "we applied our methodology to our chosen subset of foldit data to\n",
      "design a visualization of an individual’s problem-solving process\n",
      "as a solution tree. several key principles guided this design. first,\n",
      "since our goal is to discover key patterns, the visualization needs\n",
      "to highlight distinctly different strategies and approaches. these\n",
      "differences cannot be buried amidst enormous structures, nor destroyed by graph transformations. second, the visualization must\n",
      "depict the closeness of each step to the ultimate solution in both time\n",
      "and quality to give a sense of the solver’s progression. third, the\n",
      "solver’s use of automation in the form of recipes should be apparent\n",
      "since the use of automation is an important part of foldit.\n",
      "the fundamental organization of the visualization is that each node\n",
      "corresponds to a solution state encountered while solving. using the\n",
      "solution history present in the logged snapshots of solver solutions,\n",
      "we establish parent-child relationships between solutions. if solution\n",
      "β is a child of solution α, it indicates that β was generated when\n",
      "the solver performed actions on α. one crucial limitation, however,\n",
      "is that a snapshot of the solver’s current solution is captured far less\n",
      "often (only once every two minutes) than the solver takes actions.\n",
      "this means that our data is sparsely distributed along a solution’s\n",
      "history going back to the puzzle’s starting state. hence, when naively\n",
      "constructing the tree from the logged solution histories, it ends up\n",
      "dominated by vast quantities of nodes with no associated data.\n",
      "we address this issue by performing summarization on the solution\n",
      "trees, condensing them into concise representations amenable to\n",
      "analysis for important features. this summarization takes place\n",
      "in two stages. the first stage trims out nodes that (1) do not have\n",
      "corresponding data and (2) have zero children. this eliminates\n",
      "large numbers of leaf nodes that we are unable to reason about\n",
      "given that we lack the corresponding data. this stage also combines\n",
      "sequences of nodes each with only one child into a single node. for\n",
      "the median tree, this stage reduced the number of nodes by an order\n",
      "of magnitude from over 12,000 nodes to about 1,600.\n",
      "the second stage consists of four phases, each informed by our\n",
      "observations of common patterns in trees produced by the first stage\n",
      "that would benefit from summarization. the first phase, called\n",
      "prune, focuses on simplifying uninteresting branches. we observed\n",
      "many of the branches preserved by the first stage were small, with\n",
      "at most three children, and only continued the tree from one of\n",
      "those children. prune removes the leaf children of these branches\n",
      "from the tree. collapse, the second phase, transforms each of the\n",
      "sequences of single-child nodes left behind after prune into single\n",
      "nodes. the third phase, condense, targets another common pattern\n",
      "where a sequence of branches feed into each other, with a child of\n",
      "each branch the parent of the next branch. these sequences are\n",
      "summarized into a single node labeled cascade along with the\n",
      "depth (number of branches) and width (average branching factor)\n",
      "of the summarized branches. see figure 2 for an example of the\n",
      "features summarized by these three phases. the final phase, clean,\n",
      "targets the ubiquitous empty nodes (i.e., nodes for which we lack\n",
      "associated data) shown in black in figure 2. we eliminate them by\n",
      "merging them with their parent node, doing so repeatedly until they\n",
      "all have been merged into nodes that contain data. in addition to\n",
      "making the trees more concise, this step allows us to reason more\n",
      "fully over the trees since all nodes are guaranteed to contain data.\n",
      "this second stage of summarization further reduced the number of\n",
      "nodes in the median tree by another order of magnitude to about\n",
      "300 nodes. summarization similarly reduces the space required to\n",
      "store the data by two orders of magnitude.\n",
      "\n",
      "figure 2: a solution tree after only the first stage of summarization. the non-black node color represents the score of the\n",
      "solution at that node (red is worse). the black nodes are empty\n",
      "in that we do not have solution data corresponding to that node.\n",
      "this figure also shows examples of the features targeted by the\n",
      "second summarization stage: prune and collapse eliminate long\n",
      "chains like the one on the right, and condense combines sequences of branches like those going down to left in single cascade nodes.\n",
      "child-parent relationships are not the only part of the data we visually encoded in the solution trees. nodes are colored on a continuous\n",
      "gradient from red to blue according to the score of the solution represented by that node (red is low-scoring, blue is high-scoring). the\n",
      "best-scoring node is highlighted as a yellow star. edges are colored\n",
      "on a continuous gradient from light to dark green according to the\n",
      "time the corresponding transition took place, and the children of\n",
      "each node are arranged left to right in chronological order. finally,\n",
      "use of automation via recipes is an important aspect of problemsolving in foldit. since the logged solution snapshots contain a\n",
      "record of which recipes have been used at that point, we can use this\n",
      "to annotate nodes where a recipe was triggered. the annotations\n",
      "consist of the id of that recipe (a 4 to 6 digit number) and the number\n",
      "of times it was started.\n",
      "one major weakness in the data available to us is the lack of a consistent way to determine when the execution of a recipe ended (some\n",
      "recipes save and restore, possibly being responsible for multiple\n",
      "nodes in the graph beyond where they were triggered). we partially\n",
      "address this by further annotating a node with the label manual\n",
      "whenever the solver took a manual-only action at that node. this\n",
      "indicates that no previously triggered recipe continued past that node\n",
      "because no recipe could have performed the manual-only action.\n",
      "since nodes in the summarized trees can represent many individual\n",
      "steps, it is possible for them to have several of these recipe and\n",
      "manual action annotations.\n",
      "\n",
      "5.\n",
      "\n",
      "results\n",
      "\n",
      "using visualized solution trees for a large set of solvers across our\n",
      "sample of 11 puzzles, we identify a set of six prominent patterns in\n",
      "solvers’ problem-solving behavior. these patterns do not encompass\n",
      "all solving behavior in foldit, but instead capture key instances of\n",
      "strategic behavior in three categories: exploration, optimization, and\n",
      "human-computer collaboration. future work is needed to generate\n",
      "a comprehensive survey of the strategic patterns in these and other\n",
      "categories. in this analysis, our focus is on identifying a small,\n",
      "diverse set of commonly occurring patterns to both provide initial\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "35\n",
      "\n",
      "\f",
      "insight into problem-solving behavior, and to demonstrate the potential of our approach. in addition to identification, we also perform\n",
      "a quantitative comparison of how these patterns are employed by\n",
      "high-performing and lower-performing solvers to gain an understanding of how these patterns contribute to success in an open-end\n",
      "environment like foldit.\n",
      "\n",
      "5.1\n",
      "\n",
      "has a high-scoring node with a low-scoring child, and then chooses\n",
      "to explore from the low-scoring child. the solver was willing to\n",
      "ignore the short-term drop in score to try and reach a more beneficial\n",
      "state in the long-term. figure 5 gives an example of this pattern.\n",
      "\n",
      "problem-solving patterns\n",
      "\n",
      "exploration. foldit solvers are confronted with a highly discon-\n",
      "\n",
      "tinuous solution space with many local optima, creating a trade-off\n",
      "between narrowly focusing their efforts or taking the time to explore\n",
      "a broader range of possibilities. in our first two patterns, we examine the broader exploration side of this trade-off at two different\n",
      "scales. taking the macro-scale first, we identify a pattern where\n",
      "solvers make significant progress on distinct branches of the tree\n",
      "(see figure 3 for an example). we interpret this pattern as the solver\n",
      "investigating multiple hypotheses about the puzzle solution, using\n",
      "multiple instances of the game client or foldit’s save and restore features to deeply explore them all. we call this the multiple hypotheses\n",
      "pattern.\n",
      "\n",
      "figure 5: an example of the optima escape pattern. the solver\n",
      "transitions from a relatively high-scoring (i.e., blue) state in the\n",
      "upper left to a low-scoring (i.e., red) state. what makes this\n",
      "an example of the pattern is that exploration from the lowscoring state. in this case, the perseverance paid off as the\n",
      "solver reaches even higher-scoring states in the lower right.\n",
      "in the other direction, we identify the greedy pattern in which solvers\n",
      "exclusively explore from the best-scoring of the available options.\n",
      "obviously, some amount of greedy exploration is necessary in order\n",
      "to refine solutions, but in its extreme form deserves recognition\n",
      "as a pattern with significant potential impact on problem-solving\n",
      "success. naturally, these two patterns do not cover all the ways\n",
      "solvers explore the problem space, but they do characterize specific\n",
      "strategic behavior of interest in this analysis.\n",
      "\n",
      "figure 3: an example of the multiple hypotheses pattern. the\n",
      "two hypotheses branch out one of the nodes at the top and continue to the left (a) and right (b).\n",
      "at the micro-scale, solvers very frequently generate a large number\n",
      "of possible next steps (i.e., a branch with a large number of children),\n",
      "but most often proceed to explore only one of them further. this is\n",
      "natural given the iterative refinement needed to successfully participate in foldit. hence, solvers that exhibit a pattern of much more\n",
      "frequently exploring multiple local possibilities demonstrate an unusual effort to explore more broadly. we call this the inquisitive\n",
      "pattern. figure 4 shows an example of this behavior.\n",
      "\n",
      "figure 6: an example of the repeated recipe pattern. at three\n",
      "points in this solution tree snippet, the solver applies recipe\n",
      "49233 to every child of a node.\n",
      "\n",
      "human-computer collaboration. human-computer collabo-\n",
      "\n",
      "figure 4: an example of the inquisitive pattern. note how frequently multiple children of the same node are explored when\n",
      "compared to the tree in figure 3.\n",
      "\n",
      "optimization. navigating the extremely heterogeneous solution\n",
      "\n",
      "space is the primary challenge in foldit, so we look closely at how\n",
      "solvers attempt to optimize their solutions, digging deeper into\n",
      "solvers’ approach to exploration than the previous two patterns.\n",
      "we identify two related patterns describing solvers’ fine-grained\n",
      "approach to optimization. the solution spaces of foldit puzzles\n",
      "contain numerous local optima that solvers must escape, and we\n",
      "identify an optima escape pattern highly suggestive of a deliberate\n",
      "attempt to escape a local optima. this pattern occurs when a solver\n",
      "\n",
      "ration is a vital part of foldit, and managing the trade-off between\n",
      "automation and manual intervention is a key feature of solving\n",
      "foldit puzzles. we identify two patterns that each focus on one\n",
      "side of this trade-off. the first, the manual pattern, corresponds to\n",
      "extended sections of exclusively manual exploration. since recipe\n",
      "use is very common, extended manual exploration represents a significant investment in the manual intervention side of the trade-off.\n",
      "limitations with foldit logging data prevent us from capturing all\n",
      "the manual exploration (i.e., it is not always possible to determine\n",
      "whether an action was performed by a solver manually or triggered\n",
      "as part of an automated recipe), but what can be captured is still an\n",
      "important dimension of variance among problem-solving behavior.\n",
      "our final pattern concerns recipe use. some solvers apply a recipe\n",
      "to every child of a node periodically throughout their solution tree,\n",
      "using it as a clean-up or refinement step before continuing on (see\n",
      "figure 6). we call this the repeated recipe pattern. recipe use is\n",
      "very diverse and frequently doesn’t display any specific structure,\n",
      "making this pattern interesting for its regimented way of managing\n",
      "some of the automation while solving.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "36\n",
      "\n",
      "\f",
      "figure 7: the number of hypotheses pursued in each solution\n",
      "tree for high- and lower-performing solvers. high-performing\n",
      "solvers frequently pursue two or more hypotheses, whereas\n",
      "lower-performing solvers most often pursue just one. red circles show the distribution of individual solvers.\n",
      "\n",
      "5.2\n",
      "\n",
      "problem-solving patterns and\n",
      "solver performance\n",
      "\n",
      "to understand how the patterns we identify relate to skillful problemsolving in an open-ended domain like foldit, we compare their use\n",
      "among high-performing solvers to that among lower-performing\n",
      "solvers. specifically, we analyze the occurrence of these patterns in\n",
      "the 15 best-scoring solutions from each puzzle and compare that to\n",
      "the occurrence in solutions from each puzzle ranked from 36th to\n",
      "50th. though it varies somewhat between puzzles, in general the\n",
      "solutions ranked 36th to 50th represent a middle ground in terms\n",
      "of quality. they fall outside the puzzle’s state-of-the-art solutions,\n",
      "but remain well above the least successful efforts. throughout these\n",
      "comparisons we use non-parametric mann-whitney u tests with\n",
      "α = 0.008 confidence (bonferroni correction for six comparisons,\n",
      "α = 0.05/6), as our data is not normally distributed. for each test,\n",
      "we report the test statistic u, the two-tailed significance p, and the\n",
      "rank-biserial correlation measure of effect size r. in addition, since\n",
      "some of the metrics we compute may not apply to all solution trees\n",
      "(e.g., the tree contains no branches where the inquisitive pattern\n",
      "can be evaluated), we report the number of solvers involved in the\n",
      "comparison n for each test (the full sample is n = 330).\n",
      "we find high-performing solvers explore more broadly than lowerperforming solvers. for the multiple hypotheses pattern, highperforming solvers pursued significantly more hypotheses than\n",
      "lower-performing solvers (u = 10569, p = 0.000014, r = 0.217,\n",
      "n = 330) (see figure 7). for the inquisitive pattern, we compute\n",
      "the proportion of each solver’s exploration that matches the pattern\n",
      "(i.e., of all the branches in a solver’s solution tree, in what fraction of them did the solver explore more than one child) and find\n",
      "high-performing solvers explore inquisitively more often than lowerperforming solvers (u = 9343, p = 0.000295, r = 0.231, n = 313)\n",
      "\n",
      "figure 8: the proportion of all the branches in a solver’s solution tree in which the solver explored more than one child\n",
      "for high- and lower-performing solvers. red circles show the\n",
      "distribution of individual solvers.\n",
      "(see figure 8).\n",
      "we also find high-performing solvers work harder to avoid local\n",
      "optima. for the optima escape pattern, we compute the number of times this behavior occurs in each solution and find that\n",
      "high-performing solvers engage in this behavior more than lowerperforming solvers (u = 11183.5, p = 0.00185, r = 0.173, n = 330)\n",
      "(see figure 9). for the greedy pattern, we compute the proportion of each solver’s exploration that matches the pattern (i.e., of\n",
      "all the branches in a solver’s solution tree, in what fraction of\n",
      "them did the solver only explore the best-scoring child). while\n",
      "high-performing solvers engaged in greedy optimization less often\n",
      "than lower-performing solvers, the difference was not significant\n",
      "(u = 9079, p = 0.0158, r = −0.163, n = 295) (see figure 10).\n",
      "finally, we find no significant difference between high- and lowerperforming solvers in the frequency they manually explore and\n",
      "employ recipes. for the manual pattern, we compute the number of\n",
      "manual exploration sections in each solution and find no significant\n",
      "difference between high- and lower-performing solvers (u = 13334,\n",
      "p = 0.789, r = 0.014, n = 330). for the repeated recipe pattern,\n",
      "we computed the median frequency of recipe use along all paths\n",
      "in the solution (i.e., for each path from the root to a leaf, in what\n",
      "fraction of the nodes did the solver trigger at least one recipe) and\n",
      "though lower-performing solvers used recipes more frequently, the\n",
      "difference between high- and lower-performing solvers was not\n",
      "significant (u = 11342, p = 0.0140, r = −0.157, n = 329).\n",
      "\n",
      "6.\n",
      "\n",
      "discussion\n",
      "\n",
      "the results from our analysis of our solution tree visualizations illuminate some key problem-solving patterns exhibited by individual\n",
      "foldit solvers. namely, how broadly an individual explores, both\n",
      "on a macro- and micro-scale, how actively an individual avoids\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "37\n",
      "\n",
      "\f",
      "figure 9: the number of times in each solution a solver engages in optima escape behavior for high- and lower-performing\n",
      "solvers. red circles show the distribution of individual solvers.\n",
      "\n",
      "local optima by engaging in less greedy optimization and actively\n",
      "pursuing locally suboptimal lines of inquiry, and how an individual\n",
      "manages the interplay between automation and manual intervention.\n",
      "comparing high- and lower-performing solvers in their application of these patterns suggests that skillful problem-solving in an\n",
      "open-end domain like foldit involves broader exploration and more\n",
      "conscious avoidance of local minima. this finding that a key feature\n",
      "of high-skill solving behaviors is not being enamored by the current\n",
      "best solution and possessing strategies for avoiding myopic thinking\n",
      "had implications for the strategies that should be taught to develop\n",
      "successful problem solvers. further work is required on other large\n",
      "open-ended domains to confirm this trend.\n",
      "the finding that solvers of different skill use greedy exploration,\n",
      "manual exploration, and automation in similar amounts suggests\n",
      "skillful deployment of non-greedy exploration, automation, and\n",
      "manual intervention takes place at a more fine-grained level than\n",
      "overall quantity. though this work focuses on the presence or\n",
      "absence of specific solving behavior, the timing and sequencing of\n",
      "strategic moves are likely to be critical to success. further work is\n",
      "needed to investigate what differentiates effective and ineffective\n",
      "use of specific solving strategies.\n",
      "the foldit dataset itself presented significant challenges for our\n",
      "analysis, and we addressed these through an iterative visualizationbased methodology. this process served as a design method for\n",
      "generating a visual grammar to describe a complex problem-solving\n",
      "process. we do not study the generalization of this approach to\n",
      "other datasets and domains in this work, but the prerequisites for\n",
      "its application to other open-ended problem-solving domains can\n",
      "be concisely enumerated: (1) the logs of solver activity establish\n",
      "clear temporal relationships between solution states such that those\n",
      "states can be visualized as a progression through the solution space,\n",
      "\n",
      "figure 10: the proportion of all the branches in a solver’s solution tree in which the solver explored only the best-scoring\n",
      "child for high- and lower-performing solvers. the fact that the\n",
      "median for both categories of solver is above 0.5 indicates that\n",
      "this pattern in an important part of refining solutions in foldit.\n",
      "red circles show the distribution of individual solvers.\n",
      "(2) the solution state or associated metadata is amenable to visual\n",
      "encoding, so that the visualized progressions can represent finegrained details of the solving process, and (3) deep problem-solving\n",
      "domain expertise is available to provide the necessary context for\n",
      "interpreting and summarizing the visualized structures.\n",
      "our chosen subset of foldit data represents only a small fraction\n",
      "of the total available data. in particular, we limited our analysis\n",
      "to a sample of similar prediction puzzles, and compared specific\n",
      "ranges of high- and lower-performing solvers. though these choices\n",
      "are well-motivated, it is an important question for future work as\n",
      "to whether our results hold across different datasets and groups of\n",
      "comparison. more broadly, foldit supports numerous variations\n",
      "on the prediction and design puzzle archetypes, which offers an\n",
      "exciting opportunity to study problem solving across a number of\n",
      "related contexts with varying goals, constraints, inputs, and tools.\n",
      "\n",
      "7.\n",
      "\n",
      "conclusion\n",
      "\n",
      "gaining a better understanding of key patterns in problem-solving\n",
      "behavior in complex, open-ended environments is important for deploying this kind of activity in an educational setting at scale. in this\n",
      "work, we identified six key patterns in problem-solving behavior\n",
      "among solvers of foldit. the protein folding challenges in foldit\n",
      "present rich, completely open, heterogeneous solution spaces, making them a compelling domain in which to analyze these patterns.\n",
      "to facilitate the identification of these patterns, we used an iterative\n",
      "methodology to design visualizations of solvers’ problem-solving\n",
      "activity as solution trees. the size and complexity of the foldit data\n",
      "required us to develop domain-specific techniques to summarize the\n",
      "solution trees and render them tractable for analysis while preserving the salient problem-solving behaviors. finally, we compared the\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "38\n",
      "\n",
      "\f",
      "occurrence of the patterns we identified between high- and lowerperforming solvers. we found that high-performing solvers explore\n",
      "more broadly and more aggressively avoid local optima. we also\n",
      "found that both categories of solvers employ automation and manual\n",
      "intervention in similar quantities, inviting future work to study how\n",
      "these tools are used at a more fine-grained level.\n",
      "we have only scratched the surface in our analysis of a subset of\n",
      "foldit data. two integral aspects of the foldit environment are\n",
      "not within the scope of this work: collaboration and expert feedback. we only considered solutions produced by individual solvers,\n",
      "but foldit solver can also take solutions produced by others and\n",
      "try and improve them. this collaborative framework may involve\n",
      "specialization and unique solving strategies, and deserves careful\n",
      "study. expert feedback comes into play for design puzzles, where\n",
      "biochemists will select a small number of the solutions to try and\n",
      "synthesize in the lab. experts will also impose additional constraints\n",
      "on future design puzzles to try and guide solutions toward more\n",
      "promising designs. the interaction of these channels for expert\n",
      "feedback and problem-solving behavior is an important topic for\n",
      "future research. also outside the scope of this work is how individual solvers change their problem-solving behavior over time. many\n",
      "solvers have been participating in the foldit community for many\n",
      "years, and studying how their behavior evolves could yield insights\n",
      "into the acquisition of high-level problem-solving skills.\n",
      "looking more broadly at the impact of this work, our methodology\n",
      "and analysis can serve as a first step toward discovering the scaffolding necessary to develop high-level problem-solving skills. these\n",
      "results could contribute to a hint generation system, where solvers\n",
      "could be guided toward known effective strategies, or a meta-planner\n",
      "component in foldit that could tailor the parameters of particular\n",
      "puzzles to optimize the quality of the scientific results. in all of\n",
      "these cases, this work contributes to the necessary foundational\n",
      "understanding of the problem-solving behavior involved.\n",
      "\n",
      "8.\n",
      "\n",
      "acknowledgements\n",
      "\n",
      "this work was supported by the national institutes of health grant\n",
      "1uh2ca203780, rosettacommons, and amazon. this material\n",
      "is based upon work supported by the national science foundation\n",
      "under grant no. 1629879.\n",
      "\n",
      "9.\n",
      "\n",
      "[6]\n",
      "\n",
      "[7]\n",
      "\n",
      "[8]\n",
      "[9]\n",
      "[10]\n",
      "\n",
      "[11]\n",
      "[12]\n",
      "\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "\n",
      "[16]\n",
      "\n",
      "references\n",
      "\n",
      "[1] e. andersen, y.-e. liu, e. apter, f. boucher-genesse, and\n",
      "z. popović. gameplay analysis through state projection. in\n",
      "proceedings of the fifth international conference on the\n",
      "foundations of digital games, pages 1–8. acm, 2010.\n",
      "[2] s. cooper, f. khatib, i. makedon, h. lu, j. barbero, d. baker,\n",
      "j. fogarty, z. popović, et al. analysis of social gameplay\n",
      "macros in the foldit cookbook. in proceedings of the 6th\n",
      "international conference on foundations of digital games,\n",
      "pages 9–14. acm, 2011.\n",
      "[3] s. cooper, f. khatib, a. treuille, j. barbero, j. lee,\n",
      "m. beenen, a. leaver-fay, d. baker, z. popović, et al.\n",
      "predicting protein structures with a multiplayer online game.\n",
      "nature, 466(7307):756–760, 2010.\n",
      "[4] m. eagle, d. hicks, b. peddycord iii, and t. barnes.\n",
      "exploring networks of problem-solving interactions. in\n",
      "proceedings of the 5th conference on learning analytics and\n",
      "knowledge. acm, 2015.\n",
      "[5] c. b. eiben, j. b. siegel, j. b. bale, s. cooper, f. khatib,\n",
      "\n",
      "[17]\n",
      "\n",
      "[18]\n",
      "[19]\n",
      "[20]\n",
      "\n",
      "[21]\n",
      "\n",
      "b. w. shen, b. l. stoddard, z. popovic, and d. baker.\n",
      "increased diels-alderase activity through backbone\n",
      "remodeling guided by foldit players. nature biotechnology,\n",
      "30(2):190–192, 2012.\n",
      "m. h. falakmasir, j. p. gonzalez-brenes, g. j. gordon, and\n",
      "k. e. dicerbo. a data-driven approach for inferring student\n",
      "proficiency from game activity logs. in proceedings of the\n",
      "third (2016) acm conference on learning@ scale, pages\n",
      "341–349. acm, 2016.\n",
      "c. geigle, c. zhai, and d. c. ferguson. an exploration of\n",
      "automated grading of complex assignments. in proceedings of\n",
      "the third (2016) acm conference on learning@ scale, pages\n",
      "351–360. acm, 2016.\n",
      "m. l. gick. problem-solving strategies. educational\n",
      "psychologist, 21(1-2):99–120, 1986.\n",
      "j. g. greeno. natures of problem-solving abilities. handbook\n",
      "of learning and cognitive processes, 5:239–270, 1978.\n",
      "e. harpstead, c. j. maclellan, k. r. koedinger, v. aleven,\n",
      "s. p. dow, and b. myers. investigating the solution space of\n",
      "an open-ended educational game using conceptual feature\n",
      "extraction. in proceedings of the 6th conference on\n",
      "educational data mining, 2013.\n",
      "w. hung, d. h. jonassen, r. liu, et al. problem-based\n",
      "learning. handbook of research on educational\n",
      "communications and technology, 3:485–506, 2008.\n",
      "m. johnson, m. eagle, and t. barnes. invis: an interactive\n",
      "visualization tool for exploring interaction networks. in\n",
      "proceedings of the 6th conference on educational data\n",
      "mining, 2013.\n",
      "d. h. jonassen. toward a design theory of problem solving.\n",
      "educational technology research and development,\n",
      "48(4):63–85, dec 2000.\n",
      "d. a. joyner. expert evaluation of 300 projects per day. in\n",
      "proceedings of the third (2016) acm conference on\n",
      "learning@ scale, pages 121–124. acm, 2016.\n",
      "f. khatib, s. cooper, m. d. tyka, k. xu, i. makedon,\n",
      "z. popović, and d. baker. algorithm discovery by protein\n",
      "folding game players. proceedings of the national academy\n",
      "of sciences, 108(47):18949–18953, 2011.\n",
      "f. khatib, f. dimaio, s. cooper, m. kazmierczyk, m. gilski,\n",
      "s. krzywda, h. zabranska, i. pichova, j. thompson,\n",
      "z. popović, et al. crystal structure of a monomeric retroviral\n",
      "protease solved by protein folding game players. nature\n",
      "structural & molecular biology, 18(10):1175–1177, 2011.\n",
      "l. malkiewich, r. s. baker, v. shute, s. kai, and l. paquette.\n",
      "classifying behavior to elucidate elegant problem solving in\n",
      "an educational game. in proceedings of the 9th conference on\n",
      "educational data mining, 2016.\n",
      "e. rowe, r. s. baker, and j. asbell-clarke. strategic game\n",
      "moves mediate implicit science learning. in proceedings of\n",
      "the 8th conference on educational data mining, 2015.\n",
      "h. a. simon. information-processing theory of human\n",
      "problem solving. handbook of learning and cognitive\n",
      "processes, 5:271–295, 1978.\n",
      "k. tóth, h. rölke, s. greiff, and s. wüstenberg. discovering\n",
      "students’ complex problem solving strategies in educational\n",
      "assessment. in proceedings of the 7th conference on\n",
      "educational data mining, 2014.\n",
      "g. wallner and s. kriglstein. visualization-based analysis of\n",
      "gameplay data–a review of literature. entertainment\n",
      "computing, 4(3):143–155, 2013.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "39\n",
      "\n",
      "\f",
      "the antecedents of and associations with elective replay\n",
      "in an educational game: is replay worth it?\n",
      "zhongxiu liu\n",
      "\n",
      "north carolina state\n",
      "university\n",
      "\n",
      "christa cody\n",
      "\n",
      "north carolina state\n",
      "university\n",
      "\n",
      "tiffany barnes\n",
      "\n",
      "north carolina state\n",
      "university\n",
      "\n",
      "zliu24@ncsu.edu\n",
      "cncody@ncsu.edu\n",
      "tmbarnes@ncsu.edu\n",
      "collin lynch\n",
      "teomara rutherford\n",
      "north carolina state\n",
      "university\n",
      "\n",
      "cflynch@ncsu.edu\n",
      "abstract\n",
      "replayability has long been touted as a benefit of educational games. however, little research has measured its impact on learning, or investigated when students choose to replay prior content. in this study, we analyzed data on a sample of 4,827 3rd-5th graders from st math, a game-based educational platform integrated into classroom instruction in\n",
      "over 3,000 classrooms across the u.s. we identified features\n",
      "that describe elective replays relative to prior gameplay performance, and associated elective replays with in-game accuracy, confidence, and general math ability assessments outside of the games. we found some elective replay patterns\n",
      "were associated with learning, whereas others indicated that\n",
      "students were struggling in the current educational content.\n",
      "we suggest, therefore, that educational games should use\n",
      "elective replay behaviors to target interventions according\n",
      "to when and whether replay is helpful for learning.\n",
      "\n",
      "keywords\n",
      "educational games, serious game analytics, replayability\n",
      "\n",
      "1. introduction\n",
      "“replayability is an important component of successful games.”\n",
      "[15] in most games, there are two types of plays: play and\n",
      "replay to pass a level (pass attempts) and replay after passing a level (elective replay). in this paper, we investigate\n",
      "the latter. elective replay (er) is particularly interesting\n",
      "because the motivations behind a student’s decision to replay and the impact of those replays are relatively unknown.\n",
      "this paper explores potential associations between elective\n",
      "replay and student characteristics and performance in the\n",
      "domain of educational games.\n",
      "replayability has been touted as a benefit of educational\n",
      "games [9]. replayability encourages players to engage in\n",
      "\n",
      "north carolina state\n",
      "university\n",
      "\n",
      "taruther@ncsu.edu\n",
      "repeated judgement-behavior-feedback loops, where users\n",
      "make decisions based on the situation and/or feedback, act\n",
      "on those decisions, and receive feedback based on their actions [18]. in the retain model designed by gunter et al.\n",
      "[10] to evaluate educational games, replayability is a criteria for naturalization – an important component in helping\n",
      "students make their knowledge automatic, reducing the cognitive load of low-level details to allow for higher order thinking. in the retain model, “replay is encouraged to assist\n",
      "in retention and to remediate shortcomings.” [10] meaningful elective replay is often encouraged by game features\n",
      "such as score leaderboards, which inspire students to replay for higher scores [4]. because higher scores typically\n",
      "require a deeper understanding of the educational content\n",
      "in a well-designed game, encouraging elective replay may\n",
      "promote mastery. games with replay also allow the student to be exposed to more material and give them more\n",
      "freedom to control their learning. studies have shown that\n",
      "giving students control over their learning process can increase motivation, engagement, and performance [6, 8].\n",
      "however, few studies have investigated when students choose\n",
      "to replay, why they do so, or have measured the outcomes associated with elective replay. one reason is that educational\n",
      "game studies are often comparatively brief, so replayability\n",
      "is often minimally assessed with post-game questionnaires\n",
      "asking about students’ intention for future play [14, 5]. consequently, there is a need to investigate elective replay with\n",
      "actual logged actions in a game setting where students have\n",
      "sufficient time and freedom to replay.\n",
      "this work analyzed gameplay logs from a series of math\n",
      "games within the year-long supplemental digital mathematics curriculum spatial temporal (st) math. we analyzed\n",
      "gameplay data from 4,827 3rd-5th graders throughout the\n",
      "2012-2013 school year. our data contained 37,452 logged\n",
      "elective replays, accounting for 1.48% of the logged play.\n",
      "we analyzed gameplay and elective replay features in association with students’ demographic information, in-game\n",
      "math objective tests, and the state standardized math test.\n",
      "we sought to answer three research questions: q1: what are\n",
      "the characteristics of students who engage in elective replay,\n",
      "q2: what gets replayed, and under what circumstances?\n",
      "and q3: is elective replay associated with improvements\n",
      "in students’ accuracy on math objectives, confidence, and\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "40\n",
      "\n",
      "\f",
      "general math ability?\n",
      "\n",
      "2. related work\n",
      "2.1 factors influencing elective replay\n",
      "few empirical studies have investigated the motivations behind elective replay in educational games. burger et al. [5]\n",
      "studied the effect of verbal feedback from a virtual agent\n",
      "on replay in the context of a brain-training game. they\n",
      "found that elaborated feedback increases, whereas comparative feedback decreases, the students’ interest in future replay. they also found that negative feedback generated an\n",
      "immediate interest in replay, whereas positive feedback created long term interest in the educational content. in another study, plass et al. [14] compared three conditions in a\n",
      "math game: working individually, competing with another\n",
      "player, or collaborating with a peer. the study showed that\n",
      "both competition and collaboration modes heightened students’ intention to replay when compared with the individual mode, with the latter result being statistically significant. however, both studies measured replay via questionnaires asking the students’ desire to play the entire game\n",
      "again instead of observed replay behavior. moreover, these\n",
      "studies sought to understand replay only from the angle of\n",
      "game design, and did not address the connections, if any,\n",
      "between student characteristics and interest in replay.\n",
      "other studies suggest elective replay is a habitual behavior\n",
      "that arises from individual need, although these studies did\n",
      "not directly investigate replay. bartle [3] found one type\n",
      "of player who is primarily motivated by concrete measurements of success. in st math, these achiever-type players\n",
      "may largely use replay to get better ’scores’ (losing fewer\n",
      "lives when passing a level). mostow et al. [12] observed\n",
      "a student in a reading tutor who used the learner-control\n",
      "features to spend the majority of time replaying stories or\n",
      "writing ”junk” stories instead of progressing to new material. thus, some students may also use replay as a form\n",
      "of work avoidance – playing already passed levels instead\n",
      "of solving the current problem or moving on. sabourin et\n",
      "al. [17] found that students in an educational game used\n",
      "off-task behaviors to cope with frustration, implying that\n",
      "off-task behavior can be a productive self-regulation of negative emotions. in st math, when students get frustrated\n",
      "with the current educational content but still have to play\n",
      "the game in the classroom, they may replay already learned\n",
      "content as a mental break from the current task. these\n",
      "studies showed that the circumstances of replay and students’ characteristics influence their decisions to replay and\n",
      "its outcomes.\n",
      "\n",
      "2.2\n",
      "\n",
      "the outcomes of replay\n",
      "\n",
      "despite the believed benefits of replayability [9, 18, 10, 4],\n",
      "few studies have investigated the educational impact of elective replay. boyce et al. [4] evaluated the effects of game\n",
      "elements that were designed to motivate gameplay and elective replay. these included a leaderboard that shows each\n",
      "student’s rank based upon their score, a tool for creating\n",
      "custom puzzles, and a social system for messaging among\n",
      "players. the experimental design required students to play\n",
      "the game in one session, and to replay the game as more\n",
      "features were added in the subsequent sessions. the study\n",
      "found a sharp increase in test scores as these features were\n",
      "\n",
      "added to the game. the authors concluded that features designed to increase replayability can increase learning gains.\n",
      "however, this result may be due to increased time on task as\n",
      "the same group replaying the base game with new features.\n",
      "in another study, clark et al. [7] analyzed logged studentinitiated elective replay in a digital game. they found that\n",
      "frequency of elective replay did not correlate with learning\n",
      "gains, prior gaming habits/experience, or how much students liked the game. they also found that, while there\n",
      "was no statistically significant difference between the male\n",
      "and female students, males replayed more than the females.\n",
      "this may have been responsible for their slightly higher, although not statistically significant, “best level scores” – the\n",
      "highest score received on each level. these studies showed\n",
      "that elective replay may lead to increased learning or higher\n",
      "in-game performance. however, more research is needed to\n",
      "understand the potential educational impact of replay in educational games, particularly elective replays initiated solely\n",
      "by the players.\n",
      "\n",
      "3. game, data and features\n",
      "3.1 st math game\n",
      "\n",
      "figure 1: st math content and examples\n",
      "st math is designed to act as a supplemental program to\n",
      "a school’s existing mathematics curriculum. st math is\n",
      "mostly played during classroom sessions, but students have\n",
      "the option to play it at home. in st math [16], mathematics\n",
      "concepts are taught through spatial puzzles within various\n",
      "game-like arenas. st math games are structured at the top\n",
      "level by objectives, which are broad learning topics. within\n",
      "each objective, individual games teach more targeted concepts through presentation of puzzles, which are grouped\n",
      "into levels for students to play. students start by completing a series of training games on the use of the st math\n",
      "platform and features. they are then guided to complete\n",
      "the first available objective in their grade-level curriculum,\n",
      "such as “multiplication concepts.” students can only see\n",
      "this objective and must complete a pre-test before beginning\n",
      "the content. games represent scenarios for problem-solving\n",
      "using a particular mathematical concept, such as “finding\n",
      "the right number of boots for x animals of y legs.” each\n",
      "game contains between one and ten levels, which follow the\n",
      "same general structure of the game, but increase in difficulty.\n",
      "figure 1 illustrates the hierarchy of st math content and\n",
      "examples.\n",
      "as with many games, the student is given a set number of\n",
      "‘lives’ at the start of each level. every time they fail to\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "41\n",
      "\n",
      "\f",
      "complete a puzzle correctly they lose one life. if all of their\n",
      "lives for a given level are exhausted, they will fail the level\n",
      "and be required to restart the level with a new set of lives.\n",
      "once a student has passed a level, they can elect to replay\n",
      "it at any time. after a student has passed every level in an\n",
      "objective, they can take the objective post-test. students\n",
      "cannot progress to the next objective until they have completed the last objective post-test. both the objective preand post-tests consist of 5-10 multiple choice questions related to the objective. the post-tests parallel the pre-tests\n",
      "in both the question format and difficulty of the content.\n",
      "while answering each question in both tests, students indicate their relative confidence in their answer (low/high).\n",
      "\n",
      "3.2\n",
      "\n",
      "data\n",
      "\n",
      "mind research institute (mind), the developers of stmath, collected and provided to the researchers gameplay\n",
      "data from 4,827 3rd-5th graders during the school year 20122013. these students came from 17 schools and 221 classrooms. table 1 summarizes students’ demographic information. these demographic data, together with students’ state\n",
      "standardized test scores in 2012 and 2013, were matched to\n",
      "gameplay data through anonymized ids.\n",
      "table 1: populations’ demographics information\n",
      "grade3 grade4 grade5\n",
      "#students\n",
      "male\n",
      "eligible for reduced\n",
      "lunch\n",
      "hispanic or latino\n",
      "english language\n",
      "learner\n",
      "with listed disability\n",
      "\n",
      "1567\n",
      "50.6%\n",
      "na:2.9%\n",
      "80.7%\n",
      "na:2.9%\n",
      "84.7%\n",
      "na:2.8%\n",
      "66.2%\n",
      "na:2.9%\n",
      "10.9%\n",
      "na:2.1%\n",
      "\n",
      "1528\n",
      "50.1%\n",
      "na:2.0%\n",
      "77.8%\n",
      "na:2.1%\n",
      "82.3%\n",
      "na:1.9%\n",
      "56.1%\n",
      "na:2.1%\n",
      "11.5%\n",
      "na:1.7%\n",
      "\n",
      "1732\n",
      "52.2%\n",
      "na:3.5%\n",
      "81.4%\n",
      "na:3.2%\n",
      "83.5%\n",
      "na:3.1%\n",
      "53.0%\n",
      "na:3.2%\n",
      "11.9%\n",
      "na:2.8%\n",
      "\n",
      "this gameplay data includes pre- and post-tests for each\n",
      "objective and the number of level attempts. for each preand post-test, st math logged students’ accuracy and selfreported confidence level (1 for ’high’ and 0 for ’low) for\n",
      "each question. for each play at a level, st math logged the\n",
      "student’s id, timestamp, and the number of puzzles completed. from these data, we identified er as plays made\n",
      "after a student initially passed the level. we found ers in\n",
      "89.6% of all objectives in st math, accounting for 1.48%\n",
      "of all level attempts. among 4,827 students, 59.85% ered\n",
      "at least one level, with an average of 7.84 levels (sd=12.99,\n",
      "95% ci [7.37, 8.32]) across 3.06 average objectives replayed\n",
      "per student. in the next section, we describe the features\n",
      "we created to analyze er.\n",
      "\n",
      "3.3\n",
      "\n",
      "features\n",
      "\n",
      "we created features at three different levels of granularity\n",
      "(from finest to largest): level, objective, and student. for\n",
      "the level granularity, we treated each unique student-level\n",
      "combination as an observation. we calculated the features\n",
      "by averaging all gameplay for a specific student at a specific level. for objective granularity, each unique studentobjective combination was treated as a single observation.\n",
      "\n",
      "features were created by averaging across all levels played by\n",
      "a specific student within a single objective. the objective\n",
      "granularity also included the objective pre- and post-test\n",
      "accuracy and confidence. for the student granularity, we\n",
      "treated each student as a single observation. we calculated\n",
      "the features by averaging across all objectives played by a\n",
      "student over the entire year. the student granularity also\n",
      "included student demographic data and state standardized\n",
      "math test scores. these granularities ensured that our analysis did not favor units with the majority of data logs. each\n",
      "student was considered equally in our analysis, regardless\n",
      "of how many objectives they played. our data contained\n",
      "4,827 students and 2,524,681 plays, which yielded 1,462,660\n",
      "student-level observations, and 74,985 student-objective observations.\n",
      "table 2 shows five example plays of “division-level3,” including four pass attempts and one er of this level, interspersed with ers from other levels. we consider consecutive\n",
      "ers as an er session, as these ers are circumstanced on\n",
      "the same pass attempts.\n",
      "table 2: example of er and pass attempts\n",
      "play objective-level\n",
      "passed? play type\n",
      "1\n",
      "division- level3\n",
      "no\n",
      "pass attempt\n",
      "2\n",
      "division- level3\n",
      "no\n",
      "pass attempt\n",
      "3\n",
      "division-level1\n",
      "yes\n",
      "er (er session1)\n",
      "4\n",
      "division- level3\n",
      "no\n",
      "pass attempt\n",
      "5\n",
      "division-level1\n",
      "yes\n",
      "er (er session2)\n",
      "6\n",
      "division- level3\n",
      "yes\n",
      "pass attempt\n",
      "7\n",
      "division- level3\n",
      "yes\n",
      "er (er session3)\n",
      "8\n",
      "subtraction-level1 no\n",
      "er (er session3)\n",
      "\n",
      "3.3.1\n",
      "\n",
      "pass attempt features\n",
      "\n",
      "we defined performance to be the percentage of puzzles a\n",
      "student completed before losing all lives on the level. pass\n",
      "attempts are plays prior to er, where we assumed students play with the intention of passing the level. pass attempt features included: performance when a student first\n",
      "attempted a level (1st pass attempt performance), number of\n",
      "attempts taken to pass a level (# pass attempts), and average performance of all pass attempts (average pass attempt\n",
      "performance). at the student granularity, students took an\n",
      "average of 1.91 (sd=0.89) attempts to pass each level, with\n",
      "average performance of 0.80 (sd=0.10) on the first pass attempt, and 0.87 (sd=0.07) on all pass attempts (indicating\n",
      "overall improved performance on later attempts).\n",
      "\n",
      "3.3.2\n",
      "\n",
      "elective replay features\n",
      "\n",
      "table 3 shows er features that describe er from three angles: (i) the frequencies of er, (ii) the performance of er,\n",
      "and (iii) the circumstances of er in terms of the er’s prior\n",
      "plays. to summarize, the majority of ers had higher performance than their levels’ first attempt, and resulted in\n",
      "another pass of their levels. levels that were ered had similar performance compared to levels that weren’t ered, but\n",
      "levels that were followed(54.65%) or interrupted (54.35%)\n",
      "by er had much lower performance than those that weren’t\n",
      "followed or interrupted by er. most ers’ immediately prior\n",
      "pass attempts were from different levels or objectives. there\n",
      "were few instances (9.80%) where students passed a level and\n",
      "immediately ered it following the pass.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "42\n",
      "\n",
      "\f",
      "table 3: elective replay (er) features and their descriptive statistics among students who electively replayed, collapsed to the student granularity.\n",
      "er features\n",
      "\n",
      "descriptive stats\n",
      "\n",
      "i. frequencies of er\n",
      "% er out of all plays\n",
      "m=2.40%, sd=4.26%\n",
      "% objectives that have been electively replayed\n",
      "m=22.94%, sd=20.89%\n",
      "% objectives whose pass attempts were interrupted/followed by er\n",
      "m=19.48%, sd=17.57%\n",
      "ii. performance of er\n",
      "performance of er\n",
      "m=0.71, sd=0.28\n",
      "m=71.96%, sd=31.44%\n",
      "% ers performed better than the level’s first attempt\n",
      "% ers that result in another pass of the level\n",
      "m=60.36%, sd=35.51%\n",
      "iii. circumstances of er\n",
      "the replayed level e.g. “division-lvl1,”“division-lvl3,” and “subtraction-lvl1” in table 2\n",
      "pass attempts features\n",
      "m=0.79, 1.98, 0.87 for 1st performance, #pass attempts, and avg performance\n",
      "the immediately-prior play of the er e.g. play 2 is the immediately-prior play of play 3 in table2\n",
      "performance on the immediately-prior play\n",
      "m=0.63, sd=0.29\n",
      "% ers whose immediately-prior plays is also an er\n",
      "m=0.31, sd=0.28\n",
      "% er whose immediately prior pass attempt is on the same level\n",
      "m=9.80%, sd=23.84%\n",
      "m=40.75%, sd=39.09%\n",
      "% ...... on a different level in the same objective\n",
      "% ...... on a different objective\n",
      "m=49.44%, sd=40.76%\n",
      "the immediate prior pass attempts followed or interrupted by er and er session e.g. “division-lvl3” for\n",
      "all er sessions in table 2\n",
      "pass attempts features\n",
      "m=0.51, 3.62, 0.55 for 1st performance, #pass attempts, and avg performance\n",
      "% er sessions whose prior pass attempt passed the level\n",
      "m=45.65%, sd=40.69%\n",
      "note. statistics are reported at the student granularity, which are calculated through averaging across all objectives played by a student,\n",
      "and then averaged across all students who electively replayed. this means each student contributes equally to the average, regardless of\n",
      "how many objectives s/he played.\n",
      "\n",
      "3.3.3\n",
      "\n",
      "student grouping from er features\n",
      "\n",
      "we created student groups to encapsulate the circumstances\n",
      "under which er occurred, based on students’ majority er\n",
      "and er sessions. based on prior literature, we hypothesized\n",
      "that er is a habitual behavior that arises from individual\n",
      "needs, such as gaining higher scores [3], avoiding progress on\n",
      "the current task [12], or taking a mental break from negative emotions [17]. thus, grouping students based upon the\n",
      "circumstances of replay based on their majority behaviors\n",
      "provides high level profiles to investigate characteristics of\n",
      "students who engaged in er and benefited from er.\n",
      "we characterized er by the timing relative to the student’s\n",
      "current learning objectives and gameplay. the first grouping describes whether the majority er sessions started before (group b) or after (group a) passing the previous attempted level (current learning objective). if there is a tie\n",
      "between the two types of replay session, the student belongs to neither group. for example, table 2 describes a\n",
      "group b student, who has two replay sessions before passing\n",
      "“division-level3,” and one replay session after passing this\n",
      "level but before moving on to the next level.\n",
      "the second grouping describes whether an er followed plays\n",
      "on the same level (sl), a different level under the same objective (dlso), or a different objective (do). for our example in table 2, the student’s pass attempts on “divisionlevel3” was interrupted twice on the third and fifth plays, by\n",
      "replays on “division-level1”(dlso). after passing “division-\n",
      "\n",
      "level3”, the student replayed the same level(sl) once during\n",
      "the seventh play, and a different objective “ subtractionlevel1” (do) once during the eighth play. this group b\n",
      "student had two dlso replays, one sl, and one do replays.\n",
      "thus, this student also belongs to group dlso, because the\n",
      "two groupings are independent of each other.\n",
      "\n",
      "4. methods & results\n",
      "4.1 who engaged in elective replay?\n",
      "we first investigated the demographic characteristics of students who engaged in elective replay. we found that males\n",
      "did so more often than females (male: 63.2%, female: 57.0%,\n",
      "c2(1, n=4827) = 17.99, p<.001). we also found that english\n",
      "language learners (ell) did so more often than their nonell peers (ell: 62.3%, non-ell: 57.1%, c2(1, n=4827)\n",
      "= 12.69, p<.001 ), as did students with reported disabilities (disability: 68.7%, non disability: 59.1%, c2(1, n =\n",
      "4827) = 18.17, p<.001). there were no statistically significant differences in the frequencies of er based on race\n",
      "when operationalized as hispanic/non hispanic, or based\n",
      "on free/reduced lunch eligibility. the frequency of er was\n",
      "not found to be correlated with other out-of-game student\n",
      "factors, such as state standardized math test scores.\n",
      "the frequency of er was also not correlated with in-game\n",
      "pre-test accuracy and confidence at the objective granularity. next, we investigated the gameplay characteristics of\n",
      "students who electively replayed. we first separated students into groups based on their replay patterns. the first\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "43\n",
      "\n",
      "\f",
      "table 4: mann-whitney u tests comparing gameplay characteristics between er pattern student groups\n",
      "group (# stu- pre-test\n",
      "pre-test\n",
      "avg pass at- avg 1st at- #pass at- er perfordents)\n",
      "accuracy\n",
      "confidence tempts’ per- tempt per- tempts\n",
      "mance\n",
      "formance\n",
      "formance\n",
      "base:no er\n",
      "(n=1938)\n",
      "er (n=2889)\n",
      "group a\n",
      "(n=1114)\n",
      "group b\n",
      "(n=1464)\n",
      "group sl\n",
      "(n=173)\n",
      "group dlso\n",
      "(n=983)\n",
      "group do\n",
      "(n=1399)\n",
      "\n",
      "m=0.61\n",
      "sd=0.17\n",
      "*m=0.57\n",
      "sd=0.17\n",
      "m=0.62\n",
      "sd=0.16\n",
      "*m=0.52\n",
      "sd=0.17\n",
      "m=0.61\n",
      "sd=0.17\n",
      "*m=0.54\n",
      "sd=0.18\n",
      "*m=0.58\n",
      "sd=0.16\n",
      "\n",
      "m=0.75\n",
      "sd=0.23\n",
      "m=0.74\n",
      "sd=0.24\n",
      "m=0.77\n",
      "sd=0.22\n",
      "*m=0.72\n",
      "sd=0.25\n",
      "m=0.75\n",
      "sd=0.23\n",
      "m=0.73\n",
      "sd=0.24\n",
      "m=0.75\n",
      "sd=0.23\n",
      "\n",
      "m=0.88\n",
      "sd=0.08\n",
      "*m=0.87\n",
      "sd=0.07\n",
      "*m=0.90\n",
      "sd=0.05\n",
      "*m=0.84\n",
      "sd=0.07\n",
      "m=0.88\n",
      "sd=0.07\n",
      "*m=0.84\n",
      "sd=0.08\n",
      "m=0.88\n",
      "sd=0.06\n",
      "\n",
      "m=0.81\n",
      "sd=0.11\n",
      "*m=0.80\n",
      "sd=0.10\n",
      "*m=0.84\n",
      "sd=0.08\n",
      "*m=0.75\n",
      "sd=0.09\n",
      "m=0.81\n",
      "sd=0.09\n",
      "*m=0.76\n",
      "sd=0.10\n",
      "m=0.81\n",
      "sd=0.08\n",
      "\n",
      "m=1.82\n",
      "sd=0.84\n",
      "*m=1.92\n",
      "sd=0.78\n",
      "*m=1.62\n",
      "sd=0.52\n",
      "*m=2.28\n",
      "sd=1.09\n",
      "m=1.82\n",
      "sd=0.81\n",
      "*m=2.27\n",
      "sd=1.16\n",
      "m=1.80\n",
      "sd=0.71\n",
      "\n",
      "na\n",
      "m=0.72\n",
      "sd=0.29\n",
      "*m=0.77\n",
      "sd=0.27\n",
      "*m=0.67\n",
      "sd=0.29\n",
      "*m=0.84\n",
      "sd=0.29\n",
      "*m=0.67\n",
      "sd=0.32\n",
      "m=0.73\n",
      "sd=0.26\n",
      "\n",
      "note. 1) green and red indicate statistically significances higher and lower than the base class, with *p < .001, +p < .01 2)\n",
      "group a, b: most er sessions happened before (b), after (a) passing the prior non-replay level. group sl, dlso, do: most\n",
      "er followed pass attempts on the same level(sl), different level in same objective(dlso), or different objective (do)\n",
      "\n",
      "5 columns of table 4 shows the results of mann-whitney u\n",
      "tests with benjamini-hochberg correction to compare each\n",
      "group in-game performance to the students who never electively replayed any levels (the base group). the last column\n",
      "compares the averaged er performance of each group to the\n",
      "rest of students who electively replayed.\n",
      "compared to the base group, students for whom most replays happened before passing the prior non-replay level\n",
      "(group b) and students for whom most replays followed a\n",
      "different level on the same objective (group dlso) started\n",
      "with significantly lower pre-test scores and did worse in gameplay, as measured by the three pass attempt features described in section 3.3.2. for example, students in group\n",
      "b started with lower accuracy and confidence at pre-test,\n",
      "took an average 0.5 more attempts to pass a level, and had\n",
      "lower performance on the 1st pass attempt and all pass attempts (including the 1st). it seems that group b students\n",
      "who replayed earlier levels before passing the current one\n",
      "had less prior knowledge, and struggled more in the game.\n",
      "by contrast, students in group a, for whom most replay\n",
      "happened after passing the current level, did slightly better in gameplay compared to students who never electively\n",
      "replayed (the base group). because these students started\n",
      "with pre-test scores that were not statistically significantly\n",
      "different from the base group, their replay patterns are associated with higher gameplay performance.\n",
      "\n",
      "4.2\n",
      "\n",
      "what gets replayed, and when?\n",
      "\n",
      "next, we studied what levels get replayed, and under what\n",
      "circumstances. we used a decision tree classifier which allowed us to identify which factors are most important in\n",
      "relative to er. our goal was not to find precise predictive\n",
      "models, but to augment our understanding of performance\n",
      "and its relationship to er. we used r’s rpart package with\n",
      "parameters minsplit=5% and cp=0.02 to build trees to classify levels that were replayed from levels that were not replayed, and levels whose pass attempts were interrupted or\n",
      "\n",
      "followed by replay from levels that were not interrupted or\n",
      "followed by replay. we randomly undersampled the majority class (levels without replay, levels were not interrupted\n",
      "or followed by replay), so that each class represented half of\n",
      "the observations. we used pass attempt features at the level\n",
      "granularity together with pre-test results, objective, and demographic information to build our tree. we used 10-fold\n",
      "cross validation to access the trees’ accuracies.\n",
      "table 5 reports the trees and the importance of the features.\n",
      "we found that a student’s performance on a particular level\n",
      "influenced whether replay happened during/after the level’s\n",
      "pass attempts. for example, a student was more likely to\n",
      "replay a different level under the same objective (dlso)\n",
      "if they took more than two attempts to pass the current\n",
      "level. this result is related to the previous result in table 4,\n",
      "showing that, at the student level, those with lower gameplay performance were more likely to replay another level\n",
      "under the same objective.\n",
      "on the other hand, the objective to which a level belongs\n",
      "influences whether or not a level would be ered. we built\n",
      "trees to predict if a level is replayed following the same level\n",
      "(same condition of the last row in table 5, n=1,776), the\n",
      "same objective but a different level (n=12,616), or a different objective (n=31,852). for all three conditions, the\n",
      "trees only contains a single node – objective, with accuracy\n",
      "of 55.2%, 62.0%, and 66.9% respectively. this er decision\n",
      "could have been influenced by either the content or timing\n",
      "of the objectives. in our tree node, we noticed that many\n",
      "objectives with a higher chance of er occurred earlier in\n",
      "the curriculum, this could be because students had more\n",
      "time in which these objectives were available for er. our\n",
      "tree model also had only 55.2% accuracy when predicting\n",
      "whether a level would be ered following the pass attempts\n",
      "of itself. one explanation is that we do not have puzzle\n",
      "granularity data on how many lives a student actually lost.\n",
      "from prior literature [4] [7], students may replay the same\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "44\n",
      "\n",
      "\f",
      "table 5: decision trees to predict levels whose pass\n",
      "attempts were interrupted or followed by er\n",
      "condition:\n",
      "inter- trees\n",
      "rupted/followed by\n",
      "er from a different\n",
      "level in the same objective (n=8,094)\n",
      "\n",
      "er from a different\n",
      "objective (n=12,506)\n",
      "\n",
      "er on the same level\n",
      "(n=1,766)\n",
      "\n",
      "77.8% accuracy\n",
      "#pass attempts < 2.5, no\n",
      "#pass attempts ≥ 2.5, yes\n",
      "\n",
      "78.7% accuracy\n",
      "1st attempt performance ≥ 0.94\n",
      "-objective group a, no\n",
      "-objective group b, yes\n",
      "1st attempt performance < 0.94\n",
      "-objective group a\n",
      "—# pass attempts < 6.5, no\n",
      "—# pass attempts ≥ 6.5, yes\n",
      "-objective group b, yes\n",
      "55.2% accuracy\n",
      "objective group a, no\n",
      "objective group b, yes\n",
      "\n",
      "note. trees are presented in text format. for example, the first\n",
      "tree shows that if a student passed a level with less than 2.5 pass\n",
      "attempts, the tree predicts this student will not replay another\n",
      "level during/after this level.\n",
      "\n",
      "level following it pass attempts to get a better score, which\n",
      "means losing fewer lives (making fewer errors) at a level. as\n",
      "shown in table 4, group sl students who performed most\n",
      "of their ers after the same level also achieved the highest\n",
      "er performance.\n",
      "\n",
      "4.3\n",
      "\n",
      "is elective replay associated with gains?\n",
      "\n",
      "in this section we will address our second research question.\n",
      "as part of our analysis we considered three gain scores: accuracy gain, confidence gain, and math gain. the first two\n",
      "were measured by in-game pre- and post-tests. recall that\n",
      "both before and after a student attempts an objective, st\n",
      "math logs the students’ correctness and confidence scores\n",
      "on each question on the pre- and post-tests. we averaged\n",
      "these scores across the pre- and post-test questions to compute the first two gain scores. these were assessed at the\n",
      "objective granularity. math gain was calculated based upon\n",
      "the difference between the students’ state standardized math\n",
      "test scores in years 2012 and 2013. this was assessed at the\n",
      "student granularity.\n",
      "11.8% of the students were excluded from the math gain\n",
      "analysis due to missing state math test records. these excluded students performed statistically significantly worse in\n",
      "the game as measured by the three pass attempt features;\n",
      "this implies that we excluded weaker students. 8.5% of the\n",
      "objective observations were excluded from the accuracy and\n",
      "confidence gain analysis due to missing pre- or post-tests.\n",
      "these excluded observations were not statistically significantly different from the rest as measured by pass attempt\n",
      "features. the accuracy and confidence gains were significantly correlated (r=0.37, p<0.001), but these two gains\n",
      "were not strongly correlated with math gain scores at the\n",
      "student granularity (r<0.1, p<0.001). table 6 reports the\n",
      "percentage of data points that gained, dropped (mainly for\n",
      "avoiding ceiling effect in this data), and did not gain for each\n",
      "\n",
      "figure 2: decision tree to predict whether a student will gain in state standardized math test\n",
      "type of gain based on the marx and cummings normalization method [11].\n",
      "\n",
      "table 6: %observations with gains, no gains, and\n",
      "percentage dropped for the three gains\n",
      "gain types\n",
      "er?\n",
      "gained dropped no gain\n",
      "accuracy\n",
      "(n=75,083)\n",
      "confidence\n",
      "(n=75,083)\n",
      "math test\n",
      "(n=4,827)\n",
      "\n",
      "er\n",
      "no er\n",
      "er\n",
      "no er\n",
      "er\n",
      "no er\n",
      "\n",
      "48.10%\n",
      "43.70%\n",
      "28.30%\n",
      "26.40%\n",
      "41.60%\n",
      "40.80%\n",
      "\n",
      "8.60%\n",
      "6.10%\n",
      "42.60%\n",
      "37.40%\n",
      "0.40%\n",
      "0.50%\n",
      "\n",
      "37.90%\n",
      "36.60%\n",
      "23.70%\n",
      "22.70%\n",
      "46.90%\n",
      "45.70%\n",
      "\n",
      "note. 1)observations in the ’dropped’ column (pre- and posttests were both 0 or 1) were excluded from analysis. 2)accuracy and confidence gains were measured at objective granularity, math gain was measured at student granularity. 3)er and no\n",
      "er were collapsed across level.\n",
      "\n",
      "we first constructed decision trees to partition our data to\n",
      "see which factors influence gains, using the method described\n",
      "in the prior section. no sampling was necessary because the\n",
      "groups had similar sizes. we used pass attempt features,\n",
      "er features, pre-test results, and demographics. for student granularity, we also added the percentage of required\n",
      "objectives attempted by the student.\n",
      "at the objective granularity, we found that pre-test accuracy\n",
      "and confidence were the only selected nodes that predicted\n",
      "accuracy (70.0% accuracy) and confidence gain (74.1% accuracy). students with a pre-test accuracy of < 0.71 (at least 2\n",
      "questions wrong out of 5-10) had a 64.7% chance of positive\n",
      "accuracy gain in the same objective, while the remainder of\n",
      "the students had only a 25.9% chance. students with high\n",
      "pre-test confidence (≤0.95, indicated confidence on almost\n",
      "all questions) had a 62.5% chance of positive confidence gain\n",
      "in the same objective. it could be that these in-game tests\n",
      "were too easy, as 18.9% of pretests achieved full scores in\n",
      "accuracy and 54.5% achieved full scores in confidence.\n",
      "our decision tree for the student granularity is shown in\n",
      "figure 2, with a cross-validated accuracy of 57.8%. students who started with medium level of math abilities (2012\n",
      "state test math scores <474, and ≥ 347) improved their\n",
      "scores when they performed well in st math (average pass\n",
      "attempts performance > 0.8857). this shows that the game-\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "45\n",
      "\n",
      "\f",
      "play data in st math has predictive power for assessment\n",
      "outside of the game. however, for all three gain scores, the\n",
      "er features were not selected for inclusion in the decision\n",
      "tree nor was any correlation found with the students gains.\n",
      "\n",
      "research questions: q1: what are the characteristics of students who electively replay? q2: what gets replayed, and\n",
      "under what circumstances? and q3: is elective replay associated with improvements in students’ accuracy on math\n",
      "objectives, confidence, and general math ability?\n",
      "\n",
      "table 7: mann-whitney u tests comparing gains\n",
      "between er pattern student groups.\n",
      "group\n",
      "(# math\n",
      "accuracy confidence\n",
      "students)\n",
      "(max=600) (max=1) (max=1)\n",
      "\n",
      "we concluded that, with over half of students who electively\n",
      "replayed at least one level, er is a common behavior in st\n",
      "math. moreover, examining elective replay can enhance our\n",
      "understanding about how students play and the characteristics of successful play. for example, we found that students who did poorly on the current level were more likely\n",
      "to electively replay a different level during/after the level’s\n",
      "pass attempts. we also found that students who generally\n",
      "engaged in elective replay before passing the current level\n",
      "(group b) started with lower pre-test scores, did worse during gameplay, and had the lowest objective-level accuracy\n",
      "and confidence gain and math gains. one explanation for\n",
      "this result is that weaker students used er as a work avoidance tactic, as found in mostow et al. [12], and that instances of er stand in for lower motivation or engagement\n",
      "for the objective topic, st math, or mathematics overall.\n",
      "\n",
      "base:no er\n",
      "(n=1938)\n",
      "er (n=2889)\n",
      "group a\n",
      "(n=1114)\n",
      "group b\n",
      "(n=1464)\n",
      "group sl\n",
      "(n=173)\n",
      "group dlso\n",
      "(n=983)\n",
      "group do\n",
      "(n=1399)\n",
      "\n",
      "m=31.5\n",
      "sd=146.6\n",
      "m=27.3\n",
      "sd=139.7\n",
      "m=53.4\n",
      "sd=167.9\n",
      "+m=6.7\n",
      "sd=109.0\n",
      "m=46.2\n",
      "sd=161.2\n",
      "m=21.4\n",
      "sd=123.0\n",
      "m=32.3\n",
      "sd=150.6\n",
      "\n",
      "m=0.31\n",
      "sd=0.25\n",
      "m=0.30\n",
      "sd=0.25\n",
      "*m=0.35\n",
      "sd=0.24\n",
      "*m=0.24\n",
      "sd=0.25\n",
      "m=0.31\n",
      "sd=0.28\n",
      "*m=0.25\n",
      "sd=0.26\n",
      "m=0.32\n",
      "sd=0.23\n",
      "\n",
      "m=0.33\n",
      "sd=0.38\n",
      "m=0.32\n",
      "sd=0.37\n",
      "+m=0.38\n",
      "sd=0.36\n",
      "*m=0.26\n",
      "sd=0.37\n",
      "m=0.31\n",
      "sd=0.37\n",
      "*m=0.27\n",
      "sd=0.37\n",
      "m=0.34\n",
      "sd=0.36\n",
      "\n",
      "note. green and red indicate statistically significances higher\n",
      "and lower than the base class, with *p < .001, +p < .01\n",
      "\n",
      "finally, we investigated how er patterns relate to gains.\n",
      "table 7 reports the result from separating students into 6\n",
      "groups based on er patterns and conducting mann-whitney\n",
      "u tests with benjamini-hochberg correction (as in the previous section). moreover, although decision trees constructed\n",
      "from the complete dataset show that low pre-test results\n",
      "led to more gains, some er pattern groups showed opposite\n",
      "trends. for example, group b, who primarily ered before\n",
      "passing the current level, started with lower pre-test scores,\n",
      "did worse in the game, and had less gains, which were statistically significant, in all three gain measures. the same\n",
      "applies to group dlso. these two groups of students also\n",
      "had the lowest er performance.\n",
      "on the other hand, the base group and group a (who\n",
      "mostly ered after passing the current level) started with\n",
      "pre-test accuracy and confidence scores that are not significantly different (table 4), but group a did significantly\n",
      "better in game, and had higher gains in accuracy and confidence, which were statistically significant. because the mean\n",
      "pre-test score for the base and a groups is approximately\n",
      "0.6, these students were reasonably familiar with the objective before they began playing it. the difference in accuracy\n",
      "and confidence gains suggest that er after students successfully pass a level helped students learn, or implied better\n",
      "learning in the previous gameplay.\n",
      "\n",
      "5. discussion and conclusions\n",
      "this work presents a significant extension on prior studies of\n",
      "replay which have typically taken place over a short period of\n",
      "time and have assessed replay via intentional questionnaires\n",
      "not observed behaviors [14, 5]. this work analyzed logged\n",
      "student-initiated elective replay from a sample of 4,827 3rd5th graders during school year 2012-2013 in st math in\n",
      "a natural educational setting. we sought to answer three\n",
      "\n",
      "on the other hand, compared to students who didn’t er,\n",
      "students who mostly electively replayed after passing the\n",
      "current level (group a) started with pre-test scores that\n",
      "were not significantly different, did better in the game, and\n",
      "had higher learning and confidence gains. one reason could\n",
      "be that these students electively replayed for a better score,\n",
      "as we also found that students who mostly replayed the\n",
      "same level immediately after passing it (group sl) had the\n",
      "highest er performance. this association is especially true\n",
      "among achiever-type players [3] that prefer to gain concrete\n",
      "measurements of success. because losing fewer lives in st\n",
      "math requires better mastery of the math content, er may\n",
      "have helped these students learn. another explanation is\n",
      "that these students’ ers could imply better learning during\n",
      "prior gameplay, as table 4 also shows that group a students\n",
      "had better pass attempt performance. possibly, successful\n",
      "prior performance motivated these students to electively replay more of the game. moreover, because successful prior\n",
      "performance feeds self-efficacy [2, 13], confidence gains in\n",
      "group a students, who chose more er, may be linked to\n",
      "electively replaying levels they have already mastered.\n",
      "from the application perspective, as expected from this complex environment, our effect-sizes are too small to claim er\n",
      "itself as a powerful intervention for learning. instead, our\n",
      "findings suggest the potential of using er patterns to identify weaker students and their struggling moments for intervention. for example, students with group b er patterns\n",
      "started weaker, did poorly in the game, and had lower gains\n",
      "in learning, confidence, and math state test scores. it may\n",
      "be the case that group b er (before passing a level) is a\n",
      "signal that students are struggling in current content and\n",
      "are in need of a mental break [17] or help. if this is the case,\n",
      "it would be beneficial upon detecting these er patterns for\n",
      "st math to alert teachers or to provide interventions, such\n",
      "as suggesting the student to take a break or providing supplemental resources to further explain the math concepts\n",
      "from the pass attempts interrupted by er. our results also\n",
      "suggest avenues for experimental studies that designs a more\n",
      "effective er experience, such as preventing work-avoidance\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "46\n",
      "\n",
      "\f",
      "in er. for example, changing the number of lives students\n",
      "have at each replay, or constraining the problems offered\n",
      "each time they are replayed to be isomorphic but not identical.\n",
      "this work has several limitations. first, the in-game prepost- tests may be too easy for students, as 18.9% of pretests\n",
      "achieved a full score in accuracy, and 54.5% achieved a full\n",
      "score in confidence. the high percentage of students with\n",
      "non-positive learning and accuracy gain could also be caused\n",
      "by students’ slipping or guessing in multiple-choice questions\n",
      "(e.g., 1 incorrect answer reduces accuracy by 14%-20%). the\n",
      "accuracy of the pre- and post-test questions for assessing\n",
      "knowledge might be improved by using short answer questions. the second limitation is that we did not have puzzle\n",
      "granularity data on how many lives a student actually lost\n",
      "or the types of errors they made. third, the grouping of students based on the majority of elective replay assumes that\n",
      "elective replay is a habitual and consistent behavior. future\n",
      "research should investigate other groupings, as well as examining whether there were changes in how students used\n",
      "replay, and what caused the changes. fourth, future work\n",
      "may also include creating quantified features to compare the\n",
      "content and game features across objectives so we may better understand how the game’s content influence students’\n",
      "decision to engage in elective replay.\n",
      "in summary, this work adds new insights to our understanding of elective replay in educational games. our work reveals\n",
      "differential associations between elective replay and performance when replay is categorized by the timing in relation to\n",
      "the student’s current learning objectives and gameplay. our\n",
      "work suggests that low-performing students did not benefit\n",
      "from er; high-performing students both chose er at better\n",
      "times and their ers were associated with benefits from either er or previous gameplay, which supports the results of\n",
      "prior self-regulation research by aleven et al [1]. this work\n",
      "presents prospects for both examining more detailed characteristics of replay and utilizing experimental manipulations.\n",
      "\n",
      "6.\n",
      "\n",
      "acknowledgements\n",
      "\n",
      "this work was supported by nsf grant iuse #1544273\n",
      "“evaluation for actionable change: a data-driven approach”\n",
      "teomara rutherford pi, tiffany barnes & collin f. lynch\n",
      "co-pis.\n",
      "\n",
      "7.\n",
      "\n",
      "references\n",
      "\n",
      "[1] v. aleven, e. stahl, s. schworm, f. fischer, and\n",
      "r. wallace. help seeking and help design in\n",
      "interactive learning environments. review of\n",
      "educational research, 73(3):277–320, 2003.\n",
      "[2] a. bandura. perceived self-efficacy in cognitive\n",
      "development and functioning. educational\n",
      "psychologist, 28:117–148.\n",
      "[3] r. bartle. hearts, clubs, diamonds, spades: players\n",
      "who suit muds. journal of mud research, 1(1):19,\n",
      "1996.\n",
      "[4] a. boyce, k. doran, a. campbell, s. pickford,\n",
      "d. culler, and t. barnes. beadloom game: adding\n",
      "competitive, user generated, and social features to\n",
      "increase motivation. in the 6th international\n",
      "conference on foundations of digital games, pages\n",
      "\n",
      "139–146. acm, 2011.\n",
      "[5] c. burgers, a. eden, m. d. van engelenburg, and\n",
      "s. buningh. how feedback boosts motivation and play\n",
      "in a brain-training game. computers in human\n",
      "behavior, 48:94–103, 2015.\n",
      "[6] s. l. calvert, b. l. strong, and l. gallagher. control\n",
      "as an engagement feature for young children’s\n",
      "attention to and learning of computer content.\n",
      "american behavioral scientist, 48(5):578–589, 2005.\n",
      "[7] d. b. clark, b. c. nelson, h. y. chang,\n",
      "m. martinez-garza, k. slack, and c. m. d’angelo.\n",
      "exploring newtonian mechanics in a\n",
      "conceptually-integrated digital game: comparison of\n",
      "learning and affective outcomes for students in taiwan\n",
      "and the united states. computers education,\n",
      "57(3):2178–2195, 2011.\n",
      "[8] d. i. cordova and m. r. lepper. intrinsic motivation\n",
      "and the process of learning: beneficial effects of\n",
      "contextualization, personalization, and choice. journal\n",
      "of educational psychology, 88(4):715, 1996.\n",
      "[9] j. p. gee. what video games have to teach us about\n",
      "learning and literacy. st. martin’s griffin - macmillan,\n",
      "new york, usa, 2007.\n",
      "[10] g. a. gunter, r. f. kenny, and e. h. vick. taking\n",
      "educational games seriously: using the retain model\n",
      "to design endogenous fantasy into standalone\n",
      "educational games. educational technology research\n",
      "and development, 56(5-6):511–537, 2008.\n",
      "[11] j. d. marx and k. cummings. normalized change.\n",
      "american journal of physics, 75(1):87–91, 2007.\n",
      "[12] j. mostow, j. beck, r. chalasani, a. cuneo, p. jia,\n",
      "and k. kadaru. a la recherche du temps perdu, or as\n",
      "time goes by: where does the time go in a reading\n",
      "tutor that listens? in in international conference on\n",
      "intelligent tutoring systems, pages 320–329, 2002.\n",
      "[13] f. pajares. self-efficacy beliefs in academic setting.\n",
      "review of educational research, 66:543–578.\n",
      "[14] j. l. plass, p. a. o’keefe, b. d. homer, j. case, e. o.\n",
      "hayward, m. stein, and k. perlin. the impact of\n",
      "individual, competitive, and collaborative\n",
      "mathematics game play on learning, performance, and\n",
      "motivation. journal of educational psychology,\n",
      "105(4):1050, 2013.\n",
      "[15] m. prensky. computer games and learning: digital\n",
      "game-based learning. in handbook of computer games\n",
      "studies. the mit press, cambridge, ma, usa, 2005.\n",
      "[16] t. rutherford, g. farkas, g. duncan, m. burchinal,\n",
      "m. kibrick, j. graham, l. richland, n. tran,\n",
      "s. schneider, l. duran, and m. martinez. a\n",
      "randomized trial of an elementary school mathematics\n",
      "software intervention: spatial-temporal math. journal\n",
      "of research on educational effectiveness,\n",
      "7(4):358–383, 2014.\n",
      "[17] j. l. sabourin, j. p. rowe, b. w. mott, and j. c.\n",
      "lester. considering alternate futures to classify\n",
      "off-task behavior as emotion self-regulation: a\n",
      "supervised learning approach. jedm-journal of\n",
      "educational data mining, 5(1):9–38, 2013.\n",
      "[18] s. thomas, g. schott, and m. kambouri. designing\n",
      "for learning or designing for fun? setting usability\n",
      "guidelines for mobile educational games. learning with\n",
      "mobile devices: a book of papers, pages 173–181, 2004.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "47\n",
      "\n",
      "\f",
      "grade prediction with temporal course-wise influence\n",
      "zhiyun ren\n",
      "\n",
      "computer science\n",
      "george mason university\n",
      "4400 university drive,\n",
      "fairfax, va 22030\n",
      "\n",
      "zren4@gmu.edu\n",
      "\n",
      "xia ning\n",
      "\n",
      "computer & information\n",
      "science\n",
      "indiana university - purdue\n",
      "university indianapolis\n",
      "420 university blvd,\n",
      "indianapolis, in 46202\n",
      "\n",
      "huzefa rangwala\n",
      "\n",
      "computer science\n",
      "george mason university\n",
      "4400 university drive,\n",
      "fairfax, va 22030\n",
      "\n",
      "rangwala@cs.gmu.edu\n",
      "\n",
      "xning@cs.iupui.edu\n",
      "\n",
      "abstract\n",
      "there is a critical need to develop new educational technology applications that analyze the data collected by universities to ensure that students graduate in a timely fashion\n",
      "(4 to 6 years); and they are well prepared for jobs in their\n",
      "respective fields of study. in this paper, we present a novel\n",
      "approach for analyzing historical educational records from\n",
      "a large, public university to perform next-term grade prediction; i.e., to estimate the grades that a student will get\n",
      "in a course that he/she will enroll in the next term. accurate next-term grade prediction holds the promise for better student degree planning, personalized advising and automated interventions to ensure that students stay on track\n",
      "in their chosen degree program and graduate on time. we\n",
      "present a factorization-based approach called matrix factorization with temporal course-wise influence that incorporates course-wise influence effects and temporal effects for\n",
      "grade prediction. in this model, students and courses are\n",
      "represented in a latent “knowledge” space. the grade of a\n",
      "student on a course is modeled as the similarity of their latent representation in the “knowledge” space. course-wise\n",
      "influence is considered as an additional factor in the grade\n",
      "prediction. our experimental results show that the proposed\n",
      "method outperforms several baseline approaches and infer\n",
      "meaningful patterns between pairs of courses within academic programs.\n",
      "\n",
      "keywords\n",
      "next-term grade prediction, course-wise influence, temporal\n",
      "effect, latent factor\n",
      "\n",
      "1. introduction\n",
      "data analytics is at the forefront of innovation in several\n",
      "of today’s popular educational technologies (edtech) [17].\n",
      "currently, one of the grand challenges facing higher education is the problem of student retention and graduation [19].\n",
      "there is a critical need to develop new edtech applications\n",
      "\n",
      "that analyze the data collected by universities to ensure that\n",
      "students graduate in a timely fashion (4 to 6 years), and they\n",
      "are well prepared for jobs in their respective fields of study.\n",
      "to this end, several universities deploy a suite of software\n",
      "and tools. for example, degree planners 1 assist students\n",
      "in deciding their majors or fields of study, choosing the sequence of courses within their chosen major and providing\n",
      "advice for achieving career and learning objectives. early\n",
      "warning systems [27] inform advisors/students of progress,\n",
      "and additionally provide cues for intervention when students\n",
      "are at the risk of failing one or more courses and dropping\n",
      "out of their program of study. in this work, we focus on the\n",
      "problem of next-term grade prediction where the goal is to\n",
      "predict the grade that a student is expected to obtain in a\n",
      "course that he/she may enroll in the next term (future).\n",
      "in the past few years, several algorithms have been developed to analyze educational data, including matrix factorization (mf) algorithms inspired from recommender system\n",
      "research. mf methods decompose the student-course (or\n",
      "student-task) grade matrix into two low-rank matrices, and\n",
      "then the prediction of the grade for a student on an untaken\n",
      "course is calculated as the product of the corresponding vectors in the two decomposed matrices [22, 11]. traditional\n",
      "mf algorithms have shown a strong ability to deal with\n",
      "sparse datasets [14] and their extensions have incorporated\n",
      "temporal and dynamic information [12]. in our setting, we\n",
      "consider that a student’s knowledge is continuously being\n",
      "enriched while taking a sequence of courses; and it is important to incorporate this dynamic influence of sequential\n",
      "courses within our models. therefore, we present a novel\n",
      "approach referred as matrix factorization with temporal\n",
      "course-wise influence (mftci) model to predict next term\n",
      "student grades. mftci considers that a student’s grade on\n",
      "a certain course is determined by two components: (i) the\n",
      "student’s competence with respect to each course’s topics,\n",
      "content and requirement, etc., and (ii) student’s previous\n",
      "performance over other courses. we performed a comprehensive set of experiments on various datasets. the experimental results show that the proposed method outperforms\n",
      "several state-of-the-art methods. the main contributions of\n",
      "our work in this paper are as follows:\n",
      "1. we model and incorporate temporal course-wise influence in addition to matrix factorization for grade\n",
      "1\n",
      "http://www.blackboard.com/mobilelearning/planner.aspx\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "48\n",
      "\n",
      "\f",
      "prediction. our experimental results demonstrate significant improvement from course-wise influence.\n",
      "2. our model successfully captures meaningful coursewise influences which correlate to the course content.\n",
      "3. the learned influences between pairs of courses help\n",
      "in understanding pre-requisite structures within programs and tuning academic program chains.\n",
      "\n",
      "2. related work\n",
      "over the past few years, several methods have been developed to model student behavior and academic performance [2, 9], and they gain improvement of learning outcomes [21]. methods influenced by recommender system\n",
      "(rs) research [1], including collaborative filtering (cf) [18]\n",
      "and matrix factorization [13], have attracted increasing attention in educational mining applications which relate to\n",
      "student grade prediction [32] and in-class assessment prediction [8]. sweeney et. al. [31, 30] performed an extensive study of several recommender system approaches including svd, svd-knn and factorization machine (fm) to\n",
      "predict next-term grade performance. inspired by contentbased recommendation [20] approaches, polyzou et. al. [23]\n",
      "addressed the future course grade prediction problem with\n",
      "three approaches: course-specific regression, student-specific\n",
      "regression and course-specific matrix factorization. moreover, neighborhood-based cf approaches [25, 4, 6] predict\n",
      "grades based on the student similarities, i.e., they first identify similar students and use their grades to estimate the\n",
      "grades of the students with similar profiles.\n",
      "in order to capture the changing of user dynamics over time\n",
      "in rs, various dynamic models have been developed. many\n",
      "of such models are based on matrix factorization and state\n",
      "space models. sun et. al. [28, 29] model user preference\n",
      "change using a state space model on latent user factors, and\n",
      "estimate user factors over time using noncausal kalman filters. similarly, chua et.al. [5] apply linear dynamical systems (lds) on non-negative matrix factorization (nmf)\n",
      "to model user dynamics. ju et. al. [12] encapsulate the\n",
      "temporal relationships within a non-negative matrix formulation. zhang et. al. [34] learn an explicit transition\n",
      "matrix over the latent factors for each user, and estimate\n",
      "the user and item latent factors and the transition matrices within a bayesian framework. other popular methods\n",
      "for dynamic modeling include time-weighting similarity decaying [7], tensor factorization [33] and point processes [16].\n",
      "the method proposed in this paper tackle the challenges of\n",
      "next-term grade prediction which relates to the evolvement\n",
      "of student knowledge over taking a sequence of courses. our\n",
      "key contribution involves how we incorporate the temporal\n",
      "course-wise relationships within a mf approach. additionally, the proposed approach learns pairwise relationships between courses that can help in understanding pre-requisite\n",
      "structures within programs and tuning academic program\n",
      "chains.\n",
      "\n",
      "3. preliminaries\n",
      "3.1 problem statement and notations\n",
      "formally, student-course grades will be represented by a series of matrices {g1 , g2 , ..., gt } for t terms. each row\n",
      "of gt represents a student, each column of gt represents a\n",
      "\n",
      "t\n",
      "course, and each value in gt , denoted as gs,c\n",
      ", represents a\n",
      "t\n",
      "grade that student s got on course c in term t (gs,c\n",
      "∈ (0, 4],\n",
      "t\n",
      "gs,c = 0 indicates that student s did not take the course c in\n",
      "term t. we add a small value to failing grade to distinguish\n",
      "0 score from such situation.). student-course\n",
      "p grades up to\n",
      "the tth term will be represented by gt = ti=1 gi with size\n",
      "of n × m, where n is the number of students and m is the\n",
      "number of courses. given the database of (student, course,\n",
      "grade) up to term (t − 1) (i.e., gt −1 ), the next-term grade\n",
      "prediction problem is to predict grades for each student on\n",
      "courses they might enroll in the next term t . to simplify\n",
      "the notations, if not specifically stated in this paper, we will\n",
      "t\n",
      "use gs,c to denote gs,c\n",
      ". our testing set is then (student,\n",
      "course, grade) triples in the tth term, represented by matrix\n",
      "gt . rows from the grade matrices representing a student s\n",
      "will simply be represented as g(s, :) and the specific courses\n",
      "that student has a grade for in this row can be given by\n",
      "c0 ∈ g(s, :).\n",
      "\n",
      "in this paper, all vectors (e.g., uts and vc ) are represented\n",
      "by bold lower-case letters and all matrices (e.g., a) are represented by upper-case letters. column vectors are represented by having the transpose supscriptt , otherwise by default they are row vectors. a predicted/approximated value\n",
      "is denoted by having a ˜ head.\n",
      "\n",
      "4. methods\n",
      "4.1 mf with temporal course-wise influence\n",
      "we consider the student s’ grade on a certain course c, denoted as gs,c , as determined by two factors. the first factor\n",
      "is the student s’ competence with respect to the course c’s\n",
      "topics, content and requirement. this is modeled through\n",
      "a latent factor model, in which s’ competence is captured\n",
      "using a size-k latent factor us , c’s topics and contents are\n",
      "captured using a size-k latent factor vc in the same latent\n",
      "space as us . then the competence of s over c is modeled\n",
      "by the “similarity” between us and vc via their dot product\n",
      "(i.e., uts vc ).\n",
      "the second factor is the previous performance of student s\n",
      "over other courses. we hypothesize that if course c0 has a\n",
      "positive influence on course c, and student s achieved a high\n",
      "grade on c0 , then s tends to have a high grade on c. under\n",
      "this hypothesis, we model this second factor as a product\n",
      "between the performance of student on a previous “related”\n",
      "course where the pairwise course relationships are learned\n",
      "in our formulation. note that we consider this pairwise\n",
      "course influence as time independent, i.e., the influence of\n",
      "one course over another does not change over time. however, the impact from previous performance/grades can be\n",
      "modeled using a decay function over time. taking these two\n",
      "factors, the estimated grade is given as follows:\n",
      "g̃s,c = uts vc\n",
      "p\n",
      "+ e−α\n",
      "|\n",
      "\n",
      "+ e−2α\n",
      "|\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "c0 ∈gt −1 (s,:)\n",
      "\n",
      "p\n",
      "\n",
      "a(c0 , c)gs,c0\n",
      "\n",
      "|gt −1 (s, :)|\n",
      "{z\n",
      "∆(t −1)\n",
      "\n",
      "c00 ∈gt −2 (s,:)\n",
      "\n",
      "00\n",
      "\n",
      "(1)\n",
      "\n",
      "a(c , c)gs,c00\n",
      "\n",
      "|gt −2 (s, :)|\n",
      "{z\n",
      "∆(t −2)\n",
      "\n",
      "}\n",
      "\n",
      ",\n",
      "\n",
      "}\n",
      "\n",
      "49\n",
      "\n",
      "\f",
      "in which a(c0 , c) is the influence of c0 on c, gt −1 (s, :)/gt −2 (s, :\n",
      ") is the subset of courses out of all courses that s has taken in\n",
      "the first/second previous terms, |gt −1 (s, :)|/|gt −2 (s, :)| is\n",
      "the number of such taken courses. e−α /e−2α denote the\n",
      "time-decay factors. in equation 1, we consider previous\n",
      "two terms. more previous terms can be included with even\n",
      "stronger time-decay factors. given the grade estimation as\n",
      "in equation 1, we formulate the grade prediction problem\n",
      "for term t as the following optimization problem,\n",
      "min\n",
      "\n",
      "u,v,a\n",
      "\n",
      "γ\n",
      "1x\n",
      "(gs,c − g̃s,c )2 + (ku k2f + kv k2f )\n",
      "2 s,c\n",
      "2\n",
      "+ τ kak∗ + λkak`1\n",
      "\n",
      "×\n",
      "\n",
      "e−α\n",
      "g\n",
      "|gt −1 (s,:)| s,ci\n",
      "e−2α\n",
      "g\n",
      "|g\n",
      "(s,:)| s,ci\n",
      "t −2\n",
      "\n",
      "(if ci is taken in term t − 1)\n",
      "\n",
      "(if ci is taken in term t − 2)]\n",
      "\n",
      "min τ kz1 k∗ +\n",
      "z1\n",
      "\n",
      "ρ\n",
      "ka − z1 k2f + ρ(tr(u1t (a − z1 )))\n",
      "2\n",
      "\n",
      "we apply the admm [3] technique for equation 2 by reformulating the optimization problem as follows,\n",
      "γ\n",
      "1x\n",
      "(gs,c − g̃s,c )2 + (ku k2f + kv k2f )\n",
      "2 s,c\n",
      "2\n",
      "\n",
      "+τ kz1 k∗ + λkz2 k`1\n",
      "ρ\n",
      "+ (ka − z1 k2f + ka − z2 k2f )\n",
      "2\n",
      "+ρ(tr(u1t (a − z1 )))\n",
      "\n",
      "(4)\n",
      "\n",
      "the closed-form solution of this problem is\n",
      "z1 = s τρ (a + u1 )\n",
      "\n",
      "(5)\n",
      "\n",
      "where sα (x) is a soft-thresholding function that shrinks the\n",
      "singular values of x with a threshold α, that is,\n",
      "sα (x) = u diag((σ − α)+ )v t\n",
      "\n",
      "4.1.1 optimization algorithm of mftci\n",
      "\n",
      "s.t.,\n",
      "\n",
      "s,cj\n",
      "\n",
      "(\n",
      "\n",
      "step 3: update z1 and z2 . for z1 , the problem becomes\n",
      "\n",
      "where u and v are the latent non-negative student factors\n",
      "and course factors, respectively; kak∗ is the nuclear norm\n",
      "of a, which will induce an a of low rank; and kak`1 is the\n",
      "`1 norm of a, which will introduce sparsity in a. in addition, the non-negativity constraint on a is to enforce only\n",
      "positive influence across courses.\n",
      "\n",
      "u,v,a,u1 ,u2 ,z1 ,z2\n",
      "\n",
      "a(ci , cj ) = a(ci , cj ) − lr × [ρ(a(ci , cj ) − z1 (ci , cj ))\n",
      "+ ρ(a(ci , cj ) − z2 (ci , cj )) + ρu1 (ci , cj ) + ρu2 (ci , cj )\n",
      "x\n",
      "−\n",
      "(gs,cj − g̃s,cj )\n",
      "\n",
      "(3)\n",
      "with projection into [0, +∞), where lr is a learning rate.\n",
      "\n",
      "s.t., a ≥ 0\n",
      "\n",
      "min\n",
      "\n",
      "using the gradient descent, the elements in a can be updated as follows.\n",
      "\n",
      "where x = u σv\n",
      "and\n",
      "\n",
      "t\n",
      "\n",
      "(6)\n",
      "\n",
      "is the singular value decomposition of x,\n",
      "(x)+ = max(x, 0).\n",
      "\n",
      "for z2 , the problem becomes\n",
      "ρ\n",
      "min λkz2 k`1 + ka − z2 k2f + ρ(tr(u2t )(a − z2 ))\n",
      "z2\n",
      "2\n",
      "\n",
      "(7)\n",
      "\n",
      "(8)\n",
      "\n",
      "the closed-form solution is\n",
      "z2 = e λ (a + u2 )\n",
      "ρ\n",
      "\n",
      "+ρ(tr(u2t (a − z2 )))\n",
      "\n",
      "(9)\n",
      "\n",
      "where eα (x) is a soft-thresholding function that shrinks the\n",
      "values in x with a threshold α, that is,\n",
      "\n",
      "a≥0\n",
      "\n",
      "eα (x) = (x − α, 0)+\n",
      "\n",
      "(10)\n",
      "\n",
      "where z1 and z2 are two auxiliary variables, and u1 and u2\n",
      "are two dual variables. all the variables are solved via an\n",
      "alternating approach as follows.\n",
      "\n",
      "where ()+ is defined as in equation 7.\n",
      "\n",
      "step 1: update u and v . fixing all the other variables and\n",
      "\n",
      "step 4: update u1 and u2 . u1 and u2 are updated based\n",
      "on standard admm updates:\n",
      "\n",
      "solving for u and v , the problem becomes a classical matrix\n",
      "factorization problem:\n",
      "min\n",
      "u,v\n",
      "\n",
      "x\n",
      "1x\n",
      "γ x\n",
      "(fs,c − uts vc )2 + (\n",
      "kus k22 +\n",
      "kvc k22 )\n",
      "2 s,c\n",
      "2 s\n",
      "c\n",
      "\n",
      "(2)\n",
      "\n",
      "where fs,c = gs,c − ∆(t − 1) − ∆(t − 2) (see eq 1). the\n",
      "matrix factorization problem can be solved using alternating\n",
      "minimization.\n",
      "\n",
      "step 2: update a. fixing all the other variables and solving for a, the problem becomes\n",
      "min\n",
      "a\n",
      "\n",
      "s.t.,\n",
      "\n",
      "ρ\n",
      "1x\n",
      "(gs,c − g̃s,c )2 + (ka − z1 k2f + ka − z2 k2f )\n",
      "2 s,c\n",
      "2\n",
      "\n",
      "+ρ(tr(u1t (a − z1 ))) + ρ(tr(u2t (a − z2 )))\n",
      "a≥0\n",
      "\n",
      "u1 = u1 + (a − z1 );\n",
      "\n",
      "u2 = u2 + (a − z2 )\n",
      "\n",
      "(11)\n",
      "\n",
      "in addition, we conduct computational complexity analysis\n",
      "of mftci and put it in appendix.\n",
      "\n",
      "5. experiments\n",
      "5.1 dataset description\n",
      "we evaluated our method on student grade records obtained\n",
      "from george mason university (gmu) from fall 2009 to\n",
      "spring 2016. this period included data for 23,013 transfer\n",
      "students and 20,086 first-time freshmen (non-transfer i.e.,\n",
      "students who begin their study at gmu) across 151 majors\n",
      "enrolled in 4,654 courses.\n",
      "specifically, we extracted data for six large and diverse majors for both non-transfer and transfer students. these majors include: (i) applied information technology (ait), (ii)\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "50\n",
      "\n",
      "\f",
      "table 1: dataset descriptions\n",
      "major\n",
      "ait\n",
      "biol\n",
      "ceie\n",
      "cpe\n",
      "cs\n",
      "psyc\n",
      "total\n",
      "\n",
      "non-transfer students\n",
      "#s\n",
      "#c\n",
      "#(s,c)\n",
      "239\n",
      "453\n",
      "5,739\n",
      "1,448\n",
      "990\n",
      "33,527\n",
      "393\n",
      "642\n",
      "9,812\n",
      "340\n",
      "649\n",
      "7,710\n",
      "908\n",
      "818\n",
      "18,376\n",
      "911\n",
      "874\n",
      "22,598\n",
      "4,239 1,115 97,762\n",
      "\n",
      "transfer students\n",
      "#s\n",
      "#c\n",
      "#(s,c)\n",
      "982\n",
      "465\n",
      "14,396\n",
      "1,330\n",
      "833\n",
      "22,691\n",
      "227\n",
      "305\n",
      "4,538\n",
      "91\n",
      "219\n",
      "1,614\n",
      "480\n",
      "464\n",
      "7,967\n",
      "1504\n",
      "788\n",
      "24,661\n",
      "4,614 1,019 75,867\n",
      "\n",
      "#s, #c and #s-c are number of students, courses and student-course\n",
      "pairs in educational records across the 6 majors from fall 2009 to\n",
      "spring 2016, respectively.\n",
      "\n",
      "fall 2009 to fall 2015\n",
      "\n",
      "fall 2009 to spring 2015\n",
      "\n",
      "fall 2009 to fall 2014\n",
      "\n",
      "spring 2015\n",
      "\n",
      "spring 2016\n",
      "\n",
      "fall 2015\n",
      "training set:\n",
      "test set:\n",
      "\n",
      "figure 1: different experimental protocols\n",
      "\n",
      "biology (biol), (iii) civil, environmental and infrastructure engineering (ceie), (iv) computer engineering (cpe)\n",
      "(v) computer science (cs) and (vi) psychology (psyc).\n",
      "table 1 provides more information about these datasets.\n",
      "\n",
      "5.2\n",
      "\n",
      "experimental protocol\n",
      "\n",
      "to assess the performance of our next-term grade prediction\n",
      "models, we trained our models on data up to term t − 1\n",
      "and make predictions for term t . we evaluate our method\n",
      "for three test terms, i.e., spring 2016, fall 2015 and spring\n",
      "2015. as an example, for evaluating predictions for term\n",
      "fall 2015, data from fall 2009 to spring 2015 is considered\n",
      "as training data and data from fall 2015 is testing data.\n",
      "datasets. figure 1 shows the three different train-test splits.\n",
      "\n",
      "define a tick to denote the difference between two consecutive letter grades (e.g., c+ vs c or c vs c-). to assess the\n",
      "performance of our grade prediction method, we convert the\n",
      "predicted grades into their closest letter grades and compute the percentage of predicted grades with no error (or\n",
      "0-ticks), within 1-tick and within 2-ticks denoted by pct0 ,\n",
      "pct1 and pct2 , respectively. for the problem of course selection and degree planning, courses predicted within 2 ticks\n",
      "can be considered sufficiently correct. we name these metrics as percentage of tick accuracy (pta).\n",
      "\n",
      "5.4\n",
      "\n",
      "baseline methods\n",
      "\n",
      "we compare the performance of our proposed method to the\n",
      "following baseline approaches.\n",
      "\n",
      "5.4.1\n",
      "\n",
      "matrix factorization\n",
      "\n",
      "matrix factorization is known to be successful in predicting ratings accurately in recommender systems [26]. this\n",
      "approach can be applied directly on next-term grade prediction problem by considering student-course grade matrix as\n",
      "a user-item rating matrix in recommender systems. based\n",
      "on the assumption that each course and student can be represented in the same low-dimensional space, corresponding\n",
      "to the knowledge space, two low-rank matrices containing\n",
      "latent factors are learned to represent courses and students\n",
      "[30]. specifically, the grade a student s will achieve on a\n",
      "course c is predicted as follows:\n",
      "g̃s,c = µ + ps + qc + uts vc\n",
      "\n",
      "(12)\n",
      "n\n",
      "\n",
      "where µ is a global bias term, ps (p ∈ r ) and qc (q ∈\n",
      "rm ) are the student and course bias terms (in this case, for\n",
      "student s and course c), respectively, and us (u ∈ rk×n )\n",
      "and vc (v ∈ rk×m ) are the latent factors for student s and\n",
      "course c, respectively.\n",
      "\n",
      "5.4.2\n",
      "\n",
      "matrix factorization without bias (mf0 )\n",
      "\n",
      "we only considered the student and course latent factors to\n",
      "predict the next-term grades. therefore, the grade a student\n",
      "s will achieve on a course c is calculated as follows:\n",
      "g̃s,c = uts vc\n",
      "\n",
      "5.3\n",
      "\n",
      "evaluation metrics\n",
      "\n",
      "we use root mean squared error (rmse) and mean\n",
      "absolute error (mae) as metrics for evaluation, and are\n",
      "defined as follows:\n",
      "sp\n",
      "2\n",
      "s,c∈gt (gs,c − g̃s,c )\n",
      ",\n",
      "rm se =\n",
      "|gt |\n",
      "p\n",
      "s,c∈gt |gs,c − g̃s,c |\n",
      "m ae =\n",
      "|gt |\n",
      "\n",
      "where gs,c and g̃s,c are the ground truth and predicted grade\n",
      "for student s on course c, and gt is the testing set of (student, course, grade) triples in the tth term. normally, in\n",
      "next-term grade prediction problem, mae is more intuitive\n",
      "than rmse since mae is a straightforward method which\n",
      "calculates the deviation of errors directly while rmse has\n",
      "implications such as penalizing large errors more.\n",
      "for our dataset, a student’s grade can be a letter grade (i.e.\n",
      "a, a-, . . . , f). as done previously by polyzou et. al. [24] we\n",
      "\n",
      "5.4.3\n",
      "\n",
      "(13)\n",
      "\n",
      "non-negative matrix factorization (nmf) [15]\n",
      "\n",
      "we add non-negative constraints on matrix u and matrix v\n",
      "in equation 13. the non-negativity constraints allows mf\n",
      "approaches to have better interpretability and accuracy for\n",
      "non-negative data [10].\n",
      "\n",
      "6. results and discussion\n",
      "6.1 overall performance\n",
      "table 2 presents the comparison of pct0 , pct1 and pct2 for\n",
      "non-transfer students for the three terms considered as test:\n",
      "spring 2016, fall 2015 and spring 2015. we observe that the\n",
      "mftci model outperforms the baselines across the different\n",
      "test sets. on average, mftci outperforms the mf, mf0\n",
      "and nmf methods by 34.18%, 11.59% and 4.08% in terms of\n",
      "pct0 , 16.64%, 7.96% and 4.03% in terms of pct1 , and 2.10%,\n",
      "3.00% and 1.98% in terms of pct2 , respectively. we observe\n",
      "similar results for transfer students as well (not included\n",
      "here for brevity).\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "51\n",
      "\n",
      "\f",
      "table 2: comparison performance with pta (%)\n",
      "methods\n",
      "mf\n",
      "mf0\n",
      "nmf\n",
      "mftci\n",
      "\n",
      "spring 2016\n",
      "fall 2015\n",
      "spring 2015\n",
      "pct0 (↑) pct1 (↑) pct2 (↑) pct0 pct1 pct2 pct0 pct1 pct2\n",
      "13.25\n",
      "27.71\n",
      "58.02 12.05 26.63 58.89 13.03 26.09 54.83\n",
      "16.52\n",
      "31.65\n",
      "57.46 15.51 30.03 55.64 15.53 29.53 54.94\n",
      "13.21\n",
      "27.04\n",
      "57.18 15.33 30.12 56.15 15.56 29.23 54.93\n",
      "19.78 35.52 61.44 19.71 35.16 60.12 18.56 32.78 58.80\n",
      "\n",
      "i) “↑” indicates the higher the better. ii) reported values of pct0 , pct1 and pct2 are percentages. iii) best performing methods are highlighted with bold.\n",
      "\n",
      "0.70\n",
      "\n",
      "table 3 presents the performance of the baselines and mftci\n",
      "model for the three different terms of both non-transfer and\n",
      "transfer students using rmse and mae as evaluation metrics. the mftci model consistently outperforms the baselines across the different datasets in terms of mae. in addition, the results shows that mf0 , nmf and mftci tend\n",
      "to have better performance for spring 2016 term than fall\n",
      "2015 term. similar trend is observed between fall 2015 term\n",
      "and spring 2015 term. this suggests that mftci is likely\n",
      "to have better performance with more information in the\n",
      "training set.\n",
      "\n",
      "6.2\n",
      "\n",
      "analysis on individual majors\n",
      "\n",
      "we divide non-transfer students based on their majors and\n",
      "test the baselines and mftci model on each major, separately. table 4 shows the comparison of pct0 , pct1 and\n",
      "pct2 on different majors. the results show that mftci has\n",
      "the best performance for almost all the majors. among all\n",
      "the results, mftci has the highest accuracy when predicting grades for psyc and biol students for which we have\n",
      "more student-course pairs in the training set.\n",
      "\n",
      "6.3\n",
      "\n",
      "effects from previous terms on mftci\n",
      "\n",
      "in order to see the influence of number of previous terms\n",
      "considered in mftci, we run our model with only ∆(t − 1)\n",
      "in equation 1. this method is represented as mftcip1 .\n",
      "figure 2 shows the comparison results of mae for six subsets of data which are reported in table 3, where “ntr”\n",
      "stands for non-transfer students and “tr” stands for transfer students. the results show that mftci consistently\n",
      "outperforms mftcip1 on all datasets. this suggests that\n",
      "considering two previous terms is necessary for achieving\n",
      "good prediciton results. moreover, since we consider that\n",
      "the student’s knowledge is modeled using an exponential\n",
      "decaying function over time, we do not include the influence\n",
      "from the third previous term in our model as its influence\n",
      "for the grade prediction is negligible in comparison to the\n",
      "previous two terms.\n",
      "\n",
      "6.4\n",
      "\n",
      "visualization of course influence\n",
      "\n",
      "to interpret what is captured in the course influence matrix\n",
      "a (see eq 1), we extract the top 20 values with the corresponding course names (and topics) for analysis. figure 3\n",
      "and 4 show the captured pairwise course influences for cs\n",
      "and ait majors, respectively. each node corresponds to\n",
      "one course which is represented by the shortened course’s\n",
      "name. we can notice from the figures that most influences\n",
      "reflect content dependency between courses. for example,\n",
      "in the cs major, “object oriented programming” course\n",
      "has significant influence on performance of “low-level pro-\n",
      "\n",
      "mftcip1\n",
      "mftci\n",
      "\n",
      "mae\n",
      "\n",
      "0.68\n",
      "0.66\n",
      "0.64\n",
      "0.62\n",
      "0.60\n",
      "\n",
      "figure 2:\n",
      "mftci\n",
      "\n",
      "ntr spring ntr fall ntr spring tr spring tr fall tr spring\n",
      "2016\n",
      "2015\n",
      "2015\n",
      "2016\n",
      "2015\n",
      "2015\n",
      "\n",
      "comparison performance for mftcip1 and\n",
      "\n",
      "gramming” course (the former one is also the latter one’s\n",
      "prerequisite course); “linear algebra” and “discrete mathematics” have influence on each other; “formal methods &\n",
      "models” course has influence on “analysis of algorithms”\n",
      "course. in case of the ait major, both “introductory it”\n",
      "course and “introductory computing” course have influence\n",
      "on “it problem & programming” course; “multimedia &\n",
      "web design” course has influence on both “applied it programming” course and “it in the global economy” course.\n",
      "gmu has a sample schedule of eight-term courses for each\n",
      "major in order to guide undergraduate students to finish\n",
      "their study step by step based on the level, content and\n",
      "difficulty of courses 2 . among the identified relationships\n",
      "shown in figures 3 and 4 we found 17 and 13 of the cs and\n",
      "ait courses influences in the guide map, respectively. the\n",
      "rest of the identified influences are among other general electives but required courses (e.g., “public speaking” course),\n",
      "or specific electives pertaining to the major (e.g., “research\n",
      "methods” course). this shows that our model learns meaningful course-wise influences and successfully uses it to improve mf model.\n",
      "figure 5 shows the identified course influences for the biol,\n",
      "ceie, cpe and psyc majors. these identified course-wise\n",
      "influences seem to capture similarity of course content.\n",
      "\n",
      "7.\n",
      "\n",
      "conclusion and future work\n",
      "\n",
      "we presented a matrix factorization with temporal coursewise influence (mftci) model that integrates factorization\n",
      "models and the influence of courses taken in the preceding\n",
      "terms to predict student grades for the next term.\n",
      "we evaluate our model on the student educational records\n",
      "from fall 2009 to spring 2016 collected from george ma2\n",
      "\n",
      "http://catalog.gmu.edu\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "52\n",
      "\n",
      "\f",
      "table 3: comparison performance with rmse and mae.\n",
      "methods\n",
      "mf\n",
      "mf0\n",
      "nmf\n",
      "mftci\n",
      "\n",
      "spring 2016\n",
      "rmse mae\n",
      "0.999 0.754\n",
      "0.929 0.714\n",
      "1.020 0.769\n",
      "0.928 0.685\n",
      "\n",
      "non-transfer students\n",
      "fall 2015\n",
      "spring\n",
      "rmse mae\n",
      "rmse\n",
      "1.037 0.786\n",
      "1.023\n",
      "0.977 0.752\n",
      "1.014\n",
      "0.967 0.746\n",
      "1.000\n",
      "0.982 0.717\n",
      "1.012\n",
      "\n",
      "2015\n",
      "mae\n",
      "0.784\n",
      "0.778\n",
      "0.771\n",
      "0.750\n",
      "\n",
      "spring\n",
      "rmse\n",
      "0.925\n",
      "0.893\n",
      "0.906\n",
      "0.887\n",
      "\n",
      "2016\n",
      "mae\n",
      "0.688\n",
      "0.668\n",
      "0.683\n",
      "0.636\n",
      "\n",
      "transfer students\n",
      "fall 2015\n",
      "rmse mae\n",
      "0.921 0.686\n",
      "0.944 0.705\n",
      "0.932 0.701\n",
      "0.927 0.662\n",
      "\n",
      "research methods\n",
      "\n",
      "western history\n",
      "\n",
      "0.563\n",
      "object oriented programming\n",
      "\n",
      "computer ethics\n",
      "\n",
      "0.691\n",
      "0.3661\n",
      "\n",
      "0.4953\n",
      "\n",
      "data structures\n",
      "0.4313\n",
      "digital electronics\n",
      "\n",
      "0.4314\n",
      "\n",
      "introductory programming\n",
      "0.4264\n",
      "\n",
      "formal methods & models\n",
      "\n",
      "analytic geometry & calculus\n",
      "\n",
      "0.3526\n",
      "0.3646\n",
      "\n",
      "reading & writng\n",
      "\n",
      "0.4199\n",
      "public speaking\n",
      "\n",
      "0.3797\n",
      "\n",
      "0.3691\n",
      "\n",
      "0.536\n",
      "\n",
      "0.3852\n",
      "\n",
      "low-level programming\n",
      "\n",
      "0.4392\n",
      "\n",
      "spring 2015\n",
      "rmse mae\n",
      "0.985 0.732\n",
      "1.011 0.765\n",
      "0.979 0.746\n",
      "1.000 0.721\n",
      "\n",
      "0.3512\n",
      "\n",
      "linear algebra\n",
      "\n",
      "0.6033\n",
      "advanced composition\n",
      "\n",
      "0.4122 0.4929\n",
      "\n",
      "discrete mathematics\n",
      "\n",
      "0.3512\n",
      "analysis of algorithms\n",
      "\n",
      "figure 3: identified course influences for cs major\n",
      "\n",
      "table 4: comparison performance for different majors\n",
      "methods\n",
      "mf\n",
      "mf0\n",
      "pct0\n",
      "nmf\n",
      "mftci\n",
      "mf\n",
      "mf0\n",
      "pct1\n",
      "nmf\n",
      "mftci\n",
      "mf\n",
      "mf0\n",
      "pct2\n",
      "nmf\n",
      "mftci\n",
      "\n",
      "ait\n",
      "18.71\n",
      "19.45\n",
      "19.77\n",
      "22.30\n",
      "37.95\n",
      "37.21\n",
      "36.79\n",
      "39.64\n",
      "67.02\n",
      "66.17\n",
      "66.70\n",
      "66.70\n",
      "\n",
      "biol ceie cpe\n",
      "cs psyc\n",
      "18.00 15.99 12.99 15.98 20.18\n",
      "22.10 16.70 14.21 16.47 22.12\n",
      "22.16 17.01 14.32 16.61 22.17\n",
      "24.24 16.80 14.32 17.32 25.83\n",
      "35.43 31.47 27.86 31.53 39.41\n",
      "39.68 31.87 27.97 30.51 39.63\n",
      "39.74 31.67 27.19 30.43 39.36\n",
      "40.87 32.38 27.53 31.78 42.29\n",
      "67.78 58.66 52.28 56.91 71.01\n",
      "67.54 58.35 50.72 56.24 67.74\n",
      "67.54 58.55 51.17 56.17 67.79\n",
      "68.25 58.76 52.94 58.18 68.29\n",
      "\n",
      "son university. the dataset in this study contains both\n",
      "non-transfer and transfer students from six different majors. our experimental evaluation shows that mftci consistently outperforms the different state-of-the-art methods.\n",
      "moreover, we analyze the effects from previous terms on\n",
      "mftci, and we make the conclusion that it is necessary\n",
      "to consider two previous terms. in addition, we visualize\n",
      "the patterns learned between pairs of courses. the results\n",
      "strongly demonstrate that the learned course influences correlate with the course content within academic programs.\n",
      "in the future, we will explore incorporation of additional constraints over the the pairwise course influence matrix, such\n",
      "as prerequisite information, compulsory and elective provision of a course. we will explore using the course influence\n",
      "\n",
      "information to build a degree planner for future students.\n",
      "\n",
      "8.\n",
      "\n",
      "acknowledgments\n",
      "\n",
      "funding was provided by nsf grant, 1447489.\n",
      "\n",
      "appendix\n",
      "a. computational complexity analysis\n",
      "the computational complexity of mftci is determined by\n",
      "the four steps in the alternating approach as described above.\n",
      "to update u and v as in equation 2 using gradient descent method via alternating minimization, the computational complexity is o(niteruv (k × ns,c + k × m + k × n)) =\n",
      "o(niteruv (k×ns,c )) (typically ns,c ≥ max(m, n)), where ns,c\n",
      "is the total number of student-course dyads, n is the number of students, m is the number of courses, k is the latent\n",
      "dimensions of u and v , and niteruv is the number of iterations. to update a as in equation 3 using gradient descent\n",
      "method, the computational complexity is upper-bounded by\n",
      "ns,c\n",
      ")), where ncc is the number of course pairs\n",
      "o(nitera (ncc × m\n",
      "ns,c\n",
      "that have been taken by at least one student, m\n",
      "is the average number of students for a course, which upper bounds\n",
      "the average number of students who co-take two courses,\n",
      "and nitera is the number of iteractions. essentially, to update a, we only need to update a(ci , cj ) where ci and cj\n",
      "have been co-taken by some students. for a(ci , cj ) where\n",
      "ci and cj have never been taken together, they will remain\n",
      "0. to update z1 as in equation 4, a singular value decomposition is involved and thus its computational complexity\n",
      "is upper bounded by o(m3 ). to update z2 as in equation 8, the computational complexity is o(m2 ). to update\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "53\n",
      "\n",
      "\f",
      "calculus & applications\n",
      "\n",
      "composition\n",
      "\n",
      "0.2262\n",
      "\n",
      "0.2753\n",
      "\n",
      "introductory computing\n",
      "\n",
      "0.2523\n",
      "\n",
      "computer hardware\n",
      "\n",
      "public speaking\n",
      "\n",
      "0.31\n",
      "\n",
      "0.2317 0.2624\n",
      "\n",
      "multimedia & web design\n",
      "0.2602\n",
      "\n",
      "0.3392\n",
      "\n",
      "western history\n",
      "\n",
      "0.2248\n",
      "\n",
      "discrete mathematics for it\n",
      "\n",
      "0.2453\n",
      "applied it\n",
      "\n",
      "0.2461\n",
      "\n",
      "0.276\n",
      "\n",
      "it in the global economy\n",
      "\n",
      "0.2675 0.3012\n",
      "\n",
      "information security\n",
      "\n",
      "0.3033\n",
      "\n",
      "it problem & programming\n",
      "\n",
      "introductory statistics\n",
      "\n",
      "0.226\n",
      "\n",
      "database fundamentals\n",
      "\n",
      "0.2456\n",
      "\n",
      "applied it programming\n",
      "\n",
      "0.2393\n",
      "\n",
      "introductory it\n",
      "\n",
      "it problem & object oriented techniques\n",
      "\n",
      "0.2217\n",
      "advanced composition\n",
      "\n",
      "figure 4: identified course influences for ait major\n",
      "\n",
      "introductory engineering\n",
      "general chemistry i\n",
      "\n",
      "cell structure & function\n",
      "\n",
      "biostatistics\n",
      "\n",
      "0.6901\n",
      "0.6581\n",
      "\n",
      "1.5541\n",
      "\n",
      "0.7832\n",
      "\n",
      "1.1224\n",
      "\n",
      "1.1074\n",
      "0.5888\n",
      "\n",
      "organic chemistry i\n",
      "\n",
      "general chemistry ii\n",
      "\n",
      "computer graphics\n",
      "\n",
      "0.6835\n",
      "\n",
      "0.6277 0.7009\n",
      "\n",
      "chemistry for engineers\n",
      "\n",
      "0.8673\n",
      "\n",
      "0.6068\n",
      "\n",
      "organic chemistry lab i\n",
      "\n",
      "organic chemistry lab ii\n",
      "\n",
      "physics lab i\n",
      "\n",
      "physics i\n",
      "\n",
      "0.9025\n",
      "\n",
      "0.6707\n",
      "\n",
      "0.5658\n",
      "\n",
      "0.6046\n",
      "\n",
      "physics ii\n",
      "\n",
      "microeconomic\n",
      "\n",
      "calculus ii\n",
      "\n",
      "0.8467\n",
      "\n",
      "0.7125\n",
      "\n",
      "0.5907\n",
      "\n",
      "calculus i\n",
      "\n",
      "0.5345\n",
      "physics i\n",
      "\n",
      "biology of microorganisms\n",
      "\n",
      "(a) identified course influences for biol major\n",
      "\n",
      "(b) identified course influences for ceie major\n",
      "\n",
      "statistics in psychology\n",
      "\n",
      "composition i\n",
      "\n",
      "social psychology\n",
      "\n",
      "0.3382 0.4064\n",
      "introductory engineering\n",
      "0.0556\n",
      "calculus iii\n",
      "\n",
      "0.0478\n",
      "0.0682\n",
      "\n",
      "university physics i\n",
      "0.0436\n",
      "\n",
      "physics lab i\n",
      "\n",
      "linear algebra\n",
      "\n",
      "calculus i\n",
      "0.0509\n",
      "\n",
      "0.0675\n",
      "\n",
      "calculus ii\n",
      "0.0548\n",
      "\n",
      "0.0495\n",
      "\n",
      "university physics ii\n",
      "\n",
      "0.0611\n",
      "introductory programming\n",
      "\n",
      "0.6269\n",
      "\n",
      "cognitive psychology\n",
      "\n",
      "0.4069\n",
      "\n",
      "0.4037\n",
      "research in psychology\n",
      "\n",
      "0.4545\n",
      "abnormal psychology\n",
      "\n",
      "0.389\n",
      "composition ii\n",
      "\n",
      "0.385\n",
      "0.4304\n",
      "\n",
      "0.4898\n",
      "\n",
      "0.0397\n",
      "physics lab ii\n",
      "\n",
      "(c) identified course influences for cpe major\n",
      "\n",
      "physiological psychology\n",
      "\n",
      "(d) identified course influences for psyc major\n",
      "\n",
      "figure 5: identified course influences for different majors\n",
      "\n",
      "u1 and u2 as in equation 11, the computational complexity\n",
      "is o(m2 ). thus, the computational complexity for mtfci\n",
      "ns,c\n",
      ") + m3 + m2 ))\n",
      "is o(niter(niteruv (k × ns,c ) + nitera (ncc × m\n",
      "ns,c\n",
      "= o(niter(niteruv (k×ns,c )+nitera (ncc × m )+m3 )), where\n",
      "niter is the number of iterations for the four steps. although the complexity is dominated by m3 due to the svd\n",
      "on a + u1 , since n (i.e., the number of courses) is typically\n",
      "not large, the run time will be more dominated by ns,c (i.e.,\n",
      "the number of student-course dyads).\n",
      "\n",
      "b.\n",
      "\n",
      "references\n",
      "\n",
      "[1] charu c. aggarwal. recommender systems: the\n",
      "textbook. springer publishing company, incorporated,\n",
      "\n",
      "1st edition, 2016.\n",
      "[2] rsjd baker et al. data mining for education.\n",
      "international encyclopedia of education, 7:112–118,\n",
      "2010.\n",
      "[3] stephen boyd, neal parikh, eric chu, borja peleato,\n",
      "and jonathan eckstein. distributed optimization and\n",
      "statistical learning via the alternating direction\n",
      "r in\n",
      "method of multipliers. foundations and trends\n",
      "machine learning, 3(1):1–122, 2011.\n",
      "[4] hana bydžovská. are collaborative filtering methods\n",
      "suitable for student performance prediction? in\n",
      "portuguese conference on artificial intelligence, pages\n",
      "425–430. springer, 2015.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "54\n",
      "\n",
      "\f",
      "[5] freddy chong tat chua, richard j oentaryo, and\n",
      "ee-peng lim. modeling temporal adoptions using\n",
      "dynamic matrix factorization. in 2013 ieee 13th\n",
      "international conference on data mining, pages\n",
      "91–100. ieee, 2013.\n",
      "[6] tristan denley. course recommendation system and\n",
      "method, january 10 2013. us patent app. 13/441,063.\n",
      "[7] yi ding and xue li. time weight collaborative\n",
      "filtering. in proceedings of the 14th acm international\n",
      "conference on information and knowledge\n",
      "management, cikm ’05, pages 485–492, new york,\n",
      "ny, usa, 2005. acm.\n",
      "[8] asmaa elbadrawy, scott studham, and george\n",
      "karypis. personalized multi-regression models for\n",
      "predicting students performance in course activities.\n",
      "umn cs, pages 14–011, 2014.\n",
      "[9] wu he. examining studentsâăź online interaction in\n",
      "a live video streaming environment using data mining\n",
      "and text mining. computers in human behavior,\n",
      "29(1):90–102, 2013.\n",
      "[10] ngoc-diep ho. nonnegative matrix factorization\n",
      "algorithms and applications. phd thesis, école\n",
      "polytechnique, 2008.\n",
      "[11] chein-shung hwang and yi-ching su. unified\n",
      "clustering locality preserving matrix factorization for\n",
      "student performance prediction. iaeng int. j.\n",
      "comput. sci, 42(3):245–253, 2015.\n",
      "[12] bin ju, yuntao qian, minchao ye, rong ni, and\n",
      "chenxi zhu. using dynamic multi-task non-negative\n",
      "matrix factorization to detect the evolution of user\n",
      "preferences in collaborative filtering. plos one,\n",
      "10(8):e0135090, 2015.\n",
      "[13] yehuda koren, robert bell, and chris volinsky.\n",
      "matrix factorization techniques for recommender\n",
      "systems. computer, 42(8):30–37, august 2009.\n",
      "[14] yehuda koren, robert bell, chris volinsky, et al.\n",
      "matrix factorization techniques for recommender\n",
      "systems. computer, 42(8):30–37, 2009.\n",
      "[15] daniel d lee and h sebastian seung. algorithms for\n",
      "non-negative matrix factorization. in advances in\n",
      "neural information processing systems, pages 556–562,\n",
      "2001.\n",
      "[16] dixin luo, hongteng xu, yi zhen, xia ning,\n",
      "hongyuan zha, xiaokang yang, and wenjun zhang.\n",
      "multi-task multi-dimensional hawkes processes for\n",
      "modeling event sequences. in proceedings of the 24th\n",
      "international conference on artificial intelligence,\n",
      "ijcai’15, pages 3685–3691. aaai press, 2015.\n",
      "[17] rabab naqvi. data mining in educational settings.\n",
      "pakistan journal of engineering, technology &\n",
      "science, 4(2), 2015.\n",
      "[18] xia ning, christian desrosiers, and george karypis.\n",
      "a comprehensive survey of neighborhood-based\n",
      "recommendation methods. in francesco ricci, lior\n",
      "rokach, and bracha shapira, editors, recommender\n",
      "systems handbook, pages 37–76. springer, 2015.\n",
      "[19] michelle parker. advising for retention and\n",
      "graduation. 2015.\n",
      "[20] michael j. pazzani and daniel billsus. the adaptive\n",
      "web. chapter content-based recommendation\n",
      "systems, pages 325–341. springer-verlag, berlin,\n",
      "\n",
      "heidelberg, 2007.\n",
      "[21] alejandro peña-ayala. educational data mining: a\n",
      "survey and a data mining-based analysis of recent\n",
      "works. expert systems with applications,\n",
      "41(4):1432–1462, 2014.\n",
      "[22] štefan pero and tomáš horváth. comparison of\n",
      "collaborative-filtering techniques for small-scale\n",
      "student performance prediction task. in innovations\n",
      "and advances in computing, informatics, systems\n",
      "sciences, networking and engineering, pages 111–116.\n",
      "springer, 2015.\n",
      "[23] agoritsa polyzou and george karypis. grade\n",
      "prediction with models specific to students and\n",
      "courses. international journal of data science and\n",
      "analytics, pages 1–13, 2016.\n",
      "[24] agoritsa polyzou and george karypis. grade\n",
      "prediction with models specific to students and\n",
      "courses. international journal of data science and\n",
      "analytics, pages 1–13, 2016.\n",
      "[25] sanjog ray and anuj sharma. a collaborative\n",
      "filtering based approach for recommending elective\n",
      "courses. in international conference on information\n",
      "intelligence, systems, technology and management,\n",
      "pages 330–339. springer, 2011.\n",
      "[26] francesco ricci, lior rokach, bracha shapira, and\n",
      "paul b kantor. recommender systems handbook.,\n",
      "2011.\n",
      "[27] jill m simons. a national study of student early\n",
      "alert models at four-year institutions of higher\n",
      "education. eric, 2011.\n",
      "[28] john z sun, dhruv parthasarathy, and kush r\n",
      "varshney. collaborative kalman filtering for dynamic\n",
      "matrix factorization. ieee transactions on signal\n",
      "processing, 62(14):3499–3509, 2014.\n",
      "[29] john z sun, kush r varshney, and karthik subbian.\n",
      "dynamic matrix factorization: a state space\n",
      "approach. in 2012 ieee international conference on\n",
      "acoustics, speech and signal processing (icassp),\n",
      "pages 1897–1900. ieee, 2012.\n",
      "[30] mack sweeney, jaime lester, and huzefa rangwala.\n",
      "next-term student grade prediction. in big data (big\n",
      "data), 2015 ieee international conference on, pages\n",
      "970–975. ieee, 2015.\n",
      "[31] mack sweeney, huzefa rangwala, jaime lester, and\n",
      "aditya johri. next-term student performance\n",
      "prediction: a recommender systems approach. arxiv\n",
      "preprint arxiv:1604.01840, 2016.\n",
      "[32] nguyen thai-nghe, lucas drumond, artus\n",
      "krohn-grimberghe, and lars schmidt-thieme.\n",
      "recommender system for predicting student\n",
      "performance. procedia computer science,\n",
      "1(2):2811–2819, 2010.\n",
      "[33] liang xiong, xi chen, tzu-kuo huang, jeff\n",
      "schneider, and jaime g. carbonell. temporal\n",
      "collaborative filtering with bayesian probabilistic\n",
      "tensor factorization, pages 211–222. 2010.\n",
      "[34] chenyi zhang, ke wang, hongkun yu, jianling sun,\n",
      "and ee-peng lim. latent factor transition for\n",
      "dynamic collaborative filtering. in sdm, pages\n",
      "452–460. siam, 2014.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "55\n",
      "\n",
      "\f",
      "toward the automatic labeling of course questions for\n",
      "ensuring their alignment with learning outcomes\n",
      "s. supraja\n",
      "\n",
      "kevin hartman\n",
      "\n",
      "sivanagaraja tatinati\n",
      "\n",
      "andy w. h. khong\n",
      "\n",
      "nanyang technological\n",
      "university\n",
      "50 nanyang ave\n",
      "singapore 639798\n",
      "ssupraja001@e.ntu.edu.sg\n",
      "\n",
      "nanyang technological\n",
      "university\n",
      "50 nanyang ave\n",
      "singapore 639798\n",
      "khartman@ntu.edu.sg\n",
      "\n",
      "nanyang technological\n",
      "university\n",
      "50 nanyang ave\n",
      "singapore 639798\n",
      "tatinati@ntu.edu.sg\n",
      "\n",
      "nanyang technological\n",
      "university\n",
      "50 nanyang ave\n",
      "singapore 639798\n",
      "andykhong@ntu.edu.sg\n",
      "\n",
      "abstract\n",
      "expertise in a domain of knowledge is characterized by a greater\n",
      "fluency for solving problems within that domain and a greater\n",
      "facility for transferring the structure of that knowledge to other\n",
      "domains. deliberate practice and the feedback that takes place\n",
      "during practice activities serve as gateways for developing domain\n",
      "expertise. however, there is a difficulty in consistently aligning\n",
      "feedback about a learner’s practice performance with the intended\n",
      "learning outcomes of those activities – especially in situations\n",
      "where the person providing feedback is unfamiliar with the\n",
      "intention of those activities. to address this problem, we propose\n",
      "an intelligent model to automatically label opportunities for\n",
      "practice (assessment questions) according to the learning outcomes\n",
      "intended by the course designers. as a proof of concept, we used a\n",
      "reduced version of bloom’s taxonomy to define the intended\n",
      "learning outcomes. using a factorial design, we employed term\n",
      "frequency-inverse document frequency (tf-idf) and latent\n",
      "dirichlet allocation (lda) to transform questions from text to word\n",
      "weightages with support vector machine (svm) and extreme\n",
      "learning machine (elm) to train and automatically label the\n",
      "questions. we trained our models with 120 questions labeled by the\n",
      "subject matter expert of an undergraduate engineering course.\n",
      "compared to existing works which create models based on a selfgenerated dataset, our proposed approach uses 30 untrained\n",
      "questions from online/textbook sources to validate the performance\n",
      "of our models. exhaustive comparison analysis of the testing set\n",
      "showed that tf-idf with elm outperformed the other\n",
      "combinations by yielding 0.86 reliability (f1 measure) with the\n",
      "subject matter expert.\n",
      "\n",
      "keywords\n",
      "learning outcomes, term frequency-inverse document frequency,\n",
      "latent dirichlet allocation, extreme learning machine, support\n",
      "vector machine\n",
      "\n",
      "1. introduction\n",
      "increasingly, modern curriculum design in tertiary and adult\n",
      "learning settings has become a collaborative endeavor between\n",
      "subject matter experts, learning designers, and learning\n",
      "technologists. while these teams employ a variety of process\n",
      "\n",
      "models for the planning, execution, and revision of their curriculum\n",
      "and activity designs, often greater attention is paid to the\n",
      "construction of a course design and the course content rather than\n",
      "the assessment practices that measure learning and their ongoing\n",
      "maintenance.\n",
      "the algorithms and use case described in this paper exist in a\n",
      "particular context of outcome-based education. in this context,\n",
      "learning is defined by observable changes in a learner’s behavior.\n",
      "these changes commensurate with krathwohl’s model of learning\n",
      "objectives [1] but learning outcomes go beyond objectives.\n",
      "learning outcomes are predicated on having learners observably\n",
      "demonstrate their growing understanding of a topic or proficiency\n",
      "within a field [2]. when learning activities become more openended and exploratory, and when learners are offered choices for\n",
      "how to proceed, learners often look to how they will ultimately be\n",
      "assessed to gauge which learning strategies they should employ [3].\n",
      "when a course’s learning activities support its assessment practices\n",
      "and the assessment practices support the types of outcomes that are\n",
      "relevant to learners in the future, the course’s activities and\n",
      "intended learning outcomes exhibit constructive alignment with\n",
      "each other [2]. adhering to constructive alignment creates a\n",
      "seamless path from learning, to applying, to transferring concepts\n",
      "and relationships when solving novel problems.\n",
      "however, the promise of constructive alignment is not easily\n",
      "delivered upon. oftentimes, a course’s learning outcomes cannot\n",
      "be measured by its assessment practices, or its assessment practices\n",
      "are decontextualized from the types of activities and practices\n",
      "learners are actually preparing for [4]. whether in the context of\n",
      "higher learning or professional development, when thinking about\n",
      "developing flexible, life-long learners it is paramount to have\n",
      "mechanisms in place to support learners as they work to gain\n",
      "domain expertise. these processes should reliably measure\n",
      "learning and link assessment practices to authentic activities.\n",
      "\n",
      "1.1 learning design for domain expertise\n",
      "prior work in designing for adaptive domain expertise, the kind of\n",
      "expertise necessary for learners to function in changing\n",
      "environments and flexible job scopes, has shown that learning\n",
      "design teams need to be cognizant of three elements which will be\n",
      "discussed in turn.\n",
      "\n",
      "1.1.1 levels of learning outcomes\n",
      "learning outcomes range in sophistication and vary by field. in\n",
      "medicine, miller’s pyramid [5] lists learning outcomes beginning\n",
      "with knowing about a subject, progressing to knowing how to do\n",
      "something, to being able to actually demonstrate it in a contrived\n",
      "setting like a role-play with actors, and to being able to demonstrate\n",
      "it in a real environment like a surgical theater [6]. the idea is based\n",
      "on the belief that the development of expertise is a progression from\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "56\n",
      "\n",
      "\f",
      "the recall of facts to the execution of skills. however, as research\n",
      "on problem based learning has shown, demonstration of skill and\n",
      "the recall of facts can proceed independently of each other\n",
      "depending on the learning environment [7].\n",
      "in [8], a field agnostic method of classifying learning outcomes\n",
      "based on their quality is presented. essentially, the structure of\n",
      "observed learning outcomes (solo) taxonomy identifies the\n",
      "level of cognitive sophistication a learning outcome requires.\n",
      "lower level learning outcomes indicate a learner is capable of\n",
      "remembering facts in isolation. more sophisticated levels require\n",
      "learners to assimilate information from various sources to make\n",
      "connections and transform that understanding into something new.\n",
      "perhaps the most popular listing of learning outcomes is bloom’s\n",
      "taxonomy. similar to miller’s pyramid, bloom’s revised\n",
      "taxonomy also begins with the retrieval of facts and information\n",
      "as its foundation and builds up to application of knowledge and\n",
      "further to analyzing, evaluating, and creating. because of its\n",
      "simplicity and familiarity with learning designers and subject\n",
      "matter experts alike, bloom’s taxonomy can easily be used to\n",
      "identify the levels of learning outcomes in a course [9].\n",
      "\n",
      "1.1.2 opportunities for deliberate practice\n",
      "along with identifying a learning activity’s intended outcomes,\n",
      "expertise development requires opportunities for deliberate\n",
      "practice. in contrast to repetitive practice intended for learners to\n",
      "develop automaticity in either the recall of information or the\n",
      "application of a skill, often during time-limited tasks, deliberate\n",
      "practice focuses on mastering the nuances of the domain itself to\n",
      "fine-tune performance [10]. in fact, a learner’s level of grit, a\n",
      "combination of perseverance and passion, predicts how close to\n",
      "expert performance a learner will eventually show [11].\n",
      "the key difference in processes between repetitive practice and\n",
      "deliberate practice leads to different forms of expertise: adaptive\n",
      "and routine [12]. routine forms of expertise allow a learner to\n",
      "conduct a task at an optimal level. adaptive expertise allows\n",
      "learners to learn new tasks or solve novel problems at an\n",
      "accelerated rate. in an industrial setting, routine expertise helps a\n",
      "worker complete a particular job function. adaptive expertise\n",
      "enables that same worker to retrain to fill new job functions.\n",
      "typically, the amount of time necessary to achieve expert\n",
      "performance in a domain is in the order of years to decades [13].\n",
      "however, incremental improvement can be seen in a few practice\n",
      "cycles when activities align to the intended learning outcomes.\n",
      "\n",
      "1.1.3 formative assessments and actionable\n",
      "feedback\n",
      "hand in hand with creating opportunities for deliberate practice is\n",
      "providing formative feedback to the learner about how to improve\n",
      "that practice while that improvement is still relevant. imagine\n",
      "students who diligently answer every question in an engineering\n",
      "textbook but never receive feedback on the quality of their\n",
      "solutions. in this case, the learners would be unable to gauge their\n",
      "performance in relation to the course learning outcomes or have an\n",
      "idea about how to improve their performance in the future. now\n",
      "imagine if those same students do receive feedback, but that\n",
      "feedback arrives after the course’s final examination. if the content\n",
      "of the course is mostly self-contained and will not be revisited, the\n",
      "feedback is mostly irrelevant.\n",
      "formative feedback consists of two parts: 1) an interpretable\n",
      "indication of a learner’s performance on an assessment of learning\n",
      "with respect to a standard of performance (learning outcome) and\n",
      "\n",
      "2) the opportunity to improve performance before the final\n",
      "evaluation [14].\n",
      "cognitive tutors provide a clear example of the power of coupling\n",
      "formative assessment and actionable feedback together in the\n",
      "domain of mathematics learning [15]. by presenting learners with\n",
      "a series of structured problems, cognitive tutors are capable of\n",
      "intervening at any point during the problem-solving process to\n",
      "provide students with feedback about their performance. this\n",
      "feedback may be the identification of an error, the presentation of\n",
      "a hint, or the request for more information about the learner’s\n",
      "reasoning. after the feedback, learners have the opportunity to\n",
      "adjust their problem-solving heuristics to improve their\n",
      "performance going forward.\n",
      "such an interaction sequence works with highly structured tasks\n",
      "with application-oriented learning outcomes. however, the\n",
      "feedback cycle is more difficult to manage when the learning\n",
      "outcomes are aligned to higher-order reasoning like evaluation,\n",
      "analyzing and creating. these outcomes have multiple paths for\n",
      "reaching a satisfactory answer.\n",
      "with this difficulty in mind, we looked at techniques to automate\n",
      "the process of identifying the reasoning level of text-based\n",
      "assessment items (questions) with the intention of better aligning\n",
      "questions to learning outcomes as a first step toward being able to\n",
      "provide opportunities for deliberate practice. subsequently, the\n",
      "outcome of our proposed work is to link actionable feedback to a\n",
      "learner’s performance on assessment items.\n",
      "\n",
      "1.2 automated question classification\n",
      "techniques\n",
      "prior work has shown the viability of automatically labeling\n",
      "questions in accordance with a course’s learning outcomes.\n",
      "however, our work goes beyond labeling existing content to\n",
      "helping course instructors promote deliberate practice and expertise\n",
      "development by providing a method of finding new questions that\n",
      "align to the course designer’s original intended learning outcomes.\n",
      "we highlight the drawbacks of prior work and how our proposed\n",
      "approach addresses those limitations.\n",
      "\n",
      "1.2.1 labeling questions based on difficulty level\n",
      "early attempts at automatically labeling questions relied on subject\n",
      "matter experts to pre-define the difficulty levels of questions.\n",
      "artificial neural network trained by backpropagation then used the\n",
      "question features and assigned difficulty levels in the training set to\n",
      "classify new questions. a five-dimensional feature vector that\n",
      "consisted of query-text relevance, mean term frequency, length of\n",
      "questions and answers, term frequency distribution (variance),\n",
      "distribution of questions and answers in a text were used. the\n",
      "method yielded an f1 measure, a classification reliability metric\n",
      "that measures a test’s accuracy, of 0.78 [16]. however, a major\n",
      "pitfall this method is its lack of semantic analysis.\n",
      "entropy-based decision tree has also been used to label questions\n",
      "[17]. the weakness in this strategy is that there is high possibility\n",
      "of overfitting the model during the training phase that then\n",
      "negatively affects the subsequent prediction performance.\n",
      "\n",
      "1.2.2 labeling questions based on bloom’s\n",
      "taxonomy using natural language processing\n",
      "natural language processing (nlp) has been used for the\n",
      "generation of assessments, answering questions, supporting users\n",
      "in learning management systems and preparing course materials.\n",
      "the wordnet package has been used to detect semantic similarity.\n",
      "by performing a rule-based approach, the accuracy of labeling a\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "57\n",
      "\n",
      "\f",
      "question based on bloom’s taxonomy reaches 82% [18]. to\n",
      "improve the rule-based approach, a hybrid technique of using an ngram classifier with a rule-based approach has also been explored.\n",
      "rules were based on combining parts-of-speech tagging, and the\n",
      "n-gram classifier found the probabilities of predicting certain\n",
      "words. such a hybrid method yielded an f1 measure of 0.86 [19].\n",
      "\n",
      "understanding) were collapsed into remember. applying\n",
      "remained its own category. all of the higher-order reasoning\n",
      "categories (analyzing, evaluating, and creating) were collapsed\n",
      "into transfer. figure 1 shows how our labeling scheme categories\n",
      "map onto the original categories from bloom’s revised taxonomy.\n",
      "\n",
      "1.2.3 labeling questions based on bloom’s\n",
      "taxonomy using machine learning techniques\n",
      "machine learning algorithms can be broadly split into either\n",
      "supervised or unsupervised training implementations. generally,\n",
      "supervised training is adopted when, during training, labels have\n",
      "been pre-determined and questions are labeled by an expert. the\n",
      "most commonly used method in such cases is the term frequencyinverse document frequency (tf-idf). the algorithm assigns\n",
      "weightages to individual words in a question statement to define a\n",
      "custom vector space to each question.\n",
      "machine learning techniques such k-nearest neighbors, naïve\n",
      "bayes and support vector machine (svm) have been implemented\n",
      "for labeling questions. when doing a performance comparison\n",
      "among these three techniques, an f1 measure of 0.71 was achieved\n",
      "using svm [20]. to increase the accuracy level, additional features\n",
      "were incorporated in future versions of the work. three different\n",
      "feature selection processes, namely: odd ratio, chi-square statistic\n",
      "and mutual information were used with the three machine learning\n",
      "techniques. the f1 measure result reached 0.9 [21].\n",
      "furthermore, an integrated approach of feature extraction has been\n",
      "proposed by using headword, semantic, keyword and syntactic\n",
      "extractions, which are fed into svm [22]. however, this work has\n",
      "not yet been completed by using a testing dataset to quantify the\n",
      "reliability of prediction.\n",
      "a major downside in existing works is that both the training as well\n",
      "as testing questions are part of the same course curriculum; the\n",
      "questions are generated by the same author/instructor. even when\n",
      "a high f1 measure is achieved, it does not enable the algorithm to\n",
      "label questions written by another subject matter expert. our work\n",
      "increases the flexibility of labeling methods by testing our models\n",
      "with a new set of questions compiled from textbook and online\n",
      "resources.\n",
      "in addition, our work introduces extreme learning machine (elm),\n",
      "which has been shown to outperform svm during similar labeling\n",
      "tasks [23]. moreover, we introduce lda as an alternative technique\n",
      "to tf-idf for transforming question statements into numerical\n",
      "word weightages.\n",
      "by comparing combinations of these new techniques with more\n",
      "traditional techniques, we aim to gauge which combination attains\n",
      "the highest labeling reliability with the subject matter expert when\n",
      "automatically labeling untrained questions. for our purposes, using\n",
      "the combination with the highest f1 measure (fewest false\n",
      "negatives and false positives) becomes paramount. in our use case,\n",
      "a mislabeling by the algorithm will lead to the wrong set of practice\n",
      "questions to be given to students and diminish the impact of\n",
      "deliberate practice on reaching the intended learning outcomes.\n",
      "\n",
      "2. methods\n",
      "2.1 materials\n",
      "2.1.1 labeling scheme\n",
      "the core of this study centers on a labeling scheme for identifying\n",
      "the sophistication of learning outcomes based on a simplified\n",
      "version of bloom’s taxonomy. in this labeling scheme, the first\n",
      "two levels of bloom’s taxonomy (remembering and\n",
      "\n",
      "figure 1: mapping of bloom's revised taxonomy [24]\n",
      "we collapsed the taxonomy into three categories for two reasons.\n",
      "first, the subject matter expert tasked with labeling the questions\n",
      "was unsure about how reliably the questions could be labeled by\n",
      "someone without a background in learning design, educational\n",
      "psychology, or curriculum development. collapsing the categories\n",
      "to remember, apply, and transfer made manually labeling\n",
      "hundreds of questions to train the machine learning algorithms\n",
      "more tractable. second, collapsing the categories had the effect of\n",
      "making bloom’s taxonomy more analogous to the successful use\n",
      "cases of miller’s pyramid by subject matter experts in both higher\n",
      "education and professional development settings [5].\n",
      "\n",
      "2.1.2 question dataset\n",
      "the dataset consists of a total of 150 questions used for training and\n",
      "testing the machine learning algorithms based on the content of an\n",
      "undergraduate electrical and electronic engineering course.\n",
      "for this study, we formed a training set of 120 questions by\n",
      "randomly selecting 40 remember, apply, and transfer items from\n",
      "the larger question pool of more than 200 questions used in that\n",
      "course. the pool came from a repository of four years’ worth of\n",
      "assignment, homework, quiz and exam questions presented to\n",
      "students. these questions prompt students for a range of answer\n",
      "types (i.e., open-ended, multiple-choice, short-structured, essay).\n",
      "we then created a testing set of 30 new questions compiled from\n",
      "external sources such as textbooks and online question banks. this\n",
      "set was also balanced with equal representation of remember,\n",
      "apply, and transfer questions.\n",
      "\n",
      "2.2 data pre-processing procedures\n",
      "we pre-processed the raw questions in two phases. first, the subject\n",
      "matter expert labeled every question according to the labeling\n",
      "scheme described above. second, we transformed the text of every\n",
      "question into a machine-readable format before passing them\n",
      "through the machine learning algorithms.\n",
      "\n",
      "2.2.1 subject matter expert pre-processing\n",
      "the subject matter expert manually labeled each question in the\n",
      "training set based on its intended learning outcome (remember,\n",
      "apply or transfer). the subject matter expert then labeled the 30\n",
      "new questions in the testing set in the same manner. these new\n",
      "questions are labeled for the purpose of knowing the ground truth\n",
      "for performance evaluation. table 1 below shows some examples\n",
      "of the labeled questions.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "58\n",
      "\n",
      "\f",
      "table 1 - examples of labeled questions\n",
      "remember\n",
      "consider a signal described by y[n] = 2n +4. what would be the\n",
      "amplitude of the signal at sample index n=3?\n",
      "apply\n",
      "consider the following input and output signals: find the transfer\n",
      "function and state the poles and zeros of this transfer function.\n",
      "transfer\n",
      "describe how the bandpass filter can be utilized for radar\n",
      "applications.\n",
      "\n",
      "2.2.2 text pre-processing\n",
      "the text transformation began by excising all equations,\n",
      "mathematical symbols and diagrams from the questions. we only\n",
      "kept the core of the question prompts by removing the descriptive\n",
      "and explanatory text from scenario and hypothetical questions. for\n",
      "example, if a question began by setting the stage with “peter has\n",
      "been asked to perform…”, followed by the question prompt “how\n",
      "much voltage should peter expect in the circuit?”, all of the\n",
      "descriptive text prior to the question prompt was removed to\n",
      "improve the consistency of word length and usage between items.\n",
      "for the remaining words in the questions, we changed all of the\n",
      "characters to lower case, removed all punctuation marks, numbers,\n",
      "and non-unicode characters. we then stemmed the remaining\n",
      "words to obtain a list of root words. from this list of root words, we\n",
      "removed all words with fewer than three letters. because we were\n",
      "unsure of the relationship between the words and the labels, we did\n",
      "not create a list of stopwords for removal.\n",
      "\n",
      "3. techniques\n",
      "we tested four combinations (in no particular order) of word\n",
      "weighting and question labeling algorithms, as shown in figure 2,\n",
      "to identify the techniques with the highest reliability for our\n",
      "automated learning outcome labeler.\n",
      "\n",
      "we implemented a modified version of tf-idf that used individual\n",
      "questions as the source of the analysis instead of complete\n",
      "documents. this focused the model on finding the relevance of each\n",
      "word within each single question. by converting each question into\n",
      "a vector of weightages based on word frequencies, the machine\n",
      "learning algorithms were then used to label the questions. the\n",
      "modified tf-idf model can be described by\n",
      "𝑇𝐹 − 𝐼𝐷𝐹(𝑤𝑖 , 𝑞𝑘 ) = #(𝑤𝑖 , 𝑞𝑘 ) × log\n",
      "\n",
      "𝑇𝑅\n",
      "#𝑇𝑅(𝑤𝑖 )\n",
      "\n",
      "(1)\n",
      "\n",
      "where wi refers to a particular word i, qk refers to a particular\n",
      "question k, #(wi,qk) refers to number of times wi occurs in qk, tr\n",
      "refers to total number of questions and #tr(wi) refers to question\n",
      "frequency, or the number of questions in which wi occurs [20].\n",
      "in the case where the term frequency (tf) count is biased towards\n",
      "longer questions, the tf count is normalized as\n",
      "𝑇𝐹𝑖,𝑘 =\n",
      "\n",
      "𝑛𝑖,𝑘\n",
      "\n",
      "(2)\n",
      "\n",
      "∑𝑗 𝑛𝑗,𝑘\n",
      "\n",
      "where ni,k refers to the number of times wi occurs in qk, the\n",
      "denominator term (size of each question) refers to the sum of the\n",
      "number of times each word appears in qk [25].\n",
      "for our work, the pre-processing procedures registered a total of\n",
      "465 unique stemmed words in our compilation of 120 training\n",
      "questions and 30 testing questions. this led to each question being\n",
      "represented as a vector of 1 row and 465 columns arranged in\n",
      "alphabetical order by stemmed word. when a word is present in a\n",
      "question, the normalized weight of that word is assigned to that\n",
      "question’s vector element. if a word is not present in the question,\n",
      "the weight is zero.\n",
      "after determining the unique word weightage vectors for all 150\n",
      "questions, the entire matrix is sorted such that for each question, the\n",
      "weightages are arranged in ascending order. the top ten weightages\n",
      "are chosen for each question. the 10 weightages may correspond\n",
      "to different words in each question, but their combinations remain\n",
      "question-specific and give a numerical representation of each\n",
      "question statement. this new vector of 10 columns per question\n",
      "serves as the input to the machine learning algorithms.\n",
      "as an example, we will use the pre-processed question prompt:\n",
      "for signal which begin when the one side unilateral ztransform given\n",
      "\n",
      "table 2 below shows the weightages assigned to the above example\n",
      "after the application of the tf-idf technique. the weightages are\n",
      "then arranged in ascending order and the top 10 values are taken.\n",
      "table 2 - tf-idf weightage arrangement\n",
      "figure 2: four combinations of algorithms\n",
      "every word in each question prompt was assigned a weightage\n",
      "value based on either term frequency-inverse document frequency\n",
      "(tf-idf) or latent dirichlet allocation (lda). subsequently, the\n",
      "vector values for each question were passed through either support\n",
      "vector machine (svm) or extreme learning machine (elm) to\n",
      "assign a label. all algorithms were implemented in r studio.\n",
      "\n",
      "3.1 term frequency-inverse document\n",
      "frequency\n",
      "term frequency-inverse document frequency (tf-idf) is a\n",
      "technique for finding the relative frequency of words in a given\n",
      "document, and comparing those frequencies with the inverse of\n",
      "how often each of those words appear in the complete document\n",
      "corpus. the resulting ratio can be used to signify the relevance of\n",
      "each unique word within a single document.\n",
      "\n",
      "word (alphabetical order)\n",
      "\n",
      "weightage\n",
      "\n",
      "begin\n",
      "\n",
      "0.392\n",
      "\n",
      "for\n",
      "\n",
      "0.140\n",
      "\n",
      "given\n",
      "\n",
      "0.140\n",
      "\n",
      "one\n",
      "\n",
      "0.222\n",
      "\n",
      "side\n",
      "\n",
      "0.356\n",
      "\n",
      "signal\n",
      "\n",
      "0.116\n",
      "\n",
      "the\n",
      "\n",
      "0.007\n",
      "\n",
      "unilateral\n",
      "\n",
      "0.392\n",
      "\n",
      "when\n",
      "\n",
      "0.279\n",
      "\n",
      "which\n",
      "\n",
      "0.230\n",
      "\n",
      "ztransform\n",
      "\n",
      "0.216\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "59\n",
      "\n",
      "\f",
      "3.2 latent dirichlet allocation\n",
      "latent dirichlet allocation (lda) is a probabilistic technique for\n",
      "topic modeling based on the bayesian model. the essential idea of\n",
      "lda is that each document consists of a mixture of topics, with the\n",
      "continuous-valued mixture properties distributed in a dirichlet\n",
      "random variable, a continuous multivariate probability distribution.\n",
      "again, in the context of our work, we applied lda to questions in\n",
      "the dataset by substituting the original notion of documents in the\n",
      "lda algorithm with questions in our modified model. therefore,\n",
      "the modified model attempted to find k number of topics (k is a\n",
      "user-defined parameter to determine the desired number of topics,\n",
      "or dimensionality of the dirichlet distribution) for a given set of\n",
      "question statements based on the choice and usage of words in each\n",
      "question. the joint distribution of a topic mixture, a set of topics\n",
      "and a set of words can be represented by\n",
      "𝑝(𝜃, 𝑡, 𝑤|𝛼, 𝛽) = 𝑝(𝜃|𝛼) ∏𝑀\n",
      "𝑖=1 𝑝(𝑡𝑖 |𝜃)𝑝(𝑤𝑖 |𝑡𝑖 , 𝛽)\n",
      "\n",
      "(3)\n",
      "\n",
      "where parameter α is a k-vector with components more than zero,\n",
      "parameter β refers to the matrix of word probabilities, θ refers to a\n",
      "k-dimensional dirichlet random variable, ti refers to a topic, wi\n",
      "refers to a word [26].\n",
      "figure 3 shows a graphical model representation of lda. the\n",
      "bigger circle refers to questions while the smaller circle refers to\n",
      "the repeated choice of topics and words within each question.\n",
      "\n",
      "out of the entire set of stemmed words detected, ten words have\n",
      "been identified as topic names. hence, lda automatically\n",
      "associates the remaining words the above-mentioned ten topics.\n",
      "based on the words that appear in each question, lda displays the\n",
      "number of topics per question. based on the topic assignments, the\n",
      "topic weightages for each question is generated. for topics not\n",
      "present in a question, a minimal weightage is given to those topics\n",
      "in lieu of a zero value. the value ensures that the topic weightages\n",
      "for a question sum to one. similar to the tf-idf output, the new\n",
      "vector of 10 columns per question becomes the input for the\n",
      "machine learning algorithms.\n",
      "\n",
      "3.3 extreme learning machine\n",
      "extreme learning machine (elm) is a learning algorithm for\n",
      "single-hidden layer feedforward neural networks (slfns). elm\n",
      "can be used for classification, regression, clustering, compression\n",
      "and feature learning. elm randomly chooses the hidden nodes and\n",
      "determines the output weights of the neural networks.\n",
      "the following three-step learning model explains elm. given a\n",
      "training set that is labeled (information about the target nodes),\n",
      "hidden node activation function and number of hidden nodes,\n",
      "step 1: randomly assign hidden node parameters\n",
      "step 2: calculate the hidden layer output matrix, h\n",
      "step 3: calculate the output weight 𝛾\n",
      "given a set of inputs with unknown labels, the objective is to find\n",
      "the target outputs [27]. once the inter-layer weights have been\n",
      "found, the same weights are used during the testing phase. for a\n",
      "given set of input samples xk, the target/output is given by tk. for\n",
      "number of hidden nodes l and with a certain activation function\n",
      "f(x), the slfn is modeled as\n",
      "∑𝐿𝑗=1 𝛾𝑗 𝑓𝑗 (𝑥𝑘 ) = ∑𝐿𝑗=1 𝛾𝑗 𝑓(𝑤𝑗 ∙ 𝑥𝑘 + 𝑏𝑗 ) = 𝑜𝑘 , 𝑘 = 1, … , 𝐿 (4)\n",
      "\n",
      "figure 3: graphical model representation of lda\n",
      "since lda involves topic modeling, an appropriate k value chosen\n",
      "for our work was ten. this allowed a standard comparison between\n",
      "lda and the top ten weightages from the tf-idf method. the\n",
      "generated unique topics (based on the stemmed words) are shown\n",
      "in table 3.\n",
      "table 3 - topic names generated by lda\n",
      "topic number\n",
      "\n",
      "stemmed topic name\n",
      "\n",
      "1\n",
      "\n",
      "differ\n",
      "\n",
      "2\n",
      "\n",
      "discrete\n",
      "\n",
      "3\n",
      "\n",
      "impulse\n",
      "\n",
      "4\n",
      "\n",
      "signal\n",
      "\n",
      "5\n",
      "\n",
      "filter\n",
      "\n",
      "6\n",
      "\n",
      "apply\n",
      "\n",
      "7\n",
      "\n",
      "dft\n",
      "\n",
      "8\n",
      "\n",
      "output\n",
      "\n",
      "9\n",
      "\n",
      "sample\n",
      "\n",
      "10\n",
      "\n",
      "system\n",
      "\n",
      "where wj refers to the weight vector that stores the weights between\n",
      "input and hidden nodes, 𝛾j refers to the weight vector that stores the\n",
      "weights between the hidden and output nodes, bj refers to the\n",
      "threshold of the jth hidden nodes. the objective is that ok and tk\n",
      "(original target) should have zero difference [23] using possible\n",
      "activation functions that include sigmoid, sine, radial basis and\n",
      "hard-limit.\n",
      "in our case, the output of the elm are three continuous values that\n",
      "represent the values assigned to the three learning outcome\n",
      "categories (remember, apply and transfer). to convert the three\n",
      "values into a binary value for comparing the predicted labels with\n",
      "the actual labels, we set the learning outcome category with the\n",
      "highest value to one and the remaining two to zero.\n",
      "\n",
      "3.4 support vector machine\n",
      "support vector machine (svm) is a mapping of data samples such\n",
      "that these samples can be distinctly labeled. the concept of svm\n",
      "is derived from margins and subsequently separating data into\n",
      "groups with large gaps between them. deriving an optimal\n",
      "hyperplane for identifying linearly separable patterns is the key to\n",
      "svm. this idea is extended to cases where the patterns are nonlinearly separable, by using a kernel function to transform the\n",
      "original data samples to map onto a new space [28]. possible\n",
      "kernels are: linear, polynomial, radial basis and sigmoid.\n",
      "for our work, we used the c-support vector classification type.\n",
      "given a set of inputs and targets, the cost function is given by [29]\n",
      "1\n",
      "\n",
      "min 𝑝𝑇 𝑝 + 𝐶 ∑𝑘𝑗=1 𝜉𝑗\n",
      "\n",
      "𝑝,𝑚,𝜉 2\n",
      "\n",
      "(5)\n",
      "\n",
      "subject to 𝑦𝑗 (𝑝𝑇 𝜙(𝑣𝑗 ) + 𝑚) ≥ 1 − 𝜉𝑗 , 𝜉𝑗 ≥ 0, 𝑗 = 1, … , 𝑘\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "60\n",
      "\n",
      "\f",
      "where c>0 is the regularization parameter, m is a constant, p is the\n",
      "vector of coefficients, 𝜉𝑗 refers to parameters that handle the inputs,\n",
      "index j refers to labeling the k training cases, v refers to the\n",
      "independent variables, y refers to the class labels, 𝜙 refers to the\n",
      "kernel used that transforms data from the input to the chosen feature\n",
      "space.\n",
      "fundamentally, support vectors are data points that lie close to the\n",
      "decision boundary, which are the hardest to classify. svm\n",
      "maximizes the margin around the hyperplane that separates these\n",
      "points. the cost function is determined based on the training\n",
      "samples (support vectors). these support vectors are the basic\n",
      "elements of a training set that would change the position of the\n",
      "hyperplane dividing the dataset. svm becomes an optimization\n",
      "problem for determining the optimal hyperplane.\n",
      "\n",
      "3.5 performance metrics\n",
      "to evaluate the reliability of our four technique combinations with\n",
      "the subject matter expert’s labels, we looked at using the f1\n",
      "measure. accuracy is the number of correct labels divided by the\n",
      "size of testing data. the f1 measure is a harmonic mean of two\n",
      "other metrics: precision and recall. precision refers to the\n",
      "correctness of questions that have been selected as a particular\n",
      "category. recall refers to the correctness of selection of the correct\n",
      "category given all the questions that were correctly classified.\n",
      "because minimizing the number of false positives and false\n",
      "negatives was important for accurately assigning new questions to\n",
      "the correct practice sets, we used the f1 measure as the basis for\n",
      "our algorithm comparisons. to explain the f1 measure, we will step\n",
      "through the confusion matrix used to describe the performance of a\n",
      "labeling model on a set of testing data. there are four concepts used\n",
      "to construct the confusion matrix:\n",
      "true positive (tp) refers to the number of questions that the\n",
      "algorithm correctly identifies as presenting a label.\n",
      "false positive (fp) refers to the number of questions that the\n",
      "algorithm identifies as presenting a label while the subject matter\n",
      "expert indicates the label was absent.\n",
      "true negative (tn) refers to the number of questions that the\n",
      "algorithm correctly identifies as having a label absent.\n",
      "false negative (fn) refers to the number of questions that the\n",
      "algorithm identifies as having a label absent while the subject\n",
      "matter expert indicates the label was present.\n",
      "the f1 measure is calculated as follows [30]\n",
      "𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 =\n",
      "𝑅𝑒𝑐𝑎𝑙𝑙 =\n",
      "𝐹1 𝑚𝑒𝑎𝑠𝑢𝑟𝑒 =\n",
      "\n",
      "𝑇𝑃\n",
      "(𝑇𝑃+𝐹𝑃)\n",
      "𝑇𝑃\n",
      "\n",
      "(𝑇𝑃+𝐹𝑁)\n",
      "\n",
      "2 × 𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 × 𝑟𝑒𝑐𝑎𝑙𝑙\n",
      "𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛+𝑟𝑒𝑐𝑎𝑙𝑙\n",
      "\n",
      "(6)\n",
      "(7)\n",
      "(8)\n",
      "\n",
      "4. results and analysis\n",
      "4.1 insights by subject matter expert\n",
      "when looking at every question presented to students over the\n",
      "course of a semester, the subject matter expert identified the\n",
      "number of questions corresponding to remember, apply and\n",
      "transfer as shown in table 4. just by labeling the course questions,\n",
      "the subject matter expert realized how misaligned the course’s\n",
      "learning outcomes were with its assessment practices. a large\n",
      "emphasis on apply questions was expected, but the dearth of\n",
      "transfer questions was surprising. of those 23 transfer items, most\n",
      "were presented during the final exam.\n",
      "\n",
      "table 4 - frequency of questions aligned to learning outcomes\n",
      "learning outcome\n",
      "\n",
      "frequency (number of questions)\n",
      "\n",
      "remember\n",
      "\n",
      "62\n",
      "\n",
      "apply\n",
      "\n",
      "131\n",
      "\n",
      "transfer\n",
      "\n",
      "23\n",
      "\n",
      "one of the stated learning outcomes of the course was to prepare\n",
      "students to flexibly transfer course content to novel problems and\n",
      "new situations. however, waiting until the final exam to present\n",
      "students with such opportunities denied them actionable feedback\n",
      "during the semester. in response to the pre-processing labeling\n",
      "efforts, the subject matter expert then added 42 new transfer\n",
      "questions throughout the course for the next semester.\n",
      "\n",
      "4.2 model reliability with subject matter\n",
      "expert\n",
      "the objective of this implementation is to evaluate whether the\n",
      "trained model is able to predict the type of question (remember,\n",
      "apply or transfer). based on the trained model using questions\n",
      "from the undergraduate course, the testing questions from\n",
      "textbooks and online sources were passed through our model to\n",
      "determine the level of reliability of labeling new questions that\n",
      "were not generated by the subject matter expert. in our intended use\n",
      "case, the testing dataset would not need to be manually labeled.\n",
      "however, to determine the level of reliability of our labeling\n",
      "algorithms, the subject matter expert’s manual labels served as a\n",
      "ground truth for the f1 measure calculations.\n",
      "\n",
      "4.2.1 parameter selection\n",
      "we first determined the best set of parameters based on 10-fold\n",
      "cross validation of the training dataset. as there were 120\n",
      "questions, 90% of the questions (108 questions) were used for\n",
      "training and 10% of the questions (12 questions) were used as a\n",
      "validation set. this process was done 10 times using 10 different\n",
      "bundles of the 120 questions. the best set of parameters were\n",
      "chosen based on a grid search for both elm and svm.\n",
      "the parameters that were varied for elm were:\n",
      "1.\n",
      "2.\n",
      "\n",
      "number of hidden nodes\n",
      "activation function (sigmoid / radial basis / hard-limit)\n",
      "\n",
      "the parameters yielding the best results corresponded to 72 hidden\n",
      "nodes using hard-limit activation function.\n",
      "the parameters that were varied for svm were:\n",
      "1.\n",
      "2.\n",
      "3.\n",
      "\n",
      "kernel (sigmoid / radial basis)\n",
      "cost value\n",
      "gamma value\n",
      "\n",
      "the parameters yielding the best results corresponded to sigmoid\n",
      "kernel, cost value = 1, gamma value = 0.26\n",
      "\n",
      "4.2.2 comparing four combinations\n",
      "with respect to the f1 measure, calculations were done separately\n",
      "for the three labels. the mean of those calculations was then used\n",
      "as the algorithm’s overall performance measure. with respect to\n",
      "elm, the calculation was repeated 10 times because the\n",
      "initialization weights are randomly assigned in each iteration. the\n",
      "mean value of the f1 measure was taken.\n",
      "table 5 below shows the f1 measure values (for each individual\n",
      "class and overall f1 mean) for the four combinations. “r” refers to\n",
      "remember, “a” refers to apply, “t” refers to transfer and “s.d.”\n",
      "refers to standard deviation.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "61\n",
      "\n",
      "\f",
      "table 5 - f1 measure values for four combinations\n",
      "combination\n",
      "\n",
      "r\n",
      "\n",
      "a\n",
      "\n",
      "t\n",
      "\n",
      "mean\n",
      "\n",
      "s.d.\n",
      "\n",
      "1. tf-idf\n",
      "with svm\n",
      "\n",
      "0.870\n",
      "\n",
      "0.737\n",
      "\n",
      "0.667\n",
      "\n",
      "0.758\n",
      "\n",
      "0.084\n",
      "\n",
      "2. lda with\n",
      "svm\n",
      "\n",
      "0.400\n",
      "\n",
      "0.593\n",
      "\n",
      "0.556\n",
      "\n",
      "0.516\n",
      "\n",
      "0.084\n",
      "\n",
      "3. tf-idf\n",
      "with elm\n",
      "\n",
      "0.926\n",
      "\n",
      "0.815\n",
      "\n",
      "0.840\n",
      "\n",
      "0.860\n",
      "\n",
      "0.048\n",
      "\n",
      "4. lda with\n",
      "elm\n",
      "\n",
      "0.467\n",
      "\n",
      "0.520\n",
      "\n",
      "0.647\n",
      "\n",
      "0.545\n",
      "\n",
      "0.076\n",
      "\n",
      "tf-idf with elm achieved the highest mean f1 measure value\n",
      "and the lowest standard deviation – indicating that it was the most\n",
      "reliable combination. it can be seen that the remember label yields\n",
      "the highest f1 values out of the three labels in combination 3. in\n",
      "general, remember-labeled questions are short, resulting in about\n",
      "four to five zero values in the tf-idf vector of 10 columns that is\n",
      "passed as an input into the elm. hence, the algorithm identifies\n",
      "remember-labeled questions very accurately due to their size.\n",
      "the result of high reliability in using elm is as expected because\n",
      "it has already been demonstrated that elm outperforms svm when\n",
      "comparing in terms of standard deviation of training and testing\n",
      "root-mean-square values, time taken, network complexity, as well\n",
      "as performance comparison in real medical diagnosis application\n",
      "[23]. on the other hand, although lda has been shown to achieve\n",
      "higher performance as it groups words together in terms of topics\n",
      "instead of looking at combinations of individual words which may\n",
      "not link together, in the context of our work, tf-idf outperforms\n",
      "lda instead. this is because for lda, the goal is to correctly\n",
      "assign each document (or question) to a class label in a reduced\n",
      "dimensional space [31]. however, in our corpus of questions, there\n",
      "are several technical terms involved, without any prior labeling of\n",
      "topics. hence, lda is not appropriate for our analysis.\n",
      "\n",
      "5. conclusions\n",
      "based on the comparison of our four algorithms, our most reliable\n",
      "model (tf-idf with elm) is able to accurately label new course\n",
      "questions for the undergraduate electrical and electronic\n",
      "engineering course with 0.86 reliability in terms of f1 measure.\n",
      "any novice instructor who takes over this course in the future or\n",
      "teaching assistants tasked with refreshing the course assignments\n",
      "would be able to extract new questions from any external source\n",
      "and pass them to the algorithm to automatically label the questions\n",
      "as the original course coordinator would. this allows members of\n",
      "the course design team without a strong background in learning to\n",
      "make curriculum decisions regarding the alignment of the course’s\n",
      "learning outcomes.\n",
      "as discussed earlier, outcome-based learning environments\n",
      "facilitate transforming the model of instruction from instructorcentric and lecture-based to being more learner focused filled with\n",
      "a variety of activities and learning pathways. however, in learnercentered environments, assessment is still the key driver, and often\n",
      "the key inhibitor of learning [3]. if the assessments require shallow\n",
      "understanding, then learners calibrate their efforts to achieve this\n",
      "low bar. when assessments require deep understanding or great\n",
      "proficiency, learners are likely to put in more effortful practice.\n",
      "in line with this assessment philosophy, our tf-idf with elm\n",
      "model is theoretically capable of matching any learning activity to\n",
      "any set of learning outcomes as long as the course designers or\n",
      "subject matter experts provide enough examples that are explicitly\n",
      "\n",
      "aligned to the intended learning outcomes when training the model.\n",
      "for the convenience of the subject matter expert in our context, we\n",
      "used a reduced version of bloom’s taxonomy in this study.\n",
      "however, the final algorithm is capable of using the full bloom’s\n",
      "model, a different model, or a custom set of learning outcomes as\n",
      "its labeling framework.\n",
      "hence, with the high reliability of the prediction algorithm\n",
      "presented in our work, our process for calibrating the algorithm can\n",
      "be used in any academic or industrial setting to provide the right set\n",
      "of formative assessment opportunities to students (enhancing\n",
      "subject knowledge) or employees (professional development).\n",
      "once the learning outcomes of activities are labeled reliably, it is\n",
      "then easier to think about how to engage learners in deliberate\n",
      "practice to reach those outcomes and develop their expertise. once\n",
      "opportunities for deliberate practice that align to the course learning\n",
      "outcomes are implemented into a course, it becomes easier to think\n",
      "about how to align the feedback regarding those opportunities to\n",
      "support the development of domain expertise.\n",
      "this work provides a first step at being able to regularly introduce\n",
      "learning activities that promote the development of adaptive\n",
      "expertise into a course by matching external sources of activities\n",
      "with the course’s learning outcomes. deliberate practice requires\n",
      "repetition that varies in ways that highlight the structural elements\n",
      "of a domain. having a way to incorporate new sources of questions\n",
      "and problems into a course that align with the course’s goals\n",
      "provides learners more opportunities for internalizing when to\n",
      "apply their domain specific skills and knowledge. finally, our\n",
      "algorithm is potentially useful for designing courses to reach noncontent-based learning outcomes, making policies that support\n",
      "constructive alignment, and evaluating course assessment of\n",
      "learning plans.\n",
      "\n",
      "6. future work\n",
      "building off of our machine learning labeling work, we would like\n",
      "to explore constructing a new version of lda that can be tailormade to label questions. there are situations in which weightages\n",
      "given to words are the same, with different words representing\n",
      "those weightages. similarly, the same words can have different\n",
      "weightages. we are keen to continue working on features based on\n",
      "word arrangement, word context and word order that affect\n",
      "weightage assignments. in addition, elm can be enhanced by\n",
      "using kernels.\n",
      "from the learning aspect, we would like to extend our question\n",
      "label categories to all six outcomes described in bloom’s\n",
      "taxonomy and expand the model to label outcomes based on the\n",
      "types of sentences used in forum conversations and other\n",
      "collaborative learning activities. eventually, we aim to determine\n",
      "the proficiency level of learners so we can put learning supports in\n",
      "place to guide their learning journeys. ultimately, we wish to\n",
      "provide learners with learning activities and opportunities for\n",
      "deliberate practice embedded with actionable feedback to develop\n",
      "their adaptive expertise.\n",
      "\n",
      "7. acknowledgments\n",
      "this work was conducted within the delta-ntu corporate lab for\n",
      "cyber-physical systems with funding support from delta\n",
      "electronics inc and the national research foundation (nrf)\n",
      "singapore under the corp lab@university scheme.\n",
      "\n",
      "8. references\n",
      "[1] krathwohl, d.r. 2002. a revision of bloom's taxonomy:\n",
      "an overview. theory into practice. 41, 4 (2002), 212-218.\n",
      "doi= http://dx.doi.org/10.1207/s15430421tip4104_2\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "62\n",
      "\n",
      "\f",
      "[2] biggs, j. 1996. enhancing teaching through constructive\n",
      "alignment. higher education. 32, 3 (1996), 347-364. doi=\n",
      "http://dx.doi.org/10.1007/bf00138871\n",
      "[3] boud, d. 2010. sustainable assessment: rethinking\n",
      "assessment for the learning society. studies in continuing\n",
      "education. 22, 2 (2010), 151-167. doi=\n",
      "http://dx.doi.org/10.1080/713695728\n",
      "[4] boud, d. and falchikov, n. 2006. aligning assessment with\n",
      "long-term learning. assessment & evaluation in higher\n",
      "education. 31, 4 (2006), 399-413. doi=\n",
      "http://dx.doi.org/10.1080/02602930600679050\n",
      "[5] miller, g. e. 1990. the assessment of clinical\n",
      "skills/competence/performance. academic medicine. 65, 9\n",
      "(1990), s63-s67. doi=\n",
      "http://dx.doi.org/10.1097/00001888-199009000-00045\n",
      "[6] wass, v. et al. 2001. assessment of clinical competence.\n",
      "the lancet. 357, 9260 (2001), 945-949. doi=\n",
      "http://dx.doi.org/10.1016/s0140-6736(00)04221-5\n",
      "[7] hmelo-silver, c.e. 2004. problem-based learning: what\n",
      "and how do students learn? educational psychology\n",
      "review. 16, 3 (2004). 235-266. doi=\n",
      "http://dx.doi.org/10.1023/b:edpr.0000034022.16470.f3\n",
      "[8] biggs, j. b. and collis, k.f. 2014. evaluating the quality of\n",
      "learning: the solo taxonomy (structure of the observed\n",
      "learning outcomes). academic press.\n",
      "[9] crowe, a. et al. 2008. biology in bloom: implementing\n",
      "bloom's taxonomy to enhance student learning in biology.\n",
      "cbe-life sciences education. 7, 4 (2008), 368-381. doi=\n",
      "http://dx.doi.org/10.1187/cbe.08-05-0024\n",
      "[10] ericsson, k.a. et al. 1993. the role of deliberate practice\n",
      "in the acquisition of expert performance. psychological\n",
      "review. 100, 3 (1993), 363-406. doi=\n",
      "http://dx.doi.org/10.1037/0033-295x.100.3.363\n",
      "[11] duckworth, a. l. et al. 2007. grit: perseverance and\n",
      "passion for long-term goals. journal of personality and\n",
      "social psychology. 92, 6 (2007), 1087. doi=\n",
      "http://dx.doi.org/10.1037/0022-3514.92.6.1087\n",
      "[12] schwartz d. l. et al. 2005. efficiency and innovation in\n",
      "transfer. transfer of learning from a modern\n",
      "multidisciplinary perspective. information age publishing.\n",
      "1-51.\n",
      "[13] chi, m. t. 2006. two approaches to the study of experts'\n",
      "characteristics. the cambridge handbook of expertise and\n",
      "expert performance. cambridge university press. 21-30.\n",
      "[14] black, p. and william, d. 1998. assessment and classroom\n",
      "learning. assessment in education principles policy and\n",
      "practice. 5, 1 (1998), 7-74. doi=\n",
      "http://dx.doi.org/10.1080/0969595980050102\n",
      "[15] ritter, s. et al. 2007. cognitive tutor: applied research in\n",
      "mathematics education. psychonomic bulletin & review. 14,\n",
      "2 (2007), 249-255. doi=\n",
      "http://dx.doi.org/10.3758/bf03194060\n",
      "[16] fei, t. et al. 2003. question classification for e-learning by\n",
      "artificial neural network. in proceedings of the 2003 joint\n",
      "fourth international conference on information,\n",
      "communications and signal processing and the fourth\n",
      "pacific rim conference on multimedia (singapore, 2003),\n",
      "1-5. doi= http://dx.doi.org/10.1109/icics.2003.1292768\n",
      "\n",
      "[17] cheng, s. c. et al. 2005. automatic leveling system for elearning examination pool using entropy-based decision\n",
      "tree. in advances in web-based learning – icwl 2005\n",
      "(hong kong, 2005), 273-278. doi=\n",
      "http://dx.doi.org/10.1007/11528043_27\n",
      "[18] jayakodi, k. et al. 2015. an automatic classifier for exam\n",
      "questions in engineering: a process for bloom's\n",
      "taxonomy. in 2015 ieee international conference on\n",
      "teaching, assessment, and learning for engineering\n",
      "(tale) (zhuhai, china, 2015). doi=\n",
      "https://dx.doi.org/10.1109/tale.2015.7386043\n",
      "[19] haris, s. s. and omar, n. 2015. bloom's taxonomy question\n",
      "categorization using rules and n-gram approach. journal of\n",
      "theoretical and applied information technology. 76, 3\n",
      "(2015), 401-407.\n",
      "[20] yahya, a. a. et al. 2013. analyzing the cognitive level of\n",
      "classroom questions using machine learning techniques. in\n",
      "the 9th international conference on cognitive science\n",
      "(kuching, sarawak, malaysia, 2013). 587-595. doi=\n",
      "http://dx.doi.org/10.1016/j.sbspro.2013.10.277\n",
      "[21] abduljabbar, d. a. and omar, n. 2015. exam questions\n",
      "classification based on bloom's taxonomy cognitive level\n",
      "using classifiers combination. journal of theoretical and\n",
      "applied information technology. 78, 3 (2015), 447-455.\n",
      "[22] sangodiah, a. et al. 2014. a review in feature extraction\n",
      "approach in question classification using support vector\n",
      "machine. in 2014 ieee international conference on\n",
      "control system, computing and engineering (penang,\n",
      "malaysia, 2014), 536-541. doi=\n",
      "http://dx.doi.org/10.1109/iccsce.2014.7072776\n",
      "[23] huang, g. b. et al. 2006. extreme learning machine:\n",
      "theory and applications. neurocomputing. 70, 1-3 (2006),\n",
      "489-501. doi=\n",
      "http://dx.doi.org/10.1016/j.neucom.2005.12.126\n",
      "[24] trinity university course assessment and outcomes: 2016\n",
      "https://inside.trinity.edu/collaborative/collaborativegrants/course-redesign-stipends/course-assessment-andoutcomes. accessed: 2017-02-24.\n",
      "[25] bernardi, r. term frequency and inverted document\n",
      "frequency. university of trento, trentino.\n",
      "[26] blei, d. m. et al. 2003. latent dirichlet allocation. journal\n",
      "of machine learning research. 3 (2003), 993-1022.\n",
      "[27] huang, g. b. 2015. what are extreme learning machines?\n",
      "filling the gap between frank rosenblatt’s dream and\n",
      "john von neumann’s puzzle. cognitive computation. 7, 3\n",
      "(2015), 263-278. doi= http://dx.doi.org/10.1007/s12559015-9333-0\n",
      "[28] weston, j. support vector machine (and statistical\n",
      "learning theory). nec labs america, princeton.\n",
      "[29] chang, c. c. and lin, c. j. 2011. libsvm: a library for\n",
      "support vector machines. acm transactions on\n",
      "intelligent systems and technology (tist). 2, 3 (2011), 139. doi= http://dx.doi.org/10.1145/1961189.1961199\n",
      "[30] santra, a. k. and christy, c. j. 2012. genetic algorithm\n",
      "and confusion matrix for document clustering. ijcsi\n",
      "international journal of computer science issues. 9, 1\n",
      "(2012), 322-328.\n",
      "[31] hu, d. j. 2009. latent dirichlet allocation for text,\n",
      "images, and music.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "63\n",
      "\n",
      "\f",
      "behavior-based latent variable model\n",
      "for learner engagement\n",
      "andrew s. lan1 , christopher g. brinton2 , tsung-yen yang3 , mung chiang1\n",
      "1\n",
      "\n",
      "princeton university, 2 zoomi inc., 3 national chiao tung university\n",
      "\n",
      "andrew.lan@princeton.edu, christopher.brinton@zoomiinc.com, tsungyenyang.eecs02@nctu.edu.tw, chiangm@princeton.edu\n",
      "\n",
      "abstract\n",
      "we propose a new model for learning that relates videowatching behavior and engagement to quiz performance. in\n",
      "our model, a learner’s knowledge gain from watching a lecture\n",
      "video is treated as proportional to their latent engagement\n",
      "level, and the learner’s engagement is in turn dictated by a set\n",
      "of behavioral features we propose that quantify the learner’s\n",
      "interaction with the lecture video. a learner’s latent concept\n",
      "knowledge is assumed to dictate their observed performance\n",
      "on in-video quiz questions. one of the advantages of our\n",
      "method for determining engagement is that it can be done\n",
      "entirely within standard online learning platforms, serving\n",
      "as a more universal and less invasive alternative to existing\n",
      "measures of engagement that require the use of external\n",
      "devices. we evaluate our method on a real-world massive\n",
      "open online course (mooc) dataset, from which we find that\n",
      "it achieves high quality in terms of predicting unobserved\n",
      "first-attempt quiz responses, outperforming two state-of-theart baseline algorithms on all metrics and dataset partitions\n",
      "tested. we also find that our model enables the identification\n",
      "of key behavioral features (e.g., larger numbers of pauses\n",
      "and rewinds, and smaller numbers of fast forwards) that are\n",
      "correlated with higher learner engagement.\n",
      "\n",
      "keywords\n",
      "behavioral data, engagement, latent variable model, learning\n",
      "analytics, mooc, performance prediction\n",
      "\n",
      "1.\n",
      "\n",
      "introduction\n",
      "\n",
      "the recent and rapid development of online learning platforms, coupled with advancements in machine learning, has\n",
      "created an opportunity to revamp the traditional “one-sizefits-all” approach to education. this opportunity is facilitated\n",
      "by the ability of many learning platforms, such as massive\n",
      "open online course (mooc) platforms, to collect several\n",
      "different types of data on learners, including their assessment\n",
      "responses as well as their learning behavior [9]. the focus\n",
      "of this work is on using different forms of data to model\n",
      "the learning process, which can lead to effective learning\n",
      "analytics and potentially improve learning efficacy.\n",
      "\n",
      "1.1\n",
      "\n",
      "behavior-based learning analytics\n",
      "\n",
      "current approaches to learning analytics are focused mainly\n",
      "on providing feedback to learners about their knowledge\n",
      "states – or the level to which they have mastered given concepts/topics/knowledge components – through analysis of\n",
      "their responses to assessment questions [10, 24]. there are\n",
      "other cognitive (e.g., engagement [17, 31], confusion [37], and\n",
      "\n",
      "emotion [11]) as well as non-cognitive (e.g., fatigue, motivation, and level of financial support [14]) factors beyond\n",
      "assessment performance that are crucial to the learning process as well. accounting for them thus has the potential to\n",
      "yield more effective learning analytics and feedback.\n",
      "to date, it has been difficult to measure these factors of the\n",
      "learning process. contemporary online learning platforms,\n",
      "however, have the capability to collect behavioral data that\n",
      "can provide some indicators of them. this data commonly\n",
      "includes learners’ usage patterns of different types of learning\n",
      "resources [12, 15], their interactions with others via social\n",
      "learning networks [7, 28], their clickstream and keystroke activity logs [2, 8, 30], and sometimes other metadata including\n",
      "facial expressions [35] and gaze location [6].\n",
      "recent research has attempted to use behavioral data to\n",
      "augment learning analytics. [5] proposed a latent response\n",
      "model to classify whether a learner is gaming an intelligent\n",
      "tutoring system, for example. several of these works have\n",
      "sought to demonstrate the relationship between behavior and\n",
      "performance of learners in different scenarios. in the context\n",
      "of moocs, [22] concluded that working on more assignments\n",
      "lead to better knowledge transfer than only watching videos,\n",
      "[12] extracted probabilistic use cases of different types of\n",
      "learning resources and showed they are predictive of certification, [32] used discussion forum activity and topic analysis to\n",
      "predict test performance, and [26] discovered that submission\n",
      "activities can be used to predict final exam scores. in other\n",
      "educational domains, [2] discovered that learner keystroke\n",
      "activity in essay-writing sessions is indicative of essay quality, [29] identified behavior as one of the factors predicting\n",
      "math test achievement, and [25] found that behavior is predictive of whether learners can provide elegant solutions to\n",
      "mathematical questions.\n",
      "in this work, we are interested in how behavioral data can\n",
      "be used to model a learner’s engagement.\n",
      "\n",
      "1.2\n",
      "\n",
      "learner engagement\n",
      "\n",
      "monitoring and fostering engagement is crucial to education,\n",
      "yet defining it concretely remains elusive. research has\n",
      "sought to identify factors in online learning that may drive\n",
      "engagement; for example, [17] showed that certain production\n",
      "styles of lecture videos promote it. [20] defined disengagement\n",
      "as dropping out in the middle of a video and studied the\n",
      "relationship between disengagement and video content, while\n",
      "[31] considered the relationship between engagement and the\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "64\n",
      "\n",
      "\f",
      "semantic features of mathematical questions that learners\n",
      "respond to. [33] studied the relationship between learners’\n",
      "self-reported engagement levels in a learning session and their\n",
      "facial expressions immediately following in-session quizzes,\n",
      "and [34] considered how engagement is related to linguistic\n",
      "features of discussion forum posts.\n",
      "there are many types of engagement [3], with the type of\n",
      "interest depending on the specific learning scenario. several\n",
      "approaches have been proposed for measuring and quantifying different types. these approaches can be roughly\n",
      "divided into two categories: device-based and activity-based.\n",
      "device-based approaches measure learner engagement using\n",
      "devices external to the learning platform, such as cameras to\n",
      "record facial expressions [35], eye-tracking devices to detect\n",
      "mind wandering while reading text documents [6], and pupil\n",
      "dilation measurements, which are claimed to be highly correlated with engagement [16]. activity-based approaches, on\n",
      "the other hand, measure engagement using heuristic features\n",
      "constructed from learners’ activity logs; prior work includes\n",
      "using replies/upvote counts and topic analysis of discussions\n",
      "[28], and manually defining different engagement levels based\n",
      "on activity types found in moocs [4, 21].\n",
      "both of these types have their drawbacks. device-based\n",
      "approaches are far from universal in standard learning platforms because they require integration with external devices.\n",
      "they are also naturally invasive and carry potential privacy\n",
      "risks. activity-based approaches, on the other hand, are\n",
      "not built on the same granularity of data, and tend to be\n",
      "defined from heuristics that have no guarantee of correlating\n",
      "with learning outcomes. it is therefore desirable to develop a\n",
      "statistically principled, activity-based approach to inferring\n",
      "a learner’s engagement.\n",
      "\n",
      "1.3\n",
      "\n",
      "our approach and contributions\n",
      "\n",
      "in this paper, we propose a probabilistic model for inferring a\n",
      "learner’s engagement level by treating it as a latent variable\n",
      "that drives the learner’s performance and is in turn driven\n",
      "by the learner’s behavior. we apply our framework to a\n",
      "real-world mooc dataset consisting of clickstream actions\n",
      "generated as learners watch lecture videos, and question\n",
      "responses from learners answering in-video quiz questions.\n",
      "we first formalize a method for quantifying a learner’s behavior while watching a video as a set of nine behavioral features\n",
      "that summarize the clickstream data generated (section 2).\n",
      "these features are intuitive quantities such as the fraction\n",
      "of video played, the number of pauses made, and the average playback rate, some of which have been associated with\n",
      "performance previously [8]. then, we present our statistical\n",
      "model of learning (section 3) as two main components: a\n",
      "learning model and a response model. the learning model\n",
      "treats a learner’s gain in concept knowledge as proportional\n",
      "to their latent engagement level while watching a lecture\n",
      "video. concept knowledge is treated as multidimensional, on\n",
      "a set of latent concepts underlying the course, and videos\n",
      "are associated with varying levels to different concepts. the\n",
      "response model treats a learner’s performance on in-video\n",
      "quiz questions, in turn, as proportional to their knowledge\n",
      "on the concepts that this particular question relates to.\n",
      "by defining engagement to correlate directly with perfor-\n",
      "\n",
      "mance, we are able to learn which behavioral features lead to\n",
      "high engagement through a single model. this differs from\n",
      "prior works that first define heuristic notions of engagement\n",
      "and subsequently correlate engagement with performance,\n",
      "in separate procedures. moreover, our formulation of latent\n",
      "engagement can be made from entirely within standard learning platforms, serving as a more universally applicable and\n",
      "less invasive alternative to device-based approaches.\n",
      "finally, we evaluate two different aspects of our model (section 4): its ability to predict unobserved, first-attempt quiz\n",
      "question responses, and its ability to provide meaningful\n",
      "analytics on engagement. we find that our model predicts\n",
      "with high quality, achieving aucs of up to 0.76, and outperforming two state-of-the-art baselines on all metrics and\n",
      "dataset partitions tested. one of the partitions tested corresponds to the beginning of the course, underscoring the\n",
      "ability of our model to provide early detection of struggling\n",
      "or advanced students. in terms of analytics, we find that\n",
      "our model enables us to identify behavioral features (e.g.,\n",
      "large numbers of pauses and rewinds, and small numbers of\n",
      "fast forwards) that indicate high learner engagement, and to\n",
      "track learners’ engagement patterns throughout the course.\n",
      "more generally, these findings can enable an online learning platform to detect learner disengagement and perform\n",
      "appropriate interventions in a fully automated manner.\n",
      "\n",
      "2.\n",
      "\n",
      "behavioral data\n",
      "\n",
      "in this section, we start by detailing the setup of lecture\n",
      "videos and quizzes in moocs. we then specify videowatching clickstream data and our method for summarizing\n",
      "it into behavioral features.\n",
      "\n",
      "2.1\n",
      "\n",
      "course setup and data capture\n",
      "\n",
      "we are interested in modeling learner engagement while\n",
      "watching lecture videos to predict their performance on invideo quiz questions. for this purpose, we can view an\n",
      "instructor’s course delivery as the sequence of videos that\n",
      "learners will watch interspersed with the quiz questions they\n",
      "will answer. let q = (q1 , q2 , . . .) be the sequence of questions\n",
      "asked through the course. a video could have any number\n",
      "of questions generally, including none; to enforce a 1:1 correspondence between video content and questions, we will\n",
      "consider the “video” for question qn to be all video content\n",
      "that appears between qn−1 and qn . based on this, we will\n",
      "explain the formats of video-watching and quiz response data\n",
      "we work with in this section.\n",
      "our dataset. the dataset we will use is from the fall 2012\n",
      "offering of the course networks: friends, money, and bytes\n",
      "(fmb) on coursera [1]. this course has 92 videos distributed\n",
      "among 20 lectures, and exactly one question per video.\n",
      "\n",
      "2.1.1\n",
      "\n",
      "video-watching clickstreams\n",
      "\n",
      "when a learner watches a video on a mooc, their behavior\n",
      "is typically recorded as a sequence of clickstream actions.\n",
      "in particular, each time a learner makes an action – play,\n",
      "pause, seek, ratechange, open, or close – on the video\n",
      "player, a clickstream event is generated. formally, the ith\n",
      "event created for the course will be in the format\n",
      "ei =< ui , vi , ei , p0i , pi , xi , si , ri >\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "65\n",
      "\n",
      "\f",
      "here, ui and vi are the ids of the specific learner (user) and\n",
      "video, respectively, and ei is the type of action that ui made\n",
      "on vi . pi is the position of the video player (in seconds)\n",
      "immediately after ei is made, p0i is the position immediately\n",
      "before,1 xi is the unix timestamp (in seconds) at which ei\n",
      "was fired, si is the binary state of the video player – either\n",
      "playing or paused – once this action is made, and ri is the\n",
      "playback rate of the video player once this action is made.\n",
      "our fmb dataset has 314,632 learner-generated clickstreams\n",
      "from 3,976 learners.2\n",
      "the set eu,v = {ei |ui = u, vi = v} of clickstreams for learner\n",
      "u recorded on video v can be used to reconstruct the behavior\n",
      "u exhibits on v. in section 2.2 we will explain the features\n",
      "computed from eu,v to summarize this behavior.\n",
      "\n",
      "figure 1: distribution of the number of videos that\n",
      "each each learner completed in fmb. more than\n",
      "85% of learners completed less than 20 videos.\n",
      "\n",
      "2.1.2 quiz responses\n",
      "when a learner submits a response to an in-video quiz question, an event is generated in the format\n",
      "am =< um , vm , xm , am , ym >\n",
      "again, um and vm are the learner and video ids (i.e., the\n",
      "quiz corresponding to the video). xm is the unix timestamp\n",
      "of the submission, am is the specific response, and ym is the\n",
      "number of points awarded for the response. the questions\n",
      "in our dataset are multiple choice with a single response, so\n",
      "ym is binary-valued.\n",
      "in this work, we are interested in whether quiz responses\n",
      "were correct on first attempt (cfa) or not. as a result,\n",
      "with au,v = {am |um = u, vm = v}, we consider the event\n",
      "a0u,v in this set with the earliest timestamp x0u,v . we also\n",
      "0\n",
      "only consider the set of clickstreams eu,v\n",
      "⊆ eu,v that occur\n",
      "before x0u,v , as the ones after would be anti-causal to cfa.\n",
      "\n",
      "2.2\n",
      "\n",
      "behavioral features and cfa score\n",
      "\n",
      "0\n",
      "with the data eu,v\n",
      "and a0u,v , we construct two sets of information for each learner u on each video v, i.e., each\n",
      "learner-video pair. first is a set of nine behavioral features\n",
      "that summarize u’s video-watching behavior on v [8]:\n",
      "\n",
      "(3) fraction played. the fraction of the video that the\n",
      "learner played relative to the length. formally, it is calculated\n",
      "as gu,v /lv , where\n",
      "gu,v =\n",
      "\n",
      "x\n",
      "i∈s\n",
      "\n",
      "is the total length of video that was played (while in the\n",
      "playing state). here, s = {i ∈ a0u,v : ai+1 6= open ∧ si =\n",
      "playing}.\n",
      "(4) fraction paused. the fraction of time the learner\n",
      "stayed paused on the video relative to the length. it is\n",
      "calculated as hu,v /lv , where\n",
      "hu,v =\n",
      "\n",
      "x\n",
      "i∈s\n",
      "\n",
      "eu,v =\n",
      "\n",
      "x\n",
      "i∈s\n",
      "\n",
      "min(xi+1 − xi , lv )\n",
      "\n",
      "is the elapsed time on v obtained by finding the total unix\n",
      "time for u on v, and lv is the length of the video (in seconds).\n",
      "here, s = {i ∈ a0u,v : ai+1 6= open}. lv is included as an\n",
      "upper bound for excessively long intervals of time.\n",
      "(2) fraction completed. the fraction of the video that the\n",
      "learner completed, between 0 (none) and 1 (all). formally,\n",
      "it is cu,v /lv , where cu,v is the number of unique 1 second\n",
      "segments of the video that the learner visited.\n",
      "\n",
      "(5) number of pauses. the number of times the learner\n",
      "paused the video, or\n",
      "\n",
      "x\n",
      "\n",
      "pi and p0i will only differ when i is a skip event.\n",
      "this number excludes invalid stall, null, and error events,\n",
      "as well as open and close events which are generated automatically.\n",
      "\n",
      "1{ai = pause}\n",
      "\n",
      "where 1{} is the indicator function.\n",
      "(6) number of rewinds. the number of times the learner\n",
      "skipped backwards in the video, or\n",
      "\n",
      "x\n",
      "\n",
      "i∈a0u,v\n",
      "\n",
      "1{ai = skip ∧ p0i < pi }\n",
      "\n",
      "(7) number of fast forwards. the number of times the\n",
      "learner skipped forward in the video, i.e., with p0i > pi in the\n",
      "previous equation.\n",
      "(8) average playback rate. the time-average of the\n",
      "learner’s playback rate on the video. formally, it is calculated\n",
      "as\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "min(ti+1 − ti , lv )\n",
      "\n",
      "is the total time the learner stayed in the paused state on this\n",
      "video. here, s = {i ∈ a0u,v : ai+1 6= open ∧ si = paused}.\n",
      "\n",
      "i∈a0u,v\n",
      "\n",
      "(1) fraction spent. the fraction of time the learner spent\n",
      "on the video, relative to the playback length of the video.\n",
      "formally, this quantity is eu,v /lv , where\n",
      "\n",
      "min(p0i+1 − pi , lv )\n",
      "\n",
      "r̄u,v =\n",
      "\n",
      "p\n",
      "i∈s ri · min(xi+1 − xi , lv )\n",
      "p\n",
      "i∈s\n",
      "\n",
      "where s = {i ∈\n",
      "\n",
      "a0u,v\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "min(xi+1 − xi , lv )\n",
      "\n",
      ": ai+1 6= open ∧ si = playing}.\n",
      "\n",
      "66\n",
      "\n",
      "\f",
      "(9) standard deviation of playback rate. the standard\n",
      "deviation of the learner’s playback rate. it is calculated as\n",
      "\n",
      " p\n",
      "\n",
      "i∈s (ri\n",
      "\n",
      "− r̄u,v )2 · min(xi+1 − xi , lv )\n",
      "i∈s min(xi+1 − xi , lv )\n",
      "\n",
      "p\n",
      "\n",
      "with the same s as the average playback rate.\n",
      "the second piece of information for each learner-video pair\n",
      "is u’s cfa score yu,v ∈ {0, 1} on the quiz question for v.\n",
      "\n",
      "2.3\n",
      "\n",
      "dataset subsets\n",
      "\n",
      "we will consider different groups of learner-video pairs when\n",
      "evaluating our model in section 4. our motivation for doing\n",
      "so is the heterogeneity of learner motivation and high dropoff\n",
      "rates in moocs [9]: many will quit the course after watching\n",
      "just a few lectures. modeling in a small subset of data,\n",
      "particularly those at the beginning of the course, is desirable\n",
      "because it can lead to “early detection” of those who may\n",
      "drop out [8].\n",
      "figure 1 shows the dropoff for our dataset in terms of the\n",
      "number of videos each learner completed: more than 85%\n",
      "of learners completed just 20% of the course. “completed”\n",
      "is defined here as having watched some of the video and\n",
      "responded to the corresponding question. let tu be the\n",
      "number of videos learner u completed and γ(v) be the index\n",
      "of video v in the course, we define ωu0 ,v0 = {(u, v) : tu ≥\n",
      "u0 ∧ γ(v) ≤ v0 } to be the subset of learner-video pairs\n",
      "such that u completed at least u0 videos and v is within the\n",
      "first v0 videos. the full dataset is ω1,92 , and we will also\n",
      "consider ω20,92 as the subset of 346 active learners over the\n",
      "full course and ω1,20 as the subset of all learners over the\n",
      "first two weeks3 in our evaluation.\n",
      "\n",
      "3.\n",
      "\n",
      "statistical model of learning\n",
      "with latent engagement\n",
      "\n",
      "in this section, we propose our statistical model. let u\n",
      "denote the number of learners (indexed by u) and v the\n",
      "number of videos (indexed by v). further, we use tu to\n",
      "denote the number of time instances registered by learner\n",
      "u (indexed by t); we take a time instance to be a learner\n",
      "completing a video, i.e., watching a video and answering the\n",
      "corresponding quiz question. for simplicity, we use a discrete\n",
      "notion of time, i.e., each learner-video pair will correspond\n",
      "to one time instance for one learner.\n",
      "our model considers learners’ responses to quiz questions\n",
      "as measurements of their underlying knowledge on a set of\n",
      "concepts; let k denote the number of such concepts. further,\n",
      "our model considers the action of watching lecture videos\n",
      "as part of learning that changes learners’ latent knowledge\n",
      "states over time. these different aspects of the model are\n",
      "visualized in figure 2: there are two main components, a\n",
      "response model and a learning model.\n",
      "\n",
      "3.1\n",
      "\n",
      "response model\n",
      "\n",
      "our statistical model of learner responses is given by\n",
      "t\n",
      "(t)\n",
      "p(yu(t) = 1|c(t)\n",
      "u ) = σ(wv(u,t) cu − µv(u,t) + au ),\n",
      "3\n",
      "\n",
      "(1)\n",
      "\n",
      "in fmb, the first two weeks of lectures is the first 20 videos.\n",
      "\n",
      "figure 2: our proposed statistical model of learning\n",
      "consists of two main parts, a response model and a\n",
      "learning model.\n",
      "where v(u, t) : ω ⊆ {1, . . . , u } × {1, . . . , maxu tu } →\n",
      "{1, . . . , v } denotes a mapping from a learner index-time\n",
      "index pair to the index of the video v that u was watching at\n",
      "(t)\n",
      "t. yu ∈ {0, 1} is the binary-valued cfa score of learner u\n",
      "on the quiz question corresponding to the video they watch\n",
      "at time t, with 1 denoting a correct response (cfa) and 0\n",
      "denoting an incorrect response (non-cfa).\n",
      "the variable wv ∈ rk\n",
      "+ denotes the non-negative, kdimensional quiz question–concept association vector that\n",
      "characterizes how the quiz question corresponding to video v\n",
      "tests learners’ knowledge on each concept, and the variable\n",
      "µv is a scalar characterizing the intrinsic difficulty of the quiz\n",
      "(t)\n",
      "question. cu is the k-dimensional concept knowledge vector\n",
      "of learner u at time t, characterizing the knowledge level of\n",
      "the learner on each concept at the time, and au denotes the\n",
      "static, intrinsic ability of learner u. finally, σ(x) = 1+e1−x is\n",
      "the sigmoid function.\n",
      "we restrict the question–concept association vector wv to be\n",
      "non-negative in order to make the parameters interpretable\n",
      "[24]. under this restriction, the values of concept knowledge\n",
      "(t)\n",
      "vector cu can be understood as follows: large, positive values\n",
      "lead to higher chances of answering a question correctly, thus\n",
      "corresponding to high knowledge, while small, negative values\n",
      "lead to lower chances of answering a question correctly, thus\n",
      "corresponding to low knowledge.\n",
      "\n",
      "3.2\n",
      "\n",
      "learning model\n",
      "\n",
      "our model of learning considers transitions in learners’ knowledge states as induced by watching lecture videos. it is given\n",
      "by\n",
      "(t−1)\n",
      "c(t)\n",
      "+ e(t)\n",
      "u = cu\n",
      "u dv(u,t) ,\n",
      "\n",
      "t = 1, . . . , tu ,\n",
      "\n",
      "(2)\n",
      "\n",
      "where the variable dv ∈ rk\n",
      "+ denotes the non-negative, kdimensional learning gain vector for video v; each entry\n",
      "characterizes the degree to which the video improves learners’\n",
      "knowledge level on each concept. the assumption of nonnegativity on dv implies that videos will not negatively affect\n",
      "(0)\n",
      "learners’ knowledge, as in [23]. cu is the initial knowledge\n",
      "state of learner u at time t = 0, i.e., before starting the\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "67\n",
      "\n",
      "\f",
      "ω20,92\n",
      "\n",
      "ω1,20\n",
      "\n",
      "ω1,92\n",
      "\n",
      "acc\n",
      "\n",
      "auc\n",
      "\n",
      "acc\n",
      "\n",
      "auc\n",
      "\n",
      "acc\n",
      "\n",
      "auc\n",
      "\n",
      "proposed model\n",
      "\n",
      "0.7293±0.0070\n",
      "\n",
      "0.7608±0.0094\n",
      "\n",
      "0.7096±0.0057\n",
      "\n",
      "0.7045±0.0066\n",
      "\n",
      "0.7058±0.0054\n",
      "\n",
      "0.7216±0.0054\n",
      "\n",
      "sparfa\n",
      "\n",
      "0.7209±0.0070\n",
      "\n",
      "0.7532±0.0098\n",
      "\n",
      "0.7061±0.0069\n",
      "\n",
      "0.7020±0.0070\n",
      "\n",
      "0.6975±0.0048\n",
      "\n",
      "0.7124±0.0050\n",
      "\n",
      "bkt\n",
      "\n",
      "0.7038±0.0084\n",
      "\n",
      "0.7218±0.0126\n",
      "\n",
      "0.6825±0.0058\n",
      "\n",
      "0.6662±0.0065\n",
      "\n",
      "0.6803±0.0055\n",
      "\n",
      "0.6830±0.0059\n",
      "\n",
      "table 1: quality comparison of the different algorithms on predicting unobserved quiz question responses.\n",
      "the obtained acc and auc metrics on different subsets of the fmb dataset are given. our proposed model\n",
      "obtains higher quality than the sparfa and bkt baselines in each case.\n",
      "course and watching any video.\n",
      "(t)\n",
      "\n",
      "the scalar latent variable eu ∈ [0, 1] in (2) characterizes\n",
      "the engagement level that learner u exhibits when watching\n",
      "video v(u, t) at time t. this is in turn modeled as\n",
      "t (t)\n",
      "e(t)\n",
      "u = σ(β fu ),\n",
      "\n",
      "(3)\n",
      "\n",
      "(t)\n",
      "\n",
      "where fu is a 9-dimensional vector of the behavioral features\n",
      "defined in section 2.2, summarizing learner u’s behavior while\n",
      "the video at time t. β is the unknown, 9-dimensional parameter vector that characterizes how engagement associates\n",
      "with each behavioral feature.\n",
      "taken together, (2) and (3) state that the knowledge gain a\n",
      "learner will experience on a particular concept while watching\n",
      "a particular video is given by\n",
      "(i) the video’s intrinsic association with the concept, modulated by\n",
      "(ii) the learner’s engagement while watching the video, as\n",
      "manifested by their clickstream behavior.\n",
      "from (2), a learner’s (latent) engagement level dictates the\n",
      "fraction of the video’s available learning gain they acquire\n",
      "to improve their knowledge on each concept. the response\n",
      "model (1) in turn holds that performance is dictated by a\n",
      "learner’s concept knowledge states. in this way, engagement\n",
      "is directly correlated with performance through the concept\n",
      "knowledge states. note that in this paper, we treat the en(t)\n",
      "gagement variable eu as a scalar; the extension of modeling\n",
      "it as a vector and thus separating engagement by concept is\n",
      "part of our ongoing work.\n",
      "it is worth mentioning the similarity between our characterization of engagement as a latent variable in the learning\n",
      "model and the input gate variables in long-short term memory (lstm) neural networks [18]. in lstm, the change\n",
      "in the latent memory state (loosely corresponding to the\n",
      "(t)\n",
      "latent concept knowledge state vector cu ) is given by the\n",
      "input vector (loosely corresponding to the video learning\n",
      "gain vector dv ) modulated by a set of input gate variables\n",
      "(t)\n",
      "(corresponding to the engagement variable eu ).\n",
      "parameter inference. our statistical model of learning\n",
      "and response can be seen as a particular type of recurrent neural network (rnn). therefore, for parameter inference, we\n",
      "implement a stochastic gradient descent algorithm with standard backpropagation. given the graded learner responses\n",
      "(t)\n",
      "(t)\n",
      "yu and behavioral features fu , our parameter inference\n",
      "\n",
      "algorithm estimates the quiz question–concept association\n",
      "vectors wv , the quiz question intrinsic difficulties µv , the the\n",
      "video learning gain vectors dv , the learner initial knowledge\n",
      "(0)\n",
      "vectors cu , the learner abilities au , and the engagement–\n",
      "behavioral feature association vector β. we omit the details\n",
      "of the algorithm for simplicity of exposition.\n",
      "\n",
      "4.\n",
      "\n",
      "experiments\n",
      "\n",
      "in this section, we evaluate the proposed latent engagement\n",
      "model on the fmb dataset. we first demonstrate the gain\n",
      "in predictive quality of the proposed model over two baseline\n",
      "algorithms (section 4.1), and then show how our model can\n",
      "be used to study engagement (section 4.2).\n",
      "\n",
      "4.1\n",
      "\n",
      "predicting unobserved responses\n",
      "\n",
      "we evaluate our proposed model’s quality by testing its\n",
      "ability to predict unobserved quiz question responses.\n",
      "baselines. we compare our model against two well-known,\n",
      "state-of-the-art response prediction algorithms that do not\n",
      "use behavioral data. first is the sparse factor analysis\n",
      "(sparfa) algorithm [24], which factors the learner-question\n",
      "matrix to extract latent concept knowledge, but does not use\n",
      "a time-varying model of learners’ knowledge states. second is\n",
      "a version of the bayesian knowledge tracing (bkt) algorithm\n",
      "that tracks learners’ time-varying knowledge states, which\n",
      "incorporates a set of guessing and slipping probability parameters for each question, a learning probability parameter\n",
      "for each video, and an initial knowledge level parameter for\n",
      "each learner [13, 27].\n",
      "\n",
      "4.1.1\n",
      "\n",
      "experimental setup and metrics\n",
      "\n",
      "regularization. in order to prevent overfitting, we add\n",
      "`2 -norm regularization terms to the overall optimization\n",
      "objective function for every set of variables in both the\n",
      "proposed model and in sparfa. we use a parameter λ to\n",
      "control the amount of regularization on each variable.\n",
      "cross validation. we perform 5-fold cross validation on\n",
      "the full dataset (ω1,92 ), and on each subset of the dataset\n",
      "introduced in section 2.3 (ω20,92 and ω1,20 ). to do so, we\n",
      "randomly partition each learner’s quiz question responses\n",
      "into 5 data folds. leaving out one fold as the test set, we use\n",
      "the remaining four folds as training and validation sets to\n",
      "select the values of the tuning parameters for each algorithm,\n",
      "i.e., by training on three of the folds and validating on the\n",
      "other. we then train every algorithm on all four observed\n",
      "folds using the tuned values of the parameters, and evaluate\n",
      "them on the holdout set. all experiments are repeated for\n",
      "20 random partitions of the training and test sets.\n",
      "for the proposed model and for sparfa, we tune both the\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "68\n",
      "\n",
      "\f",
      "feature\n",
      "\n",
      "coefficient\n",
      "\n",
      "fraction spent\n",
      "\n",
      "0.1941\n",
      "\n",
      "fraction completed\n",
      "\n",
      "0.1443\n",
      "\n",
      "fraction played\n",
      "\n",
      "0.2024\n",
      "\n",
      "fraction paused\n",
      "\n",
      "0.0955\n",
      "\n",
      "number of pauses\n",
      "\n",
      "0.2233\n",
      "\n",
      "number of rewinds\n",
      "number of fast forwards\n",
      "average playback rate\n",
      "standard deviation of playback rate\n",
      "\n",
      "0.4338\n",
      "−0.1551\n",
      "0.2797\n",
      "\n",
      "0.0314\n",
      "\n",
      "table 2: regression coefficient vector β learned over\n",
      "the full dataset, associating each clickstream feature\n",
      "to engagement. all but one of the features (number\n",
      "of fast forwards) is positively correlated with engagement.\n",
      "number of concepts k ∈ {2, 4, 6, 8, 10} and the regularization parameter λ ∈ {0.5, 1.0, . . . , 10.0}. note that for the\n",
      "proposed model, when a question response is left out as part\n",
      "of the test set, only the response is left out of the training\n",
      "set: the algorithm still uses the clickstream data for the\n",
      "corresponding learner-video pair to model engagement.\n",
      "metrics. to evaluate the quality of the algorithms, we\n",
      "employ two commonly used binary classification metrics:\n",
      "prediction accuracy (acc) and area under the receiver operating characteristic curve (auc) [19]. the acc metric is\n",
      "simply the fraction of predictions that are made correctly,\n",
      "while the auc measures the tradeoff between the true and\n",
      "false positive rates of the classifier. both metrics take values\n",
      "in [0, 1], with larger values indicating higher quality.\n",
      "\n",
      "4.1.2 results and discussion\n",
      "table 1 gives the evaluation results for the three algorithms.\n",
      "the average and standard deviation over the 20 random data\n",
      "partitions are reported for each dataset group and metric.\n",
      "first of all, the results show that our proposed model consistently achieves higher quality than both baseline algorithms\n",
      "on both metrics. it significantly outperforms bkt in particular (sparfa also outperforms bkt). this shows the\n",
      "potential of our model to push the envelope on achievable\n",
      "quality in performance prediction research.\n",
      "notice that our model achieves its biggest quality improvement on the full dataset, with a 1.3% gain in auc over\n",
      "sparfa and a 5.7% gain over bkt. this observation suggests that as more clickstream data is captured and available\n",
      "for modeling – especially as we observe more video-watching\n",
      "behavioral data from learners over a longer period of time\n",
      "(the full dataset ω1,92 contains clickstream data for up to\n",
      "12 weeks, while the ω1,20 subset only contains data for the\n",
      "first 2 weeks) – the proposed model achieves more significant\n",
      "quality enhancements over the baseline algorithms. this\n",
      "is somewhat surprising, since prior work on behavior-based\n",
      "performance prediction [8] has found the largest gains in the\n",
      "presence of fewer learner-video pairs, i.e., before there are\n",
      "many question responses for other algorithms to model on.\n",
      "but our algorithm also benefits from additional question re-\n",
      "\n",
      "(t)\n",
      "\n",
      "figure 3: plot of the latent engagement level ej\n",
      "over time for one third of the learners in fmb, showing a diverse set of behaviors across learners.\n",
      "\n",
      "sponses, to update its learned relationship between behavior\n",
      "and concept knowledge.\n",
      "the first two weeks of data (ω1,20 ) is sparse in that the\n",
      "majority of learners answer at most a few questions during\n",
      "this time, many of whom will drop out (see figure 1). in\n",
      "this case, our model obtains a modest improvement over\n",
      "sparfa, which is static and uses fewer parameters. the\n",
      "gain over bkt is particularly pronounced, at 5.7%. this,\n",
      "combined with the findings for active learners over the full\n",
      "course (ω20,92 ), shows that observing video-watching behavior of learners who drop out of the course in its early states\n",
      "(these learners are excluded from ω20,92 ) leads to a slight\n",
      "increase in the performance gain of the proposed model over\n",
      "the baseline algorithms. importantly, this shows that our\n",
      "algorithm provides benefit for early detection, with the ability\n",
      "to predict performance of learners who will end up dropping\n",
      "out [8].\n",
      "\n",
      "4.2\n",
      "\n",
      "analyzing engagement\n",
      "\n",
      "given predictive quality, one benefit of our model is that it\n",
      "can be used to analyze engagement. the two parameters to\n",
      "consider for this are the regression coefficient vector β and\n",
      "(t)\n",
      "the engagement scalar eu itself.\n",
      "behavior and engagement. table 2 gives each of the\n",
      "estimated feature coefficients in β for the full dataset ω1,92 ,\n",
      "with regularization parameters chosen via cross validation.\n",
      "all of the features except for the number of fast forwards are\n",
      "positively correlated with the latent engagement level. this\n",
      "is to be expected since many of the features are associated\n",
      "with processing more video content, e.g., spending more\n",
      "time, playing more, or pausing longer to reflect, while fast\n",
      "forwarding involves skipping over the content.\n",
      "the features that contribute most to high latent engagement\n",
      "levels are the number of pauses, the number of rewinds, and\n",
      "the average playback rate. the first two of these are likely\n",
      "indicators of actual engagement as well, since they indicate\n",
      "whether the learner was thinking while pausing the video\n",
      "or re-visiting earlier content which contains knowledge that\n",
      "they need to recall or revise. the strong, positive correlation\n",
      "of average playback rate is somewhat surprising though:\n",
      "we may expect that a higher playback rate would have a\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "69\n",
      "\n",
      "\f",
      "(a) learners that consistently exhibit\n",
      "high engagement and finish the course.\n",
      "\n",
      "(b) learners that exhibit high engagement but drop out early.\n",
      "(t)\n",
      "\n",
      "figure 4: plot of the latent engagement level ej\n",
      "\n",
      "over time for selected learners in three different groups.\n",
      "\n",
      "negative impact on engagement, like fast forwarding does, as\n",
      "it involves speeding through content. on the other hand, it\n",
      "may be an indication that learners are more focused on the\n",
      "material and trying to keep their interest higher.\n",
      "engagement over time. figure 3 visualizes the evolution\n",
      "(t)\n",
      "of eu over time for 1/3 of the learners (randomly selected).\n",
      "patterns in engagement differs substantially across learners;\n",
      "those who finish the course mostly exhibit high engagement\n",
      "levels throughout, while those who drop out early vary greatly\n",
      "in their engagement, some high and others low.\n",
      "figure 4 breaks down the learners into three different types\n",
      "according to their engagement patterns, and plots their engagement levels over time separately. the first type of learner\n",
      "(a) finishes the course and consistently exhibits high engagement levels throughout the duration. the second type (b)\n",
      "also consistently exhibits high engagement levels, but drops\n",
      "out of the course after up to three weeks. the third type of\n",
      "learner (c) exhibits inconsistent engagement levels before an\n",
      "early dropout. equipped with temporal plots like these, an\n",
      "instructor could determine which learners may be in need\n",
      "of intervention, and could design different interventions for\n",
      "different engagement clusters [8, 36].\n",
      "\n",
      "5.\n",
      "\n",
      "(c) learners that exhibit inconsistent\n",
      "engagement and drop out.\n",
      "\n",
      "conclusions and future work\n",
      "\n",
      "in this paper, we proposed a new statistical model for learning, based on learner behavior while watching lecture videos\n",
      "and their performance on in-video quiz questions. our model\n",
      "has two main parts: (i) a response model, which relates a\n",
      "learner’s performance to latent concept knowledge, and (ii)\n",
      "a learning model, which relates the learner’s concept knowledge in turn to their latent engagement level while watching\n",
      "videos. through evaluation on a real-world mooc dataset,\n",
      "we showed that our model can predict unobserved question\n",
      "responses with superior quality to two state-of-the-art baselines, and also that it can lead to engagement analytics: it\n",
      "identifies key behavioral features driving high engagement,\n",
      "and shows how each learner’s engagement evolves over time.\n",
      "our proposed model enables the measurement of engagement\n",
      "solely from data that is logged within online learning platforms: clickstream data and quiz responses. in this way, it\n",
      "serves as a less invasive alternative to current approaches\n",
      "for measuring engagement that require external devices, e.g.,\n",
      "cameras and eye-trackers [6, 16, 35]. one avenue of future\n",
      "work is to conduct an experiment that will correlate our\n",
      "definition of latent engagement with these methods.\n",
      "\n",
      "additionally, one could test other, more sophisticated characterizations of the latent engagement variable. one such\n",
      "approach could seek to characterize engagement as a function of learners’ previous knowledge level. an alternative or\n",
      "addition to this would be a generative modeling approach of\n",
      "engagement to enable the prediction of future engagement\n",
      "given each learner’s learning history.\n",
      "one of the long-term, end-all goals of this work is the design\n",
      "of a method for useful, real-time analytics to instructors. the\n",
      "true test of this ability comes from incorporating the method\n",
      "into a learning system, providing its outputs – namely, performance prediction forecasts and engagement evolution – to\n",
      "an instructor through the user interface, and measuring the\n",
      "resulting improvement in learning outcomes.\n",
      "\n",
      "acknowledgments\n",
      "thanks to debshila basu mallick for discussions on the\n",
      "different types of engagement.\n",
      "\n",
      "6.\n",
      "\n",
      "references\n",
      "\n",
      "[1] networks: friends, money, and bytes. https:\n",
      "//www.coursera.org/course/friendsmoneybytes.\n",
      "[2] l. allen, m. jacovina, m. dascalu, r. roscoe, k. kent,\n",
      "a. likens, and d. mcnamara. {enter}ing the time\n",
      "series {space}: uncovering the writing process\n",
      "through keystroke analyses. in proc. intl. conf. educ.\n",
      "data min., pages 22–29, june 2016.\n",
      "[3] a. anderson, s. christenson, m. sinclair, and c. lehr.\n",
      "check & connect: the importance of relationships for\n",
      "promoting engagement with school. j. school psychol.,\n",
      "42(2):95–113, mar. 2004.\n",
      "[4] a. anderson, d. huttenlocher, j. kleinberg, and\n",
      "j. leskovec. engaging with massive online courses. in\n",
      "proc. intl. conf. world wide web, pages 687–698, apr.\n",
      "2014.\n",
      "[5] r. baker, a. corbett, and k. koedinger. detecting\n",
      "student misuse of intelligent tutoring systems. in proc.\n",
      "intl. conf. intell. tutoring syst., pages 531–540, aug.\n",
      "2004.\n",
      "[6] r. bixler and s. d’mello. automatic gaze-based\n",
      "user-independent detection of mind wandering during\n",
      "computerized reading. user model. user-adapt.\n",
      "interact., 26(1):33–68, mar. 2016.\n",
      "[7] c. brinton, s. buccapatnam, f. wong, m. chiang, and\n",
      "h. poor. social learning networks: efficiency\n",
      "optimization for mooc forums. in proc. ieee conf.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "70\n",
      "\n",
      "\f",
      "comput. commun., pages 1–9, apr. 2016.\n",
      "[8] c. brinton and m. chiang. mooc performance\n",
      "prediction via clickstream data and social learning\n",
      "networks. in proc. ieee conf. comput. commun.,\n",
      "pages 2299–2307, april 2015.\n",
      "[9] c. brinton, r. rill, s. ha, m. chiang, r. smith, and\n",
      "w. ju. individualization for education at scale: miic\n",
      "design and preliminary evaluation. ieee trans. learn.\n",
      "technol., 8(1):136–148, jan. 2015.\n",
      "[10] h. cen, k. koedinger, and b. junker. learning factors\n",
      "analysis – a general method for cognitive model\n",
      "evaluation and improvement. in proc. intl. conf. intell.\n",
      "tutoring syst., pages 164–175, june 2006.\n",
      "[11] l. chen, x. li, z. xia, z. song, l. morency, and\n",
      "a. dubrawski. riding an emotional roller-coaster: a\n",
      "multimodal study of young child’s math problem\n",
      "solving activities. in proc. intl. conf. educ. data min.,\n",
      "pages 38–45, june 2016.\n",
      "[12] c. coleman, d. seaton, and i. chuang. probabilistic\n",
      "use cases: discovering behavioral patterns for\n",
      "predicting certification. in proc. acm conf. learn at\n",
      "scale, pages 141–148, mar. 2015.\n",
      "[13] a. corbett and j. anderson. knowledge tracing:\n",
      "modeling the acquisition of procedural knowledge. user\n",
      "model. user-adapt. interact., 4(4):253–278, dec. 1994.\n",
      "[14] c. farrington, m. roderick, e. allensworth,\n",
      "j. nagaoka, t. keyes, d. johnson, and n. beechum.\n",
      "teaching adolescents to become learners: the role of\n",
      "noncognitive factors in shaping school performance–a\n",
      "critical literature review. consortium on chicago\n",
      "school research, 2012.\n",
      "[15] b. gelman, m. revelle, c. domeniconi, a. johri, and\n",
      "k. veeramachaneni. acting the same differently: a\n",
      "cross-course comparison of user behavior in moocs. in\n",
      "proc. intl. conf. educ. data min., pages 376–381, june\n",
      "2016.\n",
      "[16] m. gilzenrat, j. cohen, j. rajkowski, and\n",
      "g. aston-jones. pupil dynamics predict changes in task\n",
      "engagement mediated by locus coeruleus. in proc. soc.\n",
      "neurosci. abs., page 19, nov. 2003.\n",
      "[17] p. guo, j. kim, and r. rubin. how video production\n",
      "affects student engagement: an empirical study of\n",
      "mooc videos. in proc. acm conf. learn at scale,\n",
      "pages 41–50, mar. 2014.\n",
      "[18] s. hochreiter and j. schmidhuber. long short-term\n",
      "memory. neural comput., 9(8):1735–1780, nov. 1997.\n",
      "[19] h. jin and c. ling. using auc and accuracy in\n",
      "evaluating learning algorithms. ieee trans. knowl.\n",
      "data eng., 17(3):299–310, mar. 2005.\n",
      "[20] j. kim, p. guo, d. seaton, p. mitros, k. gajos, and\n",
      "r. miller. understanding in-video dropouts and\n",
      "interaction peaks in online lecture videos. in proc.\n",
      "acm conf. learn at scale, pages 31–40, mar. 2014.\n",
      "[21] r. kizilcec, c. piech, and e. schneider. deconstructing\n",
      "disengagement: analyzing learner subpopulations in\n",
      "massive open online courses. in proc. intl. conf. learn.\n",
      "analyt. knowl., pages 170–179, apr. 2013.\n",
      "[22] k. koedinger, j. kim, j. jia, e. mclaughlin, and\n",
      "n. bier. learning is not a spectator sport: doing is\n",
      "better than watching for learning from a mooc. in\n",
      "proc. acm conf. learn at scale, pages 111–120, mar.\n",
      "2015.\n",
      "\n",
      "[23] a. lan, c. studer, and r. baraniuk. time-varying\n",
      "learning and content analytics via sparse factor\n",
      "analysis. in proc. acm sigkdd intl. conf. knowl.\n",
      "discov. data min., pages 452–461, aug. 2014.\n",
      "[24] a. lan, a. waters, c. studer, and r. baraniuk. sparse\n",
      "factor analysis for learning and content analytics. j.\n",
      "mach. learn. res., 15:1959–2008, june 2014.\n",
      "[25] l. malkiewich, r. baker, v. shute, s. kai, and\n",
      "l. paquette. classifying behavior to elucidate elegant\n",
      "problem solving in an educational game. in proc. intl.\n",
      "conf. educ. data min., pages 448–453, june 2016.\n",
      "[26] j. mcbroom, b. jeffries, i. koprinska, and k. yacef.\n",
      "mining behaviours of students in autograding\n",
      "submission system logs. in proc. intl. conf. educ. data\n",
      "min., pages 159–166, june 2016.\n",
      "[27] z. pardos and n. heffernan. modeling individualization\n",
      "in a bayesian networks implementation of knowledge\n",
      "tracing. in proc. intl. conf. user model. adapt.\n",
      "personalization, pages 255–266, june 2010.\n",
      "[28] j. reich, b. stewart, k. mavon, and d. tingley. the\n",
      "civic mission of moocs: measuring engagement across\n",
      "political differences in forums. in proc. acm conf.\n",
      "learn at scale, pages 1–10, apr. 2016.\n",
      "[29] m. san pedro, e. snow, r. baker, d. mcnamara, and\n",
      "n. heffernan. exploring dynamical assessments of\n",
      "affect, behavior, and cognition and math state test\n",
      "achievement. in proc. intl. conf. educ. data min.,\n",
      "pages 85–92, june 2015.\n",
      "[30] c. shi, s. fu, q. chen, and h. qu. vismooc:\n",
      "visualizing video clickstream data from massive open\n",
      "online courses. in ieee pacific visual. symp., pages\n",
      "159–166, apr. 2015.\n",
      "[31] s. slater, r. baker, j. ocumpaugh, p. inventado,\n",
      "p. scupelli, and n. heffernan. semantic features of\n",
      "math problems: relationships to student learning and\n",
      "engagement. in proc. intl. conf. educ. data min.,\n",
      "pages 223–230, june 2016.\n",
      "[32] s. tomkins, a. ramesh, and l. getoor. predicting\n",
      "post-test performance from online student behavior: a\n",
      "high school mooc case study. in proc. intl. conf.\n",
      "educ. data min., pages 239–246, june 2016.\n",
      "[33] a. vail, j. wiggins, j. grafsgaard, k. boyer, e. wiebe,\n",
      "and j. lester. the affective impact of tutor questions:\n",
      "predicting frustration and engagement. in proc. intl.\n",
      "conf. educ. data min., pages 247–254, june 2016.\n",
      "[34] x. wang, d. yang, m. wen, k. koedinger, and c. rosé.\n",
      "investigating how student’s cognitive behavior in\n",
      "mooc discussion forums affect learning gains. in proc.\n",
      "intl. conf. educ. data min., pages 226–233, june 2015.\n",
      "[35] j. whitehill, z. serpell, y. lin, a. foster, and\n",
      "j. movellan. the faces of engagement: automatic\n",
      "recognition of student engagement from facial\n",
      "expressions. ieee trans. affect. comput., 5(1):86–98,\n",
      "jan. 2014.\n",
      "[36] j. whitehill, j. williams, g. lopez, c. coleman, and\n",
      "j. reich. beyond prediction: towards automatic\n",
      "intervention in mooc student stop-out. in proc. intl.\n",
      "conf. educ. data min., pages 171–178, june 2015.\n",
      "[37] d. yang, r. kraut, and c. rosé. exploring the effect of\n",
      "student confusion in massive open online courses. j.\n",
      "educ. data min., 8(1):52–83, 2016.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "71\n",
      "\n",
      "\f",
      "efficient feature embeddings for student classification\n",
      "with variational auto-encoders\n",
      "severin klingler\n",
      "\n",
      "dept. of computer science\n",
      "eth zurich, switzerland\n",
      "\n",
      "kseverin@inf.ethz.ch\n",
      "\n",
      "rafael wampfler\n",
      "\n",
      "dept. of computer science\n",
      "eth zurich, switzerland\n",
      "\n",
      "wrafael@inf.ethz.ch\n",
      "\n",
      "barbara solenthaler\n",
      "\n",
      "dept. of computer science\n",
      "eth zurich, switzerland\n",
      "\n",
      "sobarbar@inf.ethz.ch\n",
      "\n",
      "abstract\n",
      "gathering labeled data in educational data mining (edm)\n",
      "is a time and cost intensive task. however, the amount\n",
      "of available training data directly influences the quality of\n",
      "predictive models. unlabeled data, on the other hand, is\n",
      "readily available in high volumes from intelligent tutoring\n",
      "systems and massive open online courses. in this paper, we\n",
      "present a semi-supervised classification pipeline that makes\n",
      "effective use of this unlabeled data to significantly improve\n",
      "model quality. we employ deep variational auto-encoders\n",
      "to learn efficient feature embeddings that improve the performance for standard classifiers by up to 28% compared\n",
      "to completely supervised training. further, we demonstrate\n",
      "on two independent data sets that our method outperforms\n",
      "previous methods for finding efficient feature embeddings\n",
      "and generalizes better to imbalanced data sets compared\n",
      "to expert features. our method is data independent and\n",
      "classifier-agnostic, and hence provides the ability to improve\n",
      "performance on a variety of classification tasks in edm.\n",
      "\n",
      "keywords\n",
      "semi-supervised classification, variational auto-encoder, deep\n",
      "neural networks, dimensionality reduction\n",
      "\n",
      "1.\n",
      "\n",
      "introduction\n",
      "\n",
      "building predictive models of student characteristics such\n",
      "as knowledge level, learning disabilities, personality traits\n",
      "or engagement is one of the big challenges in educational\n",
      "data mining (edm). such detailed student profiles allow\n",
      "for a better adaptation of the curriculum to the individual\n",
      "needs and is crucial for fostering optimal learning progress.\n",
      "in order to build such predictive models, smaller-scale and\n",
      "controlled user studies are typically conducted where detailed information about student characteristics are at hand\n",
      "(labeled data). the quality of the predictive models, however, inherently depends on the number of study participants, which is typically on the lower side due to time and\n",
      "budget constraints. in contrast to such controlled user studies, digital learning environments such as intelligent tutoring\n",
      "systems (its), educational games, learning simulations, and\n",
      "massive open online courses (moocs) produce high volumes\n",
      "of data. these data sets provide rich information about student interactions with the system, but come with no or only\n",
      "little additional information about the user (unlabeled data).\n",
      "\n",
      "tanja käser\n",
      "\n",
      "graduate school of education\n",
      "stanford university, usa\n",
      "\n",
      "tkaeser@stanford.edu\n",
      "markus gross\n",
      "\n",
      "dept. of computer science\n",
      "eth zurich, switzerland\n",
      "\n",
      "grossm@inf.ethz.ch\n",
      "\n",
      "semi-supervised learning bridges this gap by making use of\n",
      "patterns in bigger unlabeled data sets to improve predictions\n",
      "on smaller labeled data sets. this is also the focus of this\n",
      "paper. these techniques are well explored in a variety of\n",
      "domains and it has been shown that classifier performance\n",
      "can be improved for, e.g., image classification [15], natural language processing [28] or acoustic modeling [21]. in\n",
      "the education community, semi-supervised classification has\n",
      "been used employing self-training, multi-view training and\n",
      "problem-specific algorithms. self-training has e.g. been applied for problem-solving performance [22]. in self-training,\n",
      "a classifier is first trained on labeled data and is then iteratively retrained using its most confident predictions on unlabeled data. self-training has the disadvantage that incorrect predictions decrease the quality of the classifier. multiview training uses different data views and has been explored\n",
      "with co-training [27] and tri-training [18] for predicting prerequisite rules and student performance, respectively. the\n",
      "performance of these methods, however, largely depends on\n",
      "the properties of the different data views, which are not yet\n",
      "fully understood [34]. problem-specific semi-supervised algorithms have been used to organize learning resources in\n",
      "the web [19], with the disadvantage that they cannot be\n",
      "directly applied for other classification tasks.\n",
      "recently, it has been shown (outside of the education context) that variational auto-encoders (vae) have the potential to outperform the commonly used semi-supervised classification techniques. vae is a neural network that includes\n",
      "an encoder that transforms a given input into a typically\n",
      "lower-dimensional representation, and a decoder that reconstructs the input based on the latent representation. hence,\n",
      "vaes learn an efficient feature embedding (feature representation) using unlabeled data that can be used to improve the performance of any standard supervised learning\n",
      "algorithm [15]. this property greatly reduces the need for\n",
      "problem-specific algorithms. moreover, vaes feature the\n",
      "advantage that the trained deep generative models are able\n",
      "to produce realistic samples that allow for accurate data\n",
      "imputation and simulations [23], which makes them an appealing choice for edm. inspired by these advantages, and\n",
      "the demonstrated superior classifier performance in other\n",
      "domains as in computer vision [16, 23], this paper explores\n",
      "vae for student classification in the educational context.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "72\n",
      "\n",
      "\f",
      "we present a complete semi-supervised classification pipeline\n",
      "that employs deep vaes to extract efficient feature embeddings from unlabeled student data. we have optimized the\n",
      "architecture of two different networks for educational data a simple variational auto-encoder and a convolutional variational auto-encoder. while our method is generic and hence\n",
      "widely applicable, we apply the pipeline to the problem of\n",
      "detecting students suffering from developmental dyscalculia\n",
      "(dd), which is a learning disability in arithmetics. the large\n",
      "and unlabeled data set at hand consists of student data of\n",
      "more than 7k students and we evaluate the performance of\n",
      "our pipeline on two independent small and labeled data sets\n",
      "with 83 and 155 students. our evaluation first compares the\n",
      "performance of the two networks, where our results indicate\n",
      "superiority of the convolutional vae. we then apply different classifiers to both labeled data sets, and demonstrate\n",
      "not only improvements in classification performance of up to\n",
      "28% compared to other feature extraction algorithms, but\n",
      "also improved robustness to class imbalance when using our\n",
      "pipeline compared to other feature embeddings. the improved robustness of our vae is especially important for\n",
      "predicting relatively rare student conditions - a challenge\n",
      "that is often met in edm applications.\n",
      "\n",
      "2.\n",
      "\n",
      "background\n",
      "\n",
      "in the semi-supervised classification setting we have access\n",
      "to a large data set xb without labels and a much smaller\n",
      "labeled data set xs with labels ys . the idea behind semisupervised classification is to make use of patterns in the\n",
      "unlabeled data set to improve the quality of the classifier\n",
      "beyond what would be possible with the small data set\n",
      "xs alone. there are many different approaches to semisupervised classification including transductive svms, graphbased methods, self-training or representation learning [35].\n",
      "in this work we focus on learning an efficient encoding z =\n",
      "e(x) for x ∈ xb of the data domain using the unlabeled\n",
      "data xb only. this learnt data transformation e(·) - the\n",
      "encoding - is then applied to the labeled data set xs . wellknown encoders include principle component analysis (pca)\n",
      "or kernel pca (kpca). pca is a dimensionality reduction\n",
      "method that finds the optimal linear transformation from\n",
      "an n-dimensional to a k-dimensional space (given a meansquared error loss). kernel pca [24] extends pca allowing\n",
      "non-linear transformations into a k-dimensional space and\n",
      "has, among others, been successfully used for novelty detection in non-linear domains [11]. recently, variational autoencoders (vae) have outperformed other semi-supervised\n",
      "classification techniques on several data sets [15]. vae combine variational inference networks with generative models\n",
      "parametrized by deep neural networks that exploit information in the data density to find efficient lower dimensional\n",
      "representations (feature embeddings) of the data.\n",
      "auto-encoder. an auto-encoder or autoassociator [2] is a\n",
      "neural network that encodes a given input into a (typically\n",
      "lower dimensional) representation such that the original input can be reconstructed approximately. the auto-encoder\n",
      "consists of two parts. the encoder part of the network takes\n",
      "the n -dimensional input x ∈ rn and computes an encoding z = e(x) while the decoder d reconstructs the input\n",
      "based on the latent representation x̂ = d(z). if we train\n",
      "a network using the mean squared error loss and the network consists of a single linear hidden layer of size k, e.g.\n",
      "\n",
      "e(x) = w1 x + b1 and d(z) = w2 z + b2 for weights\n",
      "w1 ∈ rk×n and w2 ∈ rn ×k and offsets b1 ∈ rk and\n",
      "b2 ∈ rn , the autoencoder behaves similar to pca in that\n",
      "the network learns to project the input into the span of\n",
      "the k first principle components [2]. for more complex networks with non-linear layers multi-modal aspects of the data\n",
      "can be learnt. auto-encoders can be used in semi-supervised\n",
      "classification tasks because the encoder can compute a feature representation z of the original data x. these features\n",
      "can then be used to train a classifier. the learnt feature\n",
      "embedding facilitates classification by clustering related observations in the computed latent space.\n",
      "variational auto-encoder. variational auto-encoders [15]\n",
      "are generative models that combine bayesian inference with\n",
      "deep neural networks. they model the input data x as\n",
      "pθ (x|z) = f (x; z, θ)\n",
      "\n",
      "p(z) = n (z|0, i)\n",
      "\n",
      "(1)\n",
      "\n",
      "where f is a likelihood function that performs a non-linear\n",
      "transformation with parameters θ of z by employing a deep\n",
      "neural network. in this model the exact computation of\n",
      "the posterior pθ (z|x) is not computationally tractable. instead, the true posterior is approximated by a distribution\n",
      "qφ (z|x) [16]. this inference network qφ (z|x) is parametrized\n",
      "as a multivariate normal distribution as\n",
      "qφ (z|x) = n (z|µφ (x), diag(σφ2 (x))),\n",
      "\n",
      "(2)\n",
      "\n",
      "σφ2 (x)\n",
      "\n",
      "where µφ (x) and\n",
      "denote vectors of means and variance\n",
      "respectively. both functions µφ (·) and σφ2 (·) are represented\n",
      "as deep neural networks. hence, variational autoencoders\n",
      "essentially replace the deterministic encoder e(x) and decoder d(z) by a probabilistic encoder qφ (z|x) and decoder\n",
      "pθ (x|z). direct maximization of the likelihood is computationally not tractable, therefore a lower bound on the likelihood has been derived [16]. the learning task then amounts\n",
      "to maximizing this variational lower bound\n",
      "eqφ (z|x) [log pθ (x|z)] − kl [qφ (z|x)||p(z)] ,\n",
      "\n",
      "(3)\n",
      "\n",
      "where kl denotes the kullback-leibler divergence. the\n",
      "lower bound consists of two intuitive terms. the first term\n",
      "is the reconstruction quality while the second one regularizes the latent space towards the prior p(z). we perform\n",
      "optimization of this lower bound by applying a stochastic\n",
      "optimization method using gradient back-propagation [14].\n",
      "\n",
      "3.\n",
      "\n",
      "method\n",
      "\n",
      "in the following we introduce two networks. first, a simple\n",
      "variational auto-encoder consisting of fully connected layers to learn feature embeddings of student data. these encoders have shown to be powerful for semi-supervised classification [15], and are often applied due to their simplicity.\n",
      "second, an advanced auto-encoder that combines the advantages of vae with the superiority of asymmetric encoders.\n",
      "this is motivated by the fact that asymmetric auto-encoders\n",
      "have shown superior performance and more meaningful feature representations compared to simple vae in other domains such as image synthesis [29].\n",
      "student snapshots. there are many applications where\n",
      "we want to predict a label yn for each student n within an\n",
      "its based on behavioral data xn . these labels typically\n",
      "relate to external variables or properties of a student, such\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "73\n",
      "\n",
      "\f",
      "simple student auto-encoder (s-sae)\n",
      "𝑞𝜙 𝒛 𝒙)\n",
      "\n",
      "x\n",
      "\n",
      "sampling connection\n",
      "\n",
      "x\n",
      "\n",
      "fc\n",
      "\n",
      "fully connected layer\n",
      "\n",
      "con\n",
      "con\n",
      "con\n",
      "\n",
      "fc\n",
      "\n",
      "network connection\n",
      "\n",
      "fc\n",
      "\n",
      "𝜎\n",
      "\n",
      "𝑧\n",
      "\n",
      "con\n",
      "con\n",
      "con\n",
      "\n",
      "𝜇\n",
      "\n",
      "fc\n",
      "\n",
      "fc\n",
      "\n",
      "x\n",
      "\n",
      "cnn student auto-encoder (cnn-sae)\n",
      "𝑞𝜙 𝒛 𝒙)\n",
      "\n",
      "𝑝𝜃 𝒙 𝒛)\n",
      "\n",
      "𝜇\n",
      "𝜎\n",
      "\n",
      "𝑝𝜃 𝒙 𝒛)\n",
      "lstm\n",
      "\n",
      "fc\n",
      "\n",
      "lstm\n",
      "\n",
      "fc\n",
      "\n",
      "𝑧\n",
      "\n",
      "lstm recurrent lstm\n",
      "\n",
      "x\n",
      "\n",
      "con\n",
      "\n",
      "convolutional layer\n",
      "\n",
      "figure 1: network layouts for our simple student auto-encoder (left) using only fully connected layers and our\n",
      "improved cnn student auto-encoder (right) using convolutions for the encoder and recurrent lstm layers\n",
      "for the decoder. in contrast to standard auto-encoders, the connections to the latent space z are sampled\n",
      "(red dashed arrows) from a gaussian distribution.\n",
      "\n",
      "as age, learning disabilities, personality traits, learner types,\n",
      "learning outcome etc. similar to knowledge tracing (kt)\n",
      "we propose to model the data xn = {xn1 , . . . , xnt } as a\n",
      "sequence of t observations. in contrast to kt we store f\n",
      "different feature values xnt ∈ rf for each element in the\n",
      "sequence, where t denotes the tth opportunity within a task.\n",
      "this allows us to simultaneously store data from multiple\n",
      "tasks in xnt , e.g. xn1 stores all features for student n that\n",
      "were observed during the first task opportunities. for every task in an its we can extract various different features\n",
      "that characterize how a student n was approaching the task.\n",
      "these features include performance, answer times, problem\n",
      "solving strategies, etc. we combine this information into a\n",
      "student snapshot xn ∈ rt ×f , where t is the number of task\n",
      "opportunities and f is the number of extracted features.\n",
      "simple student auto-encoder (s-sae). our simple variational autoencoder is following the general design outlined\n",
      "in section 2 and is based on the student snapshot representation. for ease of notation we use x := vec(xn ), where\n",
      "vec(·) is the matrix vectorization function to represent the\n",
      "student snapshot of student n. the complete network layout is depicted in figure 1, left. the encoder and decoder\n",
      "networks consist of l fully connected layers that are implemented as an affine transformation of the input followed by\n",
      "a non-linear activation function β(·) as xl = β(wl xl−1 +bl ),\n",
      "where l is the layer index and wl and bl are a weight matrix\n",
      "and offset vector of suitable dimensions. typical choices for\n",
      "β(·) include tanh, rectified linear units or sigmoid functions\n",
      "[6]. to produce latent samples z we sample from the normal\n",
      "distribution (see equation (2)) using re-parametrization [16]\n",
      "z = µφ (x) + σφ (x)\u000f,\n",
      "\n",
      "(4)\n",
      "\n",
      "where \u000f ∼ n (0, 1), to allow for back-propagation of gradients. for pθ (x|z) (see (1)) any suitable likelihood function can be used. we used a gaussian distribution for all\n",
      "presented examples. note that the likelihood function is\n",
      "parametrized by the entire (non-linear) decoder network.\n",
      "the training of variational auto-encoders can be challenging\n",
      "as stochastic optimization was found to set qφ (z|x) = p(z)\n",
      "in all but vanishingly rare cases [3], which corresponds to a\n",
      "local maximum that does not use any information from x.\n",
      "we therefore add a warm-up phase that gradually gives the\n",
      "regularization term in the target function more weight:\n",
      "eqφ (z|x) [log pθ (x|z)] − α kl [qφ (z|x)||p(z)] ,\n",
      "\n",
      "(5)\n",
      "\n",
      "where α ∈ [0, 1] is linearly increased with the number of\n",
      "epochs. the warm-up phase has been successfully used\n",
      "for training deep variational auto-encoders [25]. furthermore, we initialize the weights of the dense layer computing\n",
      "log(σφ2 (x)) to 0 (yielding a variance of 1 at the beginning of\n",
      "the training). this was motivated by our observations that if\n",
      "we employ standard random weight initialization techniques\n",
      "(glorot-norm, he-norm [9]) we can get relatively high initial\n",
      "estimates for the variance σφ2 (x), which due to the sampling\n",
      "leads to very unreliable samples z in the latent space. the\n",
      "large variance in sampled points in the latent space leads to\n",
      "bad convergence properties of the network.\n",
      "cnn student auto-encoder (cnn-sae). following\n",
      "the recent findings in computer vision we present a second,\n",
      "more advanced network that typically outperforms simpler\n",
      "vae. in [29], for example, these asymmetric auto-encoders\n",
      "resulted in superior reconstruction of images as well as more\n",
      "meaningful feature embeddings. a specific kind of convolutional neural network was combined with an auto-encoder,\n",
      "being able to directly capture low level pixel statistics and\n",
      "hence to extract more high-level feature embeddings.\n",
      "inspired by this previous work, we combine an asymmetric\n",
      "auto-encoder (and a decoder that is able to capture low level\n",
      "statistics) with the advantages of variational auto-encoders.\n",
      "figure 1, right, shows our combined network. we employ\n",
      "multiple layers of one-dimensional convolutions to parametrize\n",
      "the encoder qφ (z|x) (again we assume a gaussian distribution, see (2)). the distribution is parametrized as follows:\n",
      "µφ (x) = wµ h + bµ\n",
      "log(σφ2 (x)) = wσ h + bσ\n",
      "h = convl (x) = β(wl ∗ convl−1 (x)),\n",
      "\n",
      "where ∗ is the convolution operator, wl , wµ , wσ are weights\n",
      "of suitable dimensions, β(·) is a non-linear activation function and l denotes the layer depth. further, conv0 (x) = x.\n",
      "we keep the standard variational layer (see (4)) while changing the output layer to a recurrent layer using long term\n",
      "short term units (lstm). recurrent layers have successfully been used in auto-encoders before, e.g. in [5]. lstm\n",
      "were very successful for modeling temporal sequences because they can model long and short term dependencies between time steps. every lstm unit receives a copy of the\n",
      "sampled points in latent-space, which allows the lstm network to combine context information (point in the latent\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "74\n",
      "\n",
      "\f",
      "feature\n",
      "selection\n",
      "\n",
      "naive bayes\n",
      "logistic regression\n",
      "svm\n",
      "\n",
      "labels\n",
      "\n",
      "𝑞𝜙 𝒛 𝒙)\n",
      "\n",
      "feature\n",
      "embedding\n",
      "\n",
      "labeled\n",
      "data\n",
      "\n",
      "𝑝𝜃 𝒙 𝒛)\n",
      "\n",
      "encoder\n",
      "unlabeled\n",
      "data\n",
      "\n",
      "𝑞𝜙 𝒛 𝒙)\n",
      "\n",
      "feature\n",
      "embedding\n",
      "\n",
      "unlabeled\n",
      "data\n",
      "\n",
      "semi-supervised classification pipeline\n",
      "encoder\n",
      "decoder\n",
      "\n",
      "use trained encoder\n",
      "\n",
      "figure 2: pipeline overview. we train the variational auto-encoder on a large unlabeled data set. the trained\n",
      "encoder of the auto-encoder can be used to transform other data sets into an expressive feature embedding.\n",
      "based on this feature embedding we train different classifiers to predict the student labels.\n",
      "\n",
      "space) with the sequence information (memory unit in the\n",
      "lstm cell). using lstm cells the decoder pθ (x|z) assumes\n",
      "a gaussian distribution and is parametrized as follows:\n",
      "µθt (z) = wµz · lstmt (z) + bµz\n",
      "\n",
      "4.1 experimental setup\n",
      "\n",
      "2\n",
      "log(σθt\n",
      "(z)) = wσz · lstmt (z) + bσz ,\n",
      "2\n",
      "where µθt (z) and σθt\n",
      "(z) are the tth components of µθ (z) and\n",
      "σθ2 (z), respectively, lstmt (·) denotes the tth lstm cell and\n",
      "w∗ and b∗ denote suitable weight and offset parameters.\n",
      "\n",
      "feature selection. vae provide a natural way for performing feature selection. the inference network qφ (z|x)\n",
      "infers the mean and variance for every dimension zi . therefore, the most informative dimension zi has the highest kl\n",
      "divergence from the prior distribution p(zi ) = n (0, 1) while\n",
      "uninformative dimensions will have a kl divergence close to\n",
      "0 [10]. the kl divergence of zi to p(zi ) is given by\n",
      "kl [qφ (zi |x)||p(zi )] = − log(σi ) +\n",
      "\n",
      "1\n",
      "σi2 µ2i\n",
      "− ,\n",
      "2\n",
      "2\n",
      "\n",
      "sets since their distribution of dd and non-dd children differs: the first study has approximately 50% dd, while the\n",
      "second one includes 5% dd (typical prevalence of dd).\n",
      "\n",
      "(6)\n",
      "\n",
      "where µi and σi are the inferred parameter for the gaussian\n",
      "distribution qφ (zi |x). feature selection proceeds by keeping\n",
      "the k dimensions zi with the largest kl divergence.\n",
      "semi-supervised classification pipeline. the encoder\n",
      "and the decoder of the variational auto-encoder can be used\n",
      "independently of each other. this independence allows us\n",
      "to take the trained encoder and map new data to the learnt\n",
      "feature embedding. figure 2 provides an overview of the\n",
      "entire pipeline for semi-supervised classification. in a first\n",
      "unsupervised step we train a vae on unlabeled data. the\n",
      "learnt encoder qφ (z|x) is then used to transform labeled data\n",
      "sets to the feature embedding. we finally apply our feature\n",
      "selection step that considers the relative importance of the\n",
      "latent dimensions as previously described. we then train\n",
      "standard classifiers (logistic regression, naive bayes and\n",
      "support vector machine) on the feature embeddings.\n",
      "\n",
      "4. results\n",
      "we evaluated our approach for the specific example of detecting developmental dyscalculia (dd), which is a learning\n",
      "disability affecting the acquisition of arithmetic skills [33].\n",
      "based on the learnt feature embedding on a large unlabeled\n",
      "data set the classifier performance was measured on two independent, small and labeled data sets from controlled user\n",
      "studies. we refer to them as balanced and imbalanced data\n",
      "\n",
      "all three data sets were collected from calcularis, which is\n",
      "an intelligent tutoring system (its) targeted at elementary\n",
      "school children suffering from dd or exhibiting difficulties\n",
      "in learning mathematics [13]. calcularis consists of different\n",
      "games for training number representations and calculation.\n",
      "previous work identified a set of games that are predictive\n",
      "of dd within calcularis [17]. since timing features were\n",
      "found to be one of the most relevant indicators for detecting\n",
      "dd [4] and to facilitate comparison to other feature embedding techniques we limited our analysis to log-normalized\n",
      "timing features, for which we can assume normal distribution [30]. therefore, we evaluated our pipeline on the subset of games from [17] for which meaningful timing features\n",
      "could be extracted and sufficient samples were available in all\n",
      "data sets (we used >7000 samples for training the vaes).\n",
      "since our pipeline currently does not handle missing data\n",
      "only students with complete data were included.\n",
      "timing features were extracted for the first 5 tasks in 5 different games. the selected games involve addition tasks\n",
      "(adding a 2-digit number to a 1-digit number with tencrossing; adding two 2-digit numbers with ten-crossing), number conversion (spoken to written numbers in the ranges 010 and 0-100) and subtraction tasks (subtracting a 1-digit\n",
      "number from a 2-digit number with ten-crossing). for every\n",
      "task we extracted the total answer time (time between the\n",
      "task prompt until the answer was entered) and the response\n",
      "time (time between the task prompt and the first input by\n",
      "the student). hence, each student is represented by a 50dimensional snapshot x (see section 3).\n",
      "unlabeled data set. the unlabeled data set was extracted\n",
      "using live interaction logs from the its calcularis. in total,\n",
      "we collected data from 7229 children. note that we have\n",
      "no additional information about the children such as dd or\n",
      "grade. we excluded all teacher accounts as well as log files\n",
      "that were < 20kb. since every new game in calcularis is\n",
      "introduced by a short video during the very first task, we\n",
      "excluded this particular task for all games.\n",
      "balanced data set. the first labeled data set is based\n",
      "on log files from 83 participants of a multi-center user study\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "75\n",
      "\n",
      "\f",
      "conducted in germany and switzerland, where approximately\n",
      "half of the participants were diagnosed with dd (47 dd, 36\n",
      "control) [31]. during the study, children trained with calcularis at home for five times per week during six weeks and\n",
      "solved on average 1551 tasks. there were 28 participants\n",
      "in 2nd grade (9 dd, 19 control), 40 children in 3rd grade\n",
      "(23 dd, 17 control), 12 children in 4th grade (12 dd) and\n",
      "3 children in 5th grade (3 dd). the diagnosis of dd was\n",
      "based on standardized neuropsychological tests [31].\n",
      "imbalanced data set. the second labeled data set is from\n",
      "a user study conducted in the classroom of ten swiss elementary school classes. in total, 155 children participated, and\n",
      "a prevalence of dd of 5% could be detected (8 dd, 147 control). there were 97 children in 2nd grade (3 dd, 94 control)\n",
      "and 58 children in 3rd grade (5 dd, 53 control). the dd diagnosis was computed based on standardized tests assessing\n",
      "the mathematical abilities of the children [32, 7]. during the\n",
      "study, children solved 85 tasks directly in the classroom. on\n",
      "average, children needed 26 minutes to complete the tasks.\n",
      "implementation. the unlabeled data set was used to train\n",
      "the unsupervised vae for extracting compact feature embeddings of the data. based on the learnt data transformations we evaluated two standard classifiers: logistic regression (lr) and naive bayes (nb). we restricted our evaluation to simple classification models because we wanted to\n",
      "assess the quality of the feature embedding and not the quality of the classifier. more advanced classifiers typically perform a (sometimes implicit) feature transformation as part\n",
      "of their data fitting procedure. to represent at least one\n",
      "model that performs such an embedding we included support vector machine (svm) in all our results. all classifier\n",
      "parameters were chosen according to the default values in\n",
      "scikit-learn. note that we have additionally performed randomized cross-validated hyper-parameter search for all classifiers, which, however, resulted in marginal improvements\n",
      "only. because of that, and to keep the model simple and especially easily reproducible, we use the default parameter set\n",
      "in this work. for logistic regression we used l2 regularization with c = 1, for naive bayes we used gaussian distributions and for the svm rbf kernels and data point weights\n",
      "have been set inversely proportional to label frequencies. all\n",
      "results are cross-validated using 30 randomized training-test\n",
      "splits on the unlabeled data (test size 5%). the classification\n",
      "part of the pipeline is additionally cross-validated using 300\n",
      "label-stratified random training-test splits (test size 20%) to\n",
      "ensure highly reproducible classification results.\n",
      "network hyper-parameters were defined using the approach\n",
      "described in [1]. we increased the number of nodes per\n",
      "layer, the number of layers and the number of epochs until\n",
      "a good fit of the data was achieved. we then regularized\n",
      "the network using dropout [26] with increasing dropout rate\n",
      "until the network was no longer overfitting the data. activation and weight initialization have been chosen according to common standards: we employ the most common\n",
      "activation function, namely rectified linear activation units\n",
      "(relu) [20], for all activations. weight initialization was\n",
      "performed using the method by he et al. [9]. following this\n",
      "procedure, the following parameters were used for the ssae model: encoder and decoders used 3 layers of size 320.\n",
      "the cnn-sae model was parametrized as follows: 3 convo-\n",
      "\n",
      "lution layers with 64 convolution kernels and a filter length\n",
      "of 3. we used a single layer of lstm cells with 80 nodes.\n",
      "we used a batch size of 500 samples and batch normalization and dropout (r = 0.25) at every layer. the warm-up\n",
      "phase (see section 3) was set to 300 epochs. training was\n",
      "stopped after 1000 (s-sae) and 500 (cnn-sae) epochs.\n",
      "the number of latent units was set to 8 in accordance to\n",
      "previous work on detecting students with dd that used 17\n",
      "features but found that about half of the features were sufficient to detect dd with high accuracy [17]. when feature\n",
      "selection was applied we set the number of features to k = 4\n",
      "and thus we kept exactly half of the latent space features.\n",
      "all networks were implemented using the keras framework\n",
      "with tensorflowtm and optimized using adam stochastic\n",
      "optimization with standard parameters according to [14].\n",
      "\n",
      "4.2\n",
      "\n",
      "performance comparison\n",
      "\n",
      "our vae models are trained to extract efficient feature embeddings of the data. to assess the quality of these computed feature representations, we compare the classification\n",
      "performance of our method to previous techniques for finding efficient feature embeddings, as well as to feature sets\n",
      "optimized specifically for the task of predicting dd.\n",
      "network comparison. in a first experiment we compared\n",
      "the feature embeddings generated by our simple s-sae and\n",
      "our asymmetric cnn-sae with and without feature selection. figure 3 illustrates the average roc curves of our\n",
      "complete semi-supervised classification pipeline. our feature embeddings based on asymmetric cnn-sae clearly\n",
      "outperform the ones from the simple s-sae on both the\n",
      "imbalanced and the balanced data set for naive bayes (nb)\n",
      "and logistic regression (lr). for both models, feature selection improves the area under the roc curve (auc) for\n",
      "the imbalanced data set (cnn-sae: lr 4.2%, nb 6.3%;\n",
      "s-sae: lr 6.8%, nb: 1.6%), but has no effect for the balanced data set. we believe that this is due to the ability of\n",
      "the classifiers to distinguish useful features from noisy ones\n",
      "given enough samples. since the performance of the classifiers with feature selection (fs) is better or equal to no\n",
      "feature selection in each experiment, we used the cnn-sae\n",
      "fs model for all further evaluations.\n",
      "classification performance. in figure 4 we compare the\n",
      "classifier performance for different feature embeddings. we\n",
      "compare our method based on vae to two well-known methods for finding optimal feature embeddings, namely principle\n",
      "component analysis (pca, green) and kernel pca (kpca,\n",
      "red) [24]. for comparison and as a baseline for the performance of the different methods, we include direct classification results (gray), for which no feature embedding was\n",
      "computed. we used k = 8 (dimensionality of feature embedding) for all methods. the features extracted by our\n",
      "pipeline compare favorably to pca and kernel pca showing improvements in terms of auc of 28% for logistic regression and 23% for naive bayes on the imbalanced data\n",
      "set and an improvement of 3.75% for logistic regression\n",
      "and 7.5% for naive bayes on the balanced data set. by\n",
      "using simple classifiers, we demonstrated that our encoder\n",
      "learns an effective feature embedding. more sophisticated\n",
      "classifiers (such as svm with non-linear kernels) typically\n",
      "proceed by first embedding the input into a specific feature\n",
      "space that is different from the original space.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "76\n",
      "\n",
      "\f",
      "logistic regression\n",
      "\n",
      "1.0\n",
      "cnn-sae\n",
      "cnn-sae\n",
      "0.8 fs\n",
      "s-sae\n",
      "s-sae\n",
      "0.6 fs\n",
      "\n",
      "0.8\n",
      "\n",
      "true positive rate\n",
      "\n",
      "true positive rate\n",
      "\n",
      "1.0\n",
      "\n",
      "0.6\n",
      "0.4\n",
      "0.2\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "0.2\n",
      "\n",
      "0.4\n",
      "\n",
      "0.6\n",
      "\n",
      "0.8\n",
      "\n",
      "cnn-sae\n",
      "cnn-sae fs\n",
      "s-sae\n",
      "s-sae fs\n",
      "\n",
      "0.4\n",
      "0.2\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "1.0\n",
      "\n",
      "naive bayes\n",
      "\n",
      "false positive rate\n",
      "\n",
      "0.2\n",
      "\n",
      "0.4\n",
      "\n",
      "0.6\n",
      "\n",
      "0.8\n",
      "\n",
      "1.0\n",
      "\n",
      "false positive rate\n",
      "\n",
      "(a) imbalanced data set\n",
      "logistic regression\n",
      "\n",
      "1.0\n",
      "cnn-sae\n",
      "cnn-sae\n",
      "0.8 fs\n",
      "s-sae\n",
      "s-sae\n",
      "0.6 fs\n",
      "\n",
      "0.8\n",
      "\n",
      "true positive rate\n",
      "\n",
      "true positive rate\n",
      "\n",
      "1.0\n",
      "\n",
      "0.6\n",
      "0.4\n",
      "0.2\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "0.2\n",
      "\n",
      "0.4\n",
      "\n",
      "0.6\n",
      "\n",
      "0.8\n",
      "\n",
      "false positive rate\n",
      "\n",
      "1.0\n",
      "\n",
      "naive bayes\n",
      "cnn-sae\n",
      "cnn-sae fs\n",
      "s-sae\n",
      "s-sae fs\n",
      "\n",
      "0.4\n",
      "0.2\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "0.2\n",
      "\n",
      "0.4\n",
      "\n",
      "0.6\n",
      "\n",
      "0.8\n",
      "\n",
      "1.0\n",
      "\n",
      "false positive rate\n",
      "\n",
      "(b) balanced data set\n",
      "figure 3: roc curves for the two proposed models with and without feature selection (fs). our\n",
      "asymmetric cnn-sae outperforms the simple ssae consistently with (blue) and without (purple)\n",
      "feature selection. feature selection improves performance only on the imbalanced data set.\n",
      "\n",
      "for the imbalanced data set the overall performance for\n",
      "svm is significantly lower for all embeddings. this is in line\n",
      "with previous work [12] showing that for imbalanced data\n",
      "sets, the decision boundaries of svms are heavily skewed\n",
      "towards the minority class resulting in a preference for the\n",
      "majority class and thus a high miss-classification rate for the\n",
      "minority class. indeed, we found that svm predicted only\n",
      "majority labels on the imbalanced data set. for the balanced data set our feature embedding shows improvements\n",
      "of 2.5% over alternative embeddings when using svm.\n",
      "further, table 1 shows the performance of all feature embeddings using three additional common classification metrics:\n",
      "root mean squared error (rmse), classification accuracy\n",
      "(acc.) and area under the precision recall curve (aupr).\n",
      "we statistically compared the classification metrics of our\n",
      "feature embedding to the best alternative feature embedding using an independent t-test and bonferroni correction\n",
      "for multiple tests (α = 0.05). our feature embedding significantly outperformed alternative embeddings for all classifiers on both the balanced and imbalanced data sets on most\n",
      "metrics. the main exception was the performance of svm\n",
      "on the imbalanced data set, which exhibited large variance\n",
      "for all feature embeddings and the worst overall classification performance (compared to the other classifiers).\n",
      "when comparing classification performance on the imbalanced and the balanced data sets we observed that our\n",
      "pipeline using vaes showed significant performance improvements compared to other methods for finding feature embeddings. while the unlabeled and the balanced data sets stem\n",
      "from an adaptive version of calcularis the imbalanced data\n",
      "was collected using a fixed task sequence. as our method\n",
      "shows larger improvements on the imbalanced data, we be-\n",
      "\n",
      "lieve cnn-sae learned an embedding that is robust beyond\n",
      "adaptive its. the relative improvements of our feature embeddings is smallest for svm on the balanced data set. we\n",
      "believe that this is due to ability of the svm to learn complex decision boundaries given sufficient data. however, the\n",
      "ability for complex decision boundaries renders svms more\n",
      "vulnerable to class imbalance, yielding performance at random level on the imbalanced data set.\n",
      "comparison to specialized models. recently, a specialized naive bayes classifier (s-nb) for the detection of\n",
      "developmental dyscalculia (dd) was introduced presenting\n",
      "a set of features optimized for the detection of dd [17].\n",
      "the development of s-nb including the set of features was\n",
      "based on the balanced data set used in this work. in comparison to s-nb, our approach relies on timing data only\n",
      "and the extracted features are independent of the classification task. we compared the performance of s-nb to our\n",
      "cnn-sae model on both data sets. for the balanced data\n",
      "set we found an auc of 0.94 for the specialized model (snb) compared to an auc of 0.86 for naive bayes using our\n",
      "feature embedding. on the imbalanced data set we found\n",
      "an auc of 0.67 for s-nb compared to an auc of 0.77 using logistic regression with our feature embedding. these\n",
      "findings demonstrate that while our feature embedding performs slightly worse on the balanced data set (for which the\n",
      "s-nb was developed), we significantly outperform s-nb by\n",
      "15% on the imbalanced data set, which suggests that our\n",
      "vae model automatically extracts feature embeddings that\n",
      "are more robust than expert features.\n",
      "robustness on sample size. ideally, a classifier’s performance should gracefully decrease as fewer data is provided.\n",
      "a good feature embedding allows a classifier to generalize\n",
      "well based on few labeled examples because similar samples\n",
      "are clustered together in the feature embedding. we therefore investigated the robustness of the different feature representations with respect to the training set size. for this we\n",
      "used the balanced data set where we varied the training set\n",
      "size between 7 (10% of the data) and 62 (90% of the data)\n",
      "by random label-stratified sub-sampling. figure 5 compares\n",
      "the auc of the different feature embeddings over different\n",
      "sizes of the training set. in case of naive bayes and logistic regression our embedding provides superior performance\n",
      "for all training set sizes. for large enough data sets svm\n",
      "using the raw feature data (direct, grey) is performing as\n",
      "well as using our embedding (cnn-sae, blue). however,\n",
      "for smaller data sets starting at 30 samples the performance\n",
      "of svm based on the raw features declines more rapidly\n",
      "compared to the svm based on our feature embedding.\n",
      "\n",
      "5.\n",
      "\n",
      "conclusion\n",
      "\n",
      "we adapted the recently developed variational auto-encoders\n",
      "to educational data for the task of semi-supervised classification of student characteristics. we presented a complete pipeline for semi-supervised classification that can be\n",
      "used with any standard classifier. we demonstrated that extracted structures from large scale unlabeled data sets can\n",
      "significantly improve classification performance for different\n",
      "labeled data sets. our findings show that the improvements\n",
      "are especially pronounced for small or imbalanced data sets.\n",
      "imbalanced data sets typically arise in edm when detecting\n",
      "relatively rare conditions such as learning disabilities. im-\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "77\n",
      "\n",
      "\f",
      "\u0000,\u0000p\u0000e\u0000d\u0000o\u0000d\u0000q\u0000f\u0000h\u0000g\u0000\u0003\u0000g\u0000d\u0000w\u0000d\u0000\u0003\u0000v\u0000h\u0000w\n",
      "\n",
      "\u00001\u0000d\u0000l\u0000y\u0000h\u0000\u0003\u0000%\u0000d\u0000\\\u0000h\u0000v\n",
      "\n",
      "\u0000\u0013\u0000\u0011\u0000\u001c",
      "\u0000\u0013\n",
      "\u0000'\u0000l\u0000u\u0000h\u0000f\u0000w\n",
      "\u0000\u0013\u0000\u0011\u0000\u001b\u0000\u0018\u00003\u0000&\u0000$\n",
      "\u0000\u0013\u0000\u0011\u0000\u001b\u0000\u0013\u0000.\u0000h\u0000u\u0000q\u0000h\u0000o\u0000\u0003\u00003\u0000&\u0000$\n",
      "\u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0018\u0000&\u00001\u00001\u0000\u0010\u00006\u0000$\u0000(\n",
      "\u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0013\n",
      "\u0000\u0013\u0000\u0011\u0000\u0019\u0000\u0018\n",
      "\u0000\u0013\u0000\u0011\u0000\u0019\u0000\u0013\n",
      "\u0000\u0013\u0000\u0011\u0000\u0018\u0000\u0018\n",
      "\u0000\u0013\u0000\u0011\u0000\u0018\u0000\u0013\n",
      "\n",
      "\u0000%\u0000d\u0000o\u0000d\u0000q\u0000f\u0000h\u0000g\u0000\u0003\u0000g\u0000d\u0000w\u0000d\u0000\u0003\u0000v\u0000h\u0000w\n",
      "\n",
      "\u0000$\u00008\u0000&\n",
      "\n",
      "\u0000$\u00008\u0000&\n",
      "\n",
      "\u0000$\u00008\u0000&\n",
      "\n",
      "\u0000/\u0000r\u0000j\u0000l\u0000v\u0000w\u0000l\u0000f\u0000\u0003\u00005\u0000h\u0000j\u0000u\u0000h\u0000v\u0000v\u0000l\u0000r\u0000q\n",
      "\n",
      "\u0000\u0013\u0000\u0011\u0000\u001c",
      "\u0000\u0013\n",
      "\u0000\u0013\u0000\u0011\u0000\u001b\u0000\u0018\n",
      "\u0000\u0013\u0000\u0011\u0000\u001b\u0000\u0013\n",
      "\u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0018\n",
      "\u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0013\n",
      "\u0000\u0013\u0000\u0011\u0000\u0019\u0000\u0018\n",
      "\u0000\u0013\u0000\u0011\u0000\u0019\u0000\u0013\n",
      "\u0000\u0013\u0000\u0011\u0000\u0018\u0000\u0018\n",
      "\u0000\u0013\u0000\u0011\u0000\u0018\u0000\u0013\n",
      "\n",
      "\u0000,\u0000p\u0000e\u0000d\u0000o\u0000d\u0000q\u0000f\u0000h\u0000g\u0000\u0003\u0000g\u0000d\u0000w\u0000d\u0000\u0003\u0000v\u0000h\u0000w\n",
      "\n",
      "\u0000v\u0000r\u0000x\u0000u\u0000f\u0000h\n",
      "\n",
      "\u00006\u00009\u00000\n",
      "\n",
      "\u0000\u0013\u0000\u0011\u0000\u001c",
      "\u0000\u0013\n",
      "\u0000'\u0000l\u0000u\u0000h\u0000f\u0000w\n",
      "\u0000\u0013\u0000\u0011\u0000\u001b\u0000\u0018\u00003\u0000&\u0000$\n",
      "\u0000\u0013\u0000\u0011\u0000\u001b\u0000\u0013\u0000.\u0000h\u0000u\u0000q\u0000h\u0000o\u0000\u0003\u00003\u0000&\u0000$\n",
      "\u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0018\u0000&\u00001\u00001\u0000\u0010\u00006\u0000$\u0000(\n",
      "\u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0013\n",
      "\u0000\u0013\u0000\u0011\u0000\u0019\u0000\u0018\n",
      "\u0000\u0013\u0000\u0011\u0000\u0019\u0000\u0013\n",
      "\u0000\u0013\u0000\u0011\u0000\u0018\u0000\u0018\n",
      "\u0000\u0013\u0000\u0011\u0000\u0018\u0000\u0013\n",
      "\n",
      "\u0000%\u0000d\u0000o\u0000d\u0000q\u0000f\u0000h\u0000g\u0000\u0003\u0000g\u0000d\u0000w\u0000d\u0000\u0003\u0000v\u0000h\u0000w\n",
      "\n",
      "\u0000'\u0000l\u0000u\u0000h\u0000f\u0000w\n",
      "\u00003\u0000&\u0000$\n",
      "\u0000.\u0000h\u0000u\u0000q\u0000h\u0000o\u0000\u0003\u00003\u0000&\u0000$\n",
      "\u0000&\u00001\u00001\u0000\u0010\u00006\u0000$\u0000(\n",
      "\n",
      "\u0000,\u0000p\u0000e\u0000d\u0000o\u0000d\u0000q\u0000f\u0000h\u0000g\u0000\u0003\u0000g\u0000d\u0000w\u0000d\u0000\u0003\u0000v\u0000h\u0000w\n",
      "\n",
      "\u0000v\u0000r\u0000x\u0000u\u0000f\u0000h\n",
      "\n",
      "\u0000%\u0000d\u0000o\u0000d\u0000q\u0000f\u0000h\u0000g\u0000\u0003\u0000g\u0000d\u0000w\u0000d\u0000\u0003\u0000v\u0000h\u0000w\n",
      "\n",
      "\u0000v\u0000r\u0000x\u0000u\u0000f\u0000h\n",
      "\n",
      "logistic regression\n",
      "\n",
      "0\n",
      "\n",
      "10\n",
      "\n",
      "20\n",
      "\n",
      "30\n",
      "\n",
      "40\n",
      "\n",
      "50\n",
      "\n",
      "60\n",
      "\n",
      "70\n",
      "\n",
      "0.90\n",
      "direct\n",
      "0.85pca\n",
      "0.80kernel pca\n",
      "cnn-sae\n",
      "0.75\n",
      "0.70\n",
      "0.65\n",
      "0.60\n",
      "0.55\n",
      "0.50\n",
      "0\n",
      "10\n",
      "\n",
      "number of training samples\n",
      "\n",
      "naive bayes\n",
      "\n",
      "auc\n",
      "\n",
      "0.90\n",
      "0.85\n",
      "0.80\n",
      "0.75\n",
      "0.70\n",
      "0.65\n",
      "0.60\n",
      "0.55\n",
      "0.50\n",
      "\n",
      "auc\n",
      "\n",
      "auc\n",
      "\n",
      "figure 4: classification performance for different feature embeddings. our variational auto-encoder (blue)\n",
      "outperforms other embeddings by up to 28% (imbalanced data set) and by up to 7.5% (balanced data set).\n",
      "\n",
      "20\n",
      "\n",
      "30\n",
      "\n",
      "40\n",
      "\n",
      "50\n",
      "\n",
      "60\n",
      "\n",
      "70\n",
      "\n",
      "0.90\n",
      "direct\n",
      "0.85pca\n",
      "0.80kernel pca\n",
      "cnn-sae\n",
      "0.75\n",
      "0.70\n",
      "0.65\n",
      "0.60\n",
      "0.55\n",
      "0.50\n",
      "0\n",
      "10\n",
      "\n",
      "number of training samples\n",
      "\n",
      "svm\n",
      "direct\n",
      "pca\n",
      "kernel pca\n",
      "cnn-sae\n",
      "\n",
      "20\n",
      "\n",
      "30\n",
      "\n",
      "40\n",
      "\n",
      "50\n",
      "\n",
      "60\n",
      "\n",
      "70\n",
      "\n",
      "number of training samples\n",
      "\n",
      "figure 5: comparison of classifier performance on the balanced data for different training set sizes (moving\n",
      "average fitted to data points). the features automatically extracted by our variational auto-encoder (blue)\n",
      "maintain a performance advantage even if the training size shrinks to 7 samples (10% of the original size).\n",
      "\n",
      "table 1: comparison of our method to alternative embeddings. our approach using a variational auto-encoder\n",
      "(cnn-sae) significantly outperforms other approaches for most cases. the best score for each metric and\n",
      "classifier is shown in bold. *= statistically significant difference (t-test with bonferroni correction, α = 0.05).\n",
      "direct\n",
      "auc rmse\n",
      "\n",
      "aupr\n",
      "\n",
      "acc.\n",
      "\n",
      "pca\n",
      "auc rmse\n",
      "\n",
      "aupr\n",
      "\n",
      "acc.\n",
      "\n",
      "kernel pca\n",
      "auc rmse\n",
      "\n",
      "aupr\n",
      "\n",
      "acc.\n",
      "\n",
      "cnn-sae\n",
      "auc\n",
      "rmse\n",
      "\n",
      "aupr\n",
      "\n",
      "acc.\n",
      "\n",
      "imbalanced data set\n",
      "logistic regression\n",
      "naive bayes\n",
      "svm\n",
      "\n",
      "0.53\n",
      "0.51\n",
      "0.55\n",
      "\n",
      "0.27\n",
      "0.29\n",
      "0.25\n",
      "\n",
      "0.18\n",
      "0.23\n",
      "0.22*\n",
      "\n",
      "0.91\n",
      "0.91\n",
      "0.94\n",
      "\n",
      "0.54\n",
      "0.50\n",
      "0.40\n",
      "\n",
      "0.25\n",
      "0.29\n",
      "0.25\n",
      "\n",
      "0.17\n",
      "0.10\n",
      "0.08\n",
      "\n",
      "0.93\n",
      "0.90\n",
      "0.94\n",
      "\n",
      "0.61\n",
      "0.57\n",
      "0.42\n",
      "\n",
      "0.25\n",
      "0.28\n",
      "0.25\n",
      "\n",
      "0.16\n",
      "0.20\n",
      "0.09\n",
      "\n",
      "0.93\n",
      "0.91\n",
      "0.93\n",
      "\n",
      "0.78*\n",
      "0.70*\n",
      "0.59\n",
      "\n",
      "0.24*\n",
      "0.25*\n",
      "0.25\n",
      "\n",
      "0.28*\n",
      "0.24\n",
      "0.16\n",
      "\n",
      "0.94*\n",
      "0.93*\n",
      "0.94\n",
      "\n",
      "balanced data set\n",
      "logistic regression\n",
      "naive bayes\n",
      "svm\n",
      "\n",
      "0.80\n",
      "0.80\n",
      "0.81\n",
      "\n",
      "0.44\n",
      "0.49\n",
      "0.42\n",
      "\n",
      "0.82\n",
      "0.80\n",
      "0.84*\n",
      "\n",
      "0.73\n",
      "0.73\n",
      "0.75\n",
      "\n",
      "0.80\n",
      "0.77\n",
      "0.79\n",
      "\n",
      "0.42\n",
      "0.46\n",
      "0.43\n",
      "\n",
      "0.84\n",
      "0.77\n",
      "0.81\n",
      "\n",
      "0.73\n",
      "0.71\n",
      "0.73\n",
      "\n",
      "0.80\n",
      "0.76\n",
      "0.80\n",
      "\n",
      "0.42\n",
      "0.46\n",
      "0.43\n",
      "\n",
      "0.83\n",
      "0.76\n",
      "0.83\n",
      "\n",
      "0.75\n",
      "0.70\n",
      "0.73\n",
      "\n",
      "0.83*\n",
      "0.86*\n",
      "0.83\n",
      "\n",
      "0.40*\n",
      "0.38*\n",
      "0.40*\n",
      "\n",
      "0.84\n",
      "0.86*\n",
      "0.81\n",
      "\n",
      "0.77\n",
      "0.80*\n",
      "0.79*\n",
      "\n",
      "proved classification results with simple classifiers such as\n",
      "logistic regression might indicate that vaes learn feature\n",
      "embeddings that are interpretable by human experts. in\n",
      "the future we want to explore the learnt representations and\n",
      "compare it to traditional categorizations of students (skills,\n",
      "performance, etc.). additionally, we want to extend our\n",
      "results to include additional feature types and data reliability indicators to handle missing data. although we trained\n",
      "our networks on comparatively small sample sizes, the presented method scales (due to mini-batch learning) to much\n",
      "larger data sets (>100k users ) allowing the training of more\n",
      "complex vae. moreover, the generative model pθ (x|z) that\n",
      "is part of any vae can be used to produce realistic data\n",
      "samples [29]. up-sampling of the minority class provides a\n",
      "potential way to improve the decision boundaries for classi-\n",
      "\n",
      "fiers. in contrast to common up-sampling methods such as\n",
      "adasyn [8], vae-based sampling does not require nearest\n",
      "neighbor computations which makes them better applicable\n",
      "to small data sets. preliminary results for random subsets\n",
      "of the balanced data set showed improvements in auc by\n",
      "up-sampling based on vae of 2-3% compared to adasyn.\n",
      "while we applied our method to the specific case of detecting\n",
      "developmental dyscalculia, the presented pipeline is generic\n",
      "and thus can be applied to any educational data set and\n",
      "used for the detection of any student characteristic.\n",
      "acknowledgments. this work was supported by eth\n",
      "research grant eth-23 13-2.\n",
      "\n",
      "6.\n",
      "\n",
      "references\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "78\n",
      "\n",
      "\f",
      "[1] y. bengio. practical recommendations for gradientbased training of deep architectures. in neural\n",
      "networks: tricks of the trade, pages 437–478. 2012.\n",
      "[2] y. bengio et al. learning deep architectures for ai.\n",
      "foundations and trends in machine learning, 2009.\n",
      "[3] s. r. bowman, l. vilnis, o. vinyals, a. dai,\n",
      "r. jozefowicz, and s. bengio. generating sentences\n",
      "from a continuous space. in proc. conll, pages\n",
      "10–21, 2016.\n",
      "[4] b. butterworth. dyscalculia screener. nelson\n",
      "publishing company ltd., 2003.\n",
      "[5] o. fabius and j. r. van amersfoort. variational\n",
      "recurrent auto-encoders. in proc. iclr, 2015.\n",
      "[6] i. goodfellow, y. bengio, and a. courville. deep\n",
      "learning. mit press, 2016.\n",
      "[7] j. haffner, k. baro, p. parzer, and f. resch.\n",
      "heidelberger rechentest: erfassung mathematischer\n",
      "basiskomptenzen im grundschulalter, 2005.\n",
      "[8] h. he, y. bai, e. a. garcia, and s. li. adasyn:\n",
      "adaptive synthetic sampling approach for imbalanced\n",
      "learning. in proc. ijcnn, pages 1322–1328, 2008.\n",
      "[9] k. he, x. zhang, s. ren, and j. sun. delving deep\n",
      "into rectifiers: surpassing human-level performance on\n",
      "imagenet classification. in proc. iccv, pages\n",
      "1026–1034, 2015.\n",
      "[10] i. higgins, l. matthey, x. glorot, a. pal, b. uria,\n",
      "c. blundell, s. mohamed, and a. lerchner. early\n",
      "visual concept learning with unsupervised deep\n",
      "learning. arxiv preprint arxiv:1606.05579, 2016.\n",
      "[11] h. hoffmann. kernel pca for novelty detection.\n",
      "pattern recognition, pages 863–874, 2007.\n",
      "[12] t. imam, k. ting, and j. kamruzzaman. z-svm: an\n",
      "svm for improved classification of imbalanced data. ai\n",
      "2006: advances in artificial intelligence, pages\n",
      "264–273, 2006.\n",
      "[13] t. käser, g.-m. baschera, j. kohn, k. kucian,\n",
      "v. richtmann, u. grond, m. gross, and m. von aster.\n",
      "design and evaluation of the computer-based training\n",
      "program calcularis for enhancing numerical cognition.\n",
      "frontiers in developmental psychology, 2013.\n",
      "[14] d. kingma and j. ba. adam: a method for stochastic\n",
      "optimization. proc. iclr, 2015.\n",
      "[15] d. p. kingma, s. mohamed, d. j. rezende, and\n",
      "m. welling. semi-supervised learning with deep\n",
      "generative models. in proc. nips, pages 3581–3589,\n",
      "2014.\n",
      "[16] d. p. kingma and m. welling. auto-encoding\n",
      "variational bayes. proc. iclr, 2014.\n",
      "[17] s. klingler, t. käser, a. busetto, b. solenthaler,\n",
      "j. kohn, m. von aster, and m. gross. stealth\n",
      "assessment in its - a study for developmental\n",
      "dyscalculia. in proc. its, pages 79–89, 2016.\n",
      "[18] g. kostopoulos, s. b. kotsiantis, and p. b. pintelas.\n",
      "predicting student performance in distance higher\n",
      "education using semi-supervised techniques. in proc.\n",
      "medi, pages 259–270, 2015.\n",
      "[19] i. labutov and h. lipson. web as a textbook:\n",
      "curating targeted learning paths through the\n",
      "heterogeneous learning resources on the web. in\n",
      "proc. edm, pages 110–118, 2016.\n",
      "[20] y. lecun, y. bengio, and g. hinton. deep learning.\n",
      "\n",
      "nature, pages 436–444, 2015.\n",
      "[21] h. liao, e. mcdermott, and a. senior. large scale\n",
      "deep neural network acoustic modeling with\n",
      "semi-supervised training data for youtube video\n",
      "transcription. in proc. asru, pages 368–373, 2013.\n",
      "[22] w. min, b. w. mott, j. p. rowe, and j. c. lester.\n",
      "leveraging semi-supervised learning to predict student\n",
      "problem-solving performance in narrative-centered\n",
      "learning environments. in proc. its, pages 664–665,\n",
      "2014.\n",
      "[23] d. j. rezende, s. mohamed, and d. wierstra.\n",
      "stochastic backpropagation and approximate\n",
      "inference in deep generative models. in proc. icml,\n",
      "pages 1278–1286, 2014.\n",
      "[24] b. schölkopf, a. smola, and k.-r. müller. kernel\n",
      "principal component analysis. in proc. icann, pages\n",
      "583–588, 1997.\n",
      "[25] c. k. sønderby, t. raiko, l. maaløe, s. k. sønderby,\n",
      "and o. winther. ladder variational autoencoders. in\n",
      "proc. nips, pages 3738–3746, 2016.\n",
      "[26] n. srivastava, g. e. hinton, a. krizhevsky,\n",
      "i. sutskever, and r. salakhutdinov. dropout: a simple\n",
      "way to prevent neural networks from overfitting.\n",
      "jmlr, pages 1929–1958, 2014.\n",
      "[27] v. tam, e. y. lam, s. fung, w. fok, and a. h. yuen.\n",
      "enhancing educational data mining techniques on\n",
      "online educational resources with a semi-supervised\n",
      "learning approach. in proc. tale, pages 203–206,\n",
      "2015.\n",
      "[28] j. turian, l. ratinov, and y. bengio. word\n",
      "representations: a simple and general method for\n",
      "semi-supervised learning. in proc. acl, pages\n",
      "384–394, 2010.\n",
      "[29] a. van den oord, n. kalchbrenner, l. espeholt,\n",
      "o. vinyals, a. graves, et al. conditional image\n",
      "generation with pixelcnn decoders. in proc. nips,\n",
      "pages 4790–4798, 2016.\n",
      "[30] w. j. van der linden. a lognormal model for response\n",
      "times on test items. journal of educational and\n",
      "behavioral statistics, 31(2):181–204, 2006.\n",
      "[31] m. von aster, l. rauscher, k. kucian, t. käser,\n",
      "u. mccaskey, and j. kohn. calcularis - evaluation of\n",
      "a computer-based learning program for enhancing\n",
      "numerical cognition for children with developmental\n",
      "dyscalculia, 2015. 62nd annual meeting of the\n",
      "american academy of child and adolescent\n",
      "psychiatry.\n",
      "[32] m. von aster, m. w. zulauf, and r. horn.\n",
      "neuropsychologische testbatterie für\n",
      "zahlenverarbeitung und rechnen bei kindern:\n",
      "zareki-r. pearson, 2006.\n",
      "[33] m. g. von aster and r. s. shalev. number\n",
      "development and developmental dyscalculia.\n",
      "developmental medicine & child neurology, pages\n",
      "868–873, 2007.\n",
      "[34] c. xu, d. tao, and c. xu. a survey on multi-view\n",
      "learning. neural comput. appl., pages 2031–2038,\n",
      "2013.\n",
      "[35] x. zhu. semi-supervised learning literature survey.\n",
      "technical report, university of wisconsin-madison,\n",
      "2006.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "79\n",
      "\n",
      "\f",
      "predicting short- and long-term vocabulary learning via\n",
      "semantic features of partial word knowledge\n",
      "sungjin nam\n",
      "\n",
      "school of information\n",
      "university of michigan\n",
      "ann arbor, mi 48109\n",
      "\n",
      "sjnam@umich.edu\n",
      "\n",
      "gwen frishkoff\n",
      "\n",
      "kevyn collins-thompson\n",
      "\n",
      "gfrishkoff@gmail.com\n",
      "\n",
      "kevynct@umich.edu\n",
      "\n",
      "department of psychology\n",
      "university of oregon\n",
      "eugene, or 97403\n",
      "\n",
      "abstract\n",
      "\n",
      "we show how the novel use of a semantic representation\n",
      "based on osgood’s semantic differential scales can lead to\n",
      "effective features in predicting short- and long-term learning\n",
      "in students using a vocabulary learning system. previous\n",
      "studies in students’ intermediate knowledge states during\n",
      "vocabulary acquisition did not provide much information\n",
      "on which semantic knowledge students gained during word\n",
      "learning practice. moreover, these studies relied on human\n",
      "ratings to evaluate the students’ responses. to solve this\n",
      "problem, we propose a semantic representation for words\n",
      "based on osgood’s semantic decomposition of vocabulary\n",
      "[16]. to demonstrate our method can effectively represent\n",
      "students’ knowledge in vocabulary acquisition, we build\n",
      "models for predicting the student’s short-term vocabulary\n",
      "acquisition and long-term retention. we compare the\n",
      "effectiveness of our osgood-based semantic representation to\n",
      "that provided by word2vec neural word embedding [13], and\n",
      "find that prediction models using features based on osgood\n",
      "scale-based scores (osg) perform better than the baseline\n",
      "and are comparable in accuracy to those using word2vec\n",
      "score-based models (w2v). by using more interpretable\n",
      "osgood-based scales, our study results can help with better\n",
      "understanding of students’ ongoing learning states and\n",
      "designing personalized learning systems that can address an\n",
      "individual’s weak points in vocabulary acquisition.\n",
      "\n",
      "keywords\n",
      "\n",
      "vocabulary learning, semantic similarity, prediction model,\n",
      "intelligent tutoring system\n",
      "\n",
      "1. introduction\n",
      "\n",
      "studies of word learning have shown that knowledge of\n",
      "individual words is typically not all-or-nothing. rather,\n",
      "people acquire varying degrees of knowledge of many words\n",
      "incrementally over time, by exposure to them in context [9].\n",
      "this is especially true for so-called “academic” words that are\n",
      "less common and more abstract — e.g., pontificate, probity,\n",
      "or assiduous [7]. binary representations and measures model\n",
      "word knowledge simply as correct or incorrect on a particular\n",
      "\n",
      "school of information\n",
      "university of michigan\n",
      "ann arbor, mi 48109\n",
      "\n",
      "item (word), but in reality, a student’s knowledge level may\n",
      "reside between these two extremes. thus, previous studies of\n",
      "vocabulary acquisition have suggested that students’ partial\n",
      "knowledge be modeled using a representation that adding an\n",
      "additional label corresponding to an intermediate knowledge\n",
      "state [6] or further, in terms of continuous metrics for\n",
      "semantic similarity [3].\n",
      "in addition, there are multiple dimensions to a word’s\n",
      "meaning [16]. measuring a student’s partial knowledge on\n",
      "a single scale may only provide abstract information about\n",
      "the student’s general answer quality and not give enough\n",
      "information to specify which dimensions of word knowledge\n",
      "a student already has learned or needs to improve. in order\n",
      "to achieve detailed understanding of a student’s learning\n",
      "state, online learning systems should be able to capture\n",
      "a student’s “learning trajectory” that tracks their partial\n",
      "knowledge on a particular item over time, over multiple\n",
      "dimensions of meaning in a multidimensional semantic\n",
      "representation.\n",
      "hence, multidimensional representations of word knowledge\n",
      "can be an important element for building an effective\n",
      "intelligent tutoring system (its) for reading and language.\n",
      "maintaining a fine-grained semantic representation of a\n",
      "student’s degree of word knowledge can be helpful for\n",
      "the its to design more engaging instructional content,\n",
      "more helpful personalized feedback, and more sensitive\n",
      "assessments [17, 19]. selecting semantic representations\n",
      "to model, understand, and predict learning outcomes is\n",
      "important to designing a more effective and efficient its.\n",
      "in this paper, we explore the use of multidimensional\n",
      "semantic word representations for modeling and predicting\n",
      "short- and long-term learning outcomes in a vocabulary\n",
      "tutoring system.\n",
      "our approach derives predictive\n",
      "features using a novel application of existing methods in\n",
      "cognitive psychology combined with methods from natural\n",
      "language processing (nlp). first, we introduce a new\n",
      "multidimensional representation of a word based on the\n",
      "osgood semantic differential [16], an empirically based,\n",
      "cognitive framework that uses a small number of scales\n",
      "to represent latent components of word meaning. we\n",
      "compare the effectiveness of model features based on this\n",
      "osgood-based representation to features based on a different\n",
      "representation, the widely-used word2vec word embedding\n",
      "[13]. second, we evaluate our prediction models using\n",
      "data from a meaning-generation task that was conducted\n",
      "during a computer-based intervention. our study results\n",
      "demonstrate how similarity-based metrics based on rich\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "80\n",
      "\n",
      "\f",
      "semantic representation can be used to automatically\n",
      "evaluate specific components of word knowledge, track\n",
      "changes in the student’s knowledge toward the correct\n",
      "meaning, and compute a rich set of features for use in\n",
      "predicting short- and long-term learning outcomes. our\n",
      "methods could support advances in real-time, adaptive\n",
      "support for word semantic learning, resulting in more\n",
      "effective personalized learning systems.\n",
      "\n",
      "semantic representation & the osgood framework.\n",
      "to quantify the semantic characteristics of a student’s\n",
      "intermediate knowledge of vocabulary, this paper uses a\n",
      "“spatial analogue” for capturing semantic characteristics of\n",
      "words. in [16], osgood investigated how the meaning of\n",
      "a word can be represented by a series of general semantic\n",
      "scales. by using these scales, osgood suggested that the\n",
      "meanings of any word can be projected and explored in a\n",
      "continuous semantic space.\n",
      "\n",
      "2.\n",
      "\n",
      "osgood asked human raters to evaluate a set of words using a\n",
      "large number of scales (e.g., tall-short, fat-thin, heavy-light)\n",
      "and captured the semantic representation of a word [16].\n",
      "respondents gave likert ratings, which indicated whether\n",
      "they thought that a word meaning was closer to one extreme\n",
      "(-3) or the other (+3), or basically irrelevant (0). a principal\n",
      "components analysis (pca) was used to represent the latent\n",
      "semantic features that can explain the patterns of response\n",
      "to individual words within this task.\n",
      "\n",
      "related work\n",
      "\n",
      "the present study is informed by three areas of research:\n",
      "(1) studies of partial word knowledge; (2) the osgood\n",
      "framework for multiple dimensions of word meaning, and (3)\n",
      "computational methods for estimating semantic similarity.\n",
      "partial word knowledge. the concept of partial word\n",
      "knowledge has interested vocabulary researchers for several\n",
      "decades, particularly in the learning and instruction of “tier\n",
      "2” words [20]. tier 2 words are low-frequency and typically\n",
      "have complex (multiple, nuanced) meanings. by nature,\n",
      "they are rarely learned through “one-shot” learning or direct\n",
      "definition. instead, they are learned partially and gaps are\n",
      "filled in over time.\n",
      "words in this intermediate state, neither novel nor fully\n",
      "known, are sometimes called “frontier words” [5]. durso\n",
      "and shore operationalized the frontier word as a word the\n",
      "student had seen previously but was not actively using it [6].\n",
      "based on this definition, the student may have had implicit\n",
      "memory of frontier words, such as general information like\n",
      "whether the word indicates a good or bad situation or refers\n",
      "a person or an action. they discovered that students are\n",
      "more familiar with frontier words than other types of words\n",
      "in terms of their sounds and orthographic characteristics [6].\n",
      "this previous work suggested that the concept of frontier\n",
      "words can be used to represent a student’s partial knowledge\n",
      "states in a vocabulary acquisition task [5, 6].\n",
      "in some studies, partial word knowledge has been\n",
      "represented using simple, categorical labels, e.g., multiplechoice tests that include “partially correct” response options,\n",
      "as well as a single “best” (correct) response. in other studies,\n",
      "the student is presented with a word and is asked to say\n",
      "what it means [1]. the definition is given partial credit\n",
      "if it reflects knowledge that is partial or incomplete. for\n",
      "example, a student may recognize that the word probity\n",
      "has a positive connotation, even if she cannot give a\n",
      "complete definition. however, single categorical or scorebased indicators may not explain which specific aspects of\n",
      "vocabulary knowledge the student is missing. moreover,\n",
      "these studies relied on human ratings to evaluate students’\n",
      "responses for unknown words [6]. although widely used\n",
      "in psychometric and psycholinguistic studies [4, 16], hiring\n",
      "human raters is expensive and may not be done in real time\n",
      "during students’ interaction with the tutoring system.\n",
      "to address these problems, we propose a data-driven method\n",
      "that can automatically extract semantic characteristics of\n",
      "a word based on a set of relatively simple, interpretable\n",
      "scales. the method benefits from existing findings in\n",
      "cognitive psychology and natural language processing. in\n",
      "the following sections, we illustrate more details of related\n",
      "findings and how they can be used in an intelligent tutoring\n",
      "system setting.\n",
      "\n",
      "in our study, we suggest a method that can automatically\n",
      "extract similar semantic information that can project a word\n",
      "into a multidimensional semantic space. by using semantic\n",
      "scales selected from [16], we verify if such representation of\n",
      "semantic attributes of words is useful for predicting students’\n",
      "short- and long-term learning.\n",
      "semantic similarity measures. studies in nlp have\n",
      "suggested methods to automatically evaluate the semantic\n",
      "association between two words. for example, markov\n",
      "estimation of semantic association (mesa) [3, 9] can\n",
      "estimate the similarity between words from a random walk\n",
      "model over a synonym network such as wordnet [14]. other\n",
      "methods like latent semantic analysis (lsa) are based on\n",
      "co-occurrence of the word in a document corpus. in lsa,\n",
      "semantic similarity between words is determined by using\n",
      "a cosine similarity measure, derived from a sparse matrix\n",
      "constructed from unique words and paragraphs containing\n",
      "the words [10].\n",
      "for this paper, we use word2vec [13], a widely used word\n",
      "embedding method, to calculate the semantic similarity\n",
      "between words. word2vec’s technique [11] transforms the\n",
      "semantic context, such as proximity between words, into a\n",
      "numeric vector space. in this way, linguistic regularities\n",
      "and patterns are encoded into linear translations. for\n",
      "example, using outputs from word2vec, relationships\n",
      "between words can be estimated by simple operations on\n",
      "their corresponding vectors, e.g., madrid - spain + france\n",
      "= paris, or germany + capital = berlin [13].\n",
      "measures from these computational semantic similarity tools\n",
      "are powerful because they can provide an automated method\n",
      "for evaluation of partial word knowledge. however, they\n",
      "typically produce a single measure (e.g., cosine similarity or\n",
      "euclidean distance), representing semantic similarity as a\n",
      "one-dimensional construct. with such a measure, it is not\n",
      "possible to determine represent partial semantic knowledge\n",
      "and changes in knowledge of latent semantic features as\n",
      "word knowledge progresses from unknown to frontier to\n",
      "fully known. in following sections, we describe how we\n",
      "address this problem, using novel methods to to estimate\n",
      "the contribution of osgood semantic features to individual\n",
      "word meanings.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "81\n",
      "\n",
      "\f",
      "2.1\n",
      "\n",
      "overview of the study\n",
      "\n",
      "based on findings from existing studies, this study will\n",
      "suggest an automatized method for evaluating students’\n",
      "partial knowledge of vocabulary that can be used to predict\n",
      "students’ short-term vocabulary acquisition and long-term\n",
      "retention. to investigate this problem, we will answer the\n",
      "following research questions with this paper.\n",
      "the first research question (rq1): can semantic similarity\n",
      "scores from word2vec be used to predict students’ shortterm learning and long-term retention? previous studies in\n",
      "vocabulary tutoring systems tend to focus on how different\n",
      "experimental conditions, such as different spacing between\n",
      "question items [18], difficulty levels [17], and systematic\n",
      "feedback [7], affect students’ short-term learning. this study\n",
      "will answer how computationally estimated trial-by-trial\n",
      "scores in a vocabulary tutoring system can be used to predict\n",
      "students’ short-term learning and long-term retention.\n",
      "rq2: compared to using regular word2vec scores, how does\n",
      "the model using osgood’s semantic scales [16] as features\n",
      "perform for immediate and delayed learning prediction\n",
      "tasks? as described in the previous section, the initial\n",
      "outcome from word2vec returns hundreds of semantic\n",
      "dimensions to represent the semantic characteristics of\n",
      "a word. summary statistics for comparing such highdimensional vectors, such as cosine similarity or euclidean\n",
      "distance, only provide the overall similarity between words.\n",
      "if measures from osgood scales work in a similar level\n",
      "to models using regular word2vec scores for predicting\n",
      "students’ learning outcomes, we can argue that it can\n",
      "be an effective method for representing students’ partial\n",
      "knowledge of vocabulary.\n",
      "\n",
      "3. method\n",
      "3.1 word learning study\n",
      "\n",
      "this study used a vocabulary tutoring system called\n",
      "dynamic support of contextual vocabulary acquisition\n",
      "for reading (dscovar) [8]). dscovar aims to support\n",
      "efficient and effective learning vocabulary in context. all\n",
      "participants accessed dscovar in a classroom-setting\n",
      "environment by using chromebook devices or the school’s\n",
      "computer lab in the presence of other students.\n",
      "\n",
      "3.1.1\n",
      "\n",
      "study participants\n",
      "\n",
      "participants included 280 middle school students (6th to\n",
      "8th grade) from multiple schools, including children from\n",
      "diverse socio-economic and educational backgrounds. table\n",
      "1 provides a summary of student demographics, including\n",
      "location (p1 or p2), age and grade level, sex. location p1 is\n",
      "a laboratory school affiliated with a large urban university in\n",
      "the northeastern united states. students from location p1\n",
      "were generally of high socio-economic status (e.g., children\n",
      "of university faculty and staff). location p2 includes three\n",
      "public middle schools in a southern metropolitan area of the\n",
      "united states. all students from location p2 qualified for\n",
      "free or reduced lunch. the study included a broad range of\n",
      "students so that the results of this analysis were more likely\n",
      "to generalize to future samples.\n",
      "\n",
      "3.1.2\n",
      "\n",
      "study materials\n",
      "\n",
      "dscovar presented students with 60 sat-level english\n",
      "words (also known as tier 2 words). these “target words,”\n",
      "lesser-known words that the students are going to learn,\n",
      "\n",
      "table 1: the number of participants by grade and\n",
      "gender\n",
      "group\n",
      "p1\n",
      "p2\n",
      "\n",
      "6th grade\n",
      "girl\n",
      "boy\n",
      "16\n",
      "28\n",
      "53\n",
      "51\n",
      "\n",
      "7th grade\n",
      "girl\n",
      "boy\n",
      "19\n",
      "23\n",
      "12\n",
      "6\n",
      "\n",
      "8th grade\n",
      "girl\n",
      "boy\n",
      "18\n",
      "13\n",
      "21\n",
      "20\n",
      "\n",
      "were balanced between different parts of speech, including 20\n",
      "adjectives, 20 nouns, and 20 verbs. based on previous works,\n",
      "we expected that students would have varying degrees of\n",
      "familiarity with the words at pre-test, but that most words\n",
      "would be either completely novel (“unknown”) or somewhat\n",
      "familiar (“partially known”) [8, 15]. this selection of\n",
      "materials ensured that there would be variability in word\n",
      "knowledge across students for each word and across words\n",
      "for each student.\n",
      "in dscovar, students learned how to infer the meaning\n",
      "of an unknown word in a sentence by using surrounding\n",
      "contextual information. having more information in a\n",
      "sentence (i.e., a sentence with a high degree of contextual\n",
      "constraint) can decrease the uncertainty of inference. in\n",
      "this study, the degree of sentence constraint was determined\n",
      "using standard cloze testing methods: quantifying the\n",
      "diversity of responses from 30 human judges when the target\n",
      "word is left as a fill-in-the-blank question.\n",
      "\n",
      "3.1.3\n",
      "\n",
      "study protocol\n",
      "\n",
      "the word learning study comprised four parts: (1) a pretest, which was used to estimate baseline knowledge of\n",
      "words, (2) a training session, where learners were exposed to\n",
      "words in meaningful contexts, (3) an immediate post-test,\n",
      "and (4) a delayed post-test, which occurred approximately\n",
      "one week after training.\n",
      "pre-test. the pre-test session was designed to measure\n",
      "the students’ prior knowledge of the target words. for\n",
      "each target word, students were asked to answer two types\n",
      "of questions: familiarity-rating questions and synonym\n",
      "selection questions. in familiarity rating questions, students\n",
      "provided their self-rated familiarity levels (unknown, known,\n",
      "and familiar) for presented target words. in synonymselection questions, students were asked to select a synonym\n",
      "word for the given target word from five multiple choice\n",
      "options. the outcome from synonym-selection questions\n",
      "provided more objective measures for students’ prior domain\n",
      "knowledge of target words.\n",
      "training. approximately one week after the pre-test\n",
      "session, students participated in the training. during\n",
      "training, students learned strategies to infer the meaning\n",
      "of an unknown word in a sentence by using surrounding\n",
      "contextual information.\n",
      "a training session consisted of two parts: an instruction\n",
      "video and practice questions. in the instruction video,\n",
      "students saw an animated movie clip about how to identify\n",
      "and use contextual information from the sentence to infer\n",
      "the meaning of an unknown word. in the practice question\n",
      "part, students could exercise the skill that they learned from\n",
      "the video. dscovar provided sentences that included a\n",
      "target word with different levels of surrounding contextual\n",
      "information. the amount of contextual information for\n",
      "each sentence was determined by external crowd workers\n",
      "(details described in section 3.1.2). in the practice question\n",
      "part, each target word was presented four times within\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "82\n",
      "\n",
      "\f",
      "different sentences. students were asked to type a synonym\n",
      "of the target word, which was presented in the sentence as\n",
      "underlined and bold. over two weeks, students participated\n",
      "in two training sessions with a week’s gap between them.\n",
      "each training session contained the instruction video and\n",
      "practice questions for 30 target words. an immediate posttest session followed right after each training session.\n",
      "figure 1: an example of a training session question.\n",
      "in this example, the target word is “education” with\n",
      "a feedback message for a high-accuracy response.\n",
      "\n",
      "figure 2: ten semantic scales used for projecting\n",
      "target words and responses [16].\n",
      "• bad – good\n",
      "\n",
      "• complex – simple\n",
      "\n",
      "• passive – active\n",
      "\n",
      "• fast – slow\n",
      "\n",
      "• powerful – helpless\n",
      "\n",
      "• noisy – quiet\n",
      "\n",
      "• big – small\n",
      "\n",
      "• new – old\n",
      "\n",
      "• helpful – harmful\n",
      "\n",
      "• healthy – sick\n",
      "\n",
      "end. the word’s relationship with each semantic anchor can\n",
      "be automatically measured from its semantic similarity with\n",
      "these exemplar semantic elements.\n",
      "\n",
      "3.2.2\n",
      "\n",
      "students were randomly selected to experience different\n",
      "instruction video conditions (full instruction video vs.\n",
      "restricted instruction video). additionally, various difficulty\n",
      "level conditions and feedback conditions (e.g., dscovar\n",
      "provides a feedback message to the student based on answer\n",
      "accuracy vs. no feedback) were tested within the same\n",
      "student. however, in this study, we focused on data\n",
      "from students who experienced a full instruction video\n",
      "and repeating difficulty conditions. repeating difficulty\n",
      "conditions included questions with all high or medium\n",
      "contextual constraint levels. by doing so, we wanted to\n",
      "minimize the impact from various experimental conditions\n",
      "for analyzing post-test outcomes. moreover, we filtered out\n",
      "response sequences that did not include all four responses\n",
      "for the target word. as a result, we analyzed 818 response\n",
      "sequences from 7,425 items in total.\n",
      "immediate and delayed post-test. the immediate\n",
      "post-test occurred right after the students finished the\n",
      "training; the delayed post-test was conducted one week later.\n",
      "data collected during the immediate and delayed posttests were used to estimate short-and long-term learning,\n",
      "respectively. test items were identical to those in the pretest\n",
      "session, except for item order, which varied across tests. for\n",
      "analysis of the delayed post-test data, we only used the data\n",
      "from target words for which the student provided a correct\n",
      "answer in the earlier, immediate post-test session. as a\n",
      "result, 449 response sequences were analyzed for predicting\n",
      "the long-term retention.\n",
      "\n",
      "3.2\n",
      "\n",
      "semantic score-based features\n",
      "\n",
      "we now describe the semantic features tested in our\n",
      "prediction models.\n",
      "\n",
      "3.2.1\n",
      "\n",
      "semantic scales\n",
      "\n",
      "for this study, we used semantic scales from osgood’s study\n",
      "[16]. ten scales were selected by a cognitive psychologist as\n",
      "being considered semantic attributes that can be detected\n",
      "during word learning (figure 2). each semantic scale\n",
      "consists of pairs of semantic attributes. for example, the\n",
      "bad–good scale can show how the meaning of a word can\n",
      "be projected on a scale with bad and good located at either\n",
      "\n",
      "basic semantic distance scores\n",
      "\n",
      "to extract meaningful semantic information, we have\n",
      "applied the following measures that can be used to explain\n",
      "various characteristics of student responses for different\n",
      "target words. in this study, we used a pre-trained model\n",
      "for word2vec,1 built based on the google news corpus\n",
      "(100 billion tokens with 3 million unique vocabularies,\n",
      "using a negative sampling algorithm), to measure semantic\n",
      "similarity between words. the output of the pre-trained\n",
      "word2vec model contained a numeric vector with 300\n",
      "hundred dimensions.\n",
      "first, we calculated the relationship between word pairs (i.e.,\n",
      "a single student response and the target word, or a pair of\n",
      "responses) in both the regular word2vec (w2v) score and\n",
      "the osgood semantic scale (osg) score. in the w2v score,\n",
      "the semantic relationship between words was represented\n",
      "with a cosine similarity between word vectors:\n",
      "dw2v (w1 , w2 ) = 1 − |sim(v (w1 ), v (w2 ))|.\n",
      "\n",
      "(1)\n",
      "\n",
      "in this equation, the function v returned the vectorized\n",
      "representation of the word (w1 or w2 ) from the pre-trained\n",
      "word2vec model. by calculating the cosine similarity\n",
      "between two vectors (a cosine similarity function is noted\n",
      "as sim), we could extract a single numeric similarity score\n",
      "between two words. this score was converted into a\n",
      "distance-like score by taking the absolute value of the cosine\n",
      "similarity score and subtracting from one.\n",
      "for the osg score, we extracted two different types of\n",
      "scores: a non-normalized score and a normalized score. a\n",
      "non-normalized score showed how a word is similar to a\n",
      "single anchor word (e.g., bad or good ) from the osgood scale.\n",
      "non\n",
      "sosg\n",
      "(w, ai,j ) = sim(v (w), v (ai,j ))\n",
      "\n",
      "(2)\n",
      "\n",
      "non\n",
      "non\n",
      "non\n",
      "dosg\n",
      "(w1 , w2 ; ai,j ) = |sosg\n",
      "(w1 , ai,j )| − |sosg\n",
      "(w2 , ai,j )| (3)\n",
      "\n",
      "in equation 2, ai,j represents a single anchor word (j) in\n",
      "the i-th osgood scale. the similarity between the anchor\n",
      "word and the evaluating word w was calculated with cosine\n",
      "similarity of word2vec outcomes for both words. in a nonnormalized setting, the distance between two words given\n",
      "by a particular anchor word was calculated by the difference\n",
      "of absolute cosine similarity scores (equation 3).\n",
      "the second type of osg score is a normalized score. by\n",
      "using word2vec’s ability to do arithmetical calculation of\n",
      "1\n",
      "api and pre-trained model for word2vec was downloaded\n",
      "from this url: https://github.com/3top/word2vec-api\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "83\n",
      "\n",
      "\f",
      "multiple word vectors, the normalized osg score provided\n",
      "a relative location of the word from two anchor ends of the\n",
      "osgood scale.\n",
      "nrm\n",
      "sosg\n",
      "(w, ai ) = sim(v (w), v (ai,1 ) − v (ai,2 ))\n",
      "nrm\n",
      "nrm\n",
      "nrm\n",
      "dosg\n",
      "(w1 , w2 ; ai ) = |sosg\n",
      "(w1 , ai ) − sosg\n",
      "(w2 , ai )|\n",
      "\n",
      "(4)\n",
      "(5)\n",
      "\n",
      "in equation 4, the output represents the cosine similarity\n",
      "score between the word w and two anchor words (ai,1\n",
      "and ai,2 ). for example, if the cosine similarity score of\n",
      "nrm\n",
      "sosg\n",
      "(w, ai ) is close to -1, it means the word w is close to\n",
      "the first anchor word ai,1 . if the score is close to 1, it is vice\n",
      "versa. in equation 5, the distance between two words was\n",
      "calculated as the absolute value of the difference between\n",
      "two cosine similarity measures.\n",
      "\n",
      "3.2.3\n",
      "\n",
      "deriving predictive features\n",
      "\n",
      "based on semantic distance equations explained in the\n",
      "previous section, this section explains examples of predictive\n",
      "features that we used to predict students’ short-term\n",
      "learning and long-term retention.\n",
      "distance between the target word and the\n",
      "response. for regular word2vec score models and osgood\n",
      "scale score models, distance measures between the target\n",
      "word and the response (by using equations 1 and 5) were\n",
      "used to estimate the accuracy of the response to a question.\n",
      "this feature represents the trial-by-trial answer accuracy of\n",
      "a student response. each response sequence for the target\n",
      "word contained four distance scores.\n",
      "difference between responses. another feature that\n",
      "we used in both types of models was the difference between\n",
      "responses. this feature could capture how a student’s\n",
      "current answer is semantically different from the previous\n",
      "response. from each response sequence, we could extract\n",
      "three derivative scores from four responses.\n",
      "convex hull area of responses.\n",
      "alternative to\n",
      "the difference between responses feature, osgood scale\n",
      "models were also tested with the area size of convex hull\n",
      "that can be generated by responses calculated with nonnormalized osgood scale scores (equation 3). for example,\n",
      "for each osgood scale, a non-normalized score provided\n",
      "two-dimensional scores that can be used for geometric\n",
      "representation. by putting the target word in an origin\n",
      "position, a sequence of responses can create a polygon\n",
      "that can represent the semantic area that the student\n",
      "explored with responses. since some response sequences\n",
      "were unable to generate the polygon by including less than\n",
      "three unique responses, we added a small, random noise\n",
      "that uniformly distributed (between −10−4 and 10−4 ) to all\n",
      "response points. additionally, a value of 10−20 was added to\n",
      "all convex hull area output to create a visible lower-bound\n",
      "value.\n",
      "unlike the measure of difference between responses, this\n",
      "feature also considers angles that can be created between\n",
      "responses and the target word. this representation can\n",
      "provide more information than just using difference between\n",
      "responses.\n",
      "\n",
      "3.3\n",
      "\n",
      "modeling\n",
      "\n",
      "to predict students’ short-term learning and long-term\n",
      "retention, we used a mixed-effect logistic regression model\n",
      "\n",
      "(mlr). mlr is a general form of logistic regression model\n",
      "that includes random effect factors to capture variations\n",
      "from repeated measures.\n",
      "\n",
      "3.3.1\n",
      "\n",
      "off-line variables\n",
      "\n",
      "off-line variables capture item- or subject-level variances\n",
      "that can be observed repeatedly from the data. in this study,\n",
      "we used multiple off-line variables as random effect factors.\n",
      "first, results from familiarity-rating and synonym-selection\n",
      "questions from the pre-test session were used to include\n",
      "item- and subject-level variances. both variables include\n",
      "information on the student’s prior domain knowledge level\n",
      "for target words. second, the question difficulty condition\n",
      "was considered as an item group level factor. in the analysis,\n",
      "sentences for the target word that were presented to the\n",
      "student contained the same difficulty level, either high or\n",
      "medium contextual constraint levels, over four trials. third,\n",
      "a different experiment group was used as a subject group\n",
      "factor. as described in section 3.1.1, this study contains\n",
      "data from students in different institutions in separate\n",
      "geographic locations. the inclusion of these participant\n",
      "groups in the model can be used to explain different\n",
      "short-term learning outcomes and long-term retention by\n",
      "demographic groups.\n",
      "\n",
      "3.3.2\n",
      "\n",
      "model building\n",
      "\n",
      "in this study, we compared the performance of mlr models\n",
      "with four different feature types. first, the baseline model\n",
      "was set to indicate the mlr model’s performance without\n",
      "any fixed effect variables but only with random intercepts.\n",
      "second, the response time model was built to be compared\n",
      "with semantic score-based models. many previous studies\n",
      "have used response time as an important predictor of student\n",
      "engagement and learning [2, 12]. in this study, we used two\n",
      "types of response time variables, the latency for initiating\n",
      "the response and finishing typing the response, as predictive\n",
      "features. both variables were measured in milliseconds over\n",
      "four trials and natural log transformed for the analysis.\n",
      "third, semantic features from regular word2vec scores were\n",
      "used as predictors. this model was built to show how\n",
      "semantic scores from word2vec can be useful for predicting\n",
      "students’ short- and long-term performance in dscovar.\n",
      "lastly, osgood scale-based features were used as predictors.\n",
      "this model was compared with the regular word2vec score\n",
      "model to examine the effectiveness of using osgood scales for\n",
      "evaluating students’ performance in dscovar. for these\n",
      "semantic-score based models, we tested out different types\n",
      "of predictive features that were described in section 3.2.3.\n",
      "all models shared the same random intercept structure\n",
      "that treated each off-line variable as an individual random\n",
      "intercept.\n",
      "for osgood scale models, we also derived reduced-scale\n",
      "models. reduced-scale models were compared with the fullscale model, which uses all ten osgood scales. in this case,\n",
      "using fewer osgood scales can provide easier interpretation\n",
      "of semantic analysis for intelligent tutoring system users.\n",
      "\n",
      "3.3.3\n",
      "\n",
      "model evaluation\n",
      "\n",
      "to compare performance between different models, this\n",
      "study used various evaluation metrics, including auc (an\n",
      "area under the curve score from a response operating\n",
      "characteristic (roc) curve), f1 (a harmonic mean of\n",
      "precision and recall), and error rate (a ratio of the number of\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "84\n",
      "\n",
      "\f",
      "misclassified items over total items). 95% confidence interval\n",
      "of each evaluation metric was calculated from the outcome of\n",
      "a ten-fold cross-validation process repeated over ten times.\n",
      "to select the semantic score-based features for models based\n",
      "on regular word2vec scores and osgood scale scores, we\n",
      "used rankings from each evaluation metric. the model with\n",
      "the highest overall rank (i.e., sum the ranks from auc, f1 ,\n",
      "and error rate, and select the model with the lowest ranksum value) was considered the best-performing model for\n",
      "the score type (i.e., models based on the regular word2vec\n",
      "score or osgood scale score). more details on this process\n",
      "will be illustrated in the next section.\n",
      "\n",
      "4. results\n",
      "4.1 selecting models\n",
      "\n",
      "in this section, we selected the best-performing model based\n",
      "on the models’ overall ranks in each evaluation metric. all\n",
      "model parameters were trained in each fold of repeated\n",
      "cross-validation. we calculated 95% confidence intervals for\n",
      "comparison. to calculate the confidence interval of f1 and\n",
      "error rate measures, the maximum (f1 ) and minimum (error\n",
      "rate) scores of each fold were extracted. these maximum\n",
      "and minimum values were derived from applying multiple\n",
      "cutoff points to the mixed-effect regression model.\n",
      "\n",
      "4.1.1\n",
      "\n",
      "predicting immediate learning\n",
      "\n",
      "first, we built models that predict the students’ immediate\n",
      "learning from the immediate post-test session.\n",
      "from\n",
      "models based on regular word2vec scores (w2v), the model\n",
      "with the distance between the target and responses and\n",
      "the difference between responses (dist+resp) provided the\n",
      "highest rank from various evaluation metrics (table 2).\n",
      "from models based on osgood scales (osg), the model with\n",
      "the difference between responses (resp) provided the highest\n",
      "rank.\n",
      "the selected w2v model provided significantly better\n",
      "performance than the baseline model. the selected osg\n",
      "model also showed significantly better performance than the\n",
      "baseline model, except for the auc score. the selected\n",
      "w2v model was significantly better than the model using\n",
      "response time features in the auc score and error rates.\n",
      "the selected w2v model showed significantly better\n",
      "performance than the osg model only with the auc score.\n",
      "figure 3 shows that the w2v model has a slightly larger area\n",
      "under the roc curve than the osg model. in the precision\n",
      "and recall curve, the selected w2v model provides more\n",
      "balanced trade-offs between precision and recall measures.\n",
      "the selected osg model outperforms the w2v model in\n",
      "precision only in a very low recall measure range.\n",
      "\n",
      "4.1.2\n",
      "\n",
      "predicting long-term retention\n",
      "\n",
      "we also built prediction models to predict the students’\n",
      "long-term retention in the delayed post-test session. in\n",
      "this analysis, a student response was included only when\n",
      "the student provided correct answers to the immediate\n",
      "post-test session questions.\n",
      "among w2v score-based\n",
      "models, the best-performing model contained the same\n",
      "feature types as the immediate post-test results (table 3).\n",
      "by using the distance between the target and responses\n",
      "and difference between responses (dist+resp), the model\n",
      "\n",
      "achieved significantly better performance than the baseline\n",
      "model, except for the auc score.\n",
      "for osg models, the model with a convex hull area of\n",
      "responses (chull ) provided the highest overall rank from\n",
      "evaluation metrics (table 3). the results were significantly\n",
      "better than the baseline model, and marginally better than\n",
      "the w2v model. both selected w2v and osg models were\n",
      "marginally better than the response time model, except the\n",
      "error rate of the osg model was significantly better.\n",
      "in figure 3, the selected w2v model slightly outperforms\n",
      "the osg model in mid-range true positive rates, while\n",
      "the osg model performed slightly better in a higher true\n",
      "positive area. precision and recall curves show similar\n",
      "patterns to those we observed from the immediate post-test\n",
      "prediction models. the osg model only outperforms the\n",
      "w2v model in a very low recall value area.\n",
      "\n",
      "4.1.3 comparing models\n",
      "compared to the selected w2v model in the immediate\n",
      "post-test condition, the selected w2v model in the delayed\n",
      "post-test retention condition showed a significantly lower\n",
      "auc score, marginally higher f1 score, and marginally\n",
      "higher error rate. in terms of osg models, the selected osg\n",
      "model for delayed post-test retention showed a significantly\n",
      "better f1 score and error rates than the selected osg model\n",
      "in the immediate post-test condition. based on these results,\n",
      "we can argue that osgood scale scores can be more useful for\n",
      "predicting student retention in the delayed post-test session\n",
      "than predicting the outcome from the immediate post-test.\n",
      "in terms of selected feature types, the best-performing\n",
      "osg models used features based on the difference between\n",
      "responses (resp) or the convex hull area (chull ) that was\n",
      "created from the relative location of the responses. on the\n",
      "other hand, selected w2v models used both the distance\n",
      "between the target word and responses and difference\n",
      "between responses (dist+resp).\n",
      "when we compared\n",
      "both w2v and osg models using the difference between\n",
      "responses feature, we found that performance is similar in\n",
      "the immediate post-test data. however, the osg model\n",
      "was significantly better in the delayed post-test data. these\n",
      "results show that osgood scale scores can be more useful for\n",
      "representing the relationship among response sequences.\n",
      "\n",
      "4.2 comparing the osgood scales\n",
      "\n",
      "to identify which osgood scales are more helpful than\n",
      "others for predicting students’ performance, we conducted\n",
      "a scale-wise importance analysis. the results from this\n",
      "section reveal which osgood scales are more important than\n",
      "others, and how the performance of prediction models with\n",
      "a reduced number of scales is comparable with the full-scale\n",
      "model.\n",
      "\n",
      "4.2.1\n",
      "\n",
      "identifying more important osgood scales\n",
      "\n",
      "in this section, based on the selected osgood score model\n",
      "from section 4.1, we identified the level of contribution for\n",
      "features based on each osgood scale. for example, the\n",
      "selected osg model for predicting the immediate post-test\n",
      "data uses the difference between responses in ten osgood\n",
      "scales as features. in order to diagnose the importance level\n",
      "of the first scale (bad–good ), we can retrain the model with\n",
      "features based on the nine other scales and compare the\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "85\n",
      "\n",
      "\f",
      "table 2: ranks of predictive feature sets for regular word2vec models (w2v) and osgood score models\n",
      "(osg) in the immediate post-test data. all models are significantly better than the baseline model. (bold:\n",
      "the selected model with highest overall rank.)\n",
      "features\n",
      "baseline\n",
      "rt\n",
      "dist\n",
      "resp\n",
      "chull\n",
      "dist+resp\n",
      "dist+chull\n",
      "\n",
      "auc\n",
      "0.68 [0.67, 0.69] (5)\n",
      "0.69 [0.68, 0.70] (4)\n",
      "0.72 [0.71, 0.74] (1)\n",
      "0.70 [0.69, 0.71] (3)\n",
      "na\n",
      "0.72 [0.71, 0.73] (2)\n",
      "na\n",
      "\n",
      "w2v models\n",
      "f1\n",
      "0.74 [0.73, 0.74] (5)\n",
      "0.75 [0.75, 0.76] (3)\n",
      "0.76 [0.75, 0.76] (2)\n",
      "0.75 [0.74, 0.76] (4)\n",
      "na\n",
      "0.76 [0.75, 0.77] (1)\n",
      "na\n",
      "\n",
      "err\n",
      "0.33 [0.33, 0.34] (5)\n",
      "0.31 [0.31, 0.32] (4)\n",
      "0.29 [0.28, 0.30] (2)\n",
      "0.31 [0.30, 0.32] (3)\n",
      "na\n",
      "0.29 [0.28, 0.30] (1)\n",
      "na\n",
      "\n",
      "auc\n",
      "0.68 [0.67, 0.69] (5)\n",
      "0.69 [0.68, 0.70] (2)\n",
      "0.67 [0.66, 0.68] (7)\n",
      "0.69 [0.68, 0.70] (1)\n",
      "0.69 [0.68, 0.70] (3)\n",
      "0.68 [0.67, 0.69] (4)\n",
      "0.67 [0.66, 0.68] (6)\n",
      "\n",
      "osg models\n",
      "f1\n",
      "0.74 [0.73, 0.74] (5)\n",
      "0.75 [0.74, 0.76] (2)\n",
      "0.73 [0.73, 0.74] (7)\n",
      "0.75 [0.75, 0.76] (1)\n",
      "0.74 [0.73, 0.75] (4)\n",
      "0.74 [0.73, 0.75] (3)\n",
      "0.74 [0.73, 0.74] (6)\n",
      "\n",
      "err\n",
      "0.33 [0.33, 0.34] (7)\n",
      "0.31 [0.31, 0.32] (2)\n",
      "0.33 [0.32, 0.34] (6)\n",
      "0.31 [0.30, 0.32] (1)\n",
      "0.32 [0.31, 0.33] (4)\n",
      "0.31 [0.31, 0.32] (3)\n",
      "0.33 [0.32, 0.34] (5)\n",
      "\n",
      "table 3: ranks of predictive feature sets for w2v and osg models in the delayed post-test data. all models\n",
      "are significantly better than the baseline model. (bold: the selected model with highest overall rank.)\n",
      "features\n",
      "baseline\n",
      "rt\n",
      "dist\n",
      "resp\n",
      "chull\n",
      "dist+resp\n",
      "dist+chull\n",
      "\n",
      "auc\n",
      "0.65 [0.64, 0.67] (5)\n",
      "0.67 [0.65, 0.68] (3)\n",
      "0.66 [0.64, 0.68] (4)\n",
      "0.69 [0.67, 0.71] (1)\n",
      "na\n",
      "0.68 [0.66, 0.70] (2)\n",
      "na\n",
      "\n",
      "w2v models\n",
      "f1\n",
      "0.75 [0.74, 0.76] (5)\n",
      "0.76 [0.76, 0.77] (4)\n",
      "0.77 [0.76, 0.78] (3)\n",
      "0.77 [0.76, 0.78] (2)\n",
      "na\n",
      "0.78 [0.77, 0.79] (1)\n",
      "na\n",
      "\n",
      "err\n",
      "0.33 [0.32, 0.34] (5)\n",
      "0.31 [0.30, 0.32] (3)\n",
      "0.31 [0.30, 0.32] (4)\n",
      "0.30 [0.29, 0.31] (2)\n",
      "na\n",
      "0.30 [0.29, 0.31] (1)\n",
      "na\n",
      "\n",
      "performance of the newly trained model with the existing\n",
      "full-scale model.\n",
      "in table 4, we picked the top five scales that were\n",
      "important in individual prediction tasks. we found that bigsmall, helpful-harmful, complex-simple, and fast-slow were\n",
      "commonly important osgood scales for predicting students’\n",
      "performance in immediate post-test and delayed post-test\n",
      "sessions. scales like bad-good and passive-active were only\n",
      "important scales in the immediate post-test prediction.\n",
      "likewise, new-old was an important scale only in the delayed\n",
      "post-test prediction.\n",
      "table 4: scale-wise importance of each osgood\n",
      "scale. scales were selected based on the sum of each\n",
      "evaluation metric’s rank. (bold: osgood scales that\n",
      "were commonly important in both prediction tasks;\n",
      "*: top five scales in each prediction task including\n",
      "tied ranks)\n",
      "scales\n",
      "bad-good\n",
      "passive-active\n",
      "powerful-helpless\n",
      "big-small\n",
      "helpful-harmful\n",
      "complex-simple\n",
      "fast-slow\n",
      "noisy-quiet\n",
      "new-old\n",
      "healthy-sick\n",
      "\n",
      "4.2.2\n",
      "\n",
      "imm. post-test\n",
      "auc f1 err all\n",
      "1\n",
      "1\n",
      "1\n",
      "1*\n",
      "2\n",
      "4\n",
      "3\n",
      "2*\n",
      "7\n",
      "9\n",
      "6\n",
      "7.5\n",
      "3\n",
      "3\n",
      "4\n",
      "3*\n",
      "4\n",
      "6\n",
      "5\n",
      "5.5*\n",
      "8\n",
      "5\n",
      "2\n",
      "5.5*\n",
      "5\n",
      "2\n",
      "7\n",
      "4*\n",
      "6\n",
      "8\n",
      "8\n",
      "7.5\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "10\n",
      "10 10\n",
      "10\n",
      "\n",
      "del. post-test\n",
      "auc f1 err all\n",
      "4\n",
      "10 4\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "7\n",
      "10\n",
      "8\n",
      "10\n",
      "10\n",
      "1\n",
      "3\n",
      "2\n",
      "2*\n",
      "2\n",
      "1\n",
      "1\n",
      "1*\n",
      "3\n",
      "5\n",
      "7\n",
      "4.5*\n",
      "6\n",
      "4\n",
      "3\n",
      "3*\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "2\n",
      "8\n",
      "4.5*\n",
      "9\n",
      "7\n",
      "5\n",
      "8\n",
      "\n",
      "performance of reduced models\n",
      "\n",
      "based on the scale-wise importance analysis results, we built\n",
      "reduced-scale models that only contain features with more\n",
      "important osgood scales. the prediction performance of\n",
      "reduced-scale models was similar or marginally better than\n",
      "full-scale osg models. for example, the osg model for\n",
      "predicting the immediate post-test outcome with the top\n",
      "two scales (bad–good and passive–active) were marginally\n",
      "better than the full-scale model (auc: 0.71 [0.70, 0.72], f1 :\n",
      "0.76 [0.75, 0.77], error rate: 0.30 [0.29, 0.30]). similar results\n",
      "were observed for predicting retention in the delayed posttest (selected scales: helpful–harmful, big–small ) (auc: 0.71\n",
      "[0.69, 0.72], f1 : 0.79 [0.78, 0.80], error rate: 0.28 [0.27,\n",
      "\n",
      "auc\n",
      "0.65 [0.64, 0.67] (5)\n",
      "0.67 [0.65, 0.68] (3)\n",
      "0.66 [0.64, 0.68] (4)\n",
      "0.63 [0.61, 0.65] (7)\n",
      "0.69 [0.68, 0.71] (1)\n",
      "0.64 [0.62, 0.66] (6)\n",
      "0.69 [0.67, 0.71] (2)\n",
      "\n",
      "osg models\n",
      "f1\n",
      "0.75 [0.74, 0.76] (7)\n",
      "0.76 [0.76, 0.77] (5)\n",
      "0.78 [0.77, 0.79] (3)\n",
      "0.76 [0.75, 0.77] (6)\n",
      "0.78 [0.77, 0.79] (2)\n",
      "0.77 [0.76, 0.78] (4)\n",
      "0.78 [0.78, 0.79] (1)\n",
      "\n",
      "err\n",
      "0.33 [0.32, 0.34] (7)\n",
      "0.31 [0.30, 0.32] (5)\n",
      "0.30 [0.29, 0.31] (3)\n",
      "0.32 [0.31, 0.33] (6)\n",
      "0.28 [0.27, 0.29] (1)\n",
      "0.31 [0.29, 0.32] (4)\n",
      "0.29 [0.27, 0.30] (2)\n",
      "\n",
      "0.29]). although differences were small, the results indicate\n",
      "that using a small number of osgood scales can be similarly\n",
      "effective to the full-scale model.\n",
      "\n",
      "5.\n",
      "\n",
      "discussion and conclusions\n",
      "\n",
      "in this paper, we introduced a novel semantic similarity\n",
      "scoring method that uses predefined semantic scales to\n",
      "represent the relationship between words. by combining\n",
      "osgood’s semantic scales [16] and word2vec [13], we could\n",
      "automatically extract the semantic relationship between\n",
      "two words in a more interpretable manner. to show this\n",
      "method can effectively represent students’ knowledge in\n",
      "vocabulary acquisition, we built prediction models that can\n",
      "be used to predict the student’s immediate learning and\n",
      "long-term retention. we found that our models performed\n",
      "significantly better than the baseline and the responsetime-based models. in the future, we believe results from\n",
      "using an osgood scale-based student model could be used\n",
      "to provide a more personalized learning experience, such\n",
      "as generating questions that can improve an individual\n",
      "student’s understanding for specific semantic attributes.\n",
      "based on our findings, we have identified the following\n",
      "points for further discussion. first, in section 4.1, we\n",
      "found that models using osgood scale scores perform\n",
      "similarly with models using regular word2vec scores\n",
      "for predicting students’ long-term retention of acquired\n",
      "vocabulary. however, we think our models can be further\n",
      "improved by incorporating additional features. for example,\n",
      "non-semantic score-based features like response time and\n",
      "orthographic similarity among responses can be useful\n",
      "features for capturing different patterns of false predictions\n",
      "of current models. moreover, some general measures to\n",
      "capture a student’s meta-cognitive or linguistic skills could\n",
      "be helpful to explain different retention results found even if\n",
      "students provided the same response sequences. similarly, in\n",
      "section 4.1.3, we found that osgood scores can be a better\n",
      "metric to characterize the relationship between responses\n",
      "in terms of predicting students’ retention. a composite\n",
      "model that uses both regular word2vec score-based feature\n",
      "(target-response distance) and osgood scale score-based\n",
      "feature (response-response distance) may also provide better\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "86\n",
      "\n",
      "\f",
      "figure 3: roc curves and precision and recall curves for selected immediate post-test prediction models\n",
      "(left) and delayed post-test prediction models (right). curves are smoothed out with a local polynomial\n",
      "regression method based on repeated cross-validation results.\n",
      "\n",
      "prediction performance.\n",
      "second, we found that models with a reduced number of\n",
      "osgood scales performed marginally better than the fullscale model. however, differences were very small. since\n",
      "this study only used some of the semantic scales from\n",
      "osgood’s study [16], further investigation would be required\n",
      "to examine the validity of these scales, including other scales\n",
      "not used for this study, for capturing the semantic attributes\n",
      "of student responses during vocabulary learning.\n",
      "also, there were some limitations in the current study\n",
      "and areas for future work. first, expanding the scope\n",
      "of analysis to the full set of experimental conditions\n",
      "used in the study may reveal more complex interactions\n",
      "between these conditions and students’ short- and longterm learning. second, this study used a fixed threshold\n",
      "of 0.5 for investigating false prediction results. however, an\n",
      "optimal threshold for each participant group or prediction\n",
      "model could be selected, especially if there are different false\n",
      "positive or negative patterns observed for different groups\n",
      "of students. lastly, this study collected data from a single\n",
      "vocabulary tutoring system that was used in a classroom\n",
      "setting. applying the proposed method to data that was\n",
      "collected from a non-classroom setting or other vocabulary\n",
      "learning system would be useful to show the generalization\n",
      "of our suggested method.\n",
      "\n",
      "6.\n",
      "\n",
      "acknowledgments\n",
      "\n",
      "the research reported here was supported by the institute of\n",
      "education sciences, u.s. department of education, through\n",
      "grant r305a140647 to the university of michigan. the\n",
      "opinions expressed are those of the authors and do not\n",
      "represent views of the institute or the u.s. department\n",
      "of education. we thank dr. charles perfetti and his lab\n",
      "team at the university of pittsburgh, particularly adeetee\n",
      "bhide and kim muth, and the helpful personnel at all of our\n",
      "partner schools.\n",
      "\n",
      "7.\n",
      "\n",
      "references\n",
      "\n",
      "[1] s. adlof, g. frishkoff, j. dandy, and c. perfetti. effects of\n",
      "induced orthographic and semantic knowledge on\n",
      "subsequent learning: a test of the partial knowledge\n",
      "hypothesis. reading and writing, 29(3):475–500, 2016.\n",
      "[2] j. e. beck. engagement tracing: using response times to\n",
      "model student disengagement. artificial intelligence in\n",
      "education: supporting learning through intelligent and\n",
      "socially informed technology, 125:88, 2005.\n",
      "[3] k. collins-thompson and j. callan. automatic and human\n",
      "scoring of word definition responses. in hlt-naacl,\n",
      "pages 476–483, 2007.\n",
      "[4] m. coltheart. the mrc psycholinguistic database. the\n",
      "\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "\n",
      "[8]\n",
      "\n",
      "[9]\n",
      "\n",
      "[10]\n",
      "[11]\n",
      "\n",
      "[12]\n",
      "[13]\n",
      "\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "\n",
      "[18]\n",
      "[19]\n",
      "\n",
      "[20]\n",
      "\n",
      "quarterly journal of experimental psychology,\n",
      "33(4):497–505, 1981.\n",
      "e. dale. vocabulary measurement: techniques and major\n",
      "findings. elementary english, 42(8):895–948, 1965.\n",
      "f. t. durso and w. j. shore. partial knowledge of word\n",
      "meanings. journal of experimental psychology: general,\n",
      "120(2):190, 1991.\n",
      "g. a. frishkoff, k. collins-thompson, l. hodges, and\n",
      "s. crossley. accuracy feedback improves word learning\n",
      "from context: evidence from a meaning-generation task.\n",
      "reading and writing, 29(4):609–632, 2016.\n",
      "g. a. frishkoff, k. collins-thompson, s. nam, l. hodges,\n",
      "and s. a. crossley. dynamic support of contextual\n",
      "vocabulary acquisition for reading (dscovar): an\n",
      "intelligent tutoring system for contextual word learning.\n",
      "handbook on educational technologies for literacy, 2016.\n",
      "g. a. frishkoff, c. a. perfetti, and k. collins-thompson.\n",
      "predicting robust vocabulary growth from measures of\n",
      "incremental learning. scientific studies of reading,\n",
      "15(1):71–91, 2011.\n",
      "t. k. landauer. latent semantic analysis. wiley online\n",
      "library, 2006.\n",
      "y. li, l. xu, f. tian, l. jiang, x. zhong, and e. chen.\n",
      "word embedding revisited: a new representation learning\n",
      "and explicit matrix factorization perspective. in\n",
      "proceedings of the 24th international joint conference on\n",
      "artificial intelligence, buenos aires, argentina, pages\n",
      "3650–3656, 2015.\n",
      "y. ma, l. agnihotri, m. h. education, r. baker, and\n",
      "s. mojarad. effect of student ability and question difficulty\n",
      "on duration. in educational data mining, 2016.\n",
      "t. mikolov, i. sutskever, k. chen, g. s. corrado, and\n",
      "j. dean. distributed representations of words and phrases\n",
      "and their compositionality. in advances in neural\n",
      "information processing systems, pages 3111–3119, 2013.\n",
      "g. a. miller. wordnet: a lexical database for english.\n",
      "communications of the acm, 38(11):39–41, 1995.\n",
      "s. nam. predicting off-task behaviors in an adaptive\n",
      "vocabulary learning system. in educational data mining,\n",
      "2016.\n",
      "c. e. osgood, g. j. suci, and p. h. tannenbaum. the\n",
      "measurement of meaning. university of illinois press, 1957.\n",
      "k. ostrow, c. donnelly, s. adjei, and n. heffernan.\n",
      "improving student modeling through partial credit and\n",
      "problem difficulty. in proc. of the second acm conference\n",
      "on learning@scale, pages 11–20. acm, 2015.\n",
      "p. i. pavlik and j. r. anderson. practice and forgetting\n",
      "effects on vocabulary memory: an activation-based model\n",
      "of the spacing effect. cog. science, 29(4):559–586, 2005.\n",
      "e. g. van inwegen, s. a. adjei, y. wang, and n. t.\n",
      "heffernan. using partial credit and response history to\n",
      "model user knowledge. international educational data\n",
      "mining society, 2015.\n",
      "l. m. yonek. the effects of rich vocabulary instruction\n",
      "on students’ expository writing. phd thesis, university of\n",
      "pittsburgh, 2008.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "87\n",
      "\n",
      "\f",
      "generalizability of face-based mind wandering detection\n",
      "across task contexts\n",
      "angela stewart\n",
      "\n",
      "nigel bosch\n",
      "\n",
      "sidney k. d’mello\n",
      "\n",
      "university of notre dame\n",
      "384 fitzpatrick hall\n",
      "notre dame, in, 46556, usa\n",
      "\n",
      "university of illinois at urbanachampaign\n",
      "1205 west clark street\n",
      "urbana, il, 61801, usa\n",
      "\n",
      "university of notre dame\n",
      "118 haggar hall\n",
      "notre dame, in, 46556\n",
      "\n",
      "astewa12@nd.edu\n",
      "\n",
      "sdmello@nd.edu\n",
      "\n",
      "pnb@illinois.edu\n",
      "abstract\n",
      "we investigate generalizability of face-based detectors of mind\n",
      "wandering across task contexts. we leveraged data from two lab\n",
      "studies: one where 152 college students read a scientific text and\n",
      "another where 109 college students watched a narrative film. we\n",
      "automatically extracted facial expressions and body motion\n",
      "features, which were used to train supervised machine learning\n",
      "models on each dataset, as well as a concatenated dataset. we\n",
      "applied models from each task context (scientific text or narrative\n",
      "film) to the alternate context to study generalizability. we found\n",
      "that models trained on the narrative film dataset generalized to the\n",
      "scientific text dataset with no modifications, but the predicted mind\n",
      "wandering rate needed to be adjusted before models trained on the\n",
      "scientific text dataset would generalize to the narrative film dataset.\n",
      "additionally, we analyzed generalizability of individual features\n",
      "and found that the lip tightener and jaw drop action units had the\n",
      "greatest potential to generalize across task contexts. we discuss\n",
      "findings and applications of our work to attention-aware learning\n",
      "technologies.\n",
      "\n",
      "keywords\n",
      "mind wandering, mental states, attention aware interfaces,\n",
      "cross-corpus training.\n",
      "\n",
      "1. introduction\n",
      "consider a typical day when you were an undergraduate college\n",
      "student. your first class is your favorite, so you are engaged in the\n",
      "lecture content and processing new information. in your next class,\n",
      "you watch a documentary about a subject that does not interest you,\n",
      "causing your attention to focus on unrelated thoughts of your social\n",
      "life, rather than processing the information in the video. later, you\n",
      "work on a homework assignment that you find frustrating, leading\n",
      "to waning motivation. towards the end of your day, you attend a\n",
      "chemistry lab, where you interact with a new educational game that\n",
      "teaches you the basics of chemical bonds. at some points you are\n",
      "enjoying the game, and thus engaged in deeply learning the content.\n",
      "however, you later become bored during a long period of repetitive\n",
      "gameplay, causing you to become distracted and miss important\n",
      "information. throughout the day, your mental states (engagement,\n",
      "frustration, boredom) influenced your learning. your learning\n",
      "\n",
      "experience could have been augmented with technology that\n",
      "responded to your changing mental state, thus assisting you in\n",
      "achieving the most effective learning experience.\n",
      "educational interfaces that detect and respond to student mental\n",
      "states are driven by work on cognitive and affective state modeling,\n",
      "which has been investigated for many years. for example, attention\n",
      "and affect has been modeled in educational tasks such as reading\n",
      "comprehension [6, 16, 28] and computerized tutoring [3, 19],\n",
      "among others. in general, there has been a plethora of work that has\n",
      "modeled a variety of mental states within specific educational tasks\n",
      "(e.g., [2, 15, 19]) to better understand these states and use that\n",
      "knowledge to facilitate student learning.\n",
      "however, prior research has overwhelmingly investigated single\n",
      "task contexts, and has overlooked generalizability to different\n",
      "contexts. for example, models that track attention during reading\n",
      "might not generalize to lecture viewing, educational gaming, and\n",
      "so on. this makes it difficult to decouple task-specific effects from\n",
      "more fundamental patterns. in contrast, models that successfully\n",
      "generalize across multiple contexts should reveal observable\n",
      "signals (i.e. eye gaze, facial features, and physiology data) that are\n",
      "general, rather than task-specific. models using such indicators will\n",
      "be key to developing adaptive technologies that are sensitive to\n",
      "student mental states and that can operate across a range of\n",
      "educational activities.\n",
      "we report results on modeling mental states in a generalized way\n",
      "using mind wandering (mw) as a case study. mw is a ubiquitous\n",
      "phenomenon where thoughts shift from task-related processing to\n",
      "task-unrelated thoughts [15]. mw is estimated to occur anywhere\n",
      "from 20% - 50% of the time, depending on the person, task, and\n",
      "environmental context [23]. it is has also been associated with\n",
      "lower performance on a variety of educational tasks, such as\n",
      "reading comprehension [16] and retention of lecture content [29],\n",
      "thus impacting student learning.\n",
      "as with work on other mental states, research on mw has largely\n",
      "failed to address models that generalize across contexts [6, 15].\n",
      "mw detection has been investigated in reading comprehension [6,\n",
      "16], narrative and instructional film comprehension [25, 26], and\n",
      "student interaction with an intelligent tutoring system (its) [19].\n",
      "to our knowledge, no work has investigated mw detection with\n",
      "the goal of generalizability across task contexts.\n",
      "we specifically investigate the generalizability of mw models\n",
      "across two task contexts - reading a scientific text and viewing a\n",
      "narrative film. these contexts were chosen because of their broad\n",
      "applicability to education in the classroom and online. for example,\n",
      "a documentary film could be shown in a sociology course or\n",
      "distance learning students could read instructional texts prior to\n",
      "engaging in an online discussion.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "88\n",
      "\n",
      "\f",
      "1.1 related work\n",
      "cross corpus training has been researched in a variety of\n",
      "classification problems, such as sentiment analysis [31] and\n",
      "acoustic-based emotion recognition [35]. cross corpus training\n",
      "seeks to improve robustness of machine-learned models by\n",
      "leveraging multiple datasets in classifier training and testing. for\n",
      "example, webb and ferguson [32] applied cross corpus training\n",
      "techniques to characterize the function of segments of dialogue\n",
      "using automatically extracted lexical and syntactic features called\n",
      "cue phrases. each extracted cue phrase was used to classify a\n",
      "segment of dialogue. they trained separate classifiers on two\n",
      "different datasets, and applied the classifier to the dataset on which\n",
      "it was not trained. they found the cross-training results were\n",
      "comparable to the results of training and testing on the same dataset\n",
      "(e.g. the best cross-trained classifier achieved and accuracy of 71%,\n",
      "compared to an accuracy of 81% when trained and tested on the\n",
      "same dataset). additionally, they examined generalizability of the\n",
      "cue phrases across datasets by reducing the feature set to contain\n",
      "only cues present in both datasets. they found that reducing the\n",
      "feature set yielded slight improvements, and demonstrated the\n",
      "discriminative nature of a small number of features.\n",
      "zhang et. al. [35] similarly explored the use of multiple datasets for\n",
      "creating context-generalizable models. they built classifiers for\n",
      "valence and arousal on highly varied emotional speech datasets\n",
      "using a leave-one-corpora-out cross-validation technique.\n",
      "additionally, they explored methods for data normalization (within\n",
      "each dataset and between datasets) and agglomeration of both\n",
      "labeled and unlabeled data. they found that, of their six emotional\n",
      "speech corpora, training on some subsets yielded higher accuracy\n",
      "than others. their work suggested that careful selection of corpora\n",
      "best suited for training might yield better emotional speech\n",
      "recognition performance than an all-or-nothing approach to crosscorpus training.\n",
      "our work approaches cross-corpus modeling through detection of\n",
      "mw. a variety of studies have investigated mw detection during\n",
      "educational tasks, such a reading [15], interacting with an\n",
      "intelligent tutoring system (its) [19], or watching an educational\n",
      "video [26]. no work has focused on mw from a cross-corpus\n",
      "modeling perspective, to our knowledge, so we review the\n",
      "individual studies below.\n",
      "detection of mw from eye gaze features while reading has been\n",
      "amply investigated. for example, bixler and d’mello [4] built\n",
      "models to detect mw while students read texts about scientific\n",
      "research methods. this work made use of probe-caught reports\n",
      "(students respond yes or no to auditory thought probes of whether\n",
      "they were mw), instead of self-caught reports (students report\n",
      "whenever they catch themselves mw). their analysis of eye gaze\n",
      "features showed that certain types of fixations were longer during\n",
      "mw. specifically, they found that longer gaze fixations\n",
      "(consecutive fixations on a single word), first-pass fixations\n",
      "(fixations on a word during the first pass through a text), and single\n",
      "fixations (fixations on a word only fixated on once) were predictive\n",
      "of mw. in other work, bixler and d’mello [5] similarly used eye\n",
      "gaze features, but used self-caught reports of mw. they found that\n",
      "a greater number of fixations, longer saccade length, and line cross\n",
      "saccades were indicative of mw. across studies on mw detection\n",
      "during reading, longer fixations were found to be indicative of mw\n",
      "[4, 15, 28], suggesting these features might generalize well.\n",
      "\n",
      "monitoring fingertip blood flow, using the back camera of a\n",
      "smartphone (i.e., photoplethysmography). their models achieved a\n",
      "22% improvement over chance. although their method for\n",
      "detecting mw could be implemented across a variety of tasks, the\n",
      "question of whether heart rate is indicative of mw across task\n",
      "contexts has not yet been investigated.\n",
      "hutt et. al. provided limited evidence of generalizability of mw\n",
      "detection across different learning tasks during student interaction\n",
      "with an its [19]. they employed a genetic algorithm to train a\n",
      "neural network using context-independent eye-gaze features and\n",
      "context-dependent interaction features (e.g., current progress\n",
      "within the its). they achieved an f1 value of .490 (chance = .190).\n",
      "this work provided some evidence of generalizability because the\n",
      "visual stimuli and interaction patterns varied throughout. for\n",
      "example, students interacted with an animated pedagogical agent in\n",
      "a scaffolded dialogue phase and completed concept maps without\n",
      "the tutoring agent in another interaction phase. however, it is still\n",
      "unclear if their model would generalize to a broader range of tasks,\n",
      "particularly less interactive ones like reading or film viewing.\n",
      "furthermore, their best-performing models used context-dependent\n",
      "features, which could prevent the detector from generalizing to a\n",
      "task where those features could not be used.\n",
      "\n",
      "1.2 novelty\n",
      "our contribution is novel in a variety of ways. first, we demonstrate\n",
      "the feasibility of building cross-context detectors of mental states,\n",
      "specifically mw. further, previous work on mw detection has\n",
      "sometimes made use of context-specific features (e.g., reading\n",
      "times) that are not expected to generalize to other contexts [19, 25].\n",
      "in contrast, our work detects mw using only facial features and\n",
      "upper body movement, recorded using commercial-off-the-shelf\n",
      "(cots) webcams that are expected to generalize more broadly.\n",
      "additionally, the use of cots webcams support a broader\n",
      "implementation of mw detectors as webcams are ubiquitous in\n",
      "modern technology. this is in contrast to prior research that has\n",
      "used specialized equipment, like eye trackers [15, 19, 25] or\n",
      "physiology sensors [7], which students would likely not have\n",
      "access to.\n",
      "\n",
      "2. datasets\n",
      "this study makes use of narrative film [23] and scientific reading\n",
      "comprehension [22] datasets collected as part of a larger project.\n",
      "here, we include details pertaining to video-based detection of\n",
      "mw.\n",
      "\n",
      "2.1 narrative film comprehension\n",
      "participants were 68 undergraduate students from a medium-sized\n",
      "private midwestern university and 41 undergraduate students from\n",
      "a large public university in the southern united states. of the 109\n",
      "students, 66% were female and their average age was 20.1 years.\n",
      "students were compensated with course credit. data from four\n",
      "students were discarded due to equipment failure.\n",
      "students viewed the narrative film the red balloon (1956), a 32.5minute french-language film with english subtitles (figure 1). the\n",
      "film has a musical score but only sparse dialogue. this short fantasy\n",
      "film depicts the story of a young parisian boy who finds a red\n",
      "helium balloon and quickly discovers it has a mind of its own as it\n",
      "follows him wherever he goes. this film was selected because of\n",
      "the low likelihood that participants have previously seen it and\n",
      "because it has been used in other film comprehension studies [34].\n",
      "\n",
      "pham and wang [26] similarly used consumer-grade equipment to\n",
      "detect mw while students watched videos from massively open\n",
      "online courses (moocs). they made use of heart rate, detected by\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "89\n",
      "\n",
      "\f",
      "figure 1. a screenshot of the narrative film (left) and scientific text (right) are shown.\n",
      "students’ faces and upper bodies were recorded with a low-cost\n",
      "($30) consumer-grade webcam (logitech c270).\n",
      "students were instructed to report mw throughout the film by\n",
      "pressing labeled keys on the keyboard. specifically, students were\n",
      "asked to report a task-unrelated thought if they were “thinking\n",
      "about anything else besides the movie” and a task-related\n",
      "interference if they were “thinking about the task itself but not the\n",
      "actual content of the movie.” a small beep sounded to register their\n",
      "report, but film play was not paused. after viewing the film,\n",
      "students took a short test about the content and completed\n",
      "additional measures not discussed further.\n",
      "we recorded a total of 1,368 mw reports from the 105 participants\n",
      "with valid video recordings. in this work, we do not distinguish\n",
      "between the two types of mw, instead merging the task-unrelated\n",
      "thoughts and the task-related interferences, both of which represent\n",
      "thoughts independent of the content of the film.\n",
      "\n",
      "2.2 scientific reading comprehension\n",
      "participants were 104 undergraduate students from a medium-sized\n",
      "private midwestern university and 48 undergraduate students from\n",
      "a large public university in the southern united states. of the 152\n",
      "participants, 61% were female and their average age was 20.1\n",
      "years. participants were compensated with course credit. data from\n",
      "eight participants were discarded due to equipment failure.\n",
      "students read an excerpt from soap-bubbles and the forces which\n",
      "mould them [8]. like the red balloon (figure 1), we chose this\n",
      "text because its content would likely be unfamiliar to a majority of\n",
      "readers. the text contained around 6,500 words from the first\n",
      "chapter of the book. in all, 57 pages (screens of text) with an\n",
      "average of 115 words each were displayed on a computer screen in\n",
      "36-pt courier new typeface. the only modification to the text was\n",
      "the removal of images and references to them after verifying that\n",
      "these were not needed for comprehension.\n",
      "students who read the scientific text were instructed to report mw\n",
      "in the same way as those who watched the narrative film. they were\n",
      "instructed to report a task-unrelated thought if they were “thinking\n",
      "about anything else besides the task” and a task-related interference\n",
      "if they were “thinking about the task itself but not the actual content\n",
      "of the text.” participants completed a comprehension assessment\n",
      "after reading the text. we recorded a total of 3,168 mw reports\n",
      "from the 144 students with valid video recordings.\n",
      "\n",
      "2.3 self reports of mw\n",
      "mw was measured via self-reports in both studies, so it is prudent\n",
      "to discuss the validity of self-reports. we used self-reports because\n",
      "\n",
      "this is currently the most common approach to measure an\n",
      "inherently internal (but conscious) phenomenon [5, 15]. selfreported mw has been linked to predictable patterns in physiology\n",
      "[30], pupillometry [17], eye-gaze [28] and task performance [27],\n",
      "providing evidence for the convergent and predictive validity for\n",
      "this approach. to improve the quality of self-reports, we\n",
      "encouraged students to report honestly and assured them that\n",
      "reporting mw would not in any way effect the credit they received\n",
      "for participation.\n",
      "the alternative to using self-caught reports is using probe-caught\n",
      "reports, which require a student response to a thought-probe (e.g.,\n",
      "a beep). we chose self-caught reports over the probe-caught\n",
      "because the probe-caught method can potentially interrupt the\n",
      "comprehension process (i.e., when participants report “no” to the\n",
      "probes). interruptions are particularly problematic in the film\n",
      "comprehension task, as participants did not have control over the\n",
      "media presentation (i.e., no pausing or rewinding of the film).\n",
      "furthermore, it is also unclear if a probe-caught report takes place\n",
      "at the beginning or end of mw, or somewhere in between.\n",
      "conversely, self-caught reports are likely to occur at the end of a\n",
      "mw episode when the student became aware that they were not\n",
      "attending to the task at hand.\n",
      "\n",
      "3. machine learning\n",
      "we explored a variety of machine learning techniques for crosscontext mw detection using the same approach to segmenting\n",
      "instances and constructing features for both datasets.\n",
      "\n",
      "3.1 segmenting instances\n",
      "reports of mw were distributed throughout the course of the film\n",
      "viewing or text reading session. we created instances that\n",
      "corresponded to reports of mw by first adding a 4-second offset\n",
      "prior to the report. this was done to ensure that we captured\n",
      "participants’ faces while mw vs. in the act of reporting mw itself\n",
      "(i.e., the preparation and execution of the key press). this 4-second\n",
      "offset was chosen based on four raters judgements of whether or\n",
      "not movement related to the key-press could be seen within offsets\n",
      "ranging from 0 to 6 seconds. data was then extracted from the 20\n",
      "seconds prior to the mw report. a window size of 20 seconds was\n",
      "chosen based on prior experimentation that sought to balance\n",
      "creating as many instances as possible (shorter window sizes) and\n",
      "having sufficient data in each window (longer window sizes) to\n",
      "detect mw.\n",
      "we extracted “not mw” instances from windows of data between\n",
      "mw reports. the entire session (reading or video watching) was\n",
      "divided into 24-second segments (20 second windows of data and\n",
      "a 4 second offset as with the mw segments). any segments\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "90\n",
      "\n",
      "\f",
      "overlapping the 30 seconds prior to a mw report were discarded.\n",
      "we do not know precisely when mw starts, so we chose to discard\n",
      "instances overlapping the 30 seconds prior to mw reports, to\n",
      "separate students when they were actually mw from when they\n",
      "were not. we also discarded any segments overlapping a page turn\n",
      "(discussed in section 3.2). all remaining segments were labeled\n",
      "not mw. our approach to segmenting instances is shown in figure\n",
      "2.\n",
      "\n",
      "table 1. an accounting of instance selection process\n",
      "\n",
      "base\n",
      "\n",
      "reading\n",
      "(% mw)\n",
      "7,267 (30%)\n",
      "\n",
      "film\n",
      "(% mw)\n",
      "7,313 (14%)\n",
      "\n",
      "face detected\n",
      "\n",
      "7,266 (30%)\n",
      "\n",
      "7,238 (14%)\n",
      "\n",
      "page boundary\n",
      "\n",
      "1,400 (36%)\n",
      "\n",
      "n/a\n",
      "\n",
      "participant matching\n",
      "\n",
      "1,273 (35%)\n",
      "\n",
      "n/a\n",
      "\n",
      "downsampling\n",
      "\n",
      "1,100 (25%)\n",
      "\n",
      "1,100 (25%)\n",
      "\n",
      "3.3 feature extraction and selection\n",
      "\n",
      "figure 2. illustration of the instance extraction method.\n",
      "\n",
      "3.2 instance selection\n",
      "a full accounting of the instance selection process is shown in\n",
      "table 1. our goal was to make the two data sets as similar as\n",
      "possible so that task-specific effects could be studied without\n",
      "additional confounds.\n",
      "we first discarded any instances where there was less than one\n",
      "second of usable data in that time window. data was not usable\n",
      "when the student’s face was occluded due to extreme head pose or\n",
      "position, hand-to-face gestures, and rapid movements.\n",
      "additionally, for the scientific reading dataset, we discarded\n",
      "instances that overlapped with page turn events. in prior\n",
      "experimentation, we trained a model to detect mw using only a\n",
      "binary feature of whether or not that instance overlapped a page\n",
      "turn boundary. mw was detected at rates above chance in this\n",
      "experimental model. therefore, we concluded that including\n",
      "instances that overlapped page turn boundaries would inflate\n",
      "performance as the detector could simply be picking up on the act\n",
      "of pressing the key to advance to the next page.\n",
      "\n",
      "we used commercial software, the emotient sdk [36] to extract\n",
      "facial features. the emotient sdk, a version of the cert\n",
      "computer vision software [24] (figure 3) provides likelihood\n",
      "estimates of the presence of 20 facial action units (aus; specifically\n",
      "1, 2, 4, 5, 6 ,7, 9, 10, 12, 14, 15, 17, 18, 20, 23, 24, 25, 26, 28, and\n",
      "43 [14]) as well as head pose (orientation), face position (horizontal\n",
      "and vertical within the frame), and face size (a proxy for distance\n",
      "to camera). additionally, we used a validated motion estimation\n",
      "algorithm to compute gross body movements [33]. body movement\n",
      "was calculated by measuring the proportion of pixels in each video\n",
      "frame that differed by a threshold from a continuously updated\n",
      "estimate of the background image generated from the four previous\n",
      "frames.\n",
      "\n",
      "figure 3. interface demonstrating au estimates detected from\n",
      "a face video.\n",
      "\n",
      "after discarding instances using the method above, we matched the\n",
      "scientific reading and narrative film datasets on school (mediumsized midwestern private university or large southern public\n",
      "university), reported ethnicity, and reported gender. the scientific\n",
      "reading dataset was randomly downsampled to contain\n",
      "approximately the same number of students in each gender, race, or\n",
      "school category, as the film dataset. this participant-level matching\n",
      "on school, ethnicity, and gender was done to eliminate external\n",
      "sources of variance that could influence mw detection, potentially\n",
      "obfuscating task effects from population effects.\n",
      "\n",
      "features were created by aggregating emotient estimates in a\n",
      "window of time leading up to each mw or not mw instance using\n",
      "minimum, maximum, median, mean, range, and standard deviation\n",
      "for aggregation. in all, there were 162 facial features (6 aggregation\n",
      "functions × [20 aus + 3 head pose orientation axes + 2 face\n",
      "position coordinates + face size + motion]). outliers (values greater\n",
      "than three standard deviations from the mean) were replaced by the\n",
      "closest non-outlier value in a process called winsorization [11].\n",
      "\n",
      "finally, the datasets were downsampled to contain equal numbers\n",
      "of instances because the size of the training set is known to bias\n",
      "classifier performance [13]. we also downsampled the data to\n",
      "achieve a 25% mw rate in order to be consistent with research that\n",
      "suggests that mw occurs between 20% and 30% of the time during\n",
      "reading and film comprehension [6, 23]. further, the mw rates of\n",
      "30% and 14% obtained in these data are more artefacts of the\n",
      "instance segmentation approach rather than the objective rate, so\n",
      "resampling ensures a dataset that is more reflective of expected\n",
      "mw rates.\n",
      "\n",
      "we used tolerance analysis to eliminate features with high\n",
      "multicollinearity (variance inflation factor > 5) [1], after which, 37\n",
      "features remained. this was followed by relief-f [21] feature\n",
      "selection (on the training data only) to rank features. we retained a\n",
      "proportion of the highest ranked features for use in the models\n",
      "(proportions ranging from .05 to 1.0 were tested). feature selection\n",
      "was performed using nested cross-validation on training data only.\n",
      "we ran 5 iterations of feature selection within each cross-validation\n",
      "fold (discussed below), using data from a randomly chosen 67% of\n",
      "students within the training set in each iteration.\n",
      "\n",
      "3.4 supervised classification and validation\n",
      "informed by preliminary experiments, we selected seven classifiers\n",
      "for more extensive tests (naïve bayes, simple logistic regression,\n",
      "logitboost, random forest, c4.5, stochastic gradient descent,\n",
      "and classification via regression) using the weka data mining\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "91\n",
      "\n",
      "\f",
      "toolkit [18]. for each classifier, we applied smote [9] to the\n",
      "training set only. smote, a common machine learning technique\n",
      "for dealing with data imbalance, creates synthetic interpolated\n",
      "instances of the minority class to increase classification\n",
      "performance.\n",
      "we evaluated the performance of our classifiers using leave-oneparticipant-out cross-validation. this process runs multiple\n",
      "iterations of each classifier in which, for each fold, the instances\n",
      "pertaining to a single participant are added to the test set and the\n",
      "training set is comprised of the instances for the other participants.\n",
      "feature selection was performed on a subset of participants in the\n",
      "training set. the leave-one-out process was repeated for each\n",
      "participant, and the classifications of all folds were weighted\n",
      "equally to produce the overall result. this cross-validation\n",
      "approach ensured that in each fold, data from the same participant\n",
      "was in the training set or testing set but never both, thereby\n",
      "improving generalization to new participants.\n",
      "accuracy (recognition rate) is a common measure to evaluate\n",
      "performance in machine learning tasks. however, any classifier\n",
      "that defaults to predicting the majority class label of an imbalanced\n",
      "dataset can appear to have high accuracy despite incorrect\n",
      "predictions of all instances of the minority class label [20]. this is\n",
      "particularly detrimental in applications where detecting the\n",
      "minority class is of upmost importance. in our task, we prioritized\n",
      "the detection of mw despite the large imbalance in our dataset.\n",
      "therefore, we considered the f1 score for the mw label as our key\n",
      "measure of detection accuracy since f1 attempts to strike a balance\n",
      "between precision and recall.\n",
      "\n",
      "4. results\n",
      "4.1 cross-dataset training and testing\n",
      "we trained three classifiers: one on the scientific text dataset, one\n",
      "on the narrative film dataset, and one on a concatenated dataset\n",
      "comprised of the first two. for each of the three training sets, the\n",
      "classifier that yielded the highest mw f1 is shown in table 2. we\n",
      "used leave-one-student-out cross validation for within-dataset\n",
      "evaluations. conversely, to measure generalizability of the models\n",
      "across contexts we applied the classifier trained on scientific text\n",
      "data to the narrative film data, and vice versa. we compared our\n",
      "model to a chance model that classified a random 25% (mw prior\n",
      "proportion) of the instances as mw. this chance-level method\n",
      "yielded a precision and recall of .250 (equal to the mw base rate).\n",
      "table 2. results for the models with highest mw f1 for the\n",
      "within-data set validation (cross-training results in\n",
      "parentheses).\n",
      "training set\n",
      "\n",
      "classifier mw f1\n",
      "\n",
      "precision\n",
      "\n",
      "recall\n",
      "\n",
      "scientific text logitboost .441 (.267) .376 (.252)\n",
      "\n",
      ".553 (.284)\n",
      "\n",
      "narrative film c4.5\n",
      "\n",
      ".436 (.407) .303 (.278)\n",
      "\n",
      ".775 (.760)\n",
      "\n",
      "both\n",
      "\n",
      ".424\n",
      "\n",
      ".655\n",
      "\n",
      "logistic\n",
      "\n",
      ".314\n",
      "\n",
      "we calculated improvement over chance as (actual performance –\n",
      "chance)/(perfect performance – chance). all three models showed\n",
      "improvement over chance (25% for scientific text, 25% for\n",
      "narrative film, and 23% for the concatenated dataset) when trained\n",
      "and tested on the same dataset. when tested on the alternative\n",
      "dataset, the narrative film classifier generalized well to the\n",
      "scientific text dataset (21% improvement over chance). however,\n",
      "the scientific text model showed chance-level performance on the\n",
      "narrative film corpus (2% improvement over chance). the mw f1\n",
      "\n",
      "of the concatenated dataset model was simply an average of the\n",
      "mw f1 score of the individual datasets when the instance\n",
      "predictions of the individual datasets are separated (.413 for the\n",
      "scientific reading dataset and .436 on the narrative film dataset).\n",
      "these results showed that the concatenated classifier does not skew\n",
      "towards predicting one dataset better than the other, but rather\n",
      "predicts both models with comparable accuracy.\n",
      "table 2 also shows precision and recall for each of the models.\n",
      "across all models, recall was higher than precision, indicating a lot\n",
      "false positives. it is important to note the near chance-level recall\n",
      "and precision of the model trained on scientific reading data when\n",
      "applied to the narrative film data. the lack of improvement over\n",
      "chance for both recall and precision demonstrated the need to\n",
      "improve generalizability in both dimensions. conversely, the crosstrained narrative film model had lower precision, but good recall,\n",
      "resulting in an improved mw f1 score.\n",
      "\n",
      "4.2 classifier generalizability\n",
      "to address the negligible improvement over chance of the scientific\n",
      "text model when tested on the narrative film dataset, we repeated\n",
      "the training and testing using c4.5 as the classifier. the c4.5\n",
      "classifier was chosen because it generalized better when trained on\n",
      "the narrative film dataset than the logitboost classifier generalized\n",
      "when trained on the scientific text dataset. the results are shown in\n",
      "table 3, where we note no notable improvement over the previous\n",
      "logitboost classifier in table 2 (change from .267 to .287 when\n",
      "tested on the narrative film dataset). therefore, the lack of evidence\n",
      "for generalizability for the scientific text model could be due to\n",
      "overfitting to the training set, rather than classifier selection.\n",
      "table 3. results (mw f1) for the c4.5 classifier for withinand cross- validation.\n",
      "training set\n",
      "\n",
      "within\n",
      "\n",
      "cross\n",
      "\n",
      "scientific text\n",
      "\n",
      "0.425\n",
      "\n",
      "0.287\n",
      "\n",
      "narrative film\n",
      "\n",
      "0.436\n",
      "\n",
      "0.407\n",
      "\n",
      "both\n",
      "\n",
      "0.415\n",
      "\n",
      "n/a\n",
      "\n",
      "4.3 prediction threshold adjustment\n",
      "we further investigated the lack of generalizability of the scientific\n",
      "text model by considering the mw prediction rate. we compared\n",
      "the performance of both models on the narrative film dataset. recall\n",
      "dropped considerably more than precision (table 2; recall dropped\n",
      "from .775 to .284; precision decreased from .303 to .252). we\n",
      "hypothesized that recall decreased because of a difference in\n",
      "predicted mw rates (table 4). in fact, the predicted mw rate in the\n",
      "narrative film data dropped from 64% to 28% when applying the\n",
      "scientific text model to the same data. this supported our\n",
      "hypothesis that the low recall was linked to lower predicted mw\n",
      "rates. furthermore, 39% of the correctly classified instances (true\n",
      "positives and true negatives) were mw when applying the narrative\n",
      "film model to the narrative film data compared to 12% for the\n",
      "scientific text model applied to the same data. this demonstrated\n",
      "that the scientific text model was much more prone to missing mw\n",
      "instances, further supporting our hypothesis.\n",
      "to address this, we adjusted the predicted mw rate of the scientific\n",
      "text model when applied to the narrative film dataset. the classifier\n",
      "outputs a likelihood of mw and we previously considered instances\n",
      "with likelihoods greater than .5 as mw. we adjusted that prediction\n",
      "threshold from .1 to 1 in increments of .1 (figure 4) to investigate\n",
      "how changes in predicted mw rate (higher for lower thresholds)\n",
      "effected recall, and thus mw f1.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "92\n",
      "\n",
      "\f",
      "to rank the subsets of features on generalizability, we examined\n",
      "mw f1 scores when testing on the alternative dataset only. for\n",
      "example, using the au9 (nose wrinkle) subset, we investigated\n",
      "mw f1 value of scientific text model applied to the narrative film\n",
      "dataset and the narrative film model applied to the scientific text\n",
      "dataset. table 4 shows these results only for features that achieved\n",
      "a mw f1 of greater than .250 (chance) on all dimensions (within\n",
      "dataset validation and cross-training). we selected features for\n",
      "further analysis if their mw f1 was greater than .300 for both crosstraining results. this value of .300 was used to filter out features\n",
      "that performed well on the within-dataset validation, but fell short\n",
      "on cross training. it also ensured that a feature performed better\n",
      "than chance on both cross-trained results (i.e., train on narrative\n",
      "film and test on scientific text, and vice versa), rather than only\n",
      "generalizing to one dataset. using this criterion, only au23 and\n",
      "au26 showed notable improvement over chance.\n",
      "\n",
      "table 4. predicted mw rates.\n",
      "training set\n",
      "\n",
      "within\n",
      "\n",
      "cross\n",
      "\n",
      "scientific text\n",
      "\n",
      "38%\n",
      "\n",
      "28%\n",
      "\n",
      "narrative film\n",
      "\n",
      "64%\n",
      "\n",
      "68%\n",
      "\n",
      "both\n",
      "\n",
      "52%\n",
      "\n",
      "n/a\n",
      "\n",
      "figure 4. mw precision, recall, and f1 as the prediction\n",
      "threshold varies for the scientific text model applied to the\n",
      "narrative film dataset.\n",
      "we note that mw f1 score degrades at a threshold of .5. we\n",
      "adjusted the threshold to .3 and yielded the results shown in table\n",
      "5. after adjusting the mw prediction threshold, both precision and\n",
      "recall of the narrative film data applied to the scientific text model\n",
      "showed comparable performance to the cross-trained narrative film\n",
      "model. it is important to note that the adjusted mw prediction\n",
      "threshold yielded a predicted mw rate of 76%, much higher than\n",
      "the mw rate of the dataset (25%). as with the generalized narrative\n",
      "film model, this reduced precision because the high predicted mw\n",
      "rate produced a large number of false positives.\n",
      "table 5. results for models with highest mw f1 (crosstraining results in parentheses). cross-training results for the\n",
      "scientific text model reflect a mw prediction threshold of .3.\n",
      "training set\n",
      "\n",
      "classifier mw f1\n",
      "\n",
      "precision\n",
      "\n",
      ".553 (.836)\n",
      "\n",
      "narrative film c4.5\n",
      "\n",
      ".436 (.407) .303 (.278)\n",
      "\n",
      ".775 (.760)\n",
      "\n",
      "both\n",
      "\n",
      ".424\n",
      "\n",
      ".655\n",
      "\n",
      ".314\n",
      "\n",
      "table 6. mw f1 score for within-data set validation with\n",
      "cross-data set scores (in parentheses).\n",
      "facial feature\n",
      "au4 (brow lowerer)\n",
      "au6 (cheek raiser)\n",
      "au9 (nose wrinkler)\n",
      "au14 (dimpler)\n",
      "au23 (lip tightener)\n",
      "au26 (jaw drop)\n",
      "face height (size)\n",
      "face x (position)\n",
      "\n",
      "training set\n",
      "scientific text narrative film\n",
      ".378 (.278)\n",
      ".398 (.395)\n",
      ".369 (.259)\n",
      ".361 (.321)\n",
      ".300 (.268)\n",
      ".392 (.303)\n",
      ".303 (.267)\n",
      ".383 (.376)\n",
      ".334 (.333)\n",
      ".363 (.317)\n",
      ".414 (.321)\n",
      ".365 (.357)\n",
      ".322 (.256)\n",
      ".339 (.289)\n",
      ".404 (.316)\n",
      ".382 (.282)\n",
      "\n",
      "recall\n",
      "\n",
      "scientific text logitboost .441 (.416) .376 (.276)\n",
      "\n",
      "logistic\n",
      "\n",
      "we used the c4.5 classifier to generate the same models in table 2\n",
      "(train/test scientific text, train scientific text/test narrative film, etc.)\n",
      "using only the features from au23 and au26 (table 7). none of\n",
      "these models (scientific text, narrative film, or concatenated)\n",
      "achieved a mw f1 as high as those in table 2, which used a\n",
      "combination of tolerance analysis and relief-f to select features.\n",
      "this suggested that, while au23 and au26 might individually\n",
      "predict mw, when used together, their prediction power might be\n",
      "limited, compared to other feature selection techniques.\n",
      "\n",
      "4.4 feature analysis\n",
      "we analyzed the facial features to further study generalizability by\n",
      "predicting mw with different subsets of the entire feature set. the\n",
      "c4.5 classifier was chosen for this feature analysis because of its\n",
      "consistency on both the scientific text model and concatenated\n",
      "dataset. each subset consisted of the features (e.g., median,\n",
      "standard deviation) from one au, or from face position, size,\n",
      "orientation, or motion. since tolerance analysis was not used here,\n",
      "we only considered the minimum, maximum, median, and standard\n",
      "deviation aggregated features to prevent redundancy (e.g., between\n",
      "median and mean). for example, we used the minimum, maximum,\n",
      "median, and standard deviation feature values for au5 (upper lid\n",
      "raiser) to predict mw. this approach was applied to the 20 au\n",
      "subsets, as well as face position, size, orientation, and motion\n",
      "subsets. we generated the same cross-training configurations of in\n",
      "section 4.1 (i.e., train on scientific text, test on narrative film, etc.).\n",
      "\n",
      "table 7. results for models when only using the c4.5 classifier\n",
      "on au23 and au26.\n",
      "training set\n",
      "\n",
      "classifier mw f1\n",
      "\n",
      "precision\n",
      "\n",
      "recall\n",
      "\n",
      "scientific text c4.5\n",
      "\n",
      ".383 (.272) .255 (.206)\n",
      "\n",
      ".764 (.404)\n",
      "\n",
      "narrative film c4.5\n",
      "\n",
      ".397 (.257) .333 (.235)\n",
      "\n",
      ".491 (.284)\n",
      "\n",
      "both\n",
      "\n",
      ".368\n",
      "\n",
      ".575\n",
      "\n",
      "c4.5\n",
      "\n",
      ".271\n",
      "\n",
      "5. analysis\n",
      "we developed automated detectors of mw using video-based\n",
      "features in the contexts of narrative film viewing and scientific\n",
      "reading. the generalizability of these models was dependent on\n",
      "corpora on which the model was trained and the rate at which the\n",
      "model predicts mw. in this section, we discuss our main findings\n",
      "and applications of this work. we also discuss limitations and\n",
      "future work.\n",
      "\n",
      "5.1 main findings\n",
      "we expanded on previous mw detection work through crosscontext modeling. we trained three models on three datasets\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "93\n",
      "\n",
      "\f",
      "(scientific text, narrative film, and a dataset concatenated from the\n",
      "two). we found each of these models (trained and tested on the\n",
      "same corpus) performed at a notable 23% to 25% improvement\n",
      "over chance. this demonstrated the feasibility of detecting mw on\n",
      "individual corpora. however, recall was greater than precision,\n",
      "indicating prediction of false positives. this should be considered\n",
      "when implementing mw detectors in educational environments\n",
      "where excessive prediction of student mw could be demotivating.\n",
      "\n",
      "learning (both in the classroom and online). for example, films can\n",
      "give historical background on a time period being discussed in\n",
      "literature classes and instructional texts can supplement lecture\n",
      "content through textbooks or technical articles. due to the\n",
      "relationship between mw and low task performance, user\n",
      "interfaces that detect and respond to mw in contexts where\n",
      "attention is key (i.e. education) would help students remain focused\n",
      "on their learning.\n",
      "\n",
      "we investigated generalizability of the single-dataset models (i.e.\n",
      "scientific text or narrative film) by applying the model to the dataset\n",
      "on which it was not trained. the model trained on the narrative film\n",
      "dataset maintained performance when applied to the scientific text\n",
      "dataset (table 2), providing some evidence for generalizability, but\n",
      "this performance was boosted by high recall (and comparatively\n",
      "low precision). precision and recall (and thus mw f1) were near\n",
      "chance-level when the model trained on the scientific text dataset\n",
      "was applied to the narrative film dataset, suggesting that the model\n",
      "might overfit to the scientific text training set.\n",
      "\n",
      "these findings are particularly promising for implementation in\n",
      "massively open online courses (moocs). our method for detecting\n",
      "mw exclusively uses cots webcams. these webcams are\n",
      "ubiquitous in today’s computers and mobile devices; thus our work\n",
      "would integrate into a variety of learning environments without\n",
      "extra cost. such a video-based detector of mw could feasibly\n",
      "respond to student mw through suggesting a student revisit text or\n",
      "video content, asking a reengaging question, or advising the student\n",
      "to take a break.\n",
      "\n",
      "we attempted to address this problem by applying the c4.5\n",
      "classifier, as it comparatively generalized well when trained on the\n",
      "narrative film dataset. mw f1 score for the scientific text classifier\n",
      "applied to the narrative film data again negligibly increased. this\n",
      "suggested that the training data (only scientific text) used was not\n",
      "appropriate for model generalization. this idea is supported by the\n",
      "performance of the narrative film model on the scientific text data\n",
      "(although detection of false positives is a limitation) and the notable\n",
      "improvement over chance (22% to 23%) for the concatenated\n",
      "dataset. the performance of both models suggested that there were\n",
      "discernable similarities between mw instances across the two\n",
      "datasets, which can be detected using our techniques.\n",
      "in addition to training data, we also found that predicted mw rate\n",
      "effected model generalizability. we adjusted mw predictions\n",
      "according to a sliding threshold for the narrative film predictions\n",
      "obtained from the scientific text model. we found that relaxing the\n",
      "criteria for classifying an instance as mw (i.e. adjusting the\n",
      "likelihood prediction threshold from .5 to .3) yielded results\n",
      "comparable to the cross-trained narrative film model. however, this\n",
      "approach to increasing recall should be used with caution as it leads\n",
      "to increased likelihood of false positives. perhaps in a real-time\n",
      "mw intervention scenario, a more balanced approach could be\n",
      "taken where the mw likelihood prediction is used to determine if a\n",
      "mw intervention is triggered (e.g., if the detector determines there\n",
      "is a 40% likelihood the student is mw, then there is a 40% chance\n",
      "a mw intervention is triggered).\n",
      "\n",
      "5.3 limitations and future work\n",
      "while we demonstrated techniques for modeling generalizability\n",
      "across task contexts, our work has a few limitations. first, precision\n",
      "is moderate, even on our best models. high predicted mw rates\n",
      "lead to high recall, but also more false positives. in this work, we\n",
      "chose to accept this tradeoff, with the goal of generalizability in\n",
      "mind. however, raising precision, while maintaining recall is key\n",
      "to task-generalizable mw detectors being successful in educational\n",
      "environments. since mw is the minority class (25% of all\n",
      "instances), investigating skew-insensitive classifiers, such as\n",
      "hellinger distance decision trees [10], could improve precision.\n",
      "additionally, this work focuses exclusively on generalizability\n",
      "from the perspective of task context (viewing a narrative film vs.\n",
      "reading a scientific text). claims of generalizability could be\n",
      "strengthened through mw detection across environments. both the\n",
      "narrative film and scientific reading datasets were collected in a\n",
      "controlled lab setting. mw detection in the field, such as computerenabled classrooms or the personal workstations of mooc users,\n",
      "should be considered prior to implementation in such\n",
      "environments. furthermore, student generalizability should be\n",
      "further examined. in this work, we detect mw in a studentindependent way. however, participants were all of similar age and\n",
      "enrolled in college. future work could examine the generalizability\n",
      "of our method for detecting mw in non-college-aged students, such\n",
      "as elementary students in a computer-enabled classroom or nontraditional students enrolled in distance learning courses.\n",
      "\n",
      "we detected mw using individual feature subsets to ascertain\n",
      "whether certain face-based features (i.e. aus, head orientation,\n",
      "position, size, and motion) generalize. we found two feature\n",
      "subsets (au23 – lip tightener and au26 – jaw drop) that showed a\n",
      "mw f1 of at least .300 on both cross-trained models. it is notable\n",
      "that when looking at the generalizability of these features, they did\n",
      "not individually achieve mw f1 scores as high as the best\n",
      "performing models in table 2. this demonstrated the need for\n",
      "multiple features to work together to detect mw, rather than relying\n",
      "on a single feature. furthermore, this showed that our method of\n",
      "feature selection (tolerance analysis and selecting a proportion of\n",
      "features using relieff) was important to model performance.\n",
      "\n",
      "5.4 concluding remarks\n",
      "\n",
      "5.2 applications\n",
      "\n",
      "this research was supported by the national science foundation\n",
      "(nsf) (drl 1235958 and iis 1523091). any opinions, findings\n",
      "and conclusions, or recommendations expressed in this paper are\n",
      "those of the authors and do not necessarily reflect the views of the\n",
      "nsf.\n",
      "\n",
      "the present findings are applicable to educational user interfaces\n",
      "that involve reading or film comprehension. monitoring and\n",
      "responding to mw could greatly improve student performance on\n",
      "these tasks. films and instructional texts play a major role in\n",
      "\n",
      "in this work, we showed evidence that generalizable detectors of\n",
      "mw can be created using video-based features. the corpora used\n",
      "to train models of mw and predicted mw rates both play a role in\n",
      "the model’s ability to generalize and should be considered as work\n",
      "on cross-context mw generalization advances. this work advances\n",
      "the field of attention-aware interfaces [12] by demonstrating the\n",
      "feasibility of modeling mw across the educational contexts of\n",
      "reading a scientific text and viewing a narrative film. our approach\n",
      "to detecting mw is the first step towards building interfaces that\n",
      "detect mw across multiple educational activities.\n",
      "\n",
      "6. acknowledgments\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "94\n",
      "\n",
      "\f",
      "7. references\n",
      "[1]\n",
      "[2]\n",
      "\n",
      "[3]\n",
      "\n",
      "[4]\n",
      "\n",
      "[5]\n",
      "\n",
      "[6]\n",
      "\n",
      "[7]\n",
      "\n",
      "[8]\n",
      "[9]\n",
      "\n",
      "[10]\n",
      "\n",
      "[11]\n",
      "\n",
      "[12]\n",
      "\n",
      "[13]\n",
      "\n",
      "[14]\n",
      "[15]\n",
      "\n",
      "[16]\n",
      "\n",
      "[17]\n",
      "\n",
      "[18]\n",
      "\n",
      "[19]\n",
      "\n",
      "allison, p.d. 1999. multiple regression: a primer. pine\n",
      "forge press.\n",
      "baker, r.s. et al. 2012. towards automatically detecting\n",
      "whether student learning is shallow. international\n",
      "conference on intelligent tutoring systems (chania, crete,\n",
      "greece, 2012), 444–453.\n",
      "baker, r.s. et al. 2012. towards sensor-free affect detection\n",
      "in a cognitive tutor for algebra. educational data mining\n",
      "(chania, crete, greece, 2012).\n",
      "bixler, r. and d’mello, s. 2016. automatic gaze-based\n",
      "user-independent detection of mind wandering during\n",
      "computerized reading. user modeling and user-adapted\n",
      "interaction. 26, 1 (2016), 33–68.\n",
      "bixler, r. and d’mello, s.k. 2015. automatic gaze-based\n",
      "detection of mind wandering with metacognitive\n",
      "awareness.\n",
      "user\n",
      "modeling,\n",
      "adaptation\n",
      "and\n",
      "personalization: 23rd international conference (dublin,\n",
      "ireland, 2015), 31–43.\n",
      "bixler, r. and d’mello, s.k. 2014. toward fully automated\n",
      "person-independent detection of mind wandering.\n",
      "proceedings of the 22nd international conference on user\n",
      "modeling, adaptation, and personalization (switzerland,\n",
      "2014), 37–48.\n",
      "blanchard, n. et al. 2014. automated physiological-based\n",
      "detection of mind wandering during learning. intelligent\n",
      "tutoring systems (honolulu, hawaii, usa, 2014), 55–60.\n",
      "boys, c.v. and others 1890. soap-bubbles, and the forces\n",
      "which mould them. cornell university library.\n",
      "chawla, n.v. et al. 2002. smote: synthetic minority oversampling technique. journal of artificial intelligence\n",
      "research. (2002), 321–357.\n",
      "cieslak, d.a. et al. 2012. hellinger distance decision trees\n",
      "are robust and skew-insensitive. data mining and\n",
      "knowledge discovery. 24, 1 (2012), 136–158.\n",
      "dixon, w.j. and yuen, k.k. 1974. trimming and\n",
      "winsorization: a review. statistische hefte. 15, 2–3 (1974),\n",
      "157–170.\n",
      "d’mello, s.k. 2016. giving eyesight to the blind: towards\n",
      "attention-aware aied. international journal of artificial\n",
      "intelligence in education. 26, (2016), 645–659.\n",
      "domingos, p. 2012. a few useful things to know about\n",
      "machine learning. communications of the acm. 55, 10\n",
      "(2012), 78–87.\n",
      "ekman, p. and friesen, w.v. 1977. facial action coding\n",
      "system.\n",
      "faber, m. et al. 2017. an automated behavioral measure of\n",
      "mind wandering during computerized reading. behavior\n",
      "research methods. (2017), 1–17.\n",
      "franklin, m.s. et al. 2011. catching the mind in flight:\n",
      "using behavioral indices to detect mindless reading in real\n",
      "time. psychonomic bulletin & review. 18, 5 (2011), 992–\n",
      "997.\n",
      "franklin, m.s. et al. 2013. window to the wandering mind:\n",
      "pupillometry of spontaneous thought while reading. the\n",
      "quarterly journal of experimental psychology. 66, 12\n",
      "(2013), 2289–2294.\n",
      "holmes, g. et al. 1994. weka: a machine learning\n",
      "workbench. proceedings of the 1994 second australian and\n",
      "new zealand conference on intelligent information systems\n",
      "(1994), 357–361.\n",
      "hutt, s. et al. 2016. the eyes have it: gaze-based detection\n",
      "of mind wandering during learning with an intelligent\n",
      "\n",
      "[20]\n",
      "\n",
      "[21]\n",
      "\n",
      "[22]\n",
      "\n",
      "[23]\n",
      "\n",
      "[24]\n",
      "\n",
      "[25]\n",
      "\n",
      "[26]\n",
      "\n",
      "[27]\n",
      "\n",
      "[28]\n",
      "[29]\n",
      "\n",
      "[30]\n",
      "\n",
      "[31]\n",
      "\n",
      "[32]\n",
      "\n",
      "[33]\n",
      "\n",
      "[34]\n",
      "\n",
      "[35]\n",
      "\n",
      "[36]\n",
      "\n",
      "tutoring system. proceedings of the 9th international\n",
      "conference on educational data mining, international\n",
      "educational data mining society (2016), 86–93.\n",
      "jeni, l.a. et al. 2013. facing imbalanced data–\n",
      "recommendations for the use of performance metrics.\n",
      "affective computing and intelligent interaction (acii),\n",
      "2013 humaine association conference on (2013), 245–251.\n",
      "kononenko, i. 1994. estimating attributes: analysis and\n",
      "extensions of relief. machine learning: ecml-94\n",
      "(1994), 171–182.\n",
      "kopp, k. et al. 2015. influencing the occurrence of mind\n",
      "wandering while reading. consciousness and cognition. 34,\n",
      "(2015), 52–62.\n",
      "kopp, k. et al. 2015. mind wandering during film\n",
      "comprehension: the role of prior knowledge and situational\n",
      "interest. psychonomic bulletin & review. 23, 3 (2015), 842–\n",
      "848.\n",
      "littlewort, g. et al. 2011. the computer expression\n",
      "recognition toolbox (cert). 2011 ieee international\n",
      "conference on automatic face & gesture recognition and\n",
      "workshops (fg 2011) (2011), 298–305.\n",
      "mills, c. et al. 2016. automatic gaze-based detection of\n",
      "mind wandering during film viewing. proceedings of the\n",
      "9th international conference on educational data mining\n",
      "(raleigh, nc, usa, jun. 2016).\n",
      "pham, p. and wang, j. 2015. attentivelearner: improving\n",
      "mobile mooc learning via implicit heart rate tracking.\n",
      "artificial intelligence in education. c. conati et al., eds.\n",
      "springer international publishing. 367–376.\n",
      "randall, j.g. et al. 2014. mind-wandering, cognition, and\n",
      "performance: a theory-driven meta-analysis of attention\n",
      "regulation. psychological bulletin. 140, 6 (2014), 1411.\n",
      "reichle, e.d. et al. 2010. eye movements during mindless\n",
      "reading. psychological science. 21, 9 (2010), 1300–1310.\n",
      "risko, e.f. et al. 2013. everyday attention: mind wandering\n",
      "and computer use during lectures. computers & education.\n",
      "68, (2013), 275–283.\n",
      "smallwood, j. et al. 2004. subjective experience and the\n",
      "attentional lapse: task engagement and disengagement\n",
      "during sustained attention. consciousness and cognition. 13,\n",
      "4 (2004), 657–690.\n",
      "wan, x. 2009. co-training for cross-lingual sentiment\n",
      "classification. proceedings of the joint conference of the\n",
      "47th annual meeting of the acl and the 4th international\n",
      "joint conference on natural language processing of the\n",
      "afnlp (stroudsburg, pa, usa, 2009), 235–243.\n",
      "webb, n. and ferguson, m. 2010. automatic extraction of\n",
      "cue phrases for cross-corpus dialogue act classification.\n",
      "proceedings of the 23rd international conference on\n",
      "computational linguistics: posters (stroudsburg, pa,\n",
      "usa, 2010), 1310–1317.\n",
      "westlund, j.k. et al. 2015. motion tracker: camera-based\n",
      "monitoring of bodily movements using motion silhouettes.\n",
      "plos one. 10, 6 (2015).\n",
      "zacks, j.m. et al. 2010. the brain’s cutting-room floor:\n",
      "segmentation of narrative cinema. frontiers in human\n",
      "neuroscience. 4, 168 (2010), 1–15.\n",
      "zhang, z. et al. 2011. unsupervised learning in cross-corpus\n",
      "acoustic emotion recognition. 2011 ieee workshop on\n",
      "automatic speech recognition understanding (dec. 2011),\n",
      "523–528.\n",
      "2016. emotient module: facial expression emotion\n",
      "analysis.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "95\n",
      "\n",
      "\f",
      "addressing student behavior and affect\n",
      "with empathy and growth mindset\n",
      "shamya karumbaiah\n",
      "\n",
      "university of massachusetts\n",
      "amherst\n",
      "140 governors drive\n",
      "amherst, ma 01003-9264\n",
      "\n",
      "shamya@cs.umass.edu\n",
      "beverly woolf\n",
      "university of massachusetts\n",
      "amherst\n",
      "140 governors drive\n",
      "amherst, ma 01003-9264\n",
      "\n",
      "bev@cs.umass.edu\n",
      "\n",
      "rafael lizarralde\n",
      "\n",
      "danielle allessio\n",
      "\n",
      "university of massachusetts\n",
      "amherst\n",
      "140 governors drive\n",
      "amherst, ma 01003-9264\n",
      "\n",
      "university of massachusetts\n",
      "amherst\n",
      "140 governors drive\n",
      "amherst, ma 01003-9264\n",
      "\n",
      "worcester polytechnic institute\n",
      "100 institute rd\n",
      "worcester, ma 01609\n",
      "\n",
      "worcester polytechnic institute\n",
      "100 institute rd\n",
      "worcester, ma 01609\n",
      "\n",
      "rezecib@cs.umass.edu\n",
      "ivon arroyo\n",
      "iarroyo@wpi.edu\n",
      "\n",
      "abstract\n",
      "we present results of a randomized controlled study that\n",
      "compared different types of affective messages delivered by\n",
      "pedagogical agents. we used animated characters that were\n",
      "empathic and emphasized the malleability of intelligence and\n",
      "the importance of effort. results showed significant correlations between students who received more empathic messages and those who were more confident, more patient, exhibited higher levels of interest, and valued math knowledge\n",
      "more. students who received more growth mindset messages, tended to get more problems correct on their first\n",
      "attempt but valued math knowledge less and had lower\n",
      "posttest scores. students who received more success/failure\n",
      "messages tended to make more mistakes, to be less learningoriented, and stated that they were more confused. we conclude that these affective messages are powerful media to\n",
      "influence students’ perceptions of themselves as learners, as\n",
      "well as their perceptions of the domain being taught. we\n",
      "have reported significant results that support the use of empathy to improve student affect and attitudes in a math\n",
      "tutor.\n",
      "\n",
      "keywords\n",
      "student affect, empathy messages, growth mindset, pedagogical agents, intelligent tutor, confidence\n",
      "\n",
      "1. introduction\n",
      "students experience many emotions while studying and taking tests [16]. students’ emotions (such as confidence, boredom, and anxiety) can influence achievement outcomes [10,\n",
      "18] and predispositions (such as low self-concept and pessimism) can diminish academic success [5, 14].\n",
      "\n",
      "allessio@umass.edu\n",
      "naomi wixon\n",
      "mwixon@wpi.edu\n",
      "\n",
      "pekrun’s control-value theory of emotion has been experimentally validated by classroom experiments that used student self-reports (answers to 5-point scale survey questions).\n",
      "these experiments provide evidence that educational interventions can reduce students’ anxiety [16, 19].\n",
      "dweck’s growth mindset theory suggests that students who\n",
      "believe that intelligence can be increased through effort and\n",
      "persistence tend to seek out academic challenges, compared\n",
      "to those who view their intelligence as immutable [8, 9].\n",
      "students who are praised for their effort (as opposed to performance) are more likely to view intelligence as being malleable, and their self-esteem remains stable regardless of how\n",
      "hard they have to work to succeed at a task.\n",
      "hattie and timperley [13] studied which types of feedback\n",
      "and conditions enable learning to flourish and which cases\n",
      "stifle growth. according to their study feedback is intended\n",
      "to help a student get from where they are to where they need\n",
      "to be. graesser et al., [12] reported that there are significant\n",
      "relationships between the content of feedback dialogue and\n",
      "the emotions experienced during learning. they found significant correlations between dialog and the affective states\n",
      "of confusion, eureka (delight) and frustration.\n",
      "pekrun et al., [17] tested a theoretical model positing that\n",
      "a student’s anticipated achievement feedback in a classroom\n",
      "setting influences his/her achievement goals and emotions.\n",
      "for example, self-referential feedback, in which a student’s\n",
      "competence is defined in terms of self-improvement, had a\n",
      "positive influence on a student’s mastery goal adoption. on\n",
      "the other hand, normative feedback, in which student competence is defined relative to other students’ mastery goals and\n",
      "performance goals, had a positive influence on performanceapproach and performance-avoidance goal adoption. furthermore, feedback condition and achievement goals predicted test-related emotions (i.e., enjoyment, hope, pride,\n",
      "relief, anger, anxiety, hopelessness, and shame).\n",
      "teachers have limited opportunities to recognize and respond to individual student’s affect in typical classrooms.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "96\n",
      "\n",
      "\f",
      "ideally, digital learning environments can manage the delicate balance between motivation and cognition, promoting\n",
      "both interest and deep learning. the overwhelming majority\n",
      "of work on affect-aware virtual tutors has focused on modeling affect, i.e., designing computational models capable of\n",
      "detecting how students feel while they interact with intelligent tutoring systems [2]. while modeling affect is a critical\n",
      "first step, very little research exists on systematically exploring the impact of interventions on students’ performance,\n",
      "learning, and attitudes, i.e., how an environment might respond to students emotions (e.g., frustration, anxiety, and\n",
      "boredom) as they arise. d’mello and graesser carried out\n",
      "close research work on empathic characters in autotutor,\n",
      "a conversational tutor that uses 3d companions to conduct\n",
      "dialogs in natural language with students [6, 7, 11].\n",
      "\n",
      "1.1\n",
      "\n",
      "oriented goals[3]. other results indicate that empathic\n",
      "characters can help decrease students’ anxiety and boredom.\n",
      "our results showed that: a) student anxiety and boredom\n",
      "can be reduced using simple 2d characters, as did d’mello et\n",
      "al., (2007); b) these benefits are due primarily to empathy,\n",
      "and secondarily to growth mindset messages; and c) indicating only success or failure is actively harmful to students,\n",
      "in comparison to emphasizing the learning process and the\n",
      "importance of effort.\n",
      "\n",
      "mathspring\n",
      "\n",
      "the testbed for this research is mathspring, an intelligent\n",
      "tutor that personalizes mathematics problems, provides help\n",
      "using multimedia, and effectively teaches students to improve in standardized test scores [4]. learning companions\n",
      "(figure 1) in mathspring suggest to students that their effort contributes to success, and that making mistakes only\n",
      "means more effort is needed. companions use about 20 different messages focused on effort and growth mindset (table 2).\n",
      "to date, mathspring learning companions have provided\n",
      "positive significant effects for the overall population of students and were more effective for lower achieving students\n",
      "and for female students in general [2]. however, characters seemed to have been harmful to some students (e.g.,\n",
      "high-achieving males), who had higher affective baselines at\n",
      "pretest time and seem to have been distracted by the characters. these results suggest that affective characters should\n",
      "probably be different for students who are not presently frustrated or anxious (often high achieving males). one possibility is that the behavior of the characters be adaptive to\n",
      "the affective state of the student.\n",
      "\n",
      "1.2\n",
      "\n",
      "recognize and respond to affect\n",
      "\n",
      "previously, we evaluated the hypothesis that tailored affective messages delivered by digital animated characters may positively impact students emotions, attitude, and learning performance. specifically, we identified concrete prescriptive principles about how to respond\n",
      "to student emotion as it occurs during online learning [1, 3].\n",
      "with models of student emotion, we explored mechanisms to\n",
      "address negative emotions. our models predict confidence,\n",
      "interest, frustration, and excitement in real-time, based on\n",
      "data from hundreds of students. the gold standard was\n",
      "students’ self-reported responses to questions, such as “how\n",
      "confident do you feel right now?”\n",
      "we found that growth mindset messages based on dweck’s\n",
      "theory [9] provide an apparent boost in student math\n",
      "learning [3], resulted in less performance-oriented goals\n",
      "(e.g., beating classmates, instead of a self-referenced focus),\n",
      "and less boredom reported on the posttest. typically\n",
      "online educational systems only report correctness: “your\n",
      "answer is correct/incorrect.” we discovered that such success/failure messages are correlated to higher reported anxiety and boredom, and appear to increase performance-\n",
      "\n",
      "figure 1: learning companions respond to student\n",
      "actions with gestures and messages shown both as\n",
      "text and audio. above: companion shows high interest while the student views an example problem\n",
      "with solution steps shown. below: companion provides a growth mindset message, encouraging the\n",
      "student to put in effort to become good at math.\n",
      "\n",
      "1.3 research goals\n",
      "the research questions in this paper focus on identifying\n",
      "messages that support students’ motivation to persist working on a task. which messages (see table 2) should a tutoring system send to students to encourage them to persist?\n",
      "how should agents respond to negative emotions? should\n",
      "students be praised when they do well? are the benefits to\n",
      "student learning and emotion due to empathic or motivational aspects of the companion? what are the results on\n",
      "learning and emotion of using an empathic or less empathic\n",
      "companion in comparison to a companion that indicates only\n",
      "success or failure?\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "97\n",
      "\n",
      "\f",
      "table 1: outcomes variables measured in the experiment. the questions on the pre- and posttest were\n",
      "answered in a 5-point scale, going from “not at all” to “very much”.\n",
      "interest - students’ interest in math. “are you interested when solving math problems?”\n",
      "excitement - how exciting students find math. “do you feel that solving math is exciting?”\n",
      "confusion - how confused students feel while solving math problems. “do you feel confident that you will\n",
      "eventually be able to understand the mathematics material?”\n",
      "frustration - how frustrating students find math. average of “do you get frustrated when solving math problems?” and “does solving math problems make your feel frustrated?”\n",
      "learning orientation - how much students focus on learning as opposed to performance. average of “when\n",
      "you are doing math exercises, is your goal to learn as much as you can?” and “do you prefer learning about things\n",
      "that make you curious even if that means you have to work harder?”\n",
      "performance approach goals - “do you want to show that you are better at math than your classmates?”\n",
      "math value - how important do students think math is. “compared to most other activities, how important is\n",
      "it or you to be good at math?”\n",
      "math liking - measure of how much students like math. “do you like your math class?”\n",
      "math test performance - student’s score on math questions that are representative of the content covered in\n",
      "mathspring.\n",
      "\n",
      "2.\n",
      "\n",
      "method\n",
      "\n",
      "we conducted a randomized controlled study to evaluate\n",
      "three different types of affective messages delivered by pedagogical agents (table 2). the study took place in an urban school district in southern california with sixty-four 6th\n",
      "grade students in three math classes for four class sessions,\n",
      "during december 2016. on part of the first and last day,\n",
      "students completed a pretest and posttest including questions related to various affective states, and questions about\n",
      "mathematics. outcome variables measured from these questions are provided in table 1.\n",
      "three conditions of learning companion messages were randomly assigned to students and delivered in both audio and\n",
      "written form in order to increase the likelihood of exposure: 1) empathy condition for 24 students, 2) growth\n",
      "mindset condition for 20 students and 3) success/failure\n",
      "condition for 20 students; see table 2 for examples of the\n",
      "different types of messages. for all conditions, students were\n",
      "asked to self-report their frustration or confidence in a fivepoint scale every five minutes or every eight problems, which\n",
      "ever came first, but only after a problem was completed.\n",
      "the prompts were shown on a separate screen and invited\n",
      "students to report on their frustration or confidence.\n",
      "the empathy condition was set to visually reflect positive\n",
      "emotion with a certain probability for each math problem\n",
      "if the last student emotion report had a positive valence.\n",
      "when the most recent emotion report had a negative valence, and with a certain probability, the character first visually reflected the negative emotion; then it reported an\n",
      "empathy message such as “sometimes these problems make\n",
      "me feel [frustrated]”, and finally a connector such as “on the\n",
      "other hand”, connected with a growth mindset message such\n",
      "as “i know that putting effort into problem solving and learning from hints will make our intelligence grow.” note that\n",
      "only students experiencing negative emotions were exposed\n",
      "to growth mindset messages, as opposed to the following\n",
      "condition.\n",
      "the growth mindset condition emphasized messages that\n",
      "accentuate the importance of effort and perseverance in achieving success. the growth mindset condition was set to pro-\n",
      "\n",
      "vide one of many growth mindset messages after a second incorrect attempt was made (the first incorrect attempt caused\n",
      "the hint button to flash), regardless of students’ emotions.\n",
      "this condition also provided occasional growth mindset messages at the beginning of a new problem.\n",
      "the success/failure condition provided both traditional\n",
      "success/failure messages and some more basic meta-cognitive\n",
      "support for when students made mistakes (e.g., acknowledging that their answer was not correct while encouraging them\n",
      "to use a hint). the success/failure condition provided students with a response if they answered a problem correctly\n",
      "and also after they made a second mistake.\n",
      "\n",
      "3.\n",
      "\n",
      "results\n",
      "\n",
      "out of the 64, three students’ data were discarded due to\n",
      "minimal interaction with mathspring. across the n =\n",
      "61 students, 21066 event log rows were recorded for three\n",
      "classes over four separate days, from which several behavioral features were derived and used throughout the analysis;\n",
      "our data and processing scripts can be found on github [15].\n",
      "all the students completed a pretest and posttest. students\n",
      "in empathy, growth mindset and success/failure conditions\n",
      "received a total of 978, 763, and 882 messages respectively.\n",
      "means, standard deviations and percentage shares for each\n",
      "type of message are given in table 3. it is important to\n",
      "note that students received messages from all categories but\n",
      "their condition emphasized the corresponding message type.\n",
      "for example, a student in growth mindset condition received\n",
      "significantly more growth mindset messages than a student\n",
      "in empathy condition. this distribution of messages means\n",
      "that different students saw different amounts of each type\n",
      "of message, which allows us to perform partial correlations\n",
      "with respect to the counts of each message type, separating\n",
      "their effects.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "98\n",
      "\n",
      "\f",
      "table 2: examples of messages spoken by characters.\n",
      "condition\n",
      "empathy\n",
      "growth\n",
      "mindset\n",
      "success/\n",
      "failure\n",
      "\n",
      "message\n",
      "“don’t you sometimes get frustrated trying to solve math problems? i do. but guess what.\n",
      "keep in mind that when you are struggling with are new idea or skill you are learning\n",
      "something and becoming smarter.”\n",
      "“hey, congratulations! your effort paid off, you got it right!”\n",
      "“did you know that when we practice to learn new math skills our brain grows and gets\n",
      "stronger?”\n",
      "“let’s click on help, and i am sure we will learn something.”\n",
      "“very good, we got another one right!”\n",
      "“hmm. wrong. shall we work it out on paper?”\n",
      "\n",
      "figure 2: time spent on a problem immediately before and after receiving the different categories of messages.\n",
      "\n",
      "3.1\n",
      "\n",
      "partial correlations\n",
      "\n",
      "first, we attempted to replicate the results of our previous\n",
      "exploratory work [3]. for the three message types, partial\n",
      "correlations of the total number of each messages were measured for the nine posttest measures, controlling for the corresponding pretest measure, time spent in the tutor, and\n",
      "message frequency (total messages heard / time spent).\n",
      "table 4 shows the result of this analysis. we observe that\n",
      "with exposure to more empathic messages, students exhibited higher levels of interest and valued math knowledge more (rows 1 and 7). increased interest can be viewed\n",
      "as analogous to the high negative correlation with boredom\n",
      "reported in our earlier work. with growth mindset messages, students valued math knowledge less and had\n",
      "lower post test performance scores (rows 7 and 9).\n",
      "with success/failure messages, students were less learningoriented and claimed to be more confused (rows 6 and 3).\n",
      "\n",
      "as we see in figure 2, students tend to spend less time\n",
      "on problems immediately after they receive growth mindset\n",
      "or success/failure messages. in contrast, the time spent on\n",
      "a problem increases slightly after receiving empathic messages. students who received more empathic and growth\n",
      "mindset messages tend to answer fewer questions than do\n",
      "students who received mostly success/failure message (figure 3). combined with the last plot, it looks like the students\n",
      "in the empathy condition continue to invest more time on\n",
      "solving problems than rushing through the problem set.\n",
      "\n",
      "figure 3: problems seen per minute across different\n",
      "pedagogies\n",
      "\n",
      "to further understand the dynamics, we derived some intutor variables and performed partial correlations shown in\n",
      "table 5. the data for this analysis was derived as per student metrics based on their interaction with mathspring.\n",
      "we observed that students tend to answer significantly more\n",
      "questions when in the success/failure condition and end up\n",
      "making more mistakes as well (rows 4 and 5). it is important\n",
      "to note that they also avoid asking for hints (row 6). it\n",
      "seems like these students tend to rush through the problems\n",
      "while being more careless. they also make more mistakes\n",
      "when they receive more growth mindset messages (row 5).\n",
      "this leads to simpler questions which they tend to get right\n",
      "in the first attempt (row 1). it appears that the students\n",
      "in empathy condition continue to invest more time on\n",
      "solving problems than rushing through the problem set. the\n",
      "number of problems seen by these students is significantly\n",
      "less (row 4).\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "99\n",
      "\n",
      "\f",
      "table 3: the distribution of messages seen by students in each pedagogical conditions.\n",
      "condition\n",
      "empathy\n",
      "growth\n",
      "mindset\n",
      "success/\n",
      "failure\n",
      "\n",
      "n\n",
      "21\n",
      "\n",
      "empathy messages\n",
      "mean\n",
      "std\n",
      "%\n",
      "7.48\n",
      "7.0\n",
      "16%\n",
      "\n",
      "growth mindset messages\n",
      "mean\n",
      "std\n",
      "%\n",
      "9.95\n",
      "7.2\n",
      "21%\n",
      "\n",
      "success/failure messages\n",
      "mean\n",
      "std\n",
      "%\n",
      "29.1\n",
      "22\n",
      "62%\n",
      "\n",
      "20\n",
      "\n",
      "0.2\n",
      "\n",
      "0.5\n",
      "\n",
      "0.5%\n",
      "\n",
      "10\n",
      "\n",
      "5\n",
      "\n",
      "26%\n",
      "\n",
      "27.9\n",
      "\n",
      "19.2\n",
      "\n",
      "73%\n",
      "\n",
      "20\n",
      "\n",
      "1.2\n",
      "\n",
      "1.7\n",
      "\n",
      "2.7%\n",
      "\n",
      "4.6\n",
      "\n",
      "4.8\n",
      "\n",
      "10%\n",
      "\n",
      "38.3\n",
      "\n",
      "26.6\n",
      "\n",
      "86%\n",
      "\n",
      "table 4: partial correlations between different types of messages seen and posttest variables (table 1),\n",
      "accounting for the corresponding pretest value, time spent in tutor and message frequency.\n",
      "variable\n",
      "(1)\n",
      "(2)\n",
      "(3)\n",
      "(4)\n",
      "(5)\n",
      "(6)\n",
      "(7)\n",
      "(8)\n",
      "(9)\n",
      "\n",
      "interest\n",
      "excitement\n",
      "confusion\n",
      "frustration\n",
      "performance\n",
      "approach\n",
      "learning\n",
      "orientation\n",
      "math value\n",
      "math liking\n",
      "performance\n",
      "\n",
      "empathy messages\n",
      "corr\n",
      "p\n",
      "0.28*\n",
      "0.03\n",
      "0.00\n",
      "1.00\n",
      "-0.05\n",
      "0.74\n",
      "0.10\n",
      "0.43\n",
      "\n",
      "growth mindset messages\n",
      "corr\n",
      "p\n",
      "0.19\n",
      "0.15\n",
      "-0.07\n",
      "0.60\n",
      "-0.05\n",
      "0.74\n",
      "-0.08\n",
      "0.54\n",
      "\n",
      "success/failure\n",
      "corr\n",
      "-0.20\n",
      "-0.08\n",
      "0.32*\n",
      "-0.18\n",
      "\n",
      "messages\n",
      "p\n",
      "0.14\n",
      "0.54\n",
      "0.02\n",
      "0.18\n",
      "\n",
      "-0.19\n",
      "\n",
      "0.14\n",
      "\n",
      "-0.05\n",
      "\n",
      "0.70\n",
      "\n",
      "0.20\n",
      "\n",
      "0.12\n",
      "\n",
      "0.02\n",
      "\n",
      "0.85\n",
      "\n",
      "0.02\n",
      "\n",
      "0.88\n",
      "\n",
      "-0.24+\n",
      "\n",
      "0.06\n",
      "\n",
      "0.09\n",
      "0.96\n",
      "0.07\n",
      "\n",
      "-0.10\n",
      "0.05\n",
      "-0.13\n",
      "\n",
      "0.25*\n",
      "0.01\n",
      "-0.01\n",
      "\n",
      "0.05\n",
      "0.96\n",
      "0.93\n",
      "\n",
      "+\n",
      "\n",
      "-0.22\n",
      "0.01\n",
      "-0.23+\n",
      "\n",
      "+\n",
      "\n",
      "0.45\n",
      "0.72\n",
      "0.33\n",
      "p ≤ 0.10, * p ≤ 0.05\n",
      "\n",
      "table 5: partial correlations between different types of messages seen and within-tutor variables, accounting\n",
      "for time spent in the tutor and message frequency.\n",
      "variable\n",
      "(1)\n",
      "(2)\n",
      "(3)\n",
      "(4)\n",
      "(5)\n",
      "(6)\n",
      "\n",
      "% problems solved on\n",
      "first attempt\n",
      "avg problem\n",
      "difficulty\n",
      "learning gain\n",
      "problems seen\n",
      "mistakes made\n",
      "hints per problem\n",
      "\n",
      "empathy messages\n",
      "corr\n",
      "p\n",
      "\n",
      "growth mindset messages\n",
      "corr\n",
      "p\n",
      "\n",
      "success/failure messages\n",
      "corr\n",
      "p\n",
      "\n",
      "0.06\n",
      "\n",
      "0.62\n",
      "\n",
      "0.34**\n",
      "\n",
      "0.007\n",
      "\n",
      "-0.01\n",
      "\n",
      "0.94\n",
      "\n",
      "0.07\n",
      "\n",
      "0.61\n",
      "\n",
      "-0.05\n",
      "\n",
      "0.69\n",
      "\n",
      "0.19\n",
      "\n",
      "0.14\n",
      "\n",
      "-0.10\n",
      "-0.23+\n",
      "-0.01\n",
      "0.10\n",
      "\n",
      "0.50\n",
      "0.07\n",
      "0.91\n",
      "0.43\n",
      "\n",
      "-0.07\n",
      "-0.04\n",
      "0.59**\n",
      "0.16\n",
      "\n",
      "0.63\n",
      "0.78\n",
      "6e-7\n",
      "0.22\n",
      "+\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "-0.14\n",
      "0.34\n",
      "0.77**\n",
      "4e-13\n",
      "0.30*\n",
      "0.02\n",
      "0.10\n",
      "-0.22+\n",
      "p ≤ 0.10, * p ≤ 0.05, ** p ≤ 0.01\n",
      "\n",
      "100\n",
      "\n",
      "\f",
      "3.2\n",
      "\n",
      "markov chain analysis\n",
      "\n",
      "as students solve problems in the tutoring system, the learning companion comments on their attempts; the effect of\n",
      "these messages on student affect is sequential, but the partial correlations do not capture this. to analyze this effect,\n",
      "we built markov chain models using in-tutor student selfreports of confidence and frustration. each model describes\n",
      "transitions in affective states, from one self-report to the\n",
      "next, where students received a particular type of character messages (empathy, growth mindset, and success/failure)\n",
      "between self-reports. to reduce the state space, the 5-point\n",
      "scale used in the self-reports was simplified to two values confident (≥ 3), not confident (< 3); similarly for frustration.\n",
      "the goal of the markov models was not to predict emotional\n",
      "changes, but rather to examine whether different messages\n",
      "had significant effects on affect. markov models can show\n",
      "the probability of transitioning between affective states, but\n",
      "also have a stationary distribution, which represents the\n",
      "amount of students that would be in each state after undergoing many transitions. for example, a group of students were to use the system for many hours and receive\n",
      "only empathic messages, our model suggests that 99.5% of\n",
      "them would be confident about learning math (figure 4).\n",
      "\n",
      "figure 4: state transitions between the confident\n",
      "(c) and not confident (n) affective states. the stationary distribution is shown below each state. only\n",
      "the empathy model was significant in the likelihood\n",
      "ratio test (p ≤ 0.05)\n",
      "after\n",
      "empathic\n",
      "message\n",
      "\n",
      "table 6: stationary distributions in the markov\n",
      "models of confidence and frustration.\n",
      "message\n",
      "type\n",
      "empathy\n",
      "growth\n",
      "mindset\n",
      "success/\n",
      "failure\n",
      "\n",
      "confidence\n",
      "conf\n",
      "not\n",
      "99.5%* 0.05%*\n",
      "\n",
      "frustration\n",
      "frust\n",
      "not\n",
      "35%\n",
      "65%\n",
      "\n",
      "74%\n",
      "\n",
      "26%\n",
      "\n",
      "30%\n",
      "\n",
      "70%\n",
      "\n",
      "80%\n",
      "\n",
      "20%\n",
      "\n",
      "25%\n",
      "\n",
      "75%\n",
      "*p ≤ 0.05\n",
      "\n",
      "4. discussion\n",
      "some of our results support the hypothesis that affective\n",
      "messages delivered by characters can positively impact students’ emotions and affective predispositions for math problem solving. this is particularly evident for empathy, as\n",
      "the more empathic messages a student saw the higher their\n",
      "interest in mathematics problem solving, as well as their beliefs that mathematics is valuable to learn (table 4). an\n",
      "analysis of student behavior suggests that students who saw\n",
      "a high frequency of empathic messages also tended to be\n",
      "more patient and cautious with problem solving, suggesting\n",
      "that empathic messages may encourage students to persist\n",
      "through adversity. exposure to empathic messages was significantly correlated to investing time in each math problem activity, leading also to fewer problems seen per session. a positive trend is exhibited between high frequency\n",
      "of empathic messages and hints requested, even if not significant (table 5). empirical temporal models generated from\n",
      "students’ changes in self-reports of affect, within the tutor,\n",
      "revealed that students receiving empathic messages have a\n",
      "higher likelihood to become more confident and to remain\n",
      "confident.\n",
      "\n",
      "0.01\n",
      "0.99\n",
      "\n",
      "c\n",
      "99.5%\n",
      "\n",
      "n\n",
      "0.50\n",
      "\n",
      "0.50\n",
      "\n",
      "0.5%\n",
      "\n",
      "0.11\n",
      "\n",
      "after growth\n",
      "mindset\n",
      "message\n",
      "\n",
      "0.89\n",
      "\n",
      "after\n",
      "success/\n",
      "failure\n",
      "message\n",
      "\n",
      "0.90\n",
      "\n",
      "c\n",
      "73%\n",
      "\n",
      "n\n",
      "0.31\n",
      "\n",
      "0.69\n",
      "\n",
      "27%\n",
      "\n",
      "0.10\n",
      "c\n",
      "80%\n",
      "\n",
      "n\n",
      "0.39\n",
      "\n",
      "0.61\n",
      "\n",
      "20%\n",
      "\n",
      "we used a likelihood ratio test to analyze the significance\n",
      "of these models: the probability of the null model (ignoring\n",
      "message type) generating the data divided by the probability\n",
      "of the alternate model (for a particular message type) generating the data gives a p-value. figure 4 shows the state transitions for confidence in the null model and the model for\n",
      "confidence after receiving empathic messages, which was\n",
      "significant with p = 0.0149 (the other models were not significant). we also examined the stationary distributions for\n",
      "each model (table 6).\n",
      "\n",
      "the response to growth mindset messages delivered by characters yielded mixed results. as students saw more of these\n",
      "kinds of messages they also succeeded more often at solving\n",
      "problems correctly (on the first attempt); interestingly, at\n",
      "the same time, they also made more mistakes. this is also\n",
      "desirable, as growth mindset messages emphasize that making mistakes is okay and can even help learning, legitimizing\n",
      "a high frequency of errors. it is possible that students were\n",
      "using those mistakes and hints to learn and succeed later on;\n",
      "a (not significant) positive trend suggests that students receiving more of these kinds of messages also asked for more\n",
      "hints per problem. in contrast, marginally significant effects\n",
      "suggest that a high frequency of growth mindset messages\n",
      "might be detrimental to students’ perception of math value,\n",
      "and that their posttest performance is worse when they receive more of this kind of messages. it is hard to conclude\n",
      "the meaning of these marginally significant effects, especially\n",
      "because a previous study suggested that these messages were\n",
      "beneficial in general [3]. note that empathic messages used\n",
      "’growth mindset’ messages also, in order to resolve the negative emotion (see table 2). one possible explanation is that\n",
      "the empathic condition was so positive because it was also\n",
      "very selective at showing growth mindset messages for only\n",
      "those who experienced negative emotions. it is likely that\n",
      "high achieving students, or those who “felt ok”, rejected\n",
      "growth mindset messages that they might have perceived to\n",
      "be unnecessary.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "101\n",
      "\n",
      "\f",
      "an important comment is that we did not expect that success/failure messages could be so harmful to students. regardless of whether messages indicated success or failure, as\n",
      "students received more of these messages they also exhibited\n",
      "lower levels of mastery/learning orientation at posttest time.\n",
      "they also reported higher levels of confusion at posttest time\n",
      "(note that the confusion can be positive for learning within\n",
      "the learning experience, but not after the learning experience has concluded). regarding behavior within the tutor,\n",
      "the more students were exposed to success/failure messages,\n",
      "the more they appeared to rush through problems, make\n",
      "mistakes, and request fewer hints per problem.\n",
      "to summarize, empathy messages were associated with variables consistent with methodical work and an increased interest/value of mathematics. however, both growth mindset\n",
      "and success/failure messages appeared to be associated with\n",
      "a greater number of mistakes. finally, success/failure messages themselves were associated with a whole host of concerning behaviors such as confusion with the material following posttest, reduced learning orientation, hurried work, and\n",
      "a reduced likelihood of requesting hints. this is consistent\n",
      "with dweck’s findings that growth mindset messages are superior to success/failure messages [8, 9]. whether empathic\n",
      "messages in fact result in improved student performance pre\n",
      "to posttest will likely require larger samples than this small\n",
      "study (n = 61). however, students in non-empathic conditions have demonstrated significantly more mistakes in their\n",
      "work.\n",
      "\n",
      "5.\n",
      "\n",
      "conclusions\n",
      "\n",
      "this research emphasizes the importance of understanding\n",
      "an intervention’s effect on a student’s affective state, which\n",
      "in turn is connected to engagement, performance, and learning. although many researchers have focused on modeling\n",
      "affect, very little research effort has been put into systematically measuring the impact of the intervention on the student behavior in an adaptive learning environment. empathic messages that respond to students’ recent emotions\n",
      "have resulted in superior results both in improving the student interaction with the system and in the overall learning\n",
      "experience. growth mindset follows next with some positive impact on in-tutor performance but its overall effect\n",
      "in the short-term is questionable. success/failure messages\n",
      "are generally harmful to students: reducing learning orientation, increasing confusion, and making students more\n",
      "careless during the learning experience.\n",
      "we conclude that affective messages delivered by characters in online tutoring environments are a very important\n",
      "medium for building student-tutor rapport in a virtual environment, powerful signals that influence perceptions of students themselves as learners, as well as perceptions of the\n",
      "domain being taught. we have reported significant results\n",
      "that support the use of empathy to improve student affect\n",
      "and attitudes in a math tutor. the long-term effect of these\n",
      "messages needs to be studied when the novelty of this intervention wears off. in the future, we hope to study the\n",
      "impact of the frequency and content of these messages. to\n",
      "evaluate the generalizability of these results, student populations across different demographics needs to be studied as\n",
      "well as the applicability of the messages to domains beyond\n",
      "mathematics.\n",
      "\n",
      "6.\n",
      "\n",
      "acknowledgments\n",
      "\n",
      "this research is supported by the national science foundation (nsf) 1324385 iis/cyberlearning dip: collaborative\n",
      "research: impact of adaptive interventions on student affect, performance, and learning. any opinions, findings,\n",
      "and conclusions, or recommendations expressed in this paper are those of the authors and do not necessarily reflect\n",
      "the views of nsf.\n",
      "\n",
      "7.\n",
      "\n",
      "additional authors\n",
      "\n",
      "additional authors: winslow burleson (new york university, 70 washington square south new york, new york,\n",
      "10012; email: wb50@nyu.edu).\n",
      "\n",
      "8.\n",
      "\n",
      "references\n",
      "\n",
      "[1] i. arroyo, w. burleson, m. tai, k. muldner, and b. p.\n",
      "woolf. gender differences in the use and benefit of\n",
      "advanced learning technologies for mathematics.\n",
      "journal of educational psychology, 105(4):957, 2013.\n",
      "[2] i. arroyo, d. g. cooper, w. burleson, b. p. woolf,\n",
      "k. muldner, and r. christopherson. emotion sensors\n",
      "go to school. in aied, volume 200, pages 17–24, 2009.\n",
      "[3] i. arroyo, s. schultz, n. wixon, k. muldner,\n",
      "w. burleson, and b. p. woolf. addressing affective\n",
      "states with empathy and growth mindset. 6th\n",
      "international workshop on personalization\n",
      "approaches in learning environments, 2016.\n",
      "[4] i. arroyo, b. p. woolf, w. burelson, k. muldner,\n",
      "d. rai, and m. tai. a multimedia adaptive tutoring\n",
      "system for mathematics that addresses cognition,\n",
      "metacognition and affect. international journal of\n",
      "artificial intelligence in education, 24(4):387–426,\n",
      "2014.\n",
      "[5] l. corno and r. e. snow. adapting teaching to\n",
      "individual differences among learners. handbook of\n",
      "research on teaching, 3(605-629), 1986.\n",
      "[6] s. d’mello and a. graesser. automatic detection of\n",
      "learner’s affect from gross body language. applied\n",
      "artificial intelligence, 23(2):123–150, 2009.\n",
      "[7] s. d’mello and a. graesser. autotutor and affective\n",
      "autotutor: learning by talking with cognitively and\n",
      "emotionally intelligent computers that talk back.\n",
      "acm transactions on interactive intelligent systems\n",
      "(tiis), 2(4):23, 2012.\n",
      "[8] c. s. dweck. self-theories: their role in motivation,\n",
      "personality, and development. psychology press, 2000.\n",
      "[9] c. s. dweck. beliefs that make smart people dumb.\n",
      "why smart people can be so stupid, 24:41, 2002.\n",
      "[10] d. goleman. emotional intelligence. why it can\n",
      "matter more than fq. learning, 24(6):49–50, 1996.\n",
      "[11] a. c. graesser, p. chipman, b. c. haynes, and\n",
      "a. olney. autotutor: an intelligent tutoring system\n",
      "with mixed-initiative dialogue. ieee transactions on\n",
      "education, 48(4):612–618, 2005.\n",
      "[12] a. c. graesser, s. k. d’mello, s. d. craig,\n",
      "a. witherspoon, j. sullins, b. mcdaniel, and\n",
      "b. gholson. the relationship between affective states\n",
      "and dialog patterns during interactions with\n",
      "autotutor. journal of interactive learning research,\n",
      "19(2):293, 2008.\n",
      "[13] j. hattie and h. timperley. the power of feedback.\n",
      "review of educational research, 77(1):81–112, 2007.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "102\n",
      "\n",
      "\f",
      "[14] a. n. kluger and a. denisi. feedback interventions:\n",
      "toward the understanding of a double-edged sword.\n",
      "current directions in psychological science, 7(3):67–72,\n",
      "1998.\n",
      "[15] r. lizarralde and s. karumbaiah. a collection of\n",
      "scripts for processing mathspring data. https:\n",
      "//github.com/rezecib/mathspringdataprocessing,\n",
      "2017.\n",
      "[16] r. pekrun. emotions and learning. international\n",
      "academy of education. australia: international\n",
      "bureau of education, 2014.\n",
      "[17] r. pekrun, a. cusack, k. murayama, a. j. elliot, and\n",
      "k. thomas. the power of anticipated feedback:\n",
      "effects on students’ achievement goals and\n",
      "achievement emotions. learning and instruction,\n",
      "29:115–124, 2014.\n",
      "[18] r. pekrun, t. goetz, l. m. daniels, r. h. stupnisky,\n",
      "and r. p. perry. boredom in achievement settings:\n",
      "exploring control-value antecedents and performance\n",
      "outcomes of a neglected emotion. journal of\n",
      "educational psychology, 102(3):531, 2010.\n",
      "[19] r. pekrun, e. vogl, k. r. muis, and g. m. sinatra.\n",
      "measuring emotions during epistemic activities: the\n",
      "epistemically-related emotion scales. cognition and\n",
      "emotion, pages 1–9, 2016.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "103\n",
      "\n",
      "\f",
      "epistemic network analysis and topic modeling for chat\n",
      "data from collaborative learning environment\n",
      "zhiqiang cai\n",
      "\n",
      "brendan eagan\n",
      "\n",
      "nia m. dowell\n",
      "\n",
      "the university of memphis\n",
      "365 innovation drive, suite 410\n",
      "memphis, tn, usa\n",
      "\n",
      "university of wisconsin-madison\n",
      "1025 west johnson street\n",
      "madison, wi, usa\n",
      "\n",
      "the university of memphis\n",
      "365 innovation drive, suite 410\n",
      "memphis, tn, usa\n",
      "\n",
      "zcai@memphis.edu\n",
      "\n",
      "eaganb@gmail.com\n",
      "\n",
      "niadowell@gmail.com\n",
      "\n",
      "james w. pennebaker\n",
      "\n",
      "david w. shaffer\n",
      "\n",
      "arthur c. graesser\n",
      "\n",
      "university of texas-austin\n",
      "116 inner campus dr stop g6000\n",
      "austin, tx, usa\n",
      "\n",
      "university of wisconsin-madison\n",
      "1025 west johnson street\n",
      "madison, wi, usa\n",
      "\n",
      "the university of memphis\n",
      "365 innovation drive, suite 403\n",
      "memphis, tn, usa\n",
      "\n",
      "pennebaker@utexas.edu\n",
      "\n",
      "dws@education.wisc.edu\n",
      "\n",
      "art.graesser@gmail.com\n",
      "\n",
      "abstract\n",
      "this study investigates a possible way to analyze chat data from\n",
      "collaborative learning environments using epistemic network\n",
      "analysis and topic modeling. a 300-topic general topic model\n",
      "built from tasa (touchstone applied science associates) corpus was used in this study. 300 topic scores for each of the 15,670\n",
      "utterances in our chat data were computed. seven relevant topics\n",
      "were selected based on the total document scores. while the aggregated topic scores had some power in predicting students’\n",
      "learning, using epistemic network analysis enables assessing the\n",
      "data from a different angle. the results showed that the topic\n",
      "score based epistemic networks between low gain students and\n",
      "high gain students were significantly different (𝑡 = 2.00). overall,\n",
      "the results suggest these two analytical approaches provide complementary information and afford new insights into the processes\n",
      "related to successful collaborative interactions.\n",
      "\n",
      "keywords\n",
      "chat; collaborative learning; topic modeling; epistemic network\n",
      "analysis\n",
      "\n",
      "1. introduction\n",
      "collaborative learning is a special form of learning and interaction\n",
      "that affords opportunities for groups of students to combine cognitive resources and synchronously or asynchronously participate in\n",
      "tasks to accomplish shared learning goals [15; 20]. collaborative\n",
      "learning groups can range from a pair of learners (called a dyad),\n",
      "to small groups (3-5 learners), to classroom learning (25-35 learners), and more recently large-scale online learning environments\n",
      "with hundreds or even thousands of students [5; 22]. the collaborative process provides learners with a more efficient learning\n",
      "experience and improves learners’ collaborative learning skills,\n",
      "which are critical competencies for students [14]. members in a\n",
      "team are different in many ways. they have their own experience,\n",
      "knowledge, skills, and approaches to learning. a student in a col-\n",
      "\n",
      "laborative learning environment can take other students’ views\n",
      "and ideas about the information provided in the learning material.\n",
      "the ideas coming out of the team can then be integrated as a\n",
      "deeper understanding of the material, or a better solution to a\n",
      "problem.\n",
      "traditional collaborative learning occurred in the form of face to\n",
      "face group discussion or problem solving. as the internet and\n",
      "learning technologies develop, online collaborative learning environments come out and are playing more and more important\n",
      "roles. for example, moocs (massive open online courses) have\n",
      "drawn massive number of learners. learners in moocs are connected by the internet and can easily interact with each other using\n",
      "various types of tools, such as forums, blogs and social networks\n",
      "[23]. these digitized environments make it possible to track the\n",
      "learning processes in collaborative learning environments in\n",
      "greater detail.\n",
      "communication is one of the main factors that differentiates collaborative learning from individual learning [4; 6; 9]. as such,\n",
      "chats from collaborative learning environments provide rich data\n",
      "that contains information about the dynamics in a learning process. understanding massive chat data from collaborative learning\n",
      "environments is interesting and challenging. many tools have\n",
      "been invented and used in chat data analysis, such as liwc (linguistic inquiry and word count) [12], coh-metrix [10], and topic\n",
      "modeling, just to name a few. epistemic network analysis (ena)\n",
      "has been playing a unique role in analyzing chat data from epistemic games [18]. ena is rooted in a specific theory of learning:\n",
      "the epistemic frame theory, in which the collection of skill,\n",
      "knowledge, identity, value and epistemology (skive) forms an\n",
      "epistemic frame. a critical theoretical assumption of ena is that\n",
      "the connections between the elements of epistemic frames are\n",
      "critical for learning, not their presence in isolation. the online\n",
      "ena toolkit allows users to analyze chat data by comparing the\n",
      "connections within the epistemic networks derived from chats.\n",
      "ena visualization displays the clustering of learners and groups\n",
      "and the network connections of individual learners and groups.\n",
      "ena requires coded data which has traditionally relied on hand\n",
      "coded data sets or classifiers that rely on regular expression mapping. combining topic modeling with ena will provide a new\n",
      "mode of preparing data sets for analysis using ena.\n",
      "in this study, we used a combination of topic modeling and ena\n",
      "to analyze chat data to see if we could detect differences between\n",
      "the connections made by students with high learning gains versus\n",
      "students with low learning gains. incorporating topic modeling\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "104\n",
      "\n",
      "\f",
      "with ena will make the analytic tool more fully automated and of\n",
      "greater use to the research community.\n",
      "\n",
      "2. related work\n",
      "chats have two obvious features. first, they appear in the form of\n",
      "text. therefore, any text analysis tool may have a role in chat\n",
      "analysis. second, chats come from individuals’ interaction, which\n",
      "reflects social dynamics between participants. therefore, a combination of text analysis and social network analysis should be\n",
      "helpful in understanding underlying chat dynamics. for instance,\n",
      "tuulos et al. [21] combined topic modeling with social network\n",
      "analysis in chat data analysis. they found that topic modeling can\n",
      "help identify the receiver of chats (the person who a chat is given\n",
      "to).\n",
      "in a similar effort, scholand et al. [16] combined liwc and social\n",
      "network analysis to form a method called “social language network analysis” (slna). the social networks were formed by\n",
      "counting the number of times chat occurred between any two\n",
      "participants. based on the counts, participants were clustered into\n",
      "a tree structure, representing the level of subgroups the participants belong to. liwc was then used to get the text features of\n",
      "chats. it was found that, some liwc features were significantly\n",
      "different between in group conversations and out of group conversations.\n",
      "researchers have also recently explored the advantages of combining sna (social network analysis) with deeper level computational linguistic tools, like coh-metrix. coh-metrix computes\n",
      "over 100 text features. the five most important coh-metrix features are: narrativity, syntax simplicity, word concreteness, referential cohesion and deep cohesion. dowell and colleagues [8]\n",
      "explored the extent to which characteristics of discourse diagnostically reveals learners’ performance and social position in\n",
      "moocs. they found that learners who performed significantly\n",
      "better engaged in more expository style discourse, with surface\n",
      "and deep level cohesive integration, abstract language, and simple\n",
      "syntactic structures. however, linguistic profiles of the centrally\n",
      "positioned learners differed from the high performers. learners\n",
      "with a more significant and central position in their social network\n",
      "engaged using a more narrative style discourse with less overlap\n",
      "between words and ideas, simpler syntactic structures and abstract\n",
      "words. an increasing methodological contribution of this work\n",
      "highlights how automated linguistic analysis of student interactions can complement social network analysis (sna) techniques\n",
      "by adding rich contextual information to the structural patterns of\n",
      "learner interactions.\n",
      "\n",
      "final sample. within the population, 50.5% of the sample identified as caucasian, 22.2% as hispanic/latino, 15.4% as asian\n",
      "american, 4.4% as african american, and less than 1% identified\n",
      "as either native american or pacific islander.\n",
      "course details and procedure. students were told that they\n",
      "would be participating in an assignment that involved a collaborative discussion on personality disorders and taking quizzes. students were told that their assignment was to log into an online\n",
      "educational platform specific to the university at a specified time,\n",
      "where they would take quizzes and interact via web chat with one\n",
      "to four random group members. students were also instructed\n",
      "that, prior to logging onto the educational platform, they would\n",
      "have to read material on personality disorders. after logging into\n",
      "the system, students took a 10 item, multiple choice pretest quiz.\n",
      "this quiz asked students to apply their knowledge of personality\n",
      "disorders to various scenarios and to draw conclusions based on\n",
      "the nature of the disorders. the following is an example of the\n",
      "types of quiz questions students were exposed to:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "jacob was diagnosed with narcissistic personality disorder. why might dr. simon think this was the wrong\n",
      "diagnosis?\n",
      "dr. level has measured and described his 10 mice of\n",
      "varying ages in terms of their length (cm) and weight\n",
      "(g). how might he describe them on these characteristics using a dimensional approach?\n",
      "danielle checks her facebook page every hour. does\n",
      "danielle have narcissistic personality disorder?\n",
      "\n",
      "after completing the quiz, they were randomly assigned to other\n",
      "students who were waiting to engage in the chatroom portion of\n",
      "the task. when there were at least 2 students and no more than 5\n",
      "students (m = 4.59), individuals were directed to an instant messaging platform that was built into the educational platform. the\n",
      "group chat began as soon as someone typed the first message and\n",
      "lasted for 20 minutes. the chat window closed automatically after\n",
      "20 minutes, at which time students took a second 10 multiplechoice question quiz. each student contributed 154.0 words on\n",
      "average (sd = 104.9) in 19.5 sentences (sd = 12.5). as a group,\n",
      "discussions were about 714.8 words long (sd = 235.7) and 90.6\n",
      "sentences long (sd = 33.5).\n",
      "an excerpt of a collaborative interaction chat in a chat room is\n",
      "shown below in table 1. (student names have been changed):\n",
      "table 1. an excerpt of a collaborative interaction chat\n",
      "student\n",
      "\n",
      "chat text\n",
      "\n",
      "in another study, dowell et al. [7] showed that students’ linguistic\n",
      "characteristics, namely higher degrees of narrativity and deep\n",
      "cohesion, are predictive of their learning. that is, students engaged in deep cohesive interactions performed better.\n",
      "\n",
      "art\n",
      "\n",
      "ok cool, everyone's here. sooo first question\n",
      "\n",
      "art\n",
      "\n",
      "ok so the certain characteristics to be considered to\n",
      "have a personality disorder?\n",
      "\n",
      "in the present research, we explore collaborative interaction chat\n",
      "data using the combination of topic modeling and epistemic network analysis. while previous studies focused on the relationship\n",
      "between language features and social network connections, our\n",
      "study focuses on prediction learning performance by semantic\n",
      "network connections students make in chats.\n",
      "\n",
      "shaffer\n",
      "\n",
      "alright sooo first question: based on these criteria describe several reasons why a psychologist might not\n",
      "label someone with grandiose thoughts as having narcissistic personality disorder?\n",
      "\n",
      "shaffer\n",
      "\n",
      "hahaha never mind\n",
      "\n",
      "shaffer\n",
      "\n",
      "that was the second question.\n",
      "\n",
      "3. methods\n",
      "\n",
      "art\n",
      "\n",
      "lol its all good\n",
      "\n",
      "shaffer\n",
      "\n",
      "okay so certain characteristics: doesn't it have to be like\n",
      "a stable thing?\n",
      "\n",
      "carl\n",
      "\n",
      "i think the main thing about having a disorder is that its\n",
      "disruptive socially and/or makes the person a danger to\n",
      "himself or others\n",
      "\n",
      "participants. participants were enrolled in an introductory-level\n",
      "psychology course taught in the fall semester of 2011 at a large\n",
      "university in the usa. while 854 students participated in this\n",
      "course, some minor data loss occurred after removing outliers and\n",
      "those who failed to complete the outcome measures. the final\n",
      "sample consisted of 844 students. females made up 64.3% of this\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "105\n",
      "\n",
      "\f",
      "vasile\n",
      "\n",
      "yes, stable over time\n",
      "\n",
      "shaffer\n",
      "\n",
      "yeah, and it also mentioned it can't be because of drugs\n",
      "\n",
      "art\n",
      "\n",
      "also they have to have like unrealistic fantasies\n",
      "\n",
      "nia\n",
      "\n",
      "yeah and not normal in their culture\n",
      "\n",
      "carl\n",
      "\n",
      "no drugs or physical injury\n",
      "\n",
      "vasile\n",
      "\n",
      "begins in early adulthood or adolescence\n",
      "\n",
      "shaffer\n",
      "\n",
      "i think that covers them? haha\n",
      "\n",
      "art\n",
      "\n",
      "ok, so arrogance doesn't just define it, they have to have\n",
      "most of these characteristics\n",
      "\n",
      "art\n",
      "\n",
      "yeah i think we got them\n",
      "\n",
      "shaffer\n",
      "\n",
      "is it most or is it like 6?\n",
      "\n",
      "from the above excerpt, we can see several obvious things. first,\n",
      "the lengths of the utterances varied from one single word to multiple sentences. this needs to be considered in text analysis because some methods work only for longer texts. for example,\n",
      "coh-metrix usually works well for texts with more than 200\n",
      "words. topic modeling also needs enough length to reliably infer\n",
      "topic scores. second, the number of utterances each participant\n",
      "gave were different. from how much and what a member said, we\n",
      "can see each member played a different role in that chat. third,\n",
      "the ordered sequence of the utterances forms a time series. understanding and visualizing the underlying discourse dynamics are\n",
      "important for meaning making with this type of data.\n",
      "the data set contained 15,670 utterances, pretest scores (the first\n",
      "quiz) and post test scores (the second quiz) for 844 students,\n",
      "grouped in 182 chat rooms. each chat room had 2 to 5 students,\n",
      "4.73 by average. the average speech turns each student gave was\n",
      "18.2 and the average speech turns in each room was 86.1.\n",
      "the average pretest score was 36.01% correct and the average\n",
      "post-test scores 45.73% correct. paired sample test shows that the\n",
      "post-test is significantly higher (𝑡 = 14.13, 𝑁 = 844). we computed the learning gain of each student, using the formula\n",
      "𝑔𝑎𝑖𝑛 =\n",
      "\n",
      "𝑝𝑜𝑠𝑡𝑡𝑒𝑠𝑡 𝑠𝑐𝑜𝑟𝑒 − 𝑝𝑟𝑒𝑡𝑒𝑠𝑡 𝑠𝑐𝑜𝑟𝑒\n",
      "1−𝑝𝑟𝑒𝑡𝑒𝑠𝑡 𝑠𝑐𝑜𝑟𝑒\n",
      "\n",
      ".\n",
      "\n",
      "for all students (𝑁 = 844), the average learning gain is 0.11,\n",
      "59.5% had positive learning gains above 0.1. 16.5% had the same\n",
      "scores and 23% had negative learning gains. not surprisingly,\n",
      "students who had lower pretest scores had higher learning gains\n",
      "because they had greater potential to learn. figure 1 shows the\n",
      "average learning gain as function of pretest score.\n",
      "\n",
      "0.6\n",
      "0.4\n",
      "\n",
      "this data set has been analyzed in multiple studies. cade et al. [3]\n",
      "analyzed the cohesion of the chats and found that deep cohesion\n",
      "of the chats predicts the students feeling of power and connectedness to the group. dowell et al. [7] found that some coh-metrix\n",
      "measures predicts learning. coh-metrix measures describe common textual features that are not content specific. for example,\n",
      "cohesion is about how text segments are semantically linked to\n",
      "each other, which has nothing to do with what the text content is\n",
      "about. in this study, we use topic modeling to provide content\n",
      "dependent features and use epistemic network analysis to explore\n",
      "how the topics were associated in the chats.\n",
      "\n",
      "4. topic modeling\n",
      "topic modeling has been widely used in text analysis to find what\n",
      "topics are in a text and what proportion/amount of each topic is\n",
      "contained. latent dirichlet allocation (lda) [2; 24] is one of the\n",
      "most popular methods for topic modeling. lda uses a generative\n",
      "process to find topic representations. lda starts from a large\n",
      "document set 𝐷 = {𝑑1 , 𝑑2 , ⋯ , 𝑑𝑚 }. a word list 𝑊 =\n",
      "{𝑤1 , 𝑤2 , ⋯ , 𝑤𝑛 } is then extracted from the document set. lda\n",
      "assumes that the document set contains a certain number of topics,\n",
      "say, k topics. each document has a probability distribution over\n",
      "the k topics and each topic has a probability distribution over the\n",
      "given list of words. when a document was composed, each word\n",
      "that occurred in a document was assumed to be drawn based on\n",
      "the document-topic probability and the topic-word probability.\n",
      "for a given corpus (document set) and a given number of topics\n",
      "k, lda can compute the topic assignment of each word in each\n",
      "document.\n",
      "for a given topic, the word probability distribution can be easily\n",
      "computed from the number of times each word was assigned to\n",
      "the given topic. the beauty of topic modeling is that the “top\n",
      "words” (words with highest probabilities in a topic) usually give a\n",
      "meaningful interpretation of a topic. the distributions are the\n",
      "underlying representation of the topics. the top words are usually\n",
      "used to show what topics are contained in the corpus.\n",
      "by counting the number of words assigned to each topic, a topic\n",
      "proportion score can be computed for each document on each\n",
      "topic. the topic proportion scores then become a document feature that can be used in further analysis. however, the proportion\n",
      "scores are based on the statistical topic assignment of words.\n",
      "when documents are very short, such as most utterances in our\n",
      "chat data, the topic proportion scores won’t be reliable. cai et al.\n",
      "[4] argued that alternative ways to compute document topic scores\n",
      "are possible.\n",
      "\n",
      "4.1 tasa topic model\n",
      "\n",
      "0.2\n",
      "0.0\n",
      "-0.2\n",
      "\n",
      "for students with pretest scores less than 50% correct (n=624),\n",
      "the average learning gain is 0.88, 69.7% had positive learning\n",
      "gains, 15.7% had the same scores and 14.6% had negative learning gains.\n",
      "\n",
      ".00 .10 .20 .30 .40 .50 .60 .70 .80\n",
      "\n",
      "-0.4\n",
      "-0.6\n",
      "figure 1. average learning gain as a function of pretest score.\n",
      "\n",
      "although our chat data set contained 15,670 utterances, the utterances were short and the corpus is not large enough to build a\n",
      "reliable topic model. to get a reliable model, we used a well\n",
      "known corpus provided by tasa (touchstone applied science\n",
      "associates). this corpus contained documents on seven known\n",
      "categories, including business, health, home economics, industrial\n",
      "arts, language arts, science and social studies. our content topic,\n",
      "personality disorders, is obviously in the health category. of\n",
      "course, not all topics in tasa are relevant to our study. therefore, after building up the model, we need to select relevant topics. we will cover that in the next sub-section.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "106\n",
      "\n",
      "\f",
      "there are a total of 37,651 documents in tasa corpus, each of\n",
      "which is about 250 words long. before we ran lda, we filtered\n",
      "out very high frequency words and very low frequency words.\n",
      "high frequency words, such as “the”, “of”, “in”, etc., won’t contain much topic information. rare words won’t contribute to\n",
      "meaningful statistics. 28,483 words (it might be better to say\n",
      "“terms”) were left after filtering. a model with 300 topics was\n",
      "constructed by lda.\n",
      "\n",
      "4.2 topic score computation and topic selection\n",
      "from the tasa topic model, we computed the word-topic probabilities based on the number of times a word was assigned to each\n",
      "of the 300 topics. thus, each word is represented by a 300 dimensional probability distribution vector. for each chat in our chat\n",
      "corpus, we simply summed up the word probability vectors for the\n",
      "words appeared in each chat. that gave us 300 topic scores for\n",
      "each chat. recall that, the chats were associated with a reading\n",
      "material and two quizzes. while the students were free to talk\n",
      "about anything, the content of the reading material and the quizzes\n",
      "set up the main chat topics, that is, personality disorders.\n",
      "\n",
      "topic score\n",
      "1400\n",
      "1200\n",
      "1000\n",
      "800\n",
      "600\n",
      "\n",
      "200\n",
      "0\n",
      "0\n",
      "\n",
      "20\n",
      "\n",
      "40\n",
      "\n",
      "60\n",
      "\n",
      "figure 2. sorted topic scores for topic selection.\n",
      "the first thing we needed to do then was to investigate whether or\n",
      "not the “hot” topics from the computation made sense. to find\n",
      "that out, we computed the sum of all topic scores over all chats.\n",
      "the topics were sorted according the total topic score. the hottest\n",
      "topic had a total score higher than 1300, much higher than the\n",
      "second highest (less than 900). by examining the top words, this\n",
      "topic is about “illness”, which is highly relevant to personality\n",
      "disorders. six hot topics scored in the range from 600 to 900.\n",
      "they are about “outdoors”, “biology”, “people/social”, “education” and “healthcare”. the top words are listed below.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "“illness”, “biology”, “psychology” and “healthcare” are the topics\n",
      "the learning materials involved. “education” topic is about the\n",
      "education environment where the chat happened. “outdoor” and\n",
      "“people/social” are off-task topics.\n",
      "to get an idea about whether or not the topic scores were related\n",
      "to the learning gain, we aggregated the scores by person and computed the correlation between the total topic score and the learning\n",
      "gain for each topic. we were only interested in looking at the\n",
      "students with larger potential to learn, so we removed the data\n",
      "with pretest score greater than or equal to 0.5, leaving 624 students out of 844. the results (table 1) showed that all topics were\n",
      "significantly correlated to learning gain. it doesn’t seem to be\n",
      "great, because that seems to suggest that, whatever topic a student\n",
      "talked about, more a student talked, larger gain the student obtained. the real reason is that in the aggregation, all topic scores\n",
      "were summed up. therefore, all topic scores were influenced by\n",
      "the chat length. so the correlation in table 2 basically showed the\n",
      "chat length effect.\n",
      "table 2. correlation between total topic scores and learning\n",
      "gain (n=624, pretest<0.5)\n",
      "\n",
      "400\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "person, animal, mental, response, positive, stress, personality, subject, reaction\n",
      "people/social: joe, pete, mr, charlie, dad, frank, billy,\n",
      "tony, jerry, 'll, mom, 'd, going, 're, got, boys, looked,\n",
      "asked, paper, go\n",
      "education: students, teacher, teachers, child, children,\n",
      "student, school, education, schools, learning, parents,\n",
      "tests, test, program, teaching, behavior, skills, reading,\n",
      "team, information\n",
      "healthcare: patient, doctor, health, hospital, medical,\n",
      "dr, patients, nurse, disease, doctors, team, care, office,\n",
      "nursing, drugs, medicine, services, dental, diseases, help\n",
      "\n",
      "illness: health, disease, patient, body, diseases, medical,\n",
      "stress, mental, physical, heart, doctor, problems, cause,\n",
      "person, patients, exercise, illness, problem, nurse,\n",
      "healthy\n",
      "outdoors: dog, energy, plants, earth, car, light, food,\n",
      "heat, words, animals, music, rock, language, children,\n",
      "air, uncle, city, sun, women, plant\n",
      "biology: cells, cell, genes, chromosomes, traits, color,\n",
      "organisms, sex, egg, species, gene, body, male, female,\n",
      "parents, nucleus, eggs, sperm, organism, sexual\n",
      "psychology: behavior, learning, theory, environment,\n",
      "feelings, sexual, physical, social, sex, human, research,\n",
      "\n",
      "topic\n",
      "\n",
      "post-test\n",
      "\n",
      "pretest\n",
      "\n",
      "gain\n",
      "\n",
      "illness\n",
      "\n",
      ".183**\n",
      "\n",
      ".116**\n",
      "\n",
      ".132**\n",
      "\n",
      "outdoors\n",
      "\n",
      ".216**\n",
      "\n",
      ".133**\n",
      "\n",
      ".154**\n",
      "\n",
      "biology\n",
      "\n",
      ".159**\n",
      "\n",
      ".125**\n",
      "\n",
      ".105**\n",
      "\n",
      "psychology\n",
      "\n",
      ".182**\n",
      "\n",
      ".096*\n",
      "\n",
      ".140**\n",
      "\n",
      "people/social\n",
      "\n",
      ".115**\n",
      "\n",
      ".022\n",
      "\n",
      ".107**\n",
      "\n",
      "education\n",
      "\n",
      ".175**\n",
      "\n",
      ".118**\n",
      "\n",
      ".121**\n",
      "\n",
      "healthcare\n",
      "\n",
      ".157**\n",
      "\n",
      ".130**\n",
      "\n",
      ".097*\n",
      "\n",
      "to remove the chat length effect, the simplest way is to divide all\n",
      "scores by the number of words (terms) in each chat. however, in\n",
      "this study, to be consistent with subsequent analysis, we normalized the topic scores to topic proportion scores by dividing each\n",
      "topic score for each utterance by the sum of all seven topic scores\n",
      "of the same utterance.\n",
      "the results (table 3) showed that the topic “people/social” had a\n",
      "significant negative correlation to learning gain. others were not\n",
      "significant but were in the direction we would expect. “illness”,\n",
      "“biology”, “psychology” and “healthcare” were positively correlated with gain scores, while “outdoors” and “people/social” topics were negatively correlated with gains scores. we observed\n",
      "almost no correlation for the “education” topic. this seems to\n",
      "indicate that the aggregated topic scores have limited power in\n",
      "predicting learning. therefore, we used ena to examine the connections or association of these topics in the students discourse to\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "107\n",
      "\n",
      "\f",
      "develop a predictive model of learning gains based on the use of\n",
      "these topics.\n",
      "table 3. correlation between normalized topic proportion\n",
      "scores and learning gain (n=624, pretest<0.5)\n",
      "topic\n",
      "\n",
      "post-test\n",
      "\n",
      "pretest\n",
      "\n",
      "gain\n",
      "\n",
      "illness\n",
      "\n",
      ".099*\n",
      "\n",
      "0.077\n",
      "\n",
      "0.067\n",
      "\n",
      "outdoors\n",
      "\n",
      "-0.063\n",
      "\n",
      "-0.043\n",
      "\n",
      "-0.044\n",
      "\n",
      "biology\n",
      "\n",
      ".085*\n",
      "\n",
      "0.054\n",
      "\n",
      "0.063\n",
      "\n",
      "psychology\n",
      "\n",
      "0.067\n",
      "\n",
      "0.019\n",
      "\n",
      "0.058\n",
      "\n",
      "people/social\n",
      "\n",
      "-.127**\n",
      "\n",
      "-0.076\n",
      "\n",
      "-.083*\n",
      "\n",
      "education\n",
      "\n",
      "0.027\n",
      "\n",
      "0.056\n",
      "\n",
      "-0.002\n",
      "\n",
      "healthcare\n",
      "\n",
      "0.073\n",
      "\n",
      ".096*\n",
      "\n",
      "0.027\n",
      "\n",
      "5. epistemic network analysis\n",
      "ena measures the connections between elements in data and\n",
      "represents them in dynamic network models. ena creates these\n",
      "network models in a metric space that enables the comparison of\n",
      "networks in terms of (a) difference graph that highlights how the\n",
      "weighted connections of one network differ from another; and (b)\n",
      "statistics that summarize the weighted structure of network connections, enabling comparisons of many networks at once.\n",
      "ena was originally developed to model cognitive networks involved in complex thinking. these cognitive networks represent\n",
      "associations between knowledge, skills, habits of mind of individual learners or groups of learners. in this study, we used ena to\n",
      "construct network models. for each individual student, we constructed an ena network using the selected seven topic scores for\n",
      "each utterance the student contributed to the group.\n",
      "\n",
      "5.1 process\n",
      "while the process of creating ena models is described in more\n",
      "detail elsewhere (e.g. [11; 17-19]), we will briefly describe how\n",
      "ena models are created based on topic modeling. here we defined network nodes as the seven topics identified from the topic\n",
      "model. we defined the connections between nodes, or edges, as\n",
      "the strength of the co-occurrence of topics within a moving stanza\n",
      "window (msw) of size 5 [19]. to model connections between\n",
      "topics we used the products of the topic scores summed across all\n",
      "chats in the msw. that is, for each topic, the topic scores are\n",
      "summed across all 5 chats in the msw. then ena computed the\n",
      "product of the summed topic loadings for each pair topics to\n",
      "measure the strength of their co-occurrence. for example, if the\n",
      "sum of the topics scores across five chats was 0.5 for “illness”, 0.3\n",
      "for “psychology”, and 0.2 for “healthcare”, these scores would\n",
      "result in three co-occurrences, “illness-psychology”, “illnesshealthcare”, and “psychology-healthcare”, with scores of 0.15,\n",
      "0.1, and 0.06, respectively.\n",
      "next ena created adjacency matrices for each student that quantified the co-occurrences of topics within the students’ discourse\n",
      "in the context of their chat group. subsequently, the adjacency\n",
      "matrices were then treated as vectors in a high dimensional space,\n",
      "where each dimension corresponds to co-occurrence of a pair of\n",
      "topics. the vectors were then normalized to unit vectors. notice\n",
      "that the normalization removed the effect of chat length embedded\n",
      "in the topic scores. a singular value decomposition (svd) was\n",
      "then performed for dimensional reduction. ena then projected a\n",
      "vector for each student into a low dimensional space that maximizes the variance explained in the data. finally, the nodes of the\n",
      "\n",
      "networks, which in this case correspond to the seven selected\n",
      "topics generated from tasa corpus, were placed in the low dimensional space. the topic nodes were placed using an optimization algorithm such that the overall distances between centroids\n",
      "(centers of the mass of the networks) and the corresponding projected student locations was minimized. a critical feature of ena\n",
      "is that these node placements are fixed, that is, the nodes of each\n",
      "network are in the same place for all units in the analysis. this\n",
      "fixing of the location of the nodes allows for meaningful comparisons between networks in terms of their connection patterns\n",
      "which allow us to interpret the metric space. as a result, ena\n",
      "produced two coordinated representations: (1) the location of each\n",
      "student in a projected metric space, in which all units of analysis\n",
      "included in the model were located, and (2) weighted network\n",
      "graphs for each student, which explained why the student was\n",
      "positioned where it was in the space.\n",
      "ena also allows us to compare the mean network graphs and\n",
      "mean position in ena space between different groups of students. in this study, we only considered the students with high\n",
      "potential to learn, i.e., the 624 students with pretest score < 0.5\n",
      "(50% correct). among these students, we compared the networks\n",
      "of low learning gain students (gain<-0.1, 𝑁=194) with the networks of high learning gain students (gain>0.43, 𝑁=105). we\n",
      "compared these groups using difference network graph, which\n",
      "was formed by subtracting the edge weights of the mean discourse\n",
      "network for the low gain group students from the mean discourse\n",
      "network from the high gain group. this difference network graph\n",
      "shows us which topic connections are stronger for each group. in\n",
      "addition, we conducted a t-test to test the difference between\n",
      "group means.\n",
      "\n",
      "5.2 results\n",
      "figure 3 shows mean discourse networks for students with low\n",
      "gain scores (left, red), students with high gain scores (right, blue),\n",
      "and a difference network graph (center) that shows how the discourse patterns of each group differs. students with low gains had\n",
      "stronger connections between the “people/social” topic and all\n",
      "other topics except for “illness”. more importantly, the connection that was the strongest for low gain students compared to high\n",
      "gain students was between “people/social” and “outdoors”. students with high gain scores made stronger connections between\n",
      "the topics of “illness”, “psychology”, “healthcare”, “biology”, and\n",
      "“education”.\n",
      "table 4. comparison of centroids between low gain and high\n",
      "gain students, 𝒑 = 𝟎. 𝟎𝟒𝟕, 𝒕 = 𝟐. 𝟎𝟎\n",
      "n\n",
      "\n",
      "mean\n",
      "\n",
      "sd\n",
      "\n",
      "high gain\n",
      "\n",
      "105\n",
      "\n",
      "0.033\n",
      "\n",
      "0.220\n",
      "\n",
      "low gain\n",
      "\n",
      "194\n",
      "\n",
      "-0.048\n",
      "\n",
      "0.322\n",
      "\n",
      "figure 4 shows centroids, or the centers of mass, of individual\n",
      "students’ discourse networks and their means with low gain score\n",
      "students in red and high gain score students in blue. the differences between these two groups were significant on the x dimensions (see table 4). this means that the differences we saw in\n",
      "figure 2 and described above are statistically significant. in other\n",
      "words, the high learning gain students’ discourse was more towards the right side of the ena space and the low learning gain\n",
      "students’ discourse was more towards the left side. that indicates\n",
      "that the discourse of students with high learning gains made more\n",
      "connections between on-task topics (“illness”, “psychology”,\n",
      "“healthcare”, “biology”, and “education”), while the discourse of\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "108\n",
      "\n",
      "\f",
      "low gain students made more connections between off-task topics\n",
      "(“people/social” and “outdoors”).\n",
      "\n",
      "6. discussion\n",
      "ena makes it possible to visualize the chat dynamics to help\n",
      "researchers gain deeper understanding of what is going on in a\n",
      "collaborative learning environment. differences in what topics\n",
      "students connect in discourse can predict learning outcomes. previous use of ena has relied on human coded data or use of regular expressions to classify data. utilizing topic modeling can lead\n",
      "to fully automated ena, making it more accessible to a wider\n",
      "group of researchers and allows ena to be used with more and\n",
      "larger data sets.\n",
      "the fact that the epistemic network predicts learning validates\n",
      "further application of ena. for example, the turn by turn chat\n",
      "dynamics can be plotted as trajectories in the 2-d space, where the\n",
      "\n",
      "topics are placed. investigating the trajectory patterns and their\n",
      "relationship to learning or socio-affective components are interesting future research directions.\n",
      "we used a general topic model in this study. many studies in the\n",
      "literature used lda for topic modeling on relatively small corpora. this causes two problems. 1) lda topic models built upon\n",
      "small corpora are not reliable, because lda requires large number documents with relatively large size for each document. inadequate corpus can result in misleading results. 2) using a topic\n",
      "model that is not common would result in arbitrary interpretation.\n",
      "for example, the representation of “illness” from different corpus\n",
      "could be very different. therefore, it is hard to compare the claims\n",
      "made to “illness” across different studies. using a reliable, common topic models will set up a common language for different\n",
      "studies.\n",
      "\n",
      "figure 3: mean discourse networks for students with low gain scores (left, red), students with high gain scores (right, blue), and a\n",
      "difference network graph (center).\n",
      "chat utterances are too short. the statistical inference algorithm\n",
      "contains a high degree of randomness for short documents. as an\n",
      "extreme example, an utterance with a single word, would result in\n",
      "inferred topic proportion scores with “1” on one topic and “0” on\n",
      "others. the problem is that, this “1” was assigned to a topic with\n",
      "certain degree of uncertainty. that is, the topic this “1” was assigned to could be any topic. while aggregated analysis may not\n",
      "be sensitive to such uncertainty, detailed utterance by utterance\n",
      "analysis would suffer from it.\n",
      "our method of computing topic scores is based on the topic probability distribution over each word. we treat the topic distribution\n",
      "of each word as a vector. when computing the topic score, the\n",
      "simple sum of all word vectors gives scores to all topics. as we\n",
      "have pointed out, the summation algorithm will have a length\n",
      "effect. therefore, when such topic scores are used, removing\n",
      "length effects through normalization is necessary. in this article,\n",
      "we did not use weighted sum as suggested in cai et al. [4]. comparing the effect of different weighting is beyond the scope of this\n",
      "paper.\n",
      "figure 4: discourse network centroids low gain score students\n",
      "red, high gain score students blue.\n",
      "topic scores for documents are usually inferred from topic models. while for longer documents, the topic scores can be used in\n",
      "many applications (e.g., text clustering [1]), the inferred topic\n",
      "proportion scores won’t be useful for analyzing chats if we need\n",
      "to treat each utterance as a unit of analysis. it is not useful because\n",
      "\n",
      "when a general topic model is used, selecting topics relevant to\n",
      "the specific analysis becomes important. our approach was to\n",
      "look at the total scores of utterances and find the “hot” topics by\n",
      "sorting the total topic scores. in our study, we had a quickly decreasing curve that helped us to select topics. we believe this\n",
      "would be the case for most studies using a model containing far\n",
      "more topics than the topics contained in the target data.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "109\n",
      "\n",
      "\f",
      "although our study started with topic modeling to capture the\n",
      "“what” in the chats, the association networks constructed in the\n",
      "epistemic network analysis actually turned the “what” into a\n",
      "“how”: how the topics in the chats associated with each other.\n",
      "this is conceptually similar to the cohesion features dowell [7]\n",
      "and cade [3] used.\n",
      "topic modeling emphasizes content words. when a topic model is\n",
      "built, stop words are usually removed. an interesting question is,\n",
      "what if we do the opposite: keep stop words and remove content\n",
      "words? pennebaker (e.g., [13]) laid foundational work in this direction. the liwc tool pennebaker and his colleagues created\n",
      "provides over a hundred text measures by counting non-content\n",
      "words. liwc measures could provide different features to epistemic network analysis and reveal different aspects of the chat\n",
      "dynamics.\n",
      "\n",
      "7. acknowledgments\n",
      "the research on was supported by the national science foundation (drk-12-0918409, drk-12 1418288), the institute of education sciences (r305c120001), army research lab (w911inf12-2-0030), and the office of naval research (n00014-12-c0643; n00014-16-c-3027). any opinions, findings, and conclusions or recommendations expressed in this material are those of\n",
      "the authors and do not necessarily reflect the views of nsf, ies,\n",
      "or dod. the tutoring research group (trg) is an interdisciplinary research team comprised of researchers from psychology,\n",
      "computer science, and other departments at university of memphis (visit http://www.autotutor.org).\n",
      "\n",
      "8. references\n",
      "[1]\n",
      "\n",
      "alghamdi, r. and alfalqi, k. 2015. a survey of topic\n",
      "modeling in text mining. ijacsa) international journal\n",
      "of advanced computer science and applications. 6, 1\n",
      "(2015), 147–153.\n",
      "\n",
      "[2]\n",
      "\n",
      "blei, d.m., edu, b.b., ng, a.y., edu, a.s., jordan, m.i.\n",
      "and edu, j.b. 2003. latent dirichlet allocation. journal\n",
      "of machine learning research. 3, (2003), 993–1022.\n",
      "\n",
      "[3]\n",
      "\n",
      "cade, w.l., dowell, n.m.m. and pennebaker, j. 2014.\n",
      "modeling student socioaffective responses to group\n",
      "interactions in a collaborative online chat environment.\n",
      "proceedings of the 7th international conference on\n",
      "educational data mining (edm). 2, 21 (2014), 399–400.\n",
      "\n",
      "[4]\n",
      "\n",
      "[5]\n",
      "\n",
      "cai, z., li, h., graesser, a.c. and hu, x. 2016. can\n",
      "word probabilities from lda be simply added up to\n",
      "represent documents ? proceedings of the 9th\n",
      "international conference on educational data mining.\n",
      "(2016), 577–578.\n",
      "von davier, a.a. and halpin, p.f. 2013. collaborative\n",
      "problem-solving and the assessment of cognitive skills:\n",
      "psychometric considerations. ets research report\n",
      "series. december (2013), 36 p.\n",
      "\n",
      "[6]\n",
      "\n",
      "dillenbourg, p. and traum, d. 2006. sharing solutions:\n",
      "persistence and grounding in multimodal collaborative\n",
      "problem solving. the journal of the learning sciences.\n",
      "15, 1 (2006), 121–151.\n",
      "\n",
      "[7]\n",
      "\n",
      "dowell, n., cade, w. , tausczik, y., pennebaker, j., and\n",
      "graesser, a. 2014. what works: creating adaptive and\n",
      "intelligent systems for collaborative learning support.\n",
      "springer international publishing switzerland. (2014),\n",
      "124–133.\n",
      "\n",
      "[8]\n",
      "\n",
      "dowell, n.m.m., skrypnyk, s., joksimović, s., graesser,\n",
      "\n",
      "a., dawson, s., gašević, d., hennis, t. a., vries, p. de\n",
      "and kovanović, v. 2015. modeling learners ’ social\n",
      "centrality and performance through language and\n",
      "discourse. educational data mining - edm’15 (2015),\n",
      "250–257.\n",
      "[9]\n",
      "\n",
      "fiore, s.m., rosen, m. a., smith-jentsch, k. a., salas, e.,\n",
      "letsky, m. and warner, n. 2010. toward an\n",
      "understanding of macrocognition in teams: predicting\n",
      "processes in complex collaborative contexts. human\n",
      "factors. 52, 2 (2010), 203–224.\n",
      "\n",
      "[10]\n",
      "\n",
      "graesser, a.c., mcnamara, d.s., louwerse, m.m. and\n",
      "cai, z. 2004. coh-metrix: analysis of text on cohesion\n",
      "and language. behavior research methods, instruments,\n",
      "& computers. 36, 2 (2004), 193–202.\n",
      "\n",
      "[11]\n",
      "\n",
      "li, h., samei, b., olney, a., graesser, a. and shaffer, d.\n",
      "2014. question classification in an epistemic game.\n",
      "international conference on intelligent tutoring\n",
      "systems. (2014).\n",
      "\n",
      "[12]\n",
      "\n",
      "pennebaker, j.w., boyd, r.l., jordan, k. and blackburn,\n",
      "k. 2015. the development and psychometric properties\n",
      "of liwc2015. austin, tx: university of texas at austin.\n",
      "(2015).\n",
      "\n",
      "[13]\n",
      "\n",
      "pennebaker, j.w., chung, c.k., frazee, j. and lavergne,\n",
      "g.m. 2014. when small words foretell academic\n",
      "success : the case of college admissions essays.\n",
      "(2014), 1–10.\n",
      "\n",
      "[14]\n",
      "\n",
      "rosen, y. 2014. assessing collaborative problem\n",
      "solving through computer agent technologies.\n",
      "encyclopedia of information science and technology. 9,\n",
      "november (2014), 94–102.\n",
      "\n",
      "[15]\n",
      "\n",
      "sawyer, r.k. 2014. the new science of learning. the\n",
      "cambridge handbook of the learning sciences. 1–18.\n",
      "\n",
      "[16]\n",
      "\n",
      "scholand, a.j., tausczik, y.r. and pennebaker, j.w.\n",
      "2010. assessing group interaction with social language\n",
      "network analysis. lecture notes in computer science\n",
      "(including subseries lecture notes in artificial\n",
      "intelligence and lecture notes in bioinformatics). 6007\n",
      "lncs, (2010), 248–255.\n",
      "\n",
      "[17]\n",
      "\n",
      "shaffer, d.w. 2006. epistemic frames for epistemic\n",
      "games. computers and education. 46, 3 (2006), 223–\n",
      "234.\n",
      "\n",
      "[18]\n",
      "\n",
      "shaffer, d.w., hatfield, d., svarovsky, g.n., nash, p.,\n",
      "nulty, a., bagley, e., frank, k., rupp, a.a. and\n",
      "mislevy, r.j. 2009. epistemic network analysis: a\n",
      "prototype for 21st-century assessment of learning.\n",
      "international journal of learning and media. 1, 2\n",
      "(2009), 33–53.\n",
      "\n",
      "[19]\n",
      "\n",
      "siebert-evenstone, a.l., arastoopour, g., collier, w.,\n",
      "swiecki, z., ruis, a.r. and shaffer, d.w. 2016. in\n",
      "search of conversational grain size: modeling semantic\n",
      "structure using moving stanza windows. international\n",
      "conference of the learning sciences. (2016).\n",
      "\n",
      "[20]\n",
      "\n",
      "slavin, r.e. 1995. cooperative learning: theory,\n",
      "research and practice (2nd ed.). the nature of learning.\n",
      "(1995), 208.\n",
      "\n",
      "[21]\n",
      "\n",
      "tuulos, v.h. and tirri, h. 2004. combining topic\n",
      "models and social networks for chat data mining.\n",
      "proceedings of the 2004 ieee/wic/acm international\n",
      "conference on web intelligence. october (2004), 206–\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "110\n",
      "\n",
      "\f",
      "213.\n",
      "[22]\n",
      "[23]\n",
      "\n",
      "whitepaper, a.r. 2014. what happens when we learn\n",
      "together. (2014).\n",
      "yousef, a.m.f., chatti, m.a., schroeder, u., wosnitza,\n",
      "m. and jakobs, h. 2014. a review of the state-of-theart. proceedings of the 6th international conference on\n",
      "\n",
      "computer supported education - csedu2014. (2014),\n",
      "9–20.\n",
      "[24]\n",
      "\n",
      "wang z., qiu b., bai, w., chuan, s. and le, y. 2014.\n",
      "collapsed gibbs sampling for latent dirichlet\n",
      "allocation on spark. jmlr: workshop and conference\n",
      "proceedings. 2004 (2014), 17–28.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "111\n",
      "\n",
      "\f",
      "towards closing the loop: bridging machine-induced\n",
      "pedagogical policies to learning theories\n",
      "guojing zhou, jianxun wang, collin f. lynch, min chi\n",
      "department of computer science\n",
      "north carolina state university\n",
      "raleigh, nc 27695\n",
      "\n",
      "{gzhou3,jwang75,cflynch,mchi}@ncsu.edu\n",
      "abstract\n",
      "in this study, we applied decision trees (dt) to extract\n",
      "a compact set of pedagogical decision-making rules from\n",
      "an original full set of 3,702 reinforcement learning (rl)induced rules, referred to as the dt-rl rules and full-rl\n",
      "rules respectively. we then evaluated the effectiveness of\n",
      "the two rule sets against a baseline random condition in\n",
      "which the tutor made random yet reasonable decisions. we\n",
      "explored two types of trees (weighted and unweighted) as\n",
      "well as two pruning strategies (pre- and post-pruning). we\n",
      "found that post-pruned weighted trees produced the best results with 529 dt-rl rules. the empirical evaluation was\n",
      "conducted in a classroom study using an existing intelligent\n",
      "tutoring system (its) named pyrenees. 153 students were\n",
      "randomly assigned to three conditions. the procedure was\n",
      "the same for all students with domain content and required\n",
      "steps strictly controlled. the only substantive differences\n",
      "between the three conditions were the policy: (full-rl vs.\n",
      "dt-rl vs. random). our result showed that as expected\n",
      "the machine induced policies (full-rl and dt-rl) are significantly more effective than the random policy; more importantly, no significant difference was found between the\n",
      "full-rl and dt-rl policies though the number of dt-rl\n",
      "rules is less than 15% of the number of the full-rl rules\n",
      "and the former group also took significantly less time than\n",
      "the latter.\n",
      "\n",
      "1.\n",
      "\n",
      "introduction\n",
      "\n",
      "intelligent tutoring systems (itss) are interactive e-learning\n",
      "environments that support students’ learning by providing\n",
      "instruction, scaffolded practice, and on-demand help. the\n",
      "system’s behaviors can be viewed as a sequential decisionmaking process where at each step the system chooses an\n",
      "appropriate action from a set of options. pedagogical strategies are the policies used to decide what action to take next\n",
      "in the face of alternatives. each system decision will affect\n",
      "the user’s subsequent actions and performance. its impact\n",
      "on outcomes cannot always be immediately observed and the\n",
      "effectiveness of each decision depends upon the effectiveness\n",
      "\n",
      "of subsequent actions. ideally, an effective learning environment will adapt its decisions to users’ specific needs [1, 11].\n",
      "however, there is no existing well-established theory on how\n",
      "to make these system decisions effectively. generally speaking, prior research on pedagogical policies can be divided\n",
      "into two general categories: top-down or theory-driven, and\n",
      "bottom-up or data-driven.\n",
      "in theory-driven approaches, itss employ hand-coded pedagogical rules that seek to implement existing cognitive or\n",
      "learning theories [1, 10, 17]. while existing learning literature gives helpful guidance on the design of pedagogical\n",
      "rules, such guidance is often too general to implement as\n",
      "effective immediate decisions. for example, the aptitudetreatment interaction (ati) theory states that instructors\n",
      "should match their interventions to the aptitude of the learner\n",
      "[5]. while the principle behind this theory is understandable, it is not clear how to implement that rule for each\n",
      "decision. how do we represent learner’s aptitude for each\n",
      "equation, how exact should be the system’s adaptation, and\n",
      "so on.\n",
      "data-driven approaches, on the other hand, derive pedagogical policies directly from prior data. here the policies\n",
      "specify the pedagogical decisions at a detailed level. reinforcement learning (rl), which we use here, is one popular\n",
      "approach that is able to derive pedagogical policies directly\n",
      "from student-system interaction logs. these policies are defined as a set of state-action mapping rules, which give the\n",
      "best decision to take in each state. the states are typically\n",
      "represented as sets of features and the actions are pedagogical actions such as presenting a worked example (we) or\n",
      "requiring the student to solve problems (ps). when the system presents a worked example, the students will be given a\n",
      "detailed example showing a complete expert solution for the\n",
      "problem or the best step to take given their current solution\n",
      "state. in problem solving, by contrast, students are tasked\n",
      "with solving a problem using the its or with completing an\n",
      "individual problem-solving step.\n",
      "for this project, our original complete rl-induced policy involves the following seven features representing the students’\n",
      "learning process from different perspectives1 .\n",
      "\n",
      "1\n",
      "in the format of: [feature-name] (discretization procedure): explanation of the feature.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "112\n",
      "\n",
      "\f",
      "1. [nwesinceps] (0 → 0; (0, 1] → 1; (1, +∞) → 2):\n",
      "the number of worked example (we) steps received\n",
      "since the last problem solving (ps) step.\n",
      "2. [timeinsession] ([0, 2290] → 0; (2290, 4775] → 1;\n",
      "(4775, 7939] → 2; (7939, +∞) → 3): the total time\n",
      "spent in the current session.\n",
      "3. [avgtimeonstepps] ([0, 29.01] → 0; (29.01,\n",
      "48.71] → 1; (48.71, +∞) → 2): the average amount of\n",
      "time spent on each ps step.\n",
      "4. [avgtimeonstepsessionps] ([0, 23.51] → 0;\n",
      "(23.51, 36.56] → 1; (36.56, 55] → 2; (55, +∞) → 3):\n",
      "the average amount of time spent on each ps step in\n",
      "the current session.\n",
      "5. [nstepsincelastwrongkc] ([0, 1] → 0; (1, 7]\n",
      "→ 1; (7, 25] → 2; (25, +∞) → 3): the number of steps\n",
      "received since the last wrong ps step on the current\n",
      "knowledge component (kc).\n",
      "6. [nwestepsincelastwrong] ([0, 1] → 0; (1, 4]\n",
      "→ 1; (4, 10] → 2; (10, +∞) → 3): the number of we\n",
      "steps since the last wrong ps step.\n",
      "7. [ncorrectpsstepsincelastwrongkcsession]\n",
      "(0 → 0; (0, 3] → 1; (3, 10] → 2; (10, +∞) → 3): the\n",
      "number of correct ps steps since the last wrong ps\n",
      "step on the current kc in the current session.\n",
      "with this feature set, a state can be represented as a 7dimensional vector where each element denotes a discretized\n",
      "feature value. then, the rules can then be represented as:\n",
      "(0:0:0:0:0:0:0) -> ps\n",
      "(0:0:0:0:0:0:1) -> ps\n",
      "(0:0:0:0:0:1:0) -> ps\n",
      "(0:0:0:0:0:1:1) -> we\n",
      "in this study we discretized the features into three-four values producing a seven-feature state. this results in a state\n",
      "space of 32 ∗ 45 = 9216, that is 9216 rules in one rl-induced\n",
      "policy. while these types of polices can specify the exact\n",
      "action to take in each case, they are usually too narrow to\n",
      "be aligned to existing learning theories. each of the rules\n",
      "covers only a very specific case and the relationship between\n",
      "rules is unknown. thus it is impossible to explain the power\n",
      "of those rules from the perspective of learning theory. the\n",
      "opacity of those induced rules not only hinders us in improving data-driven methodologies when they go wrong, it also\n",
      "prevents us from advancing learning science research more\n",
      "generally. moreover, it is possible that some of the decisions\n",
      "are environment-specific and may not generalize to other\n",
      "contexts. this in turn prevents translating these induced\n",
      "policies to environments other than the one from which they\n",
      "are induced. therefore, a general method is needed to shed\n",
      "some light on the extracted detailed data-driven policies.\n",
      "decision tree (dt) induction is a robust data mining approach which can be used to extract a compact set of rules\n",
      "from a set of specific examples. it builds a tree-like hierarchical decision-making pattern which represents the knowledge it learned. each path from root to leaf represents a\n",
      "single rule which may be dealt with separately. prior studies have shown that dts can match training examples in\n",
      "most cases, even with relatively small trees. davidson et\n",
      "\n",
      "al., for example, built a dt for predicting the extinction\n",
      "risk of mammals [6]. each of the species was described by\n",
      "11 ecological features (e.g body mass, geographic range and\n",
      "population density) and were labeled with their extinction\n",
      "risk (threatened vs. non-threatened). their tree contained\n",
      "20 general rules which covered 4500 training examples, with\n",
      "a decision accuracy over 80%. additionally, reinchard et al.\n",
      "built a dt for predicting the invasiveness of woody plants\n",
      "[13]. the resulting dt encoded 15 rules from 235 examples,\n",
      "with a decision accuracy over 76%. therefore, in our study,\n",
      "we will apply dt to extract general pedagogical decisionmaking rules from the detailed rl-induced policies.\n",
      "in short, our primary research question is: is dt an effective methodology for extracting more general pedagogical\n",
      "rules from the detailed rl-induced pedagogical rules? in order to investigate this question, we will build dts using the\n",
      "rules in a rl-induced policy as training examples and empirically evaluate the effectiveness of the extracted set of dt\n",
      "rules by comparing it to the full set of rl-induced rules in a\n",
      "classroom study. the state features in the rl-induced policies are the input features for the dt and the pedagogical\n",
      "actions are the output labels. in our empirical evaluation,\n",
      "we separate the pedagogical decisions from the instructional\n",
      "content, strictly controlling the content so that it is equivalent for all participants by 1) using an its which provides\n",
      "equal support for all learners; and 2) focusing on tutorial\n",
      "decisions that cover the same domain content, in this case\n",
      "we versus ps.\n",
      "\n",
      "2. background\n",
      "2.1 applying rl to itss\n",
      "beck et al. applied rl to induce pedagogical policies that\n",
      "would minimize the time students take to complete problems on animalwatch, an its for grade school arithmetic\n",
      "[2]. they trained the model with simulated students. the\n",
      "low cost of generated data allowed them to apply a modelfree rl method, temporal difference learning. during the\n",
      "test phase, the induced policies were added to animalwatch\n",
      "and the new system was empirically compared with the original system. their results showed that the policy group\n",
      "spent significantly less time per problem than their no-policy\n",
      "peers. note that their primary goal was to reduce the amount\n",
      "of time per problem, however faster problem-solving does\n",
      "not always result in better learning performance. nonetheless, their results showed that rl can be successfully applied\n",
      "to induce pedagogical policies for itss.\n",
      "iglesias et al., on the other hand, focused on applying rl to\n",
      "improve the effectiveness of an intelligent educational system that teaches students database design [8, 9]. they\n",
      "applied another model-free rl algorithm, q-learning to induce policies that provide students with direct navigation\n",
      "support through the system’s content. they used simulated\n",
      "students to induce the policy and empirically evaluated its\n",
      "effectiveness on real students. their results showed that\n",
      "while the policy led to more effective system usage behaviors from students, the policy students did not outperform\n",
      "the no-policy peers in terms of learning outcomes.\n",
      "shen investigated the impact of both immediate and delayed reward functions on rl-induced policies and empirically evaluated the effectiveness of the induced policies within\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "113\n",
      "\n",
      "\f",
      "an intelligent tutoring system called deep thought [15].\n",
      "the induced pedagogical policies are used to decide whether\n",
      "the next task should be we or ps. they found that some\n",
      "learners benefited significantly more from effective pedagogical policies than others.\n",
      "finally, chi et al. applied model-based rl to induce pedagogical policies to improve the effectiveness of an intelligent\n",
      "natural language tutoring system for college-level physics\n",
      "called cordillera [4]. the authors collected an exploratory\n",
      "corpus by training human students on an its that makes\n",
      "random decisions and then applied rl to induce pedagogical policies from the corpus. they showed that the induced\n",
      "policies were significantly more effective than the prior ones.\n",
      "in short, prior studies have shown that rl-induced pedagogical policies can improve students’ learning or reduce\n",
      "training time. however, all of these studies focused on the\n",
      "effectiveness of the rl-induced policies. none of them considered extracting more general rules from the induced policies.\n",
      "\n",
      "2.2\n",
      "\n",
      "extracting general rules\n",
      "\n",
      "in addition to the work of davidson et al. [6] and reinchard\n",
      "et al. [13], dts have been used for other tasks. vayssiers\n",
      "et al., for example, applied classification and regression\n",
      "trees to predict the presence of 3 species of oak in california [18]. their training examples were vegetation type map\n",
      "records for 2085 unique locations. each record consisted of\n",
      "25 climatic and geographic features as well as 3 labels showing the presence of the species (quercus agrifolia, quercus\n",
      "douglasii and quercus lobata). one dt was induced for\n",
      "each type. the dts were tested on another dataset which\n",
      "contains the same type of records for 2016 locations. for\n",
      "quercus agrifolia, the induced tree had 10 leaf nodes and\n",
      "94.9% of its predictions are correct for the locations that\n",
      "have the presence of this oak (sensitivity) while 86.7% of\n",
      "its predictions are correct for cases without the oak (specificity). for quercus douglasii, the induced tree had 22 leaf\n",
      "nodes and a sensitivity and specificity of 87% and 79.9%\n",
      "respectively. for quercus lobata, the tree had 6 leaves but\n",
      "reached a sensitivity of 77% and a specificity of 73.3%.\n",
      "thus, prior studies have shown that dt can effectively extract a small set of general decision-making rules from a\n",
      "large set of specific examples. however, all the examples\n",
      "used by these studies were observations of existing phenomena. so far as we know, this work is the only relevant research on the application of dt to extract a compact set\n",
      "of decision-making rules directly from full rl-induced rules\n",
      "and empirically evaluated the two sets of the rules.\n",
      "\n",
      "2.3\n",
      "\n",
      "applying dt to rl\n",
      "\n",
      "prior research on incorporating dt with rl has largely\n",
      "focused on seeking a better representation of state space\n",
      "or policy for rl. boutilier et al [3]. proposed representational and computational techniques for markov decision\n",
      "processes (mdps) to reduce the size of the state space.\n",
      "they used dynamic bayesian networks and dts to represent stochastic actions as well as dts to represent rewards.\n",
      "based upon this representation, they then developed algorithms to find conditional optimal policies. their method\n",
      "was empirically evaluated on several planning problems and\n",
      "\n",
      "they showed significant savings in both time and space for\n",
      "some types of problems. gupta et al. proposed the policy\n",
      "tree algorithm for rl. this algorithm is designed to directly\n",
      "induce a functional representation of the conditional optimal\n",
      "policies as a dt. they evaluated it on a variety of domains\n",
      "and showed that it was able to make splits properly [7].\n",
      "in short, prior researchers have shown that properly combining dt with rl can result in a large amount of savings\n",
      "in time and space for finding good policies. however, none\n",
      "of these studies directly applied dt on rl-induced policies.\n",
      "\n",
      "3.\n",
      "\n",
      "induce full set of rl-policy\n",
      "\n",
      "previously, researchers have typically used the markov decision process (mdp) [16] framework to model user-system\n",
      "interactions. the central idea behind this approach is to\n",
      "transform the problem of inducing effective pedagogical policies on what action the agent should take to the problem of\n",
      "computing an optimal policy for an mdp.\n",
      "\n",
      "3.1 markov decision process\n",
      "an mdp is a mathematical framework for representing an\n",
      "rl task. it is defined by: a tuple hs , a, t , ri. where s =\n",
      "{s1 , s2 , ..., sn } denotes the state space; a = {a1 , a2 , ..., am }\n",
      "represents a set of agent’s possible actions; and t : s × a ×\n",
      "s → [0, 1] is a transition probability table, where each element is tsai sj = p(sj |si , a). this in turn indicates the\n",
      "probability of transiting from state si to state sj by taking an action a while r : s × a × s → r assigns rewards\n",
      "to state transitions given actions. the policy is defined as\n",
      "π : s → a, mapping state s into action a with the goal of\n",
      "maximizing the expected reward.\n",
      "after defining an mdp, we can transfer the student-system\n",
      "interaction dialog into the trajectory which can then be represented as follows:\n",
      "a ,r\n",
      "\n",
      "a ,r\n",
      "\n",
      "a ,r\n",
      "\n",
      "1\n",
      "2\n",
      "3\n",
      "s1 −−1−−→\n",
      "s2 −−2−−→\n",
      "s3 −−3−−→\n",
      "... → sn\n",
      "\n",
      "a ,r\n",
      "\n",
      "i\n",
      "where si −−i−−→\n",
      "si+1 means that the tutor executed action\n",
      "ai and received reward ri in state si , and then transferred\n",
      "to the next state si+1 . in general, the reward can be divided\n",
      "into two categories, immediate and delayed, where immediate rewards are received during the state transition, and\n",
      "delayed are available after reaching to goal state.\n",
      "\n",
      "3.2 training datasets\n",
      "our training dataset was collected from three exploratory\n",
      "studies in which students were trained on an its which made\n",
      "random yet reasonable pedagogical decisions. the studies\n",
      "were given as homework assignments during csc226: discrete mathematics, a core cs course offered at ncsu during the fall 2014, spring 2015 and fall 2015 semesters. the\n",
      "dataset contains a total of 149 students’ interaction logs.\n",
      "all students used the same its, followed the same general\n",
      "procedure, studied the same training materials, and worked\n",
      "through the same training problems. in order to model the\n",
      "students’ learning process, we extracted a total of 142 state\n",
      "feature variables, which can be grouped into five categories:\n",
      "1. autonomy (am): the amount of work done by the student: such as the number of problems solved so far pscount\n",
      "or the number of hints requested hintcount.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "114\n",
      "\n",
      "\f",
      "2. temporal situation (ts): the time related information about the work process: such as the average time taken\n",
      "per problem avgtime, or the total time spent solving a problem totalpstime.\n",
      "3. problem solving (ps): information about the current\n",
      "problem solving context, such as the difficulty of the current\n",
      "problem probdiff, or whether the student changes the difficulty level newlevel.\n",
      "4. performance (pm): information about the student’s\n",
      "performance during problem solving: such as the number of\n",
      "right application of rules rightapp.\n",
      "5. student action (sa): the statistical measurement of\n",
      "student’s behavior: such as the number of non-empty-click\n",
      "actions that students take actioncount, or the number of\n",
      "clicks for derivation appcount.\n",
      "\n",
      "based methods and an ensemble method and capped the\n",
      "maximum number of state feature size to be eight. more\n",
      "details of our feature selection methods are described in [14].\n",
      "the final resulting rl policy involves seven state features\n",
      "and 3706 rules.\n",
      "\n",
      "3.3\n",
      "\n",
      "4.1 unweighted vs. weighted tree\n",
      "\n",
      "inducing rl policies\n",
      "\n",
      "in order to apply rl to induce pedagogical policies, we\n",
      "first defined the pedagogical decision-making problem as an\n",
      "mdp. the state representation includes all of the relevant\n",
      "features available at the beginning of each step. the actions are we and ps at the step level. the transition tables were calculated on our training dataset, and our reward\n",
      "function includes two types of reward: delayed and immediate. our most important reward is based on normalized\n",
      "), which measures the\n",
      "learning gain (nlg) ( posttest−pretest\n",
      "1−pretest\n",
      "students’ learning gains irrespective of their incoming competence. this reward was given as a delayed reward as nlg\n",
      "scores can only be calculated after students finish the entire\n",
      "training process. however, shen et al. [15] showed that giving immediate rewards can lead to the production of more\n",
      "effective policies when compared to delayed rewards. this\n",
      "is known as the credit-assignment problem. the more that\n",
      "we delay success measures from a series of sequential decisions, the more difficult it becomes to identify which of the\n",
      "decision(s) in the sequence are responsible for our final success or failure. therefore, for the purposes of this study we\n",
      "also assigned immediate rewards based upon the students’\n",
      "performance during training on the system.\n",
      "the value iteration algorithm was applied to find the optimal\n",
      "policy. this algorithm operates by finding the optimal value\n",
      "for each state v ∗ (s). the optimal value for a given state is\n",
      "the expected discounted reward that the agent will gain if\n",
      "it starts in s and follows the optimal policy to the goal.\n",
      "generally speaking, v ∗ (s) can be obtained by the optimal\n",
      "value function for each state-action pair q∗ (s, a) which is\n",
      "defined as the expected discounted reward the agent will\n",
      "gain if it takes an action a in a state s and follows the optimal\n",
      "policy to the end. the optimal state value v ∗ (s) and value\n",
      "function q∗ (s, a) can be obtained by iteratively updating\n",
      "v (s) and q(s, a) via equations 1 and 2 until they converge:\n",
      "x\n",
      "q(s, a) := r(s, a) + γ\n",
      "p(sj |si , a)v (s0 )\n",
      "(1)\n",
      "v (s)\n",
      "\n",
      ":=\n",
      "\n",
      "s0 ∈s\n",
      "\n",
      "max q(s, a)\n",
      "a\n",
      "\n",
      "(2)\n",
      "\n",
      "here, p(sj |si , a) is the estimated transition model t , r(s, a)\n",
      "is the estimated reward model and 0 ≤ γ ≤ 1 is a discount\n",
      "factor.\n",
      "to induce effective pedagogical policies, we combined rl\n",
      "with various feature selections including 10 types of correlation-\n",
      "\n",
      "4.\n",
      "\n",
      "extracting compact dt-rl sets\n",
      "\n",
      "in order to extract a more compact set of decision-making\n",
      "rules from the full set of rl-induced rules, we implemented\n",
      "the id3 algorithm to build dts [12]. each rule in the final\n",
      "rl-induced policy was used as a training example. two\n",
      "types of decision trees were built: unweighted and weighted,\n",
      "as well as two types of pruning strategies were implemented:\n",
      "pre- and post-pruning. next, we will discuss each of them\n",
      "in turn.\n",
      "\n",
      "the decision to give a we vs. ps may impact students’\n",
      "learning differently in different situations. we therefore built\n",
      "two types of decision trees: unweighted and weighted. unweighted trees treated each decision equally while weighted\n",
      "trees take account of the relative importance of each pedagogical rule. when applying the value iteration algorithm\n",
      "to induce the optimal policy, we generate the optimal value\n",
      "function q∗ (s, a), which gives the expected discounted reward each agent will gain if it takes an action a in a state s\n",
      "and follows the optimal policy to the end. for a given state\n",
      "s, a large difference between the values of q(s, “p s”) and\n",
      "q(s, “w e”) indicates that it is more important for the its\n",
      "to follow the optimal decision in the state s. we therefore\n",
      "used the absolute difference between the q values for each\n",
      "state s to weight each rl pedagogical rule.\n",
      "the id3 algorithm builds a tree recursively from root to\n",
      "leaves. on each iteration of the construction process the\n",
      "algorithm will check the state of the dataset for the current\n",
      "branch. it will then select a test feature for the current\n",
      "node based upon the weighted information gain. the current\n",
      "node will then be expanded by adding branches to it, each\n",
      "of which represents a possible value for the selected feature.\n",
      "the data will be partitioned over the branches according to\n",
      "the value of the test feature. the selected feature cannot\n",
      "be used again by its children. weighted information gain is\n",
      "defined by the difference between the weighted entropy of the\n",
      "examples before it is selected and after they are separated\n",
      "by feature value. the weighted entropy of a node can be\n",
      "calculated by equation 3\n",
      "h(g) = −\n",
      "\n",
      "j\n",
      "x\n",
      "\n",
      "p(i|g)log2 p(i|g)\n",
      "\n",
      "(3)\n",
      "\n",
      "i=1\n",
      "\n",
      "j is the total number of output label classes. in our case,\n",
      "it is the number of pedagogical actions (we or ps) which\n",
      "is 2 . p(i|g) is the\n",
      "weighted frequency defined by the equap\n",
      "p\n",
      "w\n",
      "tion: p(i|g) = p x∈i wxy .\n",
      "x∈i wx is the total weight of the\n",
      "y∈g\n",
      "examples\n",
      "which\n",
      "are\n",
      "in\n",
      "node\n",
      "g and which belong to class i.\n",
      "p\n",
      "and y∈g wy is the total weights of examples in node g.\n",
      "the information gain of spliting the current set of training\n",
      "examples using feature f can be calculated by equation 4:\n",
      "ig(f, g) = h(g) −\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "k\n",
      "x\n",
      "j=1\n",
      "\n",
      "p(tj |g)h(tj )\n",
      "\n",
      "(4)\n",
      "\n",
      "115\n",
      "\n",
      "\f",
      "p(tj |g) is the\n",
      "weighted frequency of the examples in node g:\n",
      "p\n",
      "p\n",
      "xf =t,x∈g wx\n",
      "p\n",
      "p(tj |g) =\n",
      ".\n",
      "xf =t,x∈g wx is the total weights\n",
      "y∈g wy\n",
      "of\n",
      "examples\n",
      "in\n",
      "nodes\n",
      "g\n",
      "whose\n",
      "value of feature f is j and\n",
      "p\n",
      "y∈g wy is the total weight of examples in nodes g.\n",
      "\n",
      "4.2\n",
      "\n",
      "pre-pruning and post-pruning\n",
      "\n",
      "to control the size of rules induced by dt, we examined\n",
      "two types of pruning strategy: pre- and post-pruning. the\n",
      "pre-pruning is conducted during the process of building the\n",
      "tree and it used the information gain to determine whether\n",
      "to expand or to terminate. only nodes with an information\n",
      "gain greater than a threshold times its depth: ig(f, g) ≥\n",
      "θ × dg will be expanded and others will be made as a leaf.\n",
      "θ is a fixed threshold and dg is the depth of node g.\n",
      "post-pruning is conducted after the whole decision tree is\n",
      "built and it used the error rate as the pruning measure. the\n",
      "error\n",
      "rate before a node is expanded is defined as: eg =\n",
      "p\n",
      "i∈i wi\n",
      ". i is the set of the decisions incorrectly classified\n",
      "|g|\n",
      "by node g and |g| is the total number of examples in the\n",
      "node g. the\n",
      "p error\n",
      "p rate after a node is expanded is defined\n",
      "wi\n",
      "as: ec = c∈c |g|j∈ic . c is the set of children nodes\n",
      "of g after it is expanded and ic is the set of the decisions\n",
      "incorrectly classified by the node c. in post-pruning, if the\n",
      "difference of a node’s error rate from before to after split is\n",
      "less than a threshold, the node will be pruned by removing\n",
      "all of its branches to make it a leaf node.\n",
      "\n",
      "4.3\n",
      "\n",
      "the compact set of dt-rl rules\n",
      "\n",
      "in order to induce a compact set of dt-rl rules, we applied the dts to the full set of 3706 rl-induced rules. the\n",
      "induced unweighted and weighted dts without pruning has\n",
      "2527 and 2456 rules (leaf nodes) respectively. thus, without pruning, dts are already able to extract a smaller set\n",
      "of rules: it reduced the total number of rules by over 1000.\n",
      "figure 1 shows the relationship between the number of leaf\n",
      "nodes (x-axis) and the inverted weighted accuracy (y-axis).\n",
      "weighted accuracy(w a) is the weighted percentage of decisions correctlypmade, which can be calculated by the equation: w a =\n",
      "\n",
      "di ∈t\n",
      "\n",
      "p\n",
      "\n",
      "di\n",
      "\n",
      "wi\n",
      "\n",
      "wi\n",
      "\n",
      ". t is the set of correct predictions\n",
      "\n",
      "made by a dt and wi is the weight of decision i. the inverted weighted accuracy (iw a) is iw a = w a−10 , the\n",
      "lower the better. since our goal is to find a good balance\n",
      "point between the iwa and the number of leaf nodes, we\n",
      "applied a widely used strategy called the elbow method,\n",
      "to select the best tree. as we can see in the figure, the\n",
      "elbows for the two unweighted tree approaches are around\n",
      "800 and 1700 rules (x-axis) for the pre and post pruning\n",
      "respectively while the elbows for the two weighted tree approaches are around 250 and 500 for the pre and post pruning respectively. so it seems that weighted tree can extract\n",
      "more compact set of rules than the unweighted trees. while\n",
      "the weighted pre-pruning approach has around 250 rules,\n",
      "its iwa is much higher than the weighted post-pruning approach. therefore, we chose the weighted tree with postpruning strategy which has the an elbow at about 500 leaf\n",
      "nodes and reasonable iwa.\n",
      "to further justify our dt choice, table 1 shows the relationship between the pruning thresholds, w a and the number\n",
      "\n",
      "figure 1: leaf nodes - accuracy\n",
      "of leaf nodes for the weighted tree with post-pruning. table 1 shows that the tree with the closest number of leaves\n",
      "to 500 is the 529 one. it can be obtained by apply a pruning\n",
      "threshold of 0.8 and the result tree has a weighted accuracy\n",
      "of 0.76. the rules in the resulted tree will be the rules used\n",
      "in the dt-rl condition.\n",
      "in short, we applied dt on rl-induced pedagogical policies\n",
      "to extract a more compact set of decision-making rules. the\n",
      "effectiveness of the original full set and the compact set of\n",
      "policies were empirically compared against a baseline policy\n",
      "which makes random yet reasonable decisions: ps vs. we.\n",
      "thus, we have three conditions:\n",
      "1. full-rl: the full set of 3706 rl-induced rules.\n",
      "2. dt-rl: the compact set of 529 dt-induced rl rules.\n",
      "3. random: the random yet reasonable policy.\n",
      "\n",
      "5.\n",
      "\n",
      "empirical experiment\n",
      "\n",
      "participants: this study was conducted in the undergraduate discrete mathematics course at the department\n",
      "of computer science at nc state university in the fall of\n",
      "2016. 153 students participated in this study, which was\n",
      "given as their final homework assignment.\n",
      "conditions: students in the study were assigned to three\n",
      "conditions via balanced random assignment based upon their\n",
      "course section and performance on the class mid-term exam.\n",
      "since the primary goal of this work is to examine the effectiveness of the two rl based policies, we assigned more\n",
      "students to the full-rl and dt-rl conditions than in the\n",
      "random condition. the final group sizes were: n = 61 (fullrl), n = 51 (dt-rl), and n = 41 (random).\n",
      "due to preparations for exams and length of the experiment,\n",
      "126 students completed the experiment. 5 students were\n",
      "excluded from the subsequent analysis due to perfect pretest\n",
      "scores, working in group or gaming the system during the\n",
      "training. the remaining 121 students were distributed as\n",
      "follows: n = 45 for full-rl; n = 41 for rl-dt; n = 35\n",
      "for random. we performed a χ2 test of the relationship\n",
      "between students’ condition and their rate of completion\n",
      "and found no significant difference among the conditions:\n",
      "χ2 (2) = 0.955, p = 0.620.\n",
      "probability tutor: pyrenees is a web-based its for probability. it covers 10 major principles of probability, such\n",
      "as the complement theorem and bayes’ rule. pyrenees\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "116\n",
      "\n",
      "\f",
      "threshold\n",
      "wa\n",
      "leaves\n",
      "\n",
      "table 1: weighted dt with post-pruning\n",
      "0\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "1.00 0.99 0.98 0.96 0.93 0.89 0.85 0.79\n",
      "2456 2217 2029 1809 1608 1383 1043 758\n",
      "\n",
      "provides step-by-step instruction and immediate feedback.\n",
      "pyrenees can also provide on-demand hints prompting the\n",
      "student with what they should do next. as with other systems, help in pyrenees is provided via a sequence of increasingly specific hints. the last hint in the sequence, the\n",
      "bottom-out hint, tells the student exactly what to do. for\n",
      "the purposes of this study we incorporated three distinct\n",
      "pedagogical decision modes into pyrenees to match the three\n",
      "conditions.\n",
      "procedure: in this experiment, students were required to\n",
      "complete 4 phases: 1) pre-training, 2) pre-test, 3) training on\n",
      "pyrenees, and 4) post-test. during the pre-training phase,\n",
      "all students studied the domain principles through a probability textbook, reviewed some examples, and solved certain\n",
      "training problems. the students then took a pre-test which\n",
      "contained 14 problems. the textbook was not available at\n",
      "this phase and students were not given feedback on their answers, nor were they allowed to go back to earlier questions.\n",
      "this was also true of the post-test.\n",
      "during phase 3, students in all three conditions received\n",
      "the same 12 rather complicated problems in the same order\n",
      "on pyrenees. each main domain principle was applied at\n",
      "least twice. the minimal number of steps needed to solve\n",
      "each training problem ranged from 20 to 50. these steps\n",
      "included defining variables, applying principles, and solving equations. the number of domain principles required to\n",
      "solve each problem ranged from 3 to 11. all of the students\n",
      "could access the corresponding pre-training textbook during this phase. each step in the problems could have been\n",
      "provided as either a we or ps based upon the condition\n",
      "policy. finally, all of the students completed a post-test\n",
      "with 20 problems. 14 of the problems were isomorphic to\n",
      "the pre-test given in phase 2. the remaining six were nonisomorphic complicated problems.\n",
      "grading criteria: the test problems required students to\n",
      "derive an answer by writing and solving one or more equations. we used three scoring rubrics: binary, partial credit,\n",
      "and one-point-per-principle. under the binary rubric, a solution was worth 1 point if it was completely correct or 0\n",
      "if not. under the partial credit rubric, each problem score\n",
      "was defined by the proportion of correct principle applications evident in the solution. a student who correctly applied 4 of 5 possible principles would get a score of 0.8. the\n",
      "one-point-per-principle rubric in turn gave a point for each\n",
      "correct principle application. all of the tests were graded in\n",
      "a double-blind manner by a single experienced grader. the\n",
      "results presented below are based upon the partial-credit\n",
      "rubric but the same results hold for the other two. for\n",
      "comparison purposes, all test scores were normalized to the\n",
      "range of [0,1].\n",
      "\n",
      "6.\n",
      "\n",
      "0.8\n",
      "0.76\n",
      "529\n",
      "\n",
      "0.9\n",
      "0.68\n",
      "231\n",
      "\n",
      "empirical results\n",
      "\n",
      "since both the full-rl and dt-rl policies are based on an\n",
      "rl-induced policy, we combined the two conditions together\n",
      "as the induced group to evaluate the effectiveness the rlinduced policy. the evaluation was conducted by comparing\n",
      "the induced group with the baseline random condition on\n",
      "learning performance and training time. moreover, in order to further discover to what extent the compact policy\n",
      "retained the power of the full policy, we compared the fullrl and dt-rl conditions on the same measures. next, we\n",
      "will discuss each of the comparisons in turn.\n",
      "\n",
      "6.1 induced vs. random\n",
      "we measured students’ incoming competence via the pretest scores collected before training took place. table 2\n",
      "shows a comparison between the induced group and the\n",
      "random group in terms of learning performance. the parenthesized values following the group names in row 1 denote\n",
      "the number of students in each group. the second row in this\n",
      "table shows the pre-test scores. the last column shows the\n",
      "pairwise t-test results. pairwise t-tests on students’ pre-test\n",
      "scores show that there is no significant difference between\n",
      "the two groups: t(119) = −0.346, p = 0.730, d = 0.069.\n",
      "thus, despite attrition, the two groups remained balanced\n",
      "in terms of incoming competence. next, we will compare the\n",
      "two groups in terms of learning performance in the post-test\n",
      "and training time.\n",
      "rows 2 - 4 in table 2 show a comparison of the pre-test, isomorphic post-test (14 isomorphic questions), and adjusted\n",
      "post-test scores between the two groups along with the mean\n",
      "and sd for each. in order to examine the students’ improvement through training on pyrenees, we compared their\n",
      "scores on the pre-test and isomorphic post-test questions.\n",
      "a repeated measures analysis using test type (pre-test and\n",
      "isomorphic post-test) as factors and test score as the dependent measure showed a main effect for test type: f (1, 119) =\n",
      "98.75, p < 0.0001. further comparisons on group by group\n",
      "basis showed that on the isomorphic questions, both groups\n",
      "scored significantly higher in the post-test than in the pretest: f (1, 85) = 81.30, p < 0.0001 for induced and f (1, 34) =\n",
      "18.30, p = 0.0001 for random respectively. this suggests\n",
      "that the basic practice and problems, domain exposure, and\n",
      "interactivity of our its might help students to learn even\n",
      "when pedagogical decisions are made randomly.\n",
      "in order to investigate the effectiveness of the induced policies, we compared students’ overall learning performance,\n",
      "which was evaluated by their adjusted post-test scores, between the two groups. a one-way ancova analysis was\n",
      "conducted on their overall post-test scores (20 questions),\n",
      "using the pretest scores as a covariate to factor out the influence of their incoming competence. the result shows a\n",
      "significant main effect: f (1, 118) = 4.628, p = 0.033. that\n",
      "is, the induced group significantly outperformed the random group on adjusted post-test scores, which is shown in\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "117\n",
      "\n",
      "\f",
      "cond\n",
      "pre\n",
      "iso post\n",
      "adjusted post\n",
      "time\n",
      "we steps\n",
      "ps steps\n",
      "we pct(%)\n",
      "\n",
      "table 2: induced vs. random\n",
      "induced(86)\n",
      "random(35)\n",
      "t-test result\n",
      ".686(.194)\n",
      ".699(.171)\n",
      "t(119) = −0.346, p = 0.730, d = 0.069\n",
      ".851(.155)\n",
      ".812(.195)\n",
      "t(119) = 1.141, p = 0.256, d = 0.229\n",
      ".751(.144)\n",
      ".689(.138)\n",
      "t(119) = 2.162, p = 0.033, d = 0.433\n",
      "105.87(34.30) 111.18(27.33) t(119) = −0.815, p = 0.417, d = 0.163\n",
      "205.74(62.73) 189.46(11.39)\n",
      "t(119) = 1.522, p = 0.131, d = 0.305\n",
      "173.69(61.14) 190.26(10.28) t(119) = −1.591, p = 0.114, d = 0.319\n",
      "54.16(16.35)\n",
      "49.89(2.78)\n",
      "t(119) = 1.532, p = 0.128, d = 0.307\n",
      "\n",
      "the fourth row of table 2. therefore, the results showed that\n",
      "the induced policies are significantly more effective than the\n",
      "random policy.\n",
      "the fifth row in table 2 shows the average amount of total\n",
      "training time (in minutes) students spent on our its for each\n",
      "group. pairwise t-test showed no significant difference in\n",
      "training time between the two groups: t(119) = −0.815, p =\n",
      "0.417, d = 0.163. the results suggest that when compared\n",
      "to the random policy, the induced policies generally do not\n",
      "have a significant different impact on students’ training time.\n",
      "the last three rows in table 2 show the number of we\n",
      "and ps steps given as well as the percentage of we steps\n",
      "received by the induced and the random group. pairwise\n",
      "t-tests showed that there is no significant difference between\n",
      "the two groups on these three measures.\n",
      "\n",
      "6.2\n",
      "\n",
      "full-rl vs. dt-rl\n",
      "\n",
      "we then performed the same comparison between the fullrl and dt-rl conditions in order to examine the effectiveness of the dt-extracted compact policy. the second row\n",
      "in table 3 shows the pre-test scores for each condition. a\n",
      "pairwise t-test on the scores shows no significant difference\n",
      "between the two conditions: t(84) = −0.168, p = 0.867,\n",
      "d = 0.036. thus the two conditions were balanced in terms\n",
      "of incoming competence.\n",
      "the pre-test, isomorphic post-test and adjusted post-test\n",
      "scores are shown in rows 2 - 4 of table 3. a repeated measures analysis using test type (pre-test and isomorphic posttest) as factors and test score as dependent measure showed\n",
      "a main effect for test type: f (1, 85) = 81.30, p < 0.0001.\n",
      "further comparisons on group by group basis showed that\n",
      "both conditions scored significantly higher in isomorphic\n",
      "post-test than in pre-test: f (1, 44) = 42.16, p < 0.0001\n",
      "for full-rl and f (1, 40) = 39.16, p < 0.0001 for dt-rl.\n",
      "these results suggest that the students can effectively learn\n",
      "from pyrenees with the full and compact policies.\n",
      "in order to discover to what degree the compact policy retained the effectiveness of the full policy, we compared the\n",
      "post-test scores between the two conditions. the results\n",
      "of a pairwise t-test showed no significant different between\n",
      "them on isomorphic post-test: t(84) = 0.505, p = 0.615,\n",
      "d = 0.109. we also conducted an ancova analysis on the\n",
      "overall post-test scores using the pretest scores as a covariate and still found no significant different between the two\n",
      "conditions: f (1, 83) = 0.348, p = 0.557. in short, while on\n",
      "post-test scores, the dt-rl condition scored slightly lower\n",
      "than the full-rl condition, the difference is not significant.\n",
      "\n",
      "the fifth row of table 3 shows the average amount of time\n",
      "students spent on training. as the row shows, the fullrl condition spent significantly more time than the dt-rl\n",
      "condition: t(84) = 3.829, p = 0.0002, d = 0.827. thus\n",
      "the full-rl and dt-rl policies have significant different\n",
      "impact upon the students’ training time.\n",
      "the last three rows of table 3 show the number of we\n",
      "and ps steps given and the percentage of we steps received by the full-rl and the dt-rl condition. pairwise t-tests showed that comparing to the dt-rl condition, the full-rl condition received significantly fewer we\n",
      "steps: t(84) = −4.952, p < 0.0001, d = 1.069; received a\n",
      "lower percentage of we steps: t(84) = −4.955, p < 0.0001,\n",
      "d = 1.070; and completed more ps steps: t(84) = 4.999,\n",
      "p < 0.0001, d = 1.079. these results suggest that the pedagogical decisions made by the compact and full policies are\n",
      "substantively different.\n",
      "\n",
      "7.\n",
      "\n",
      "discussion\n",
      "\n",
      "in this study, we applied dt to extract a compact set of\n",
      "pedagogical rules from the full set of rl-induced rules and\n",
      "empirically evaluated the effectiveness of two sets of rules in\n",
      "a classroom study. our goal was to shed some light on the\n",
      "rl-induced policies and we think this is only the first step\n",
      "towards narrowing the gap and building a bridge between\n",
      "machine-induced pedagogical policies and learning theories.\n",
      "in order to find the best dt, we explored two types of tree:\n",
      "unweighted and weighted; and for each of them, we conducted two types of pruning strategy: pre- and post-pruning.\n",
      "after comparing the performance among them, we selected\n",
      "the weighted tree with the post-pruning strategy to perform\n",
      "the extraction of general decision-making rules. the rlinduced policy contains 3706 specific rules, and the compact\n",
      "dt-rl consisted of 529 rules with a weighted decision accuracy of 76%.\n",
      "in our empirical experiment, we were able to strictly control\n",
      "the domain content and thus to isolate the impact of pedagogy from content. based on this isolation, we compared\n",
      "students’ performance with the full-rl policy, the dt-rl\n",
      "policy and the baseline random policy. our results showed\n",
      "that students in all three conditions learned significantly after training on pyrenees, this suggests that the basic training\n",
      "of the its is effective, even when the pedagogical decisions\n",
      "are made randomly. to evaluate the effectiveness of the two\n",
      "machine induced policies (full-rl policy and dt-rl policy), we combined the full-rl and dt-rl condition as the\n",
      "induced group and compared its learning performance with\n",
      "the random group. our results showed that the induced\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "118\n",
      "\n",
      "\f",
      "cond\n",
      "pre\n",
      "iso post\n",
      "adjusted post\n",
      "time\n",
      "we steps\n",
      "ps steps\n",
      "we pct(%)\n",
      "\n",
      "table 3: full-rl vs. dt-rl\n",
      "full-rl(45)\n",
      "dt-rl (41)\n",
      "t-test result\n",
      ".683(.205)\n",
      ".690(.184)\n",
      "t(84) = −0.168, p = 0.867, d = 0.036\n",
      ".859(.145)\n",
      ".842(.168)\n",
      "t(84) = 0.505, p = 0.615, d = 0.109\n",
      ".757(.144)\n",
      ".739(.145)\n",
      "t(84) = 0.594, p = 0.554, d = 0.128\n",
      "118.42(35.000) 92.10(27.95)\n",
      "t(84) = 3.829, p = 0.0002, d = 0.827\n",
      "177.44(48.86) 236.80(62.03) t(84) = −4.952, p < 0.0001, d = 1.069\n",
      "201.47(47.22) 143.20(60.57)\n",
      "t(84) = 4.999, p < 0.0001, d = 1.079\n",
      "46.77(12.78)\n",
      "62.26(16.13) t(84) = −4.955, p < 0.0001, d = 1.070\n",
      "\n",
      "group significantly outperform the random group. these\n",
      "results suggest that the machine induced policies are indeed\n",
      "more effective than the random policy.\n",
      "finally, in order to examine to what extent the compact dtrl policy retained the power of the full rl-induced policy,\n",
      "we compared the learning performance of the full-rl and\n",
      "the dt-rl conditions. our results suggest that while some\n",
      "of the power was lost in the general rules extraction, the relative performance difference between the full-rl and the\n",
      "dt-rl condition is not significant. in addition, our results\n",
      "on the pedagogical decisions made in training revealed that\n",
      "the compact dt-rl policy selected significant more we\n",
      "than the full-rl policy. this suggests that the two sets\n",
      "of policies indeed made materially different decisions. however, since the weighted dt took account of the importance\n",
      "of each rule, the dt-rl policy aims to retain maximal decision effectiveness from the full-rl policy while the size of\n",
      "the former is less than 15% of the size of the full-rl rules.\n",
      "in the future, we will apply existing learning theories to the\n",
      "decision-making process generated by decision tree to find\n",
      "a theoretical basis for the dt-induced general pedagogical\n",
      "decision-making rules.\n",
      "\n",
      "8.\n",
      "\n",
      "acknowledgements\n",
      "\n",
      "this research was supported by the nsf grant #1432156:\n",
      "“educational data mining for individualized instruction in\n",
      "stem learning environments” and #1651909: “improving\n",
      "adaptive decision making in interactive learning environments”.\n",
      "\n",
      "9.\n",
      "\n",
      "references\n",
      "\n",
      "[1] j. r. anderson, a. t. corbett, k. r. koedinger, and\n",
      "r. pelletier. cognitive tutors: lessons learned. the\n",
      "journal of the learning sciences, 4(2):167–207, 1995.\n",
      "[2] j. beck, b. p. woolf, and c. r. beal. advisor: a\n",
      "machine learning architecture for intelligent tutor\n",
      "construction. aaai/iaai, 2000:552–557, 2000.\n",
      "[3] c. boutilier, r. dearden, and m. goldszmidt.\n",
      "stochastic dynamic programming with factored\n",
      "representations. artificial intelligence, 121(1):49–107,\n",
      "2000.\n",
      "[4] m. chi, k. vanlehn, d. litman, and p. jordan.\n",
      "empirically evaluating the application of\n",
      "reinforcement learning to the induction of effective\n",
      "and adaptive pedagogical strategies. user modeling\n",
      "and user-adapted interaction, 21(1-2):137–180, 2011.\n",
      "[5] l. j. cronbach and r. e. snow. aptitudes and\n",
      "instructional methods: a handbook for research on\n",
      "interactions. irvington, 1977.\n",
      "\n",
      "[6] a. d. davidson and et al. multiple ecological pathways\n",
      "to extinction in mammals. proceedings of the national\n",
      "academy of sciences, 106(26):10702–10705, 2009.\n",
      "[7] u. d. gupta, e. talvitie, and m. bowling. policy tree:\n",
      "adaptive representation for policy gradient. in aaai,\n",
      "pages 2547–2553, 2015.\n",
      "[8] a. iglesias, p. martı́nez, r. aler, and f. fernández.\n",
      "learning teaching strategies in an adaptive and\n",
      "intelligent educational system through reinforcement\n",
      "learning. applied intelligence, 31(1):89–106, 2009.\n",
      "[9] a. iglesias, p. martı́nez, r. aler, and f. fernández.\n",
      "reinforcement learning of pedagogical policies in\n",
      "adaptive and intelligent educational systems.\n",
      "knowledge-based systems, 22(4):266–270, 2009.\n",
      "[10] k. r. koedinger and et al. intelligent tutoring goes to\n",
      "school in the big city. ijaied, 8(1):30–43, 1997.\n",
      "[11] p. phobun and j. vicheanpanya. adaptive intelligent\n",
      "tutoring systems for e-learning systems.\n",
      "procedia-social and behavioral sciences,\n",
      "2(2):4064–4069, 2010.\n",
      "[12] j. r. quinlan. induction of decision trees. machine\n",
      "learning, 1(1):81–106, 1986.\n",
      "[13] s. h. reichard and c. w. hamilton. predicting\n",
      "invasions of woody plants introduced into north\n",
      "america. conservation biology, 11(1):193–203, 1997.\n",
      "[14] s. shen and m. chi. aim low: correlation-based\n",
      "feature selection for model-based reinforcement\n",
      "learning. edm, 2016.\n",
      "[15] s. shen and m. chi. reinforcement learning: the\n",
      "sooner the better, or the later the better? in umap,\n",
      "pages 37–44. acm, 2016.\n",
      "[16] r. s. sutton and a. g. barto. reinforcement learning:\n",
      "an introduction, volume 1. mit press cambridge,\n",
      "1998.\n",
      "[17] k. vanlehn. the behavior of tutoring systems.\n",
      "ijaied, 16(3):227–265, 2006.\n",
      "[18] m. p. vayssières, r. e. plant, and b. h. allen-diaz.\n",
      "classification trees: an alternative non-parametric\n",
      "approach for predicting species distributions. journal\n",
      "of vegetation science, 11(5):679–694, 2000.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "119\n",
      "\n",
      "\f",
      "on the influence on learning of student compliance with\n",
      "prompts fostering self-regulated learning\n",
      "sébastien lallé\n",
      "\n",
      "cristina conati\n",
      "\n",
      "roger azevedo\n",
      "\n",
      "university of british columbia\n",
      "2366 main mall\n",
      "vancouver, bc v6t1z4, canada\n",
      "\n",
      "university of british columbia\n",
      "2366 main mall\n",
      "vancouver, bc v6t1z4, canada\n",
      "\n",
      "north carolina state university\n",
      "106 caldwell hall\n",
      "raleigh, nc 27695-8101, usa\n",
      "\n",
      "lalles@cs.ubc.ca\n",
      "\n",
      "conati@cs.ubc.ca\n",
      "\n",
      "razeved@ncsu.edu\n",
      "\n",
      "nicholas mudrick\n",
      "\n",
      "michelle taub\n",
      "\n",
      "north carolina state university\n",
      "106 caldwell hall\n",
      "raleigh, nc 27695-8101, usa\n",
      "\n",
      "north carolina state university\n",
      "106 caldwell hall\n",
      "raleigh, nc 27695-8101, usa\n",
      "\n",
      "nvmudric@ncsu.edu\n",
      "\n",
      "mtaub@ncsu.edu\n",
      "\n",
      "abstract\n",
      "in this paper, we investigate the relationship between students’\n",
      "learning gains and their compliance with prompts fostering selfregulated learning (srl) during interaction with metatutor, a\n",
      "hypermedia-based intelligent tutoring systems (its). when possible, we evaluate compliance from student explicit answers on\n",
      "whether they want to follow the prompts, when such answers are\n",
      "not available, we mine several student behaviors related to prompt\n",
      "compliance. these behaviors are derived from students’ eyetracking and interaction data (e.g., time spent on a learning page,\n",
      "number of gaze fixations on that page). our results reveal that\n",
      "compliance with some, but not all srl prompts provided by\n",
      "metatutor do influence learning. these results contribute to gain\n",
      "a better understanding of how students benefit from srl prompts,\n",
      "and provides insights on how to further improve their effectiveness. for instance, prompts that do improve learning when followed could be the focus of adaptation designed to foster compliance for those students who would disregard them otherwise.\n",
      "conversely, prompts that do not improve learning when followed\n",
      "could be improved based on further investigations to understand\n",
      "the reason for their lack of effectiveness\n",
      "\n",
      "keywords\n",
      "intelligent tutoring systems; self-regulated learning; scaffolding;\n",
      "compliance with prompts; learning gains; eye tracking; linear\n",
      "regression; hypermedia\n",
      "\n",
      "1. introduction\n",
      "there is extensive evidence that the effectiveness of intelligent\n",
      "tutoring systems (its) is influenced by how well students can\n",
      "regulate their learning, e.g., [13, 22]. current research has shown\n",
      "that scaffolding self-regulated learning (srl) strategies such as\n",
      "setting learning goals or assessing progress through the learning\n",
      "content can improve learning outcomes with an its, e.g., [1, 10,\n",
      "22]. in particular, one of the most common approaches to scaffold\n",
      "srl is to deliver prompts designed to guide students in applying\n",
      "specific srl strategies as needed [22]. previous work has focused\n",
      "on assessing the general effectiveness of such srl prompts, for\n",
      "instance by comparing learning outcomes of students working\n",
      "with versions of the same its with and without the prompts. (e.g.,\n",
      "[1, 19, 21]). other work has investigated the extent to which\n",
      "students comply with the overall set of prompts generated by an\n",
      "its [16, 21]. however, there has been no reported study on the\n",
      "\n",
      "relationship between compliance with specific srl prompts and\n",
      "learning outcomes. in this paper, we aim to fill this gap. specifically, we explore the impact of student compliance with srl\n",
      "prompts on learning gains with metatutor, an its designed to\n",
      "scaffold student srl processes while learning about topics of the\n",
      "human circulatory system [1].\n",
      "our results show that student learning is influenced by compliance with some, but not all, of the srl prompts delivered by\n",
      "metatutor. overall, we found a positive impact on learning for\n",
      "compliance with prompts fostering learning strategies (revising a\n",
      "summary, reviewing notes), or planning processes (setting new\n",
      "learning goals). on the other hand, we found no impact on learning with prompts related to metacognitive monitoring processes\n",
      "(e.g., prompts to stay on or move away from the current page\n",
      "depending on student performance on a quiz on that page). having information on the efficacy of each specific prompt in a its is\n",
      "important to guide further research on how to improve prompts\n",
      "that do not seem to improve learning when students follow them.\n",
      "furthermore, prompts that foster learning when followed can\n",
      "become the focus of adaptive interventions designed to improve\n",
      "compliance for those students who would disregard these prompts\n",
      "if left to their own device.\n",
      "the paper also provides initial insights into prompts design issues\n",
      "that affect how easy it is to evaluate compliance. in metatutor,\n",
      "some prompts explicitly asked students whether they wanted to\n",
      "follow the prompt, and then provided suitable affordance to accommodate a positive reply. compliance with these prompts is\n",
      "easy to assess, but the additional interactions that they require\n",
      "might not always be possible, or might even be intrusive for some\n",
      "students. other prompts did not require any specific response\n",
      "from the students. thus, such prompts are in less danger of being\n",
      "intrusive, and provide for a more open-ended interaction. on the\n",
      "other hand, assessing compliance with these prompts is not trivial,\n",
      "because there is no clear definition of what compliance means.\n",
      "for example, one of the metatutor prompts asks students to reread the current metatutor content page, but there is no obvious\n",
      "way to map this rather generic suggestion to a specific desired\n",
      "behavior (e.g., spend a specific amount of time on the page, read a\n",
      "specific number of words). we addressed this problem by running\n",
      "linear models to correlate a variety of student behaviors related to\n",
      "prompt compliance with learning. the behaviours we mined are\n",
      "based on both action and eye-tracking data (e.g., time spent on\n",
      "that page, gaze fixations on the content of the page), and our\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "120\n",
      "\n",
      "\f",
      "figure. 1. screenshot of metatutor.\n",
      "results provide initial evidence that combining these two data\n",
      "sources can help to evaluate compliance. thus, our findings represent a step toward research on how to evaluate compliance with\n",
      "prompts, both for the type of off line analysis presented in this\n",
      "paper, as well as for the real-time detection of compliance necessary if we want to have itss that adaptively help students follow\n",
      "prompts as needed.\n",
      "the remainder of the paper starts with an overview of related\n",
      "work, followed by a description of metatutor and the study that\n",
      "generated the dataset we used for this research. next, we illustrate\n",
      "how we mined data to evaluate compliance with metatutor’s\n",
      "prompts, the statistical analysis we conducted, and our results.\n",
      "\n",
      "2. related work\n",
      "there has been extensive work on assessing the effectiveness of\n",
      "scaffolding designed to support learning with itss. scaffolding\n",
      "can include prompts or hints (i.e., interventions that guide the\n",
      "student in the right direction), feedback (evaluation of students\n",
      "answers, behavior or strategies), or demonstration (e.g., worked\n",
      "examples showing expert behavior) [22, 23]. such scaffolding can\n",
      "be domain-specific to support the acquisition of domain-specific\n",
      "knowledge, or targeting domain-independent, meta-cognitive\n",
      "learning processes such as processes for self-regulated learning\n",
      "(srl). there is extensive evidence that both domain-specific\n",
      "scaffolding (e.g., [3, 12, 18, 20]) and meta-cognitive scaffolding\n",
      "(e.g., [2, 10, 11, 21]) can improve the effectiveness of its. for\n",
      "example, domain-specific hints that explain how to solve the\n",
      "current problem step have been shown to improve skill acquisition in a variety of domains such as mathematics [20] and reading\n",
      "[3, 12]. at the meta-cognitive level, roll et al. [21] tracked\n",
      "suboptimal help-seeking patterns (e.g., overuse of help) to deliver\n",
      "prompts and feedback on how to effectively use help. prompts\n",
      "and feedback designed to help construct self-explanations during\n",
      "reading [10] or solving scientific problems [11] have been found\n",
      "\n",
      "to positively influence learning. azevedo et al. [2] showed that\n",
      "srl prompts and feedback effectively foster efficient use of srl\n",
      "strategies while learning about biology.\n",
      "research has also examined student compliance with srl\n",
      "prompts in its [5, 16]. kardan and conati [16] examined the\n",
      "benefit of providing a variety of prompts designed to help students progress within an interactive learning simulation. overall\n",
      "they found that students largely complied with the prompts and\n",
      "that providing these prompts improved learning gains. however,\n",
      "they did not explore whether and how compliance with specific\n",
      "prompts influence learning outcomes, and which prompts are the\n",
      "most effective. bouchet et al. [5] adapted the frequency of prompt\n",
      "delivery in metatutor based on whether students previously complied with prompts of the same type. however, their analysis\n",
      "uncovered no influence of such adaptive prompting strategy on\n",
      "learning gains. we extend the aforementioned work on prompt\n",
      "compliance by showing how learning gains are impacted by compliance with some, but not all srl prompts in metatutor. furthermore, whereas previous solely used interaction data to evaluate compliance, we also leverage eye-tracking data when compliance cannot be inferred directly from students’ answers or actions\n",
      "(e.g., compliance with the prompts of reading a text further).\n",
      "eye-tracking has been used in its to model a variety of students\n",
      "traits and behavior, e.g., emotions [14], learning outcomes [15],\n",
      "metacognitive behavior [7], or mind wandering [4]. eye tracking\n",
      "has also been used to capture students attention to prompts [6, 8]\n",
      "and to pedagogical agents [17]. conati et al. [6] leveraged gaze\n",
      "data to detect whether students processed domain-specific textual\n",
      "prompts in an educational game for math, and found that reading\n",
      "the prompts more extensively improved game performance. lallé\n",
      "et al. [17] used gaze data to capture student visual attention to\n",
      "pedagogical agents in metatutor, and found that student learning\n",
      "gains are significantly influenced by specific metrics for visual\n",
      "attention (fixation rate, longest fixation). eye-tracking has also\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "121\n",
      "\n",
      "\f",
      "been used to add real-time adaptive prompts to guru, an agentbased its for learning biology [9]. in that work, audible prompts\n",
      "designed to reorient student attention towards the screen were\n",
      "triggered if a student had not looked at the screen for more than 5s\n",
      "while guru was providing scaffolding. this research showed that\n",
      "this gaze-reactive feedback can improve learning with guru. in\n",
      "our work, we mine eye-tracking data to evaluate compliance with\n",
      "specific srl prompts, and examine whether and how compliance\n",
      "with such srl prompts influences learning gains.\n",
      "\n",
      "3. metatutor\n",
      "metatutor [1] is a hypermedia-based its containing multiple\n",
      "pages of content about the circulatory system, as well as mechanisms to help students self-regulating their learning with the assistance of multiple speaking pedagogical agents (pas). when working with metatutor, students are given the overall goal of learning\n",
      "as much as they can about the human circulatory system. the\n",
      "main interface of metatutor (see fig. 1) includes a table of contents (fig. 1a), the text of the current content page (fig.1b), a\n",
      "miniature image allowing the student to display a diagram along\n",
      "with the text (fig. 1c), the current goals and subgoals to learn\n",
      "about (fig. 1e), a timer indicating how much time remains in the\n",
      "learning session (fig. 1f), and an srl palette (fig. 1d). this\n",
      "palette is designed to scaffold students self-regulatory processes\n",
      "by providing buttons they can select to initiate specific srl activities (e.g., making a summary, taking a quiz, setting subgoals).\n",
      "further srl scaffolding is provided by three pas in the form of\n",
      "feedback on student performance on these srl activities (e.g.,\n",
      "performance on quiz or on the quality of their summaries), as well\n",
      "as prompts designed to guide these activities as needed. the pas\n",
      "deliver these prompts based on student behavior (e.g., time spent\n",
      "on page, number of pages visited).\n",
      "specifically, pam the planner prompts planning processes primarily at the beginning of the learning session by suggesting to\n",
      "add a new subgoal and, if needed, which one to choose (e.g., path\n",
      "of blood flow, heart components). mary the monitor scaffolds\n",
      "students’ metacognitive monitoring processes by making them\n",
      "take quizzes on the target material when they appear to be ready\n",
      "for them. based on quiz outcomes, mary prompts students to\n",
      "evaluate the relevance of the current content and subgoal to their\n",
      "knowledge, and suggests how to move through the available material and sub goals accordingly. sam the strategizer prompts students to apply the learning strategies consisting of summarizing\n",
      "the content studied so far or reviewing notes they have taken on\n",
      "the content1.\n",
      "all pas provide audible assistance through the use of a text-tospeech engine (nuance). the pas are visually rendered using\n",
      "haptek virtual characters, which generate idle movements when\n",
      "the pas are not speaking (subtle, gradual head and eye movements), as well as lip movements during speech.\n",
      "\n",
      "4. user study\n",
      "the data used for the analysis presented in this paper were collected via a user study designed to gain a general understanding of\n",
      "how students learn with metatutor [1]. the study included the\n",
      "collection of a variety of multi-channel trace data (e.g., eye track-\n",
      "\n",
      "1\n",
      "\n",
      "more details about the design of the agents can be found in [1].\n",
      "\n",
      "ing, log files, physiological sensors). in this paper, we focus on\n",
      "using interaction and eye-tracking data to track compliance with\n",
      "the srl prompts provided by metatutor, and study the relationship among compliance with the prompts and learning gains.\n",
      "twenty-eight college students participated in the study, which\n",
      "consisted of two sessions conducted on separate days. during the\n",
      "first session, lasting approximately 30-60 minutes, students were\n",
      "administered several questionnaires, including a 30-item pretest to\n",
      "assess their knowledge of the circulatory system. during the second session lasting approximately three hours, students first underwent a calibration phase with the eye tracker (smi red 250)\n",
      "as well as a training session on metatutor. each student was then\n",
      "given 90 minutes to interact with the system. finally, students\n",
      "completed a posttest analogous to the pretest, followed by a series\n",
      "of questionnaires about their experience with metatutor.\n",
      "\n",
      "5. data analysis\n",
      "5.1 evaluating compliance with prompts\n",
      "in our analysis we categorize prompts into two types based on\n",
      "how compliance can be evaluated. the first type includes prompts\n",
      "for which compliance can be explicitly assessed from students\n",
      "subsequent responses (explicit compliance prompts); the second\n",
      "type includes prompts for which compliance needs to be inferred\n",
      "by mining a variety of behaviors (inferred compliance prompts).\n",
      "explicit compliance prompts are those that:\n",
      " require students to answer “yes” or “no” (using a dialogue\n",
      "panel that becomes active at the bottom of the display). if students answers yes, the only action they can perform in the\n",
      "metatutor interface is the one they agreed upon (e.g., adding a\n",
      "specific subgoal suggested by the agent, making or revising a\n",
      "summary, moving to a previously added subgoal or staying on\n",
      "the current one)2.\n",
      " require students to take a specific action within a specific time\n",
      "frame (i.e., open the diagram while they are on the current page,\n",
      "and review notes by the end of the learning session).\n",
      "table 1 lists the explicit compliance prompts considered in this\n",
      "analysis.\n",
      "inferred compliance prompts are those for which the pas do not\n",
      "force students to provide an explicit answer. specifically, after the\n",
      "agent utters one of these prompts, the student simply clicks on\n",
      "“continue” in the same dialogue panel, and can either ignore the\n",
      "prompted action, or comply at some point. these prompts (listed\n",
      "in table 2) include all prompts related to staying on or moving\n",
      "away from the current page, as well as initiating the action of\n",
      "adding a new subgoal.\n",
      "\n",
      "5.2 statistical analysis\n",
      "our analysis aims to investigate if and how compliance with\n",
      "metatutor’s srl prompts influence learning. the variable we\n",
      "\n",
      "2\n",
      "\n",
      "for the “stay on current subgoal” prompt, students are not forced\n",
      "to comply after answering “yes”, but we have listed it in this\n",
      "category because student are still required to explicitly answer\n",
      "“yes” or “no” to the pas as for whether they want to follow the\n",
      "prompt or not.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "122\n",
      "\n",
      "\f",
      "table 1. list of explicit compliance prompts provided in metatutor (grouped by type of prompted srl processes).\n",
      "prompt label\n",
      "\n",
      "description\n",
      "\n",
      "prompts for\n",
      "\n",
      "suggest subgoal recommend possible subgoals to learn about while the students is adding new subgoal.\n",
      "\n",
      "planning processes\n",
      "\n",
      "moving to next\n",
      "subgoal\n",
      "\n",
      "recommend moving on to another subgoal when the student did well on a quiz related to\n",
      "the current subgoal.\n",
      "\n",
      "stay on subgoal\n",
      "\n",
      "recommend to learn more about the current subgoal when the student did not do well\n",
      "enough on a quiz related to that subgoal.\n",
      "\n",
      "open diagram\n",
      "\n",
      "recommend opening the diagram when it is relevant to the current subgoal.\n",
      "\n",
      "summarize\n",
      "\n",
      "recommend making a summary of the current page when the student has spent enough\n",
      "time on that page.\n",
      "\n",
      "revise summary\n",
      "\n",
      "recommend revising the summary submitted by the student when there are issues with the\n",
      "learning strategies\n",
      "summary (e.g., the summary is too long or too short).\n",
      "\n",
      "review notes\n",
      "\n",
      "recommend reviewing notes taken on the learning content when approaching from the\n",
      "end of the session.\n",
      "\n",
      "metacognitive monitoring processes\n",
      "\n",
      "table 2. list of inferred compliance prompts provided in metatutor (grouped by type of prompted srl processes).\n",
      "prompt label\n",
      "\n",
      "description\n",
      "\n",
      "prompts for\n",
      "\n",
      "add subgoal\n",
      "\n",
      "recommend adding a new subgoal to learn about when a student has no active subgoal.\n",
      "\n",
      "move to next\n",
      "page\n",
      "\n",
      "recommend moving on to another page when the student did well on a quiz related to the\n",
      "current page.\n",
      "metacognitive monitorrecommend staying on the current page when the student did not well enough on a quiz ing processes\n",
      "related to that page.\n",
      "\n",
      "stay on page\n",
      "\n",
      "adopted to measure learning in our analysis is proportional learning gain, defined as:\n",
      "\n",
      "planning processes\n",
      "\n",
      "table 4 shows the compliance rate averaged across students for\n",
      "each of the seven explicit compliance prompts in metatutor, and\n",
      "the number of prompts delivered.\n",
      "table 4. descriptive statistics of the number of explicit compliance prompts delivered, as well as on compliance rate.\n",
      "\n",
      "table 3 reports statistics for pre- and post-test scores, as well as\n",
      "for the corresponding learning gains.3\n",
      "table 3. descriptive statistics for pretest, posttest, and\n",
      "learning gain.\n",
      "measures of learning\n",
      "pretest\n",
      "posttest\n",
      "proportional learning gain\n",
      "\n",
      "m\n",
      "18.6\n",
      "21.4\n",
      "15.3\n",
      "\n",
      "sd\n",
      "4.2\n",
      "4\n",
      "50.2\n",
      "\n",
      "median\n",
      "19\n",
      "21\n",
      "20\n",
      "\n",
      "we conducted two separate analyses for explicit and inferred\n",
      "compliance prompts, described next.\n",
      "explicit compliance prompts. since compliance is directly\n",
      "observed in the data for explicit compliance prompts (listed in\n",
      "table 2), we computed a compliance rate for each of these\n",
      "prompts as follow:\n",
      "\n",
      "3\n",
      "\n",
      "the increase from pretest to post-test is statistically significant\n",
      "indicating that metatutor is overall effective at fostering learning, as further discussed in [1].\n",
      "\n",
      "prompt\n",
      "suggest subgoal\n",
      "move next subgoal\n",
      "stay on subgoal\n",
      "open diagram\n",
      "summarize\n",
      "revise summary\n",
      "review notes\n",
      "\n",
      "total number of\n",
      "prompts delivered\n",
      "60\n",
      "25\n",
      "44\n",
      "77\n",
      "105\n",
      "59\n",
      "28\n",
      "\n",
      "compliance rate\n",
      "mean (sd)\n",
      ".90 (.25)\n",
      ".85 (.34)\n",
      ".27 (.37)\n",
      ".21 (.32)\n",
      ".32 (.41)\n",
      ".76 (.37)\n",
      ".46 (.51)\n",
      "\n",
      "to investigate the impact of compliance with explicit compliance\n",
      "prompts on learning, we ran a multiple linear regression model\n",
      "with proportional learning gain as the dependent variable, as\n",
      "well as the compliance rate for each of the seven explicit compliance prompts, and the total number of prompts received as the\n",
      "factors. for post-hoc analysis we ran pairwise t-test comparisons,\n",
      "and p-values were adjusted with the holm-bonferroni approach to\n",
      "account for multiple comparisons.\n",
      "inferred compliance prompts. as stated above, for inferred\n",
      "compliance prompts (listed in table 5), students are not forced to\n",
      "explicitly accept or ignore the prompt. this means that compliance with those prompts has to be assessed from student behaviors following the prompts. one approach we considered was to\n",
      "make this assessment binary, as we did for explicit compliance\n",
      "prompts, by establishing thresholds for relevant behaviors. for\n",
      "instance, compliance with the prompt to re-read the current page\n",
      "could be assessed to be true if the student stays on the page for a\n",
      "fixed number of seconds after receiving this prompts. however, it\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "123\n",
      "\n",
      "\f",
      "is difficult to fix these thresholds in an informed manner, as they\n",
      "may depend on the student (e.g., on a student’s readings speed,\n",
      "existing understanding of the page, etc.), and on the object of the\n",
      "prompt (e.g., on the length or difficulty of the page to be re-read).\n",
      "it is also difficult to decide which specific behaviors should be\n",
      "considered for compliance, as several might be relevant (e.g., time\n",
      "spent on a page, specific attention patterns on a page).\n",
      "thus, for the subsequent analysis, we avoided committing to\n",
      "specific thresholds and behaviors, and we opted instead for performing regression analyses to try to relate multiple relevant compliance behaviors to learning.\n",
      "we started by building data windows that capture student data\n",
      "from the delivery of each inferred compliance prompt in table 2,\n",
      "to the following actions:\n",
      " “moving to another page” for the move to next page and stay\n",
      "on page prompts;\n",
      " “adding a new subgoal” for the add new subgoal prompt.\n",
      "we used these data windows to derive three behavioral measures\n",
      "related to compliance:\n",
      " window length, capturing how long students spent before moving on to another page or adding a new subgoal;\n",
      " number of fixations4 made on metatutor’s learning content\n",
      "(text and diagram), as captured by eye tracking. we use this\n",
      "measure to understand whether students read the page and/or\n",
      "processed the diagram;\n",
      " number of srl strategies initiated by the student by pressing\n",
      "the corresponding buttons in the srl palette (see fig. 1 d).\n",
      "higher values of these measures (i.e., long windows, high number\n",
      "of fixations on the page and high number of srl strategies used)\n",
      "are possible indicators that the student is processing the current\n",
      "page, e.g., the student is thinking about or reading the content (as\n",
      "captured by the length of the data window and number of fixations on the page), or using srl strategies on the current page.\n",
      "thus, we hypothesized that higher values of these measures could\n",
      "reveal compliance with stay on page prompts, whereas lower\n",
      "values could reveal compliance with prompts instructing students\n",
      "to move on. similarly, because prompts to add a subgoal requires\n",
      "moving on from the learning content to actually add a subgoal, we\n",
      "expected a short window, a small number of fixations on the page,\n",
      "and a small number of srl strategies to indicate compliance.\n",
      "it should be noted that we could have generated other eyetracking measures, such as fixation duration on the text or the\n",
      "number of transitions from the text to other components of the\n",
      "metatutor’s interface. however, because valid eye-tracking data\n",
      "were collected for only 16 students out of the 28 who participated\n",
      "in the study, resulting in a rather small dataset, we focused on the\n",
      "most promising behavioral measures that could be related to compliance, as a proof of concept. table 5 shows the amount of inferred compliance prompts delivered to those 16 students.\n",
      "\n",
      "table 5. number of inferred prompts delivered.\n",
      "prompt\n",
      "add a subgoal\n",
      "stay on page\n",
      "move to next page\n",
      "\n",
      "we leveraged the three aforementioned measures of student behavior to investigate if complying with inferred compliance\n",
      "prompts influences learning, and if so, how. specifically, for each\n",
      "of the three inferred compliance prompts, we ran a multiple linear\n",
      "regression model with proportional learning gain as the dependent variable, as well as the window length, number of srl strategies performed, and number of fixations on the learning content\n",
      "as the factors. as done for explicit compliance prompts, we used\n",
      "pairwise t-test comparisons for post-hoc analysis, and all p-values\n",
      "were adjusted with the holm-bonferroni approach.\n",
      "\n",
      "6. results\n",
      "\n",
      "we describe below the significant5 effects found in our analysis,\n",
      "first for explicit compliance prompts, and second for inferred\n",
      "compliance prompts.\n",
      "\n",
      "6.1 effects for explicit compliance prompts\n",
      "our statistical analysis uncovered significant main effects of compliance rate for three explicit compliance prompts:\n",
      " revise summary (f1,20 = 6.17, p=.02, ηp2 =.15), shown fig. 2a.\n",
      " review notes (f1,20 = 7.43, p=.013, ηp2 =.16), shown fig. 2b.\n",
      " suggest subgoal (f1,20 = 11.4, p=.003, ηp2=.27), shown fig. 2c.\n",
      "these three main effects and related pairwise comparisons all\n",
      "reveal that students learned more when they complied more with\n",
      "these prompts than when complying less.\n",
      "these results for revise summary and review notes are consistent\n",
      "with previous findings showing these learning strategies can be\n",
      "beneficial for learning [17, 22, 24], and extend them by showing\n",
      "that prompting these strategies is effective when students comply\n",
      "with the prompts. notably, we found a significant effect for\n",
      "prompts to revise summary, but not for prompts to summarize.\n",
      "this indicates that solely prompting to summarize is not enough\n",
      "to improve learning, and that guiding the students through the\n",
      "process of making a good summary is necessary. results for suggest subgoal indicate that recommending a particular learning\n",
      "subgoal is useful, possibly because it is difficult for students to\n",
      "choose good subgoals by themselves.\n",
      "these results suggest to examine ways to improve compliance\n",
      "with prompts to revise summary, review notes and suggest subgoal, since our analysis reveals that not complying with them\n",
      "hinders learning. for instance, metatutor could foster compliance\n",
      "with these prompts by explaining how they can help the students,\n",
      "or conversely force the students to follow these prompts.\n",
      "\n",
      "5\n",
      "4\n",
      "\n",
      "fixation is defined as gaze maintained at one point on the screen\n",
      "for at least 80ms.\n",
      "\n",
      "total number of\n",
      "prompts delivered\n",
      "34\n",
      "117\n",
      "326\n",
      "\n",
      "we report statistical significance at the 0.05 level throughout\n",
      "this paper, and effect sizes as small for ηp2 ≥ 0.02, medium for\n",
      "ηp2 ≥ 0.13, and large for ηp2 ≥ 0.26.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "124\n",
      "\n",
      "\f",
      "a. main effect of compliance rate with “revise summary”.\n",
      "\n",
      "b. main effect of compliance rate with “review notes”.\n",
      "\n",
      "c. main effect of compliance rate with “suggest subgoal”.\n",
      "\n",
      "d. main effect of fixation on page after reception of “add\n",
      "subgoal”.\n",
      "\n",
      "figure 2. main effects found in this analysis, for explicit compliance prompts (charts a, b, c) and inferred conpliance prompts\n",
      "(chart d). error bars show 95% confidence interval.\n",
      "we found no significant effects and small effect sizes (see appendix a) for the four remaining prompts, namely summarize, stay\n",
      "on subgoal or move to next subgoal, and open the diagram.\n",
      "these results indicate it is important to study the effectiveness of\n",
      "srl prompts individually, to identify those for which compliance\n",
      "does not improve learning. based on these findings, it is justified\n",
      "to further investigate why complying with these prompts is not\n",
      "beneficial for learning in metatutor, and revise the prompts accordingly. for example, it might be due to the nature of the\n",
      "prompts, their timing, their frequency, their wording, and so forth.\n",
      "\n",
      "6.2 effects for inferred compliance prompts\n",
      "we found a main effect of fixation on learning content for the\n",
      "“add subgoal” prompts (f1,3 = 13, p = .03, ηp2 = .29), shown in\n",
      "fig. 2d. this effect and related pairwise comparisons reveal that\n",
      "students learned more when they fixate more on the current page\n",
      "than when fixating less. since students were instructed to add a\n",
      "new subgoal rather than process the current page, this finding\n",
      "suggests that complying with this prompt might not be effective\n",
      "for learning with metatutor, possibly because of the timing of\n",
      "this prompt, its frequency or its wording. although only seven\n",
      "students with valid gaze data received this prompt, the effect size\n",
      "is large, suggesting it is worth conducting further analysis to ascertain whether and why complying with this prompt is not beneficial for learning.\n",
      "\n",
      "we found no effects and small effect sizes (see appendix b) for\n",
      "the other inferred compliance prompts, namely stay on page and\n",
      "move to next page, two prompts related to metacognitive monitoring processes. we cannot make final conclusions on the pedagogical effectiveness on these prompts based on these results, because\n",
      "the dataset is not large and for this reason we did not include in\n",
      "the analysis other features that could indicate compliance (for\n",
      "example other eye-tracking measures such as fixation duration on\n",
      "text or gaze transitions from the text to other components of\n",
      "metatutor). however, it should be noted that we also found no\n",
      "effect for the explicit compliance prompts that foster metacognitive monitoring processes (stay on subgoal, move to next subgoal,\n",
      "and open the diagram, see previous section). this lack of effect\n",
      "for all prompts fostering metacognitive monitoring, even when\n",
      "compliance is explicitly assessed, suggests that these prompts are\n",
      "not beneficial for learning with metatutor. this could be due to\n",
      "the way these prompts are currently implemented in metatutor\n",
      "(e.g., their wording, timing delivery or frequency), or to the nature\n",
      "or the prompts itself. our results nonetheless justify to run further\n",
      "analysis to ascertain whether (and why) prompts fostering metacognitive monitoring are not effective, and revise them as needed.\n",
      "\n",
      "7. conclusion\n",
      "in this research we investigated the relationship between compliance with prompts designed to support the use of self-regulated\n",
      "learning (srl) processes and learning gains while learning about\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "125\n",
      "\n",
      "\f",
      "the human circulatory system with metatutor. we identified two\n",
      "approaches to evaluate compliance to metatutor’s prompts:\n",
      "(i) assess compliance from students’ subsequent response to the\n",
      "prompts when students are forced to express compliance (e.g., by\n",
      "answering “yes” or “no” to a prompt);\n",
      "(ii) run linear models to examine the influence on learning of a\n",
      "variety of student behaviors related to prompt compliance, when\n",
      "compliance is not elicited by metatutor. the behaviors we mined\n",
      "are based on both interface and eye-tracking data (e.g., time spent\n",
      "on that page, gaze fixations on the content of the page).\n",
      "our results revealed that student learning gains are influenced by\n",
      "compliance with some, but not all srl prompts provided by\n",
      "metatutor. specifically, we found a positive influence on learning\n",
      "for prompts that foster learning strategies (revise a summary and\n",
      "review notes) as well as prompts that recommend setting a specific learning subgoal. based on these findings, it is worth exploring\n",
      "ways to improve compliance with these prompts. in particular, in\n",
      "future research we plan to examine whether forcing students to\n",
      "comply with these prompts or providing detailed explanations on\n",
      "how the prompted srl strategies can be useful can improve\n",
      "learning.\n",
      "we found that compliance with the other metatutor’s prompts\n",
      "studied in this analysis does not improve learning. this finding\n",
      "reveals that assessing compliance to srl prompts individually is\n",
      "useful to identify prompts that may not be effective at supporting\n",
      "learning. in particular, we found no results for all prompts related\n",
      "to metacognitive monitoring processes (e.g., staying on/moving\n",
      "away from the current page), suggesting to examine further why\n",
      "complying with these prompts do not influence learning with\n",
      "metatutor. for example, it could be due to their timing and frequency, their wording, their nature, and so forth.\n",
      "in this paper we also addressed the challenge of evaluating compliance with rather open-ended prompts for which there is no\n",
      "clear definition of compliance. specifically we ran a linear regression analysis to relate relevant compliance behaviors to learning.\n",
      "such behaviors were derived from a combination of student interaction and eye-tracking data after receipt of a prompt (e.g., time\n",
      "spent and amount of gaze fixations on a page can reveal compliance with prompt to read that page). preliminary results show that\n",
      "such interaction-based and eye-tracking-based measures can help\n",
      "evaluate compliance. in future research, we plan to investigate\n",
      "further behavioral measures relevant to assessing compliance,\n",
      "such as tracking eye gaze patterns on the different components of\n",
      "metatutor as well as transitions between those components.\n",
      "lastly, we plan to investigate the possibility of detecting in real\n",
      "time compliance with srl prompts for which we found a positive\n",
      "effect on learning, using eye-tracking and interaction data. such\n",
      "real-time detection could inform the design of adaptive prompts to\n",
      "foster compliance for those students who might otherwise disregard these prompts. for instance, adaptive prompts could force\n",
      "students to follow them or explain how the prompted srl processes can improve learning. evaluating such adaptive prompts\n",
      "fostering srl processes would provide further insights on how\n",
      "students comply with and benefit from srl prompts.\n",
      "\n",
      "8. acknowledgments\n",
      "this publication is based upon work supported by the national\n",
      "science foundation under grant no. drl-1431552 and the social sciences and humanities research council of canada. any\n",
      "\n",
      "opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the national science foundation or the\n",
      "social sciences and humanities research council of canada.\n",
      "\n",
      "9. references\n",
      "[1] azevedo, r., harley, j., trevors, g., duffy, m., feyzibehnagh, r., bouchet, f. and landis, r. 2013. using trace\n",
      "data to examine the complex roles of cognitive, metacognitive, and emotional self-regulatory processes during learning\n",
      "with multi-agent systems. international handbook of metacognition and learning technologies. springer, 427–449.\n",
      "[2] azevedo, r., martin, s.a., taub, m., mudrick, n.v., millar,\n",
      "g.c. and grafsgaard, j.f. 2016. are pedagogical agents’\n",
      "external regulation effective in fostering learning with intelligent tutoring systems? proceedings of the 13th international conference on intelligent tutoring systems (zagreb,\n",
      "croatia, 2016). springer, 197–207.\n",
      "[3] beck, j., chang, k., mostow, j. and corbett, a. 2008. does\n",
      "help help? introducing the bayesian evaluation and assessment methodology. proceedings on the 9th international\n",
      "conference on intelligent tutoring systems (montréal, qc,\n",
      "canada, 2008). springer, 383–394.\n",
      "[4] bixler, r. and d’mello, s. 2015. automatic gaze-based\n",
      "detection of mind wandering with metacognitive awareness. proceedings of the 23rd international conference on\n",
      "user modeling, adaptation and personalization (dublin,\n",
      "ireland, 2015). springer, 31–43.\n",
      "[5] bouchet, f., harley, j.m. and azevedo, r. 2016. can adaptive pedagogical agents’ prompting strategies improve students’ learning and self-regulation? proceedings of the\n",
      "13th international conference on intelligent tutoring systems (zagreb, croatia, 2016). springer, 368–374.\n",
      "[6] conati, c., jaques, n. and muir, m. 2013. understanding\n",
      "attention to adaptive hints in educational games: an eyetracking study. international journal of artificial intelligence in education. 23, 1–4 (2013), 136–161.\n",
      "[7] conati, c. and merten, c. 2007. eye-tracking for user modeling in exploratory learning environments: an empirical\n",
      "evaluation. know.-based syst. 20, 6 (2007), 557–574.\n",
      "[8] d’mello, s., olney, a., williams, c. and hays, p. 2012.\n",
      "gaze tutor: a gaze-reactive intelligent tutoring system. international journal of human-computer studies. 70, 5\n",
      "(2012), 377–398.\n",
      "[9] d’mello, s., olney, a., williams, c. and hays, p. 2012.\n",
      "gaze tutor: a gaze-reactive intelligent tutoring system. international journal of human-computer studies. 70, 5\n",
      "(2012), 377–398.\n",
      "[10] graesser, a. and mcnamara, d. 2010. self-regulated learning in learning environments with pedagogical agents that interact in natural language. educational psychologist. 45, 4\n",
      "(2010), 234–244.\n",
      "[11] hausmann, r.g. and vanlehn, k. 2007. explaining selfexplaining: a contrast between content and generation. proceedings of the 13th international conference on artificial\n",
      "intelligence in education (los angeles, ca, usa, 2007).\n",
      "springer, 417–424.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "126\n",
      "\n",
      "\f",
      "[12] heiner, c., beck, j. and mostow, j. 2004. improving the help\n",
      "selection policy in a reading tutor that listens. proceedings\n",
      "of the instil/icall symposium on nlp and speech technologies in advanced language learning systems (venice,\n",
      "italy, 2004), 195–198.\n",
      "[13] jacobson, m.j. 2008. a design framework for educational\n",
      "hypermedia systems: theory, research, and learning emerging scientific conceptual perspectives. educational technology research and development. 56, 1 (2008), 5–28.\n",
      "[14] jaques, n., conati, c., harley, j.m. and azevedo, r. 2014.\n",
      "predicting affect from gaze data during interaction with an\n",
      "intelligent tutoring system. proceedings of the 12th international conference on intelligent tutoring systems (honolulu, hi, usa, 2014). springer, 29–38.\n",
      "[15] kardan, s. and conati, c. 2012. exploring gaze data for\n",
      "determining user learning with an interactive simulation.\n",
      "proceedings of the 20th international conference on user\n",
      "modeling, adaptation, and personalization (montréal, qc,\n",
      "canada, 2012). springer, 126–138.\n",
      "[16] kardan, s. and conati, c. 2015. providing adaptive support\n",
      "in an interactive simulation for learning: an experimental\n",
      "evaluation. proceedings of the 33rd annual acm conference on human factors in computing systems (seoul,\n",
      "south korea, 2015). acm, 3671–3680.\n",
      "[17] lallé, s., taub, m., mudrick, n.v., conati, c. and azevedo,\n",
      "r. 2017. the impact of student individual differences and\n",
      "visual attention to pedagogical agents during learning with\n",
      "metatutor. proceedings of the 18th international conference on artificial intelligence in education (wuhan, china,\n",
      "2017). springer (to appear).\n",
      "[18] mcnamara, d.s., boonthum, c., levinstein, i.b. and millis,\n",
      "k. 2007. evaluating self-explanations in istart: comparing word-based and lsa algorithms. handbook of latent\n",
      "semantic analysis. psychology press. 227–241.\n",
      "[19] najar, a.s., mitrovic, a. and mclaren, b.m. 2014. adaptive\n",
      "support versus alternating worked examples and tutored\n",
      "problems: which leads to better learning? proceedings of\n",
      "the 22nd international conference on user modeling, adaptation, and personalization (aalborg, denmark, 2014).\n",
      "springer, 171–182.\n",
      "\n",
      "[24] shute, v.j. 2008. focus on formative feedback. review of\n",
      "educational research. 78, 1 (2008), 153–189.\n",
      "[25] trevors, g., duffy, m. and azevedo, r. 2014. note-taking\n",
      "within metatutor: interactions between an intelligent tutoring system and prior knowledge on note-taking and learning.\n",
      "educational technology research and development. 62, 5\n",
      "(2014), 507–528.\n",
      "\n",
      "appendix a\n",
      "all statistical results for explicit compliance prompts (discussed in\n",
      "section 6.1). bold indicates a significant effect.\n",
      "prompt\n",
      "suggest subgoal\n",
      "review notes\n",
      "revise summary\n",
      "summarizing\n",
      "move on subgoal\n",
      "stay on subgoal\n",
      "open diagram\n",
      "\n",
      "f value\n",
      "f1,20 = 11.4\n",
      "f1,20 = 7.43\n",
      "f1,20 = 6.17\n",
      "f1,20 = 1.76\n",
      "f1,20 = 0.92\n",
      "f1,20 = 1.47\n",
      "f1,20 = 0.71\n",
      "\n",
      "p-value\n",
      "p=.003\n",
      "p=.013\n",
      "p=.02\n",
      "p=.20\n",
      "p=.35\n",
      "p=.24\n",
      "p=.41\n",
      "\n",
      "effect size\n",
      "ηp2=.27\n",
      "ηp2 =.16\n",
      "ηp2 =.15\n",
      "ηp2 =.06\n",
      "ηp2 =.02\n",
      "ηp2 =.01\n",
      "ηp2 =.08\n",
      "\n",
      "appendix b\n",
      "all statistical results for explicit compliance prompts (discussed in\n",
      "section 6.2). bold indicates a significant effect.\n",
      "prompt\n",
      "add subgoal\n",
      "move on\n",
      "page\n",
      "stay on\n",
      "page\n",
      "\n",
      "measure\n",
      "window length\n",
      "#fixations on\n",
      "page\n",
      "#srl strategies\n",
      "window length\n",
      "#fixations on page\n",
      "#srl strategies\n",
      "window length\n",
      "#fixations on page\n",
      "#srl strategies\n",
      "\n",
      "f value\n",
      "\n",
      "p-value\n",
      "\n",
      "f1,3 = .91\n",
      "\n",
      "p = .41\n",
      "\n",
      "effect\n",
      "size\n",
      "ηp2 = .04\n",
      "\n",
      "f1,3 = 13\n",
      "\n",
      "p = .03\n",
      "\n",
      "ηp2 = .29\n",
      "\n",
      "f1,3 = .02\n",
      "f1,10 = .00\n",
      "f1,10 = .03\n",
      "f1,10 = .40\n",
      "f1,10 = .34\n",
      "f1,10 = .07\n",
      "f1,10 = .004\n",
      "\n",
      "p = .90\n",
      "p = .98\n",
      "p = .86\n",
      "p = .54\n",
      "p = .57\n",
      "p = .79\n",
      "p = .95\n",
      "\n",
      "ηp2 = .01\n",
      "ηp2 = .00\n",
      "ηp2 = .00\n",
      "ηp2 = .01\n",
      "ηp2 = .01\n",
      "ηp2 = .03\n",
      "ηp2 = .02\n",
      "\n",
      "[20] poitras, e.g. and lajoie, s.p. 2014. developing an agentbased adaptive system for scaffolding self-regulated inquiry\n",
      "learning in history education. educational technology research and development. 62, 3 (2014), 335–366.\n",
      "[21] ritter, s., anderson, j.r., koedinger, k.r. and corbett, a.\n",
      "2007. cognitive tutor: applied research in mathematics education. psychonomic bulletin & review. 14, 2 (2007), 249–\n",
      "255.\n",
      "[22] roll, i., aleven, v., mclaren, b.m. and koedinger, k.r.\n",
      "2011. improving students’ help-seeking skills using metacognitive feedback in an intelligent tutoring system. learning and instruction. 21, 2 (2011), 267–280.\n",
      "[23] roll, i., wiese, e.s., long, y., aleven, v. and koedinger,\n",
      "k.r. 2014. tutoring self-and co-regulation with intelligent\n",
      "tutoring systems to help students acquire better learning\n",
      "skills. design recommendations for intelligent tutoring\n",
      "systems, volume 2. u.s. army research laboratory. 169–\n",
      "182.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "127\n",
      "\n",
      "\f",
      "assessing computer literacy of adults with low literacy\n",
      "skills\n",
      "andrew m. olney\n",
      "\n",
      "institute for intelligent systems\n",
      "university of memphis\n",
      "memphis, tn 38152\n",
      "\n",
      "aolney@memphis.edu\n",
      "daphne greenberg\n",
      "\n",
      "department of educational psychology, special\n",
      "education, and communication disorders\n",
      "georgia state university\n",
      "atlanta, ga 30302\n",
      "\n",
      "dgreenberg@gsu.edu\n",
      "\n",
      "abstract\n",
      "adaptive learning technologies hold great promise for improving the reading skills of adults with low literacy, but\n",
      "adults with low literacy skills typically have low computer\n",
      "literacy skills. in order to determine whether adults with\n",
      "low literacy skills would be able to use an intelligent tutoring system for reading comprehension, we adapted a 44 task\n",
      "computer literacy assessment and delivered it to 114 adults\n",
      "with reading skills between 3rd and 8th grade levels. this\n",
      "paper presents four analyses on these data. first, we report\n",
      "the pass/fail data natively exported by the assessment for\n",
      "particular computer-based tasks. second, we undertook a\n",
      "goms analysis of each computer-based task, to predict the\n",
      "task completion time for a skilled user, and found that it\n",
      "negatively correlated with proportion correct for each item,\n",
      "r(42) = −.4, p = .01. third, we used the goms task decomposition to develop a q-matrix of component computer\n",
      "skills for each task, and using logistic mixed effects models\n",
      "on this matrix identified five component skills highly predictive of the success or failure of an individual on a computer task: function keys, typing, using icons, right clicking,\n",
      "and mouse dragging. and finally, we assessed the predictive\n",
      "value of all component skills using logistic lasso.\n",
      "\n",
      "keywords\n",
      "adult literacy, computer literacy, goms, q-matrix, mixed\n",
      "model, lasso\n",
      "\n",
      "1. introduction\n",
      "of adults with the lowest literacy levels, 43% live in poverty,\n",
      "and low literacy costs the u.s. economy $225 billion annu-\n",
      "\n",
      "dariush bakhtiari\n",
      "\n",
      "department of educational psychology, special\n",
      "education, and communication disorders\n",
      "georgia state university\n",
      "atlanta, ga 30302\n",
      "\n",
      "dbakhtiari1@gsu.edu\n",
      "art graesser\n",
      "\n",
      "institute for intelligent systems\n",
      "university of memphis\n",
      "memphis, tn 38152\n",
      "\n",
      "a-graesser@memphis.edu\n",
      "ally [14]. the need for literacy interventions is matched\n",
      "by the complexity of delivering interventions to this population. low literacy adults have difficulty attending face\n",
      "to face programs at literacy centers because of work, child\n",
      "care, and transportation [5], and even when these challenges\n",
      "are met, two-thirds of literacy centers have long waiting\n",
      "lists [14]. adaptive computer-based interventions for literacy hold promise to overcome these challenges. such interventions can be deployed in homes and local libraries, in\n",
      "addition to literacy centers. however, computer-based interventions raise another question: can adults with low literacy\n",
      "skills use computers well enough to benefit? several surveys\n",
      "suggest that this might be a problem. the demographics\n",
      "most affected by low literacy are the same demographics\n",
      "least likely to use the internet (over age 50, making less\n",
      "than $30 thousand a year, and with less than a high school\n",
      "education [1]).\n",
      "several decades of research have investigated computer literacy using self-report measures as well as objective tests,\n",
      "i.e. multiple choice, and find that self-report measures tend\n",
      "to exaggerate proficiency while objective tests are more reliable (see [3] for a review). for an adult literacy population, however, multiple-choice tests delivered as print create\n",
      "additional concerns as to whether the questions themselves\n",
      "can be comprehended. recently a new type of assessment,\n",
      "known as the northstar digital literacy assessment (the\n",
      "northstar), has been created that directly measures ability\n",
      "to perform computer tasks [13]. unlike multiple choice assessments, the northstar can simulate a computer desktop,\n",
      "use voice prompts to instruct users to perform tasks on that\n",
      "desktop, and then record their mouse clicks and keystrokes\n",
      "to determine if the task has been completed. almost all\n",
      "of the tasks can be completed without reading by listening\n",
      "to the voice prompt instructions. the few tasks that do\n",
      "involve reading are word recognition tasks rather than sentence reading, e.g. a task to log in may require the user\n",
      "to copy a name and password to the appropriate boxes and\n",
      "so require reading of “username,” “password,” and the corresponding fillers. the northstar has been adopted as the\n",
      "computer literacy standard for adult basic education in the\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "128\n",
      "\n",
      "\f",
      "state of minnesota, which further supports its appropriateness for assessing the computer literacy skills of adults with\n",
      "low literacy skills.\n",
      "the present study investigated the computer literacy skills\n",
      "of adults with low literacy skills for the purpose of developing an intelligent tutoring system for reading comprehension for this population [7]. it includes a set of northstar\n",
      "items that were collected to cover a range of potential interface and interaction components. in the remainder of the\n",
      "paper we describe the data collection procedure and four\n",
      "analyses performed, including pass/fail frequencies for each\n",
      "task, relation of these frequencies to goms-predicted execution times for skilled users, a logistic mixed-model using a\n",
      "q-matrix decomposition of the tasks into component skills,\n",
      "and a logistic lasso model to assess the predictive value of\n",
      "component skills. from these analyses we identify specific\n",
      "tasks that are problematic for adults with low literacy skills\n",
      "as well as component skills that make it more likely adults\n",
      "with low literacy skills will succeed or fail at a computerbased task.\n",
      "\n",
      "2. analysis 1: proportion correct\n",
      "2.1 participants\n",
      "participants (n = 114) were recruited through adult literacy\n",
      "centers in atlanta, ga and toronto, on, from classes where\n",
      "the reading level was between 3rd and 8th grade. reading\n",
      "level was determined by the centers using their “business as\n",
      "usual” assessments. demographic surveys were completed\n",
      "by 90 participants (79% completion rate). completed surveys indicated that participants were slightly more female\n",
      "than male (55 vs. 35) and that participant age ranged from\n",
      "17 to 69 (m = 42.74, sd = 13.73).\n",
      "\n",
      "2.2\n",
      "\n",
      "materials\n",
      "\n",
      "forty-four items were selected from four (out of seven) of\n",
      "the northstar modules available at the time of the study:\n",
      "basic computer skills (21), www (13), windows (6), and\n",
      "email (4). task descriptions are given in table 1. basic\n",
      "computer skills covered such topics as turning a computer\n",
      "on, identifying components of a computer, files and folders, menus, and windows. www focused on browser-based\n",
      "activities like searching, search results, browser functionalities, and logging in. although the windows module focused\n",
      "on windows overall, the items selected were fairly generic\n",
      "to any windowed operating system and mostly pertained to\n",
      "desktop applications. email questions used a webmail interface (browser-based email client) and queried how one would\n",
      "create a new email, send an email, or similar email task.\n",
      "because northstar modules are integrated assessments, the\n",
      "northstar project compiled the items we selected into a custom assessment for us.\n",
      "\n",
      "2.3\n",
      "\n",
      "procedure\n",
      "\n",
      "participants first completed informed consent and then the\n",
      "demographic survey. both informed consent and demographic\n",
      "survey were read aloud to participants to ensure comprehension. participants were then asked to sit in front of a computer to take the northstar assessment. the assessment was\n",
      "delivered in the browser using adobe flash. at the start of\n",
      "the assessment, a 3-minute orientation video was played explaining how to answer questions in the assessment. if the\n",
      "\n",
      "participant was confused about what to do, an experimenter\n",
      "was available to answer questions. each question consisted\n",
      "of an voice prompt defining the task, which was also written at the top of the screen. a replay button was available\n",
      "to repeat the prompt. participants could select, click, type,\n",
      "drag, etc. on the interface in an attempt to perform the task.\n",
      "if the participant did not know how to complete the task,\n",
      "they could press an “i don’t know” button, at which point\n",
      "the system scored their attempt as a failure. attempts were\n",
      "only scored as a success if the participant completed the task\n",
      "in the manner requested in the prompt. the completion of\n",
      "each task initiated the next task until the assessment was\n",
      "complete.\n",
      "\n",
      "2.4 results & discussion\n",
      "the northstar records success/failure of each participant on\n",
      "each task, and these data are reported in detail elsewhere [2].\n",
      "here we briefly note that the proportion of correct responses\n",
      "for each task is quite wide, ranging from .19 to .98. tasks\n",
      "in which participants performed particularly well (proportion correct above .80) include identification tasks (e.g. for\n",
      "mouse, keyboard, headphone jack, and websites), turning on\n",
      "a computer or monitor, and common operations like recycling a file, using checkboxes, dragging, scrolling, and using\n",
      "hyperlinks. tasks in which participants performed poorly\n",
      "(proportion correct below .60) include identification of various keys, double- or right-clicking, typing web addresses,\n",
      "signing into email, and composing email.\n",
      "the proportion correct results from the northstar indicate\n",
      "the adults with low literacy skills can power on their device\n",
      "and perform a variety of basic operations. to the extent\n",
      "that these tasks exactly matched tasks that would be performed in a computer-based literacy intervention, like an\n",
      "intelligent tutoring system, this level of results is quite useful. however, for some tasks there is not an exact match,\n",
      "and the implications of the proportion correct results are\n",
      "less clear. for example, difficulties performing tasks using\n",
      "word, excel, or webmail may reflect problems with those\n",
      "specific interfaces that may not transfer to other programs.\n",
      "understanding these more nuanced relationships would require a deeper analysis than is afforded by northstar’s success/failure output.\n",
      "\n",
      "3.\n",
      "\n",
      "analysis 2: goms modeling\n",
      "\n",
      "the purpose of this analysis was to explore whether the\n",
      "success rate of the northstar tasks could be modeled using goms (goals, operators, methods, & selection rules),\n",
      "a well-known computational technique for modeling expert\n",
      "user performance on a task [10]. goms decomposes a particular computer task, e.g. saving a file, into goals and subgoals, perceptual, cognitive, and motor actions in service\n",
      "these goals, methods or sequences of operators that achieve\n",
      "a goal, and selection rules that choose between alternative\n",
      "methods. an important assumption of goms is that the\n",
      "users are expert at the computer task in question. therefore\n",
      "goms models of execution time represent the upper bound\n",
      "of performance after a user has learned the interface and\n",
      "practiced it many times. the expert assumption of goms\n",
      "is violated in the adult literacy population, making the outcome of this analysis non-obvious. if the goms model predictions of execution time were related to our adult’s performance, that would provide evidence that goms modeling\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "129\n",
      "\n",
      "\f",
      "click on the monitor\n",
      "click on the keyboard\n",
      "click on the system unit\n",
      "click on the headphone jack\n",
      "click on picture of a mouse\n",
      "newline key\n",
      "caps key\n",
      "shift key\n",
      "backspace key\n",
      "up arrow\n",
      "turn on monitor\n",
      "turn on computer\n",
      "log on to computer\n",
      "double click on documents\n",
      "right click menu\n",
      "\n",
      "table 1: northstar tasks\n",
      "recycle file\n",
      "checkboxes\n",
      "organize folder options\n",
      "start menu, lauch program\n",
      "turn up audio slider\n",
      "mute audio\n",
      "select browser icons\n",
      "click on the website\n",
      "drag item in browser\n",
      "click on address bar\n",
      "type the web address\n",
      "click homepage button\n",
      "click browser back button\n",
      "click browser refresh\n",
      "click browser forward\n",
      "\n",
      "click stop loading\n",
      "select search engines\n",
      "google query\n",
      "google scroll\n",
      "use hyperlink\n",
      "maximize window\n",
      "minimize window\n",
      "open excel\n",
      "open word using taskbar\n",
      "close word\n",
      "select login and password\n",
      "choose secure password\n",
      "sign into email\n",
      "compose email\n",
      "\n",
      "northstar items used in analysis 1.\n",
      "\n",
      "3.2 results & discussion\n",
      "\n",
      "figure 1: a cogtool annotation of a northstar\n",
      "task. annotations appear as semi-transparent orange boxes over the northstar interface.\n",
      "\n",
      "has some validity for this population.\n",
      "\n",
      "3.1\n",
      "\n",
      "procedure\n",
      "\n",
      "the cogtool system was used to perform a goms analysis\n",
      "[11, 9]. cogtool allows the easy creation of goms models\n",
      "by annotating an existing user interface, and then recording\n",
      "a demonstration of the task against than annotated interface. figure 1 shows the cogtool interface for the “click on\n",
      "the mouse” task. for example, when the northstar task required clicking on an icon, button, or other interface element\n",
      "as in figure 1, a cogtool button annotation was overlaid on\n",
      "the interface, and then in demonstration mode the modeler\n",
      "would demonstrate the task by clicking on the annotated\n",
      "button. from this demonstration on the annotation, cogtool builds a goms model that includes the perceptual,\n",
      "cognitive, and motor tasks required to perform the task.\n",
      "similar annotations were made for auditory directions, keyboard input, and other kinds of interface actions. once a\n",
      "task was annotated and demonstrated, a cogtool simulation\n",
      "was run on goms model to generate a predicted execution\n",
      "time of expert performance. annotations, demonstrations,\n",
      "and execution time predictions were performed for all 44\n",
      "\n",
      "goms-predicted execution times for northstar tasks ranged\n",
      "from 3.0 to 17.1 seconds (m = 6.88, sd = 4.07). these execution times were significantly negatively correlated with\n",
      "proportion correct, r(42) = −.40, p = .01, ci95 [−.61, −.10],\n",
      "indicating that tasks predicted to take an expert longer\n",
      "to accomplish were more likely to be answered incorrectly\n",
      "by low literacy adults. tasks that take longer are inherently more complex and require more operations to complete. these results suggest that goms has some validity for modeling the performance of adults with low literacy\n",
      "skills even though it was not intended for this purpose. however, by themselves these results convey little additional insight. the goms-predicted execution times, generated by\n",
      "cogtool, are still at the task level rather than the component skills required to achieve each task. this is partly\n",
      "because the orientation of cogtool is to produce execution\n",
      "times and partly because of the expert orientation of goms.\n",
      "for example, in goms the factors involved in clicking a button are the perceptual (size, location) and motor operations\n",
      "involved, but in northstar, some “buttons” are tapping specific types of knowledge, like identifying hardware, understanding icons, or various keys on a keyboard. the different\n",
      "types of knowledge behind the various cogtool annotations\n",
      "are not represented or considered in the goms analysis it\n",
      "provides.\n",
      "\n",
      "4.\n",
      "\n",
      "analysis 3: q-matrix & logistic\n",
      "mixed models\n",
      "\n",
      "we would like to understand how the component skills underlying northstar tasks differentially affect the probability\n",
      "a low literacy adult will perform the task correctly. in educational data mining, component skills are typically modeled using a q-matrix analysis [4]. in its simplest form,\n",
      "a q-matrix analysis constructs a problem by skill matrix\n",
      "such that a cellij in the matrix represents whether skilli is\n",
      "needed to solve problemj : cellij = 1 if skilli is needed to\n",
      "solve problemj , and cellij = 0 if skilli is not needed to solve\n",
      "problemj . analysis 2 provides a useful guide towards the\n",
      "creation of a q-matrix for the northstar tasks, as it has already captured each component action required to perform\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "130\n",
      "\n",
      "\f",
      "table 2: component skills coded from goms\n",
      "component skill\n",
      "probability correct given skill\n",
      "checkboxes\n",
      ".89\n",
      "mouse drag\n",
      ".86\n",
      "hardware identify\n",
      ".83\n",
      "hardware function\n",
      ".78\n",
      "complex scrolling\n",
      ".74\n",
      "browser functions\n",
      ".66\n",
      "left click\n",
      ".64\n",
      "use icons\n",
      ".61\n",
      "double click\n",
      ".58\n",
      "window functionality\n",
      ".56\n",
      "program brands\n",
      ".55\n",
      "desktop concept\n",
      ".53\n",
      "select menu\n",
      ".50\n",
      "good login info\n",
      ".50\n",
      "login info\n",
      ".48\n",
      "keyboard function\n",
      ".46\n",
      "simple typing\n",
      ".43\n",
      "right click\n",
      ".19\n",
      "\n",
      "each task. what it lacks in some cases, however, is an annotation of the knowledge behind each component action.\n",
      "\n",
      "4.1\n",
      "\n",
      "procedure\n",
      "\n",
      "the first author recoded the goms task annotations with\n",
      "18 novice-relevant component skills. the coding was done\n",
      "in one pass, and component skills were defined on the fly.\n",
      "component skills that occurred in only one task were then\n",
      "removed as they offer no predictive utility for other tasks.\n",
      "the appropriateness of the component skills was evaluated\n",
      "by correlating the total number of component skills needed\n",
      "in each task with the goms execution time and the proportion correct for the respective task. we used a logistic\n",
      "mixed model to predict the correctness of each participant\n",
      "on each task as a function of the presence of component\n",
      "skills for that task. this analysis addresses the question as\n",
      "to whether there is an effect (main effect) of the presence of\n",
      "component skills on the likelihood that an adult with low literacy skills will be able to perform the task correctly. using\n",
      "a logistic mixed model in this way has strong similarities to\n",
      "cognitive psychometric models like diagnostic classification\n",
      "models [16] or more specifically a mixed model implementation of linear logistic test models [15].\n",
      "in the logistic mixed model, random slopes were initially included but failed to converge. random intercepts for task\n",
      "and participant are theoretically motivated, and backward\n",
      "selection of these effects using akaike information criterion\n",
      "(aic) achieved a minimum when these effects were included,\n",
      "indicating that these intercepts should remain in the model.\n",
      "these random intercepts can be considered as per-task difficulty not captured by component skills and per-subject\n",
      "ability, respectively. the initial model that included left\n",
      "click was rank deficient, so left click, which appears in\n",
      "most tasks, was removed from the final model. additionally, the total number of component skills in each task (i.e.\n",
      "column sums of the q-matrix) was initially considered as\n",
      "a predictor of correctness, but was excluded based on extremely high collinearity, having a variance inflation factor\n",
      "of over 40.\n",
      "\n",
      "4.2 results & discussion\n",
      "the component skills and the conditional probability that\n",
      "a task will be correctly performed if the component skill is\n",
      "present are shown in figure 2. total component skills per\n",
      "task was marginally positive correlated with goms execution time, r(42) = .27, p = .07, ci95 [−.02, .53], suggesting\n",
      "that tasks with more component skills take longer to perform. total component skills per task was significantly negatively correlated with proportion correct, r(42) = −.35, p =\n",
      ".02, ci95 [−.59, −.06], indicating that tasks with more component skills are more difficult to perform correctly. the\n",
      "correlation between predicted execution time and proportion correct was not significantly different from the correlation between total component skills and proportion correct,\n",
      "t(82) = .18, p = .86, indicating that the q-matrix decomposition of component skills is comparable to the goms execution time in terms of its relationship to proportion correctness. altogether these correlation results provide additional\n",
      "evidence that the q-matrix decomposition is appropriate.\n",
      "the logistic mixed model had a marginal r2 of .18 (fixed\n",
      "effects only) and a conditional r2 of .47 (including random effects) [12]. we found a positive main effect of mouse\n",
      "drag, β̂ = 2.06, se = .90, p = .02, such that tasks with\n",
      "a mouse drag component were 7.87 times as likely to be\n",
      "answered correctly, ci95 [1.36, 45.50], and a marginal main\n",
      "effect of hardware identify, β̂ = .89, se = .53, p = .10,\n",
      "such that tasks with a hardware identify component were\n",
      "2.44 times as likely to be answered correctly, ci95 [.86, 6.94].\n",
      "we found negative main effects for keyboard function, β̂ =\n",
      "−1.31, se = .51, p = .01, use icon β̂ = −1.35, se =\n",
      ".55, p = .01, simple typing β̂ = −1.91, se = .64, p = .003,\n",
      "and right click β̂ = −3.20, se = 1.34, p < .02, such that\n",
      "tasks with a keyboard function component were .27 times\n",
      "as likely to be answered correctly, ci95 [.10, .73], tasks with\n",
      "a use icon component were .26 times as likely to be answered correctly, ci95 [.09, .75], tasks with a simple typing\n",
      "component were .15 times as likely to be answered correctly,\n",
      "ci95 [.04, .52], and tasks with a right click component were\n",
      ".04 times as likely to be answered correctly, ci95 [.00, .56].\n",
      "we found that mouse drag was extremely predictive of success. the reason is unclear, but we hypothesize that the\n",
      "frequency of mouse dragging in many computer tasks may\n",
      "have afforded participants the opportunity to become expert\n",
      "in this skill. mouse dragging has some similarity to swiping\n",
      "on a smartphone or tablet interface, so it may be that expertise with other devices has transferred into the northstar\n",
      "tasks. amongst the components that predict failure, perhaps the most intuitive are keyboard function and simple\n",
      "typing. typing is a complex skill that takes practice to master. function keys are difficult in that they don’t themselves\n",
      "produce a character, but either operate on a character on the\n",
      "screen (delete) or work in combination with another key to\n",
      "modify it (shift). the negative effects associated with use\n",
      "icon and right click are somewhat surprising. icons come\n",
      "in many different variations, and so it is possible that the\n",
      "negative use icon effect is attributable to a lack of knowledge of specific icons or perhaps to the conventions of icons\n",
      "generally. right click is possibly rare and usually brings up\n",
      "a context menu with commands that are often available elsewhere, making it more relevant for power users but perhaps\n",
      "less so to novice users.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "131\n",
      "\n",
      "\f",
      "figure 2: the coefficient path for the lasso model. as the l1 sparsity threshold increases along the x-axis,\n",
      "more coefficients are non-zero.\n",
      "\n",
      "5.1\n",
      "\n",
      "procedure\n",
      "\n",
      "a logistic regression base model without random effects was\n",
      "initialized with 17 component skills (left click excluded)\n",
      "and submitted to lasso. because lasso has a free parameter,\n",
      "λ, that controls sparsity of the regression, a lasso analysis\n",
      "varies the level of λ and generates regression coefficient estimates at each level. this sequence of regression coefficients\n",
      "is known as the regularization path. the value of λ that\n",
      "minimized prediction error was estimated using both cross\n",
      "validation and aic.\n",
      "\n",
      "5.2\n",
      "\n",
      "results & discussion\n",
      "\n",
      "the coefficient (regularization) path for the lasso model is\n",
      "shown in figure 2 and the corresponding aic curve is shown\n",
      "\n",
      "●\n",
      "●\n",
      "\n",
      "6400\n",
      "\n",
      "6500\n",
      "\n",
      "analysis 4: q-matrix lasso\n",
      "\n",
      "●\n",
      "\n",
      "●\n",
      "\n",
      "6200\n",
      "\n",
      "aic\n",
      "\n",
      "6300\n",
      "\n",
      "●\n",
      "\n",
      "●●\n",
      "●\n",
      "\n",
      "●\n",
      "\n",
      "6100\n",
      "\n",
      "●\n",
      "\n",
      "●\n",
      "\n",
      "●\n",
      "●\n",
      "\n",
      "6000\n",
      "\n",
      "analysis 3 provides a more traditional analysis of significant predictors in our study, but must be interpreted with\n",
      "caution with respect to generalizing to new data. it may\n",
      "be that insignificant predictors in analysis 3 nevertheless\n",
      "have predictive value on new data. the problems of relying on p-values or criteria like aic to select variables are\n",
      "well known [8]. to explore the predictive potential of the\n",
      "q-matrix component skills, we created a lasso model (least\n",
      "absolute shrinkage and selection operator [18]), a form of\n",
      "regression that promotes sparsity (i.e. zero coefficients) and\n",
      "predictive accuracy simultaneously. while not necessarily\n",
      "the best predictive model (cf. gradient boosting [6]), lasso\n",
      "has the advantage of being simple to interpret, and thus our\n",
      "results can guide what variables to use in future models.\n",
      "\n",
      "●\n",
      "\n",
      "●\n",
      "●\n",
      "●\n",
      "\n",
      "5900\n",
      "\n",
      "5.\n",
      "\n",
      "●\n",
      "\n",
      "●\n",
      "\n",
      "●\n",
      "\n",
      "0\n",
      "\n",
      "2\n",
      "\n",
      "4\n",
      "\n",
      "6\n",
      "\n",
      "8\n",
      "\n",
      "10\n",
      "\n",
      "12\n",
      "\n",
      "●\n",
      "\n",
      "●\n",
      "\n",
      "14\n",
      "\n",
      "|beta|\n",
      "\n",
      "figure 3: the aic curve for the lasso model. lower\n",
      "values of aic indicate better model fit.\n",
      "\n",
      "in figure 3. in figure 2, the center line represents coefficients having zero values. as the l1 sparsity threshold\n",
      "(|beta|) increases, more coefficients become non-zero. for selecting the optimal λ that minimizes overall prediction error,\n",
      "ten-fold cross validation and aic yielded congruent results.\n",
      "aic results are depicted in the curve in figure 3, which\n",
      "shows that that aic improves as |beta| increases, coming to\n",
      "a minimum at |beta| = 13.40. accordingly, most coefficients\n",
      "for the optimal lasso model are non-zero.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "132\n",
      "\n",
      "\f",
      "table 3: lasso component skill coefficients\n",
      "component skill\n",
      "β̂ exp(β̂)\n",
      "mouse drag\n",
      "1.80\n",
      "6.02\n",
      "checkboxes\n",
      "1.27\n",
      "3.55\n",
      "login information\n",
      ".88\n",
      "2.41\n",
      "hardware identify\n",
      ".60\n",
      "1.82\n",
      "hardware function\n",
      ".50\n",
      "1.65\n",
      "desktop concept\n",
      ".35\n",
      "1.43\n",
      "browser functions\n",
      ".24\n",
      "1.27\n",
      "double click\n",
      ".11\n",
      "1.12\n",
      "complex scrolling\n",
      ".03\n",
      "1.03\n",
      "program brands\n",
      ".00\n",
      "1.00\n",
      "select menu\n",
      "-.21\n",
      ".81\n",
      "window functionality\n",
      "-.44\n",
      ".64\n",
      "keyboard function\n",
      "-.86\n",
      ".42\n",
      "use icons\n",
      "-1.01\n",
      ".36\n",
      "good login info\n",
      "-1.28\n",
      ".28\n",
      "simple typing\n",
      "-1.47\n",
      ".23\n",
      "right click\n",
      "-2.39\n",
      ".09\n",
      "\n",
      "table 3 gives the β̂ coefficients (log odds) for the aicoptimal model as well as the odds ratio exp(β̂) for each coefficient. the coefficients converted to odds ratios have the\n",
      "same interpretation as in the logistic mixed model, e.g. tasks\n",
      "with a mouse drag component are 6.02 times as likely to be\n",
      "answered correctly as those without. although the logistic\n",
      "lasso model does not include random intercepts corresponding to task difficulty and subject ability, the magnitudes of\n",
      "coefficients in the logistic lasso are highly comparable to the\n",
      "logistic mixed model. however, the strength of the coefficients in the logistic lasso are weaker, in general, than in\n",
      "the logistic mixed model, suggesting that the logistic mixed\n",
      "model may be slightly over-fitted. for example, according to\n",
      "the logistic mixed model, mouse drag tasks are 7.87 times\n",
      "as likely to be answered correctly, but according to the logistic lasso model, mouse drag tasks are only 6.02 times as\n",
      "likely to be answered correctly; similarly right click containing tasks in the mixed model are .04 times as likely to\n",
      "be answered correctly compared to .09 times as likely in the\n",
      "logistic lasso. these results suggest that while the logistic\n",
      "mixed model might be more appropriate for assessment purposes, as it additionally estimates task difficulty and subject\n",
      "ability, the logistic lasso model might be more appropriate\n",
      "for predicting the effects of component skills on success rates\n",
      "for new tasks.\n",
      "\n",
      "6. general discussion\n",
      "together, our results suggest that not only are there specific northstar tasks that are informative with regard to\n",
      "building an adaptive computer-based intervention for adults\n",
      "with low literacy skills but also that these tasks can themselves be decomposed into component skills that can be\n",
      "further used for this purpose. the main effects of analysis 3 and coefficient rankings of analysis 4 are consistent\n",
      "and complimentary with the proportion correct results in\n",
      "analysis 1. the marginal main effect for hardware identify explains the high proportion correctness for identification tasks for mouse, keyboard, and headphone jack, and the\n",
      "main effect for mouse drag explains the high proportion correctness for recycling a file (dragging to the recycle bin),\n",
      "dragging, and scrolling (by dragging a scroll bar). these\n",
      "\n",
      "correctness-enhancing main effects are also reflected in odds\n",
      "ratios greater than one in analysis 4. similarly the main effects for keyboard function and simple typing explain the\n",
      "low proportion correctness for identifying various keys, typing web addresses, signing into email, and composing email,\n",
      "and these main effects are likewise reflected in odds ratios\n",
      "less than one in analysis 4. in these cases we infer that\n",
      "the problem is not specific to the interface in question, e.g.\n",
      "email, but rather that there is a deficiency in a component\n",
      "skill needed for the task taking place in the context of that\n",
      "interface.\n",
      "the implications for building adaptive computer-based interventions for adults with low literacy skills are clear. first,\n",
      "it is important to keep typing to a minimum, either by having users select response options or by using speech recognition. second, right clicking should be eliminated or at\n",
      "least made optional. third, icons should be close to icon\n",
      "archetypes. and finally, mouse dragging is a good skill\n",
      "around which to build user interaction. interestingly, all\n",
      "of these implications seem to point to tablet and smartphone platforms, which have a minimum of typing (and\n",
      "built in speech interfaces), no right clicking, minimal icons\n",
      "in-app, and plenty of swiping/dragging. moreover, smartphone ownership has been rapidly increasing – now 64% of\n",
      "households earning below $30 thousand own a smartphone\n",
      "[17]. it may be the case that deploying interventions on\n",
      "smartphones and tablets better makes use of both the computer literacy strengths and the material resources of low\n",
      "literacy adults.\n",
      "\n",
      "7.\n",
      "\n",
      "acknowledgments\n",
      "\n",
      "this research was supported by the institute of education\n",
      "sciences (ies; r305c120001). any opinions, findings and\n",
      "conclusions, or recommendations expressed in this paper are\n",
      "those of the author and do not represent the views of the\n",
      "ies.\n",
      "\n",
      "8.\n",
      "\n",
      "references\n",
      "\n",
      "[1] m. anderson and a. perrin. 13% of americans don’t\n",
      "use the internet. who are they? technical report, pew\n",
      "research center, 2016.\n",
      "[2] d. bakhtiari, a. olney, and d. greeberg. computer\n",
      "literacy skills of adult learners. in preparation.\n",
      "[3] j. a. ballantine, p. m. larres, and p. oyelere.\n",
      "computer usage and the validity of self-assessed\n",
      "computer competence among first-year business\n",
      "students. computers & education, 49(4):976 – 990,\n",
      "2007.\n",
      "[4] t. barnes, d. bitzer, and m. vouk. experimental\n",
      "analysis of the q-matrix method in knowledge\n",
      "discovery. in international symposium on\n",
      "methodologies for intelligent systems, pages 603–611.\n",
      "springer, 2005.\n",
      "[5] h. beder and p. medina. classroom dynamics in adult\n",
      "literacy education. ncsall research brief. technical\n",
      "report, national center for the study of adult\n",
      "learning and literacy, 2002.\n",
      "[6] j. h. friedman. stochastic gradient boosting.\n",
      "computational statistics & data analysis,\n",
      "38(4):367–378, 2002.\n",
      "[7] a. c. graesser, z. cai, w. o. baer, a. m. olney,\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "133\n",
      "\n",
      "\f",
      "[8]\n",
      "\n",
      "[9]\n",
      "\n",
      "[10]\n",
      "\n",
      "[11]\n",
      "\n",
      "[12]\n",
      "\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "\n",
      "[16]\n",
      "\n",
      "[17]\n",
      "\n",
      "[18]\n",
      "\n",
      "x. hu, m. reed, and d. greenberg. reading\n",
      "comprehension lessons in autotutor for the center for\n",
      "the study of adult literacy. in s. a. crossley and\n",
      "d. s. mcnamara, editors, adaptive educational\n",
      "technologies for literacy instruction., pages 288–293.\n",
      "routledge, 2016. doi: 10.4324/9781315647500 doi:\n",
      "10.4324/9781315647500.\n",
      "f. harrell. regression modeling strategies: with\n",
      "applications to linear models, logistic regression,\n",
      "and survival analysis. graduate texts in\n",
      "mathematics. springer, 2001.\n",
      "b. e. john. cogtool: predictive human performance\n",
      "modeling by demonstration. in proceedings of the 19th\n",
      "conference on behaviour representation in modeling\n",
      "and simulation, pages 83–84, 2010.\n",
      "b. e. john and d. e. kieras. the goms family of user\n",
      "interface analysis techniques: comparison and\n",
      "contrast. acm transactions on computer-human\n",
      "interaction (tochi), 3(4):320–351, 1996.\n",
      "b. e. john, k. prevas, d. d. salvucci, and\n",
      "k. koedinger. predictive human performance\n",
      "modeling made easy. in proceedings of the sigchi\n",
      "conference on human factors in computing systems,\n",
      "chi ’04, pages 455–462, new york, ny, usa, 2004.\n",
      "acm.\n",
      "s. nakagawa and h. schielzeth. a general and simple\n",
      "method for obtaining r2 from generalized linear\n",
      "mixed-effects models. methods in ecology and\n",
      "evolution, 4(2):133–142, 2013.\n",
      "n. d. l. project, 2016.\n",
      "proliteracy. u.s. adult literacy facts. technical\n",
      "report, 2017.\n",
      "f. rijmen, p. d. boeck, and k. u. leuven. the\n",
      "random weights linear logistic test model. applied\n",
      "psychological measurement, 26(3):271–285, 2002.\n",
      "a. a. rupp and j. l. templin. unique characteristics\n",
      "of diagnostic classification models: a comprehensive\n",
      "review of the current state-of-the-art. measurement:\n",
      "interdisciplinary research and perspectives,\n",
      "6(4):219–262, 2008.\n",
      "a. smith. record shares of americans now own\n",
      "smartphones, have home broadband. technical report,\n",
      "pew research center, 2017.\n",
      "r. tibshirani. regression shrinkage and selection via\n",
      "the lasso. journal of the royal statistical society.\n",
      "series b (methodological), 58(1):267–288, 1996.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "134\n",
      "\n",
      "\f",
      "towards reliable and valid measurement of individualized\n",
      "student parameters\n",
      "ran liu\n",
      "\n",
      "kenneth r. koedinger\n",
      "\n",
      "human-computer interaction institute\n",
      "carnegie mellon university\n",
      "\n",
      "human-computer interaction institute\n",
      "carnegie mellon university\n",
      "\n",
      "ranliu@cmu.edu\n",
      "\n",
      "koedinger@cmu.edu\n",
      "\n",
      "abstract\n",
      "research in educational data mining could benefit from greater\n",
      "efforts to ensure that models yield reliable, valid, and interpretable\n",
      "parameter estimates. these efforts have especially been lacking\n",
      "for individualized student-parameter models. we collected two\n",
      "datasets from a sizable student population with excellent “depth”\n",
      "– that is, many observations for each skill for each student. we fit\n",
      "two models, the individualized-slope additive factors model\n",
      "(iafm) and individualized bayesian knowledge tracing (ibkt),\n",
      "both of which individualize for student ability and student\n",
      "learning rate. estimates of student ability were reliable and valid:\n",
      "they were consistent across both models and across both datasets,\n",
      "and they significantly predicted out-of-tutor pretest data. in one of\n",
      "the datasets, estimates of student learning rate were reliable and\n",
      "valid: consistent across models and significantly predictive of\n",
      "pretest-posttest gains. this is the first demonstration that\n",
      "statistical models of data resulting from students’ use of learning\n",
      "technology can produce reliable and valid estimates of individual\n",
      "student learning rates. further, we sought to interpret and\n",
      "understand what differentiates a student with a high estimated\n",
      "learning rate from a student with a low one. we found that\n",
      "learning rate is significantly related to estimates of student ability\n",
      "(prior knowledge) and self-reported measures of diligence.\n",
      "finally, we suggest a variety of possible applications of models\n",
      "with reliable estimates of individualized student parameters,\n",
      "including a more novel, straightforward way of identifying wheel\n",
      "spinning.\n",
      "\n",
      "keywords\n",
      "explanatory models, model interpretability, individualized\n",
      "parameters, 3, additive factors model, individualized bayesian\n",
      "knowledge tracing\n",
      "\n",
      "1. introduction\n",
      "in educational data mining, statistical models are typically\n",
      "evaluated based on fit to overall data and/or predictive accuracy\n",
      "on test data. while this is an important initial step in evaluating\n",
      "the contributions of advancements in statistical and cognitive\n",
      "modeling, research in the field could benefit from greater efforts\n",
      "to ensure that models are reliable and valid. more reliable and\n",
      "valid models offer more explanatory power, contributing to the\n",
      "advancement of learning science. they also inspire greater\n",
      "confidence that deploying model advancements in future tutoring\n",
      "systems will genuine result in the hypothesized improvements to\n",
      "learning.\n",
      "some recent work has been done towards interpreting, validating,\n",
      "and acting upon cognitive/skill modeling improvements [7, 8, 10,\n",
      "11, 17]. educational data mining efforts oriented around\n",
      "personalizing student constructs [3, 12, 13, 14, 18], however, have\n",
      "remained focused on improving predictive accuracy and/or\n",
      "demonstrating hypothetical time savings. little has been done to\n",
      "\n",
      "validate or understand the estimates that models with\n",
      "individualized or clustered student parameters produce.\n",
      "anecdotally, efforts to do so have shown that these individualized\n",
      "student parameter estimates, or discovered student clusters, are\n",
      "often difficult to interpret.\n",
      "it is especially critical to examine the reliability and validity of\n",
      "parameter estimates for modeling advancements that dramatically\n",
      "increase the parameter count, as is generally true for\n",
      "individualized student-parameter models. more parameters create\n",
      "greater degrees of freedom and increase the likelihood that the\n",
      "model may be underdetermined by the data.\n",
      "we focus on the question: to what degree can we trust a model’s\n",
      "parameter estimates to correctly represent the constructs they are\n",
      "supposed to?\n",
      "key to expecting reliable, valid estimates of student-level\n",
      "constructs is not just big data in the “long” sense, but big data in\n",
      "the “deep” sense. oftentimes, the datasets used in secondary\n",
      "analyses in edm are large in terms of total number of students (or\n",
      "total observations) but highly sparse in terms of observations per\n",
      "skill, per student. these features make it difficult to get reliable\n",
      "measurements of constructs at the individual student level,\n",
      "particularly constructs related to learning over time.\n",
      "here, we collected two datasets from a sizable student population\n",
      "(196 students) with excellent “depth” – that is, many observations\n",
      "for each skill for each student. we then fit two models that\n",
      "individualize for student ability and student learning rate (the\n",
      "individualized-slope additive factors model [9] and\n",
      "individualized bayesian knowledge tracing [18]). we assess the\n",
      "models’ fit to data and predictive accuracy. we also move beyond\n",
      "these metrics to examine the reliability of the models’ estimates of\n",
      "student ability and student learning rate. additionally, we\n",
      "externally validate the parameter estimates against out-of-tutor\n",
      "assessment data.\n",
      "we further interpret and understand the constructs by visualizing\n",
      "representative student learning trajectories, examining the\n",
      "relationship between estimated student ability and student\n",
      "learning rate, and the relationship between those constructs and\n",
      "self-reported data on motivational attributes. finally, we propose\n",
      "some useful applications of reliable and valid individualized\n",
      "student-parameter models, including a new way to detect wheel\n",
      "spinning.\n",
      "\n",
      "2. prior work\n",
      "prior work on individualizing student parameters has focused on\n",
      "variants of bayesian knowledge tracing (bkt) [3]. this work\n",
      "includes modeling the parameters separately for each individual\n",
      "student instead of separately for each skill [3], individualizing the\n",
      "p(init) (“initial knowledge”) parameter for each student [13], and\n",
      "individualizing both p(init) and p(learn) (“learning rate”) to the\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "135\n",
      "\n",
      "\f",
      "base bkt model [18]. these models have generally focused on\n",
      "assessing predictive accuracy improvements relative to their\n",
      "respective non-individualized baseline models.\n",
      "\n",
      "“general education” classrooms designed to provide the\n",
      "opportunity for individuals with disabilities and special needs to\n",
      "learn alongside their non-disabled peers.\n",
      "\n",
      "there have also been some “time savings” analyses [12, 18] that\n",
      "evaluate the hypothetical real world impact that individualizing\n",
      "statistical model fits could have. these analyses report the effect\n",
      "of fitting individualized bkt models, compared to traditional\n",
      "bkt, on the hypothetical number of under- and over- practice\n",
      "attempts that would be predicted for each student. results\n",
      "generally have indicated that many more practice opportunities\n",
      "are needed for models to infer the same level of knowledge when\n",
      "using whole-population parameters rather than individual student\n",
      "parameters. these analyses show that individualized models differ\n",
      "in their hypothetical decision points if they were to be applied to\n",
      "drive mastery-based learning, but they do not in and of themselves\n",
      "interpret the individualized parameter estimates, nor do they\n",
      "assess the reliability and validity of such estimates.\n",
      "\n",
      "students spent five consecutive days participating in each study\n",
      "during their regular geometry class periods. on the first and last\n",
      "days, they took a computerized pretest and posttest, respectively.\n",
      "during the middle three days, they worked within an intelligent\n",
      "tutoring system [19] designed to give them practice on their\n",
      "current chapter’s content. this procedure applied to both studies,\n",
      "one of which covered the students’ chapter 3 content (parallel\n",
      "lines cut by a transversal, angles & parallel lines, finding\n",
      "slopes of lines, slope-intercept form, point-slope form) and the\n",
      "other of which covered the students’ chapter 4 content\n",
      "(classifying triangles, finding measures of triangle sides &\n",
      "angles, triangle congruence properties). figure 1 shows an\n",
      "example problem interface from the intelligent tutoring system,\n",
      "which was designed using cognitive tutor authoring tools [1].\n",
      "\n",
      "in a previous effort to better understand individualized student\n",
      "learning rate parameters [9], we examined predictive accuracy and\n",
      "parameter reliability in an extension of the additive factors\n",
      "model [2] applied to existing educational datasets. we did not\n",
      "find evidence that individualizing student rate parameters\n",
      "consistently improved predictive accuracy improvements, nor\n",
      "could we validate the parameter estimates on out-of-tutor\n",
      "assessment data. however, the datasets we analyzed either\n",
      "contained a small number of students or were largely sparse in\n",
      "observations for student-skill pairs, with the exception of two\n",
      "datasets. these two datasets happened to be the ones on which the\n",
      "individualized-slope additive factors model did achieve higher\n",
      "predictive accuracy. thus, we wondered if the sparsity of the\n",
      "datasets were the primary limitation, rather than the modeling\n",
      "advancement itself. this idea is corroborated by the fact that\n",
      "pooling students into “groups” rather than generating\n",
      "individualized estimates worked well on those datasets [9].\n",
      "for the present modeling work, we collected our own data in\n",
      "order to ensure the data features that we believe are necessary for\n",
      "reliable, valid, and potentially meaningful estimates of constructs\n",
      "at the individual student level.\n",
      "\n",
      "3. methods\n",
      "it is common in edm to do secondary analyses across multiple\n",
      "datasets. however, it can be difficult to find datasets that (1)\n",
      "contain a sizable number of students, (2) contain many\n",
      "observations for each skill for each student (i.e., are not sparse),\n",
      "(3) contain students spanning a range of abilities in the domain\n",
      "covered by the tutor, and (4) contain data from out-of-tutor\n",
      "assessment data that is well-mapped to the content in the tutor.\n",
      "for the present work, we wanted to use as close to an “ideal”\n",
      "dataset as possible for estimating student parameters. we\n",
      "collected our own dataset with a sizable number of students (196),\n",
      "many observations (5-50, depending on the skill) for each skill for\n",
      "each student. in addition, we ensured that a wide range of student\n",
      "ability levels was represented in our data to allow for the\n",
      "possibility that models could capture this variability.\n",
      "\n",
      "3.1 data collection\n",
      "196 students, spanning 10 classes taught by three different\n",
      "teachers, enrolled in high school geometry participated in two\n",
      "studies conducted about a month apart. a range of student\n",
      "abilities were included in the study. two of the 10 classes were\n",
      "“honors” and three of the 10 classes were “inclusion”. honors\n",
      "classrooms are intended for students who have strong theoretical\n",
      "interests and abilities in mathematics. inclusion classrooms are\n",
      "\n",
      "figure 1. example problem interface from the intelligent\n",
      "tutoring system used for data collection.\n",
      "we also collected self-report survey data on motivational factors\n",
      "falling along three dimensions. these were competitiveness (e.g.,\n",
      "“in this unit, i am striving to do well compared to other students”\n",
      "and “in this unit, i am striving to avoid performing worse than\n",
      "others”), effort (e.g., “i am striving to understand the content of\n",
      "this unit as thoroughly as possible” and “i work hard to do well in\n",
      "this class even if i don't like what we are doing”), and diligence\n",
      "(e.g., “when class work is difficult, i give up or only study the\n",
      "easy parts” [inverted scale] and “i am diligent”). self-report\n",
      "measures were indicated on a likert scale from 1-7.\n",
      "a key reason we collected two datasets, covering two distinct\n",
      "chapters of the curriculum, is that we were interested in\n",
      "investigating the consistency of student-level parameter estimates\n",
      "across different content, time, and contexts. we discuss this\n",
      "further, along with preliminary results, in section 4.4.1.\n",
      "\n",
      "3.2 statistical models\n",
      "3.2.1 the individualized-slope additive factors\n",
      "model (iafm)\n",
      "the additive factors model (afm) [2] is a logistic regression\n",
      "model that extends item response theory by incorporating a\n",
      "growth or learning term.\n",
      "ln\n",
      "\n",
      "!!\"\n",
      "!-!!\"\n",
      "\n",
      "= θ! +\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "!∈!\"# q !\" (β!\n",
      "\n",
      "+ γ! t!\" )\n",
      "\n",
      "(1)\n",
      "\n",
      "136\n",
      "\n",
      "\f",
      "this statistical model (equation 1) gives the probability 𝑝!\" that a\n",
      "student i will get a problem step j correct based on the student’s\n",
      "baseline ability (𝜃! ), the baseline easiness (𝛽! ) of the required\n",
      "knowledge components on that problem step (𝑄!\" ), and the\n",
      "improvement (𝛾! ) in each required knowledge component (kc)\n",
      "with each additional practice opportunity. this kc slope, or\n",
      "“learning rate,” parameter is multiplied by the number of practice\n",
      "opportunities (𝑇!\" ) the student already had on it. knowledge\n",
      "components (kcs) are the underlying facts, skills, and concepts\n",
      "required to solve problems [6].\n",
      "\n",
      "literal comparison between the predictive accuracies of the two\n",
      "classes of models due to differences in whether they use incoming\n",
      "test data towards their predictions on later test data (bkt/ibkt\n",
      "do, and afm/iafm do not).\n",
      "\n",
      "individualized-slope afm (iafm) builds upon this baseline\n",
      "model by adding a per-student learning rate parameter (𝛿! ). this\n",
      "parameter represents the improvement (𝛿! ) by student i with every\n",
      "additional practice opportunity with the kcs required on problem\n",
      "step j.\n",
      "\n",
      "counter to the majority of findings reported in [9], iafm\n",
      "achieved higher predictive accuracy than afm in both datasets\n",
      "here. this further supports the idea that the “depth” of the dataset\n",
      "is a critical factor in whether an individualized student-parameter\n",
      "model can explain unique variance in the data.\n",
      "\n",
      "ln\n",
      "\n",
      "!!\"\n",
      "!!!!\"\n",
      "\n",
      "= 𝜃! +\n",
      "\n",
      "!∈!\"# 𝑄!\" (𝛽!\n",
      "\n",
      "+ 𝛾! 𝑇!\" + 𝛿! 𝑇!\" )\n",
      "\n",
      "(2)\n",
      "\n",
      "the kc and student learning rate parameters are both multiplied\n",
      "by the number of opportunities (𝑇!\" ) the student already had to\n",
      "practice that kc.\n",
      "\n",
      "both iafm and ibkt outperform their non-individualized\n",
      "counterparts by all metrics, with the exception of bkt having a\n",
      "better bic value than ibkt for the chapter 4 dataset. this is not\n",
      "surprising, as bic is known to over-penalize for added\n",
      "parameters. we recommend cross validation as a better indicator\n",
      "that ibkt is the true better fitting model in this case.\n",
      "\n",
      "table 1. summary of model fit and predictive accuracy\n",
      "metrics comparing afm vs. iafm and bkt vs. ibkt. crossvalidation values are mean rmse values across 10 runs, with\n",
      "standard deviations included in parentheses.\n",
      "data\n",
      "set\n",
      "\n",
      "3.2.2 individualized bayesian knowledge tracing\n",
      "(ibkt)\n",
      "bayesian knowledge tracing (bkt [3]) is an algorithm that\n",
      "models student knowledge as a latent variable using a hidden\n",
      "markov model. the goal of bkt is to infer, for each skill,\n",
      "whether a student has mastered it or not based on his/her sequence\n",
      "of performance on items requiring that skill. it assumes a twostate learning model whereby each skill is either known or\n",
      "unknown. there are four parameters that are estimated in a bkt\n",
      "model: the initial probability of knowing a skill a priori – p(init),\n",
      "the probability of a skill transitioning from not known to known\n",
      "state after an opportunity to practice it – p(learn), the probability\n",
      "of slipping when applying a known skill – p(slip), and the\n",
      "probability of correctly guessing without knowing the required\n",
      "skill – p(guess). fitting bkt produces estimates for each of these\n",
      "four parameters for every skill in a given dataset. bkt models are\n",
      "usually fit using the expectation maximization method (em),\n",
      "conjugate gradient search, or discretized brute-force search.\n",
      "individualized bayesian knowledge tracing (ibkt [18]) builds\n",
      "upon this baseline bkt model by individualizing the estimate of\n",
      "the probability of initially knowing a skill, p(init), and the\n",
      "transition probability, p(learn), for each student. to accomplish\n",
      "the student-level individualization of these parameters, each of\n",
      "them is split into skill- and student-based components that are\n",
      "summed and passed through a logistic transform to yield the final\n",
      "parameter estimate. details on the decomposition of p(init) and\n",
      "p(learn) into skill- and student-based components are described\n",
      "in [18].\n",
      "\n",
      "4. results\n",
      "4.1 model fit & predictive accuracy\n",
      "as a first pass evaluation of the two individualized models, we\n",
      "assessed them using akaike information criterion (aic) and\n",
      "bayesian information criterion (bic), which are standard metrics\n",
      "for model comparison, and 10 independent runs of split-halves\n",
      "cross validation (cv). although 10-fold cross validation has been\n",
      "popular in the field, [4] showed that it has a high type-i error due\n",
      "to high overlap among training sets and recommended at least 5\n",
      "replications of 2-fold cv instead.\n",
      "here, the comparison of interest is each individualized model\n",
      "against its non-individualized counterpart. we do not encourage a\n",
      "\n",
      "ch. 3\n",
      "\n",
      "ch. 4\n",
      "\n",
      "model\n",
      "\n",
      "aic\n",
      "\n",
      "bic\n",
      "\n",
      "afm\n",
      "\n",
      "57229\n",
      "\n",
      "57283\n",
      "\n",
      "cv test rmse\n",
      "(10-run average)\n",
      "0.38440 (0.0039)\n",
      "\n",
      "iafm\n",
      "\n",
      "55931\n",
      "\n",
      "56003\n",
      "\n",
      "0.37868 (0.0044)\n",
      "\n",
      "bkt\n",
      "\n",
      "66714\n",
      "\n",
      "67473\n",
      "\n",
      "0.4222 (0.0005)\n",
      "\n",
      "ibkt\n",
      "\n",
      "56325\n",
      "\n",
      "60479\n",
      "\n",
      "0.3777 (0.0006)\n",
      "\n",
      "afm\n",
      "\n",
      "18059\n",
      "\n",
      "18106\n",
      "\n",
      "0.41037 (0.0048)\n",
      "\n",
      "iafm\n",
      "\n",
      "17863\n",
      "\n",
      "17925\n",
      "\n",
      "0.40789 (0.0050)\n",
      "\n",
      "bkt\n",
      "\n",
      "19908\n",
      "\n",
      "20376\n",
      "\n",
      "0.44091 (0.0014)\n",
      "\n",
      "ibkt\n",
      "\n",
      "18285\n",
      "\n",
      "21809\n",
      "\n",
      "0.40725 (0.0018)\n",
      "\n",
      "4.2 reliability of student parameters\n",
      "next, we examined the degree to which we can rely on these\n",
      "parameters to reasonably estimate the constructs that they should\n",
      "be estimating. we believe that a strong relationship between the\n",
      "parameter estimates of two statistical models with entirely\n",
      "different architectures is a high bar for testing reliability. that is,\n",
      "if a student genuinely displayed evidence of high overall ability in\n",
      "a dataset (relative to his/her peers), then both iafm and ibkt\n",
      "should estimate that to be the case.\n",
      "because of known and observed nonlinear relationships between\n",
      "logistic regression and bayesian knowledge tracing parameter\n",
      "estimates, we measured correlation based on spearman’s\n",
      "coefficient (rs), which is based on rank order.\n",
      "we observed strong and statistically significant correlations\n",
      "between iafm student intercept and ibkt student p(init)\n",
      "parameter estimates (figure 2, top row). we also observed a\n",
      "strong and statistically significant correlation between iafm\n",
      "student slope and ibkt student p(learn) parameter estimates for\n",
      "one of the two datasets (chapter 4). this correlation was much\n",
      "milder, though still significant, for the other dataset (chapter 3).\n",
      "we hypothesize that this difference between datasets may be due\n",
      "to the presence of more difficult kcs in chapter 4. a dataset with\n",
      "more difficult items should provide more sensitive measures of\n",
      "individual differences in improvement, since it avoids ceiling\n",
      "effects. indeed, this was the case: the mean kc easiness parameter\n",
      "estimate (𝛽! ) for chapter 4 was 0.799 (which translates to a\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "137\n",
      "\n",
      "\f",
      "probability of 0.69), compared to 1.253 for chapter 3 (which\n",
      "translates to a probability of 0.78). when students are practicing\n",
      "many opportunities at ceiling (which was the case in particular for\n",
      "chapter 3, based on exploratory analyses of the data), the\n",
      "individualized models will often assign them a lower “learning\n",
      "rate” due to an essentially flat learning trajectory.\n",
      "\n",
      "this has several interesting implications for educational\n",
      "applications. first, it suggests that formative assessment via\n",
      "modeling of process data as learning unfolds is a reasonable\n",
      "method of assessment.\n",
      "it also suggests that detailed assessment data (e.g., from a pretest)\n",
      "could be used to reasonable effect to improve different students’\n",
      "“on-line” estimates of students’ knowledge of kcs. for example,\n",
      "combining kc parameter estimates (derived from model-fitting to\n",
      "prior domain-relevant data) with student intercept priors based on\n",
      "pretest assessment data would allow a model like afm to\n",
      "generate individualized predictions of how much each student\n",
      "needs to practice to reach mastery.\n",
      "in addition, these results suggest that individualized bkt models\n",
      "could use pretest assessment data to “set” reasonably valid\n",
      "student-specific p(init) values before collecting any within-tutor\n",
      "data from those students.\n",
      "in considering the degree to which these results may generalize, it\n",
      "is important to note that the pretests in the present datasets were\n",
      "specifically designed to map closely to the practice problems in\n",
      "the intelligent tutor. pretests contained 1-2 questions for each kc\n",
      "that was practiced in the tutor, and the items were similar to those\n",
      "encountered within the tutor.\n",
      "\n",
      "figure 2. relationships between iafm student intercept and\n",
      "ibkt student p(init) parameter estimates (top row), and\n",
      "between iafm student slope and ibkt student p(learn)\n",
      "parameter estimates (bottom row), for the two datasets.\n",
      "\n",
      "4.3 validity of student parameters\n",
      "\n",
      "to assess the validity of student parameter estimates, we related\n",
      "them to out-of-tutor assessments of the relevant student\n",
      "constructs. in this case, we validated parameter estimates using\n",
      "pretest and posttest assessment data collected in the study.\n",
      "\n",
      "4.3.1 estimates of student ability\n",
      "the student intercept (𝜃! ) parameter of iafm and the student\n",
      "p(init) parameter of bkt are designed to estimate baseline\n",
      "student ability, as least for the knowledge domain represented in\n",
      "the dataset. to validate the models’ estimates of this construct, we\n",
      "examined relationships between the model estimates and students’\n",
      "pretest scores, which are an out-of-tutor assessment of student\n",
      "initial ability for the skills covered by the tutor.\n",
      "we report standard pearson correlation coefficients here, since the\n",
      "relationships between pretest scores and the parameter estimates\n",
      "did not appear to be particularly nonlinear.\n",
      "figure 3 illustrates a summary of these relationships. both\n",
      "models’ estimates of the student ability construct were strongly\n",
      "and significantly correlated with pretest scores.\n",
      "in addition, adding an individualized student slope improved the\n",
      "validity of the model’s estimate of student ability (a parameter\n",
      "that’s modeled in both afm and iafm). we compared the\n",
      "correlations between afm’s intercept estimates to pretest scores\n",
      "(chapter 3: r = 0.62, p < 0.0001, chapter 4: r = 0.58, p < 0.0001)\n",
      "to iafm’s intercept estimate / pretest score correlations (chapter\n",
      "3: 0.74, p < 0.0001, chapter 4: r = 0.66, p < 0.0001).\n",
      "\n",
      "figure 3. relationships between out-of-tutor pretest scores\n",
      "and iafm/ibkt estimates of student ability based on withintutor data.\n",
      "\n",
      "4.3.2 estimates of student learning rate\n",
      "given that the only external assessment data collected were a\n",
      "pretest and posttest, we sought to validate the construct of student\n",
      "learning rate (as estimated by the models) on pretest-posttest\n",
      "gains. students were given roughly the same amount of time to\n",
      "engage with the tutors, so those with accelerated learning rates\n",
      "might be expected to gain more knowledge in the time available.\n",
      "thus, we examined the degree to which student learning rate\n",
      "estimates predicted pretest-posttest gains while controlling for\n",
      "pretest scores. we controlled for pretest scores because they have\n",
      "been shown to negatively predict learning gains due to assessment\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "138\n",
      "\n",
      "\f",
      "ceiling effects. that is, students who start out performing well on\n",
      "the pretest have less “room for improvement”.\n",
      "\n",
      "model estimates of the student ability and student learning rate\n",
      "constructs across units?\n",
      "\n",
      "for the chapter 3 dataset, iafm student slope (𝛿! ) estimates did\n",
      "not significantly predict learning gains. in a linear regression\n",
      "predicting pretest-posttest gains, pretest scores were a significant\n",
      "predictor (β=-0.189, p=0.005) and student slope estimates were\n",
      "not (β=0.396, p=0.144). ibkt student p(learn) estimates did not\n",
      "significant predict learning gains. in a linear regression predicting\n",
      "pretest-posttest gains, pretest scores were a significant predictor\n",
      "(β=-0.226, p=0.005) and student slope estimates were not\n",
      "(β=0.062, p=0.218).\n",
      "\n",
      "figure 4 summarizes this relationship. estimates of student ability\n",
      "are fairly consistent, especially as estimated by iafm. it seems\n",
      "sensible to interpret this as suggesting that overall student ability\n",
      "on chapter 3 content is strongly related to overall student ability\n",
      "on chapter 4 content, as we have shown estimates of student\n",
      "ability to be both reliable and valid.\n",
      "\n",
      "for the chapter 4 dataset, iafm student slope (𝛿! ) estimates\n",
      "significantly predict learning gains. in a linear regression\n",
      "predicting pretest-posttest gains, pretest scores (β=-0.641,\n",
      "p<0.0001) and student slope estimates (β=0.576, p=0.007) were\n",
      "both significant predictors. ibkt student p(learn) estimates also\n",
      "significantly predict learning gains. in a linear regression\n",
      "predicting pretest-posttest gains, pretest scores (β=-0.645,\n",
      "p<0.0001) and p(learn) estimates (β=0.133, p=0.004) were both\n",
      "significant predictors.\n",
      "for one of the two units (chapter 4), we observed that student\n",
      "learning rate estimates were validated on external assessments of\n",
      "learning gain. interestingly, this is the same unit for which we\n",
      "observed a strong cross-model reliability in student learning rate\n",
      "estimates. thus, we have converging evidence that student\n",
      "learning rates estimates for the chapter 4 dataset are both reliable\n",
      "and valid.\n",
      "\n",
      "estimates of student learning rate are less consistent. this may\n",
      "either be due to the fact that chapter 3 estimates of student\n",
      "learning rate were neither very reliable nor very valid.\n",
      "alternatively, the differences in student learning rate estimates\n",
      "across the two chapters may also be due to the fact that students\n",
      "genuinely learn different material at different rates. unfortunately,\n",
      "we cannot resolve this question with the present data. we are\n",
      "currently collecting more datasets from this same group of\n",
      "students. if we obtain more reliable and valid student learning rate\n",
      "estimates in future data from this group of students, we can more\n",
      "confidently address this question in future research.\n",
      "\n",
      "4.4.2 understanding student learning rate estimates\n",
      "given that we established the reliability and validity of iafm and\n",
      "ibkt’s parameter estimates for the chapter 4 dataset were\n",
      "reasonably reliable and valid, we sought to dig deeper into the\n",
      "explanatory power of these estimates. to this end, we conducted\n",
      "exploratory analyses on the chapter 4 data to (1) visualize the\n",
      "learning trajectories of students with the highest vs. lowest\n",
      "estimated learning rates, (2) understand the relationships between\n",
      "estimated learning rates and prior-knowledge and motivational\n",
      "factors, and (3) understand the degree of variability in estimated\n",
      "learning rate across students.\n",
      "\n",
      "first attempt success\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "\n",
      "first attempt success\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "\n",
      "1.0\n",
      "\n",
      "ibkt student p(learn) estimate\n",
      "\n",
      "1.0\n",
      "\n",
      "iafm student slope estimate\n",
      "\n",
      "4\n",
      "6\n",
      "8\n",
      "# practice opportunities\n",
      "\n",
      "10\n",
      "\n",
      "0\n",
      "\n",
      "4.4 towards understanding & using student\n",
      "parameter estimates\n",
      "4.4.1 consistency of individual student constructs\n",
      "across datasets\n",
      "a core motivating question for collecting two datasets on the\n",
      "same group of students was: how consistent are iafm and ibkt\n",
      "\n",
      "4\n",
      "6\n",
      "8\n",
      "# practice opportunities\n",
      "\n",
      "10\n",
      "\n",
      "6\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "top 25% ibkt learning rates\n",
      "middle 50% ibkt learning rates\n",
      "bottom 25% ibkt learning rates\n",
      "\n",
      "0\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "likert scale\n",
      "\n",
      "4\n",
      "3\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "likert scale\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "top 25% iafm learning rates\n",
      "middle 50% iafm learning rates\n",
      "bottom 25% iafm learning rates\n",
      "\n",
      "0\n",
      "\n",
      "figure 4. relationships between student parameter estimates\n",
      "across the two datasets (same student population).\n",
      "\n",
      "2\n",
      "\n",
      "7\n",
      "\n",
      "2\n",
      "\n",
      "7\n",
      "\n",
      "0\n",
      "\n",
      "0.2\n",
      "\n",
      "0.2\n",
      "\n",
      "top 25%\n",
      "middle 50%\n",
      "bottom 25%\n",
      "\n",
      "competitiveness\n",
      "\n",
      "effort\n",
      "\n",
      "diligence\n",
      "\n",
      "competitiveness\n",
      "\n",
      "effort\n",
      "\n",
      "diligence\n",
      "\n",
      "figure 5. top row: early-opportunity learning trajectories of\n",
      "students, grouped based on iafm (left) and ibkt (right)\n",
      "estimated learning rates. solid lines are actual data; dotted\n",
      "lines are each respective model’s predicted performance.\n",
      "bottom row: mean self-report likert scale ratings of\n",
      "questions measuring dimensions of competitiveness, effort,\n",
      "and diligence. grouped based on iafm (left) or ibkt (right)\n",
      "estimated learning rates. error bars show standard errors on\n",
      "the means.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "139\n",
      "\n",
      "\f",
      "figure 5 (top row) shows the aggregate learning trajectories for\n",
      "students split based either on their iafm student slope estimates\n",
      "(top left) or their ibkt student p(learn) estimates (top right). the\n",
      "top 25% of student parameter estimates are plotted in blue, the\n",
      "middle 50% (between 1st and 3rd quartiles) are plotted in red, and\n",
      "the lower 25% are plotted in black. dotted lines represent each\n",
      "respective model’s predicted earning trajectories.\n",
      "one striking pattern, especially in the iafm learning trajectories\n",
      "(top left), is the apparent relationship between average success on\n",
      "initial practice opportunities (i.e., prior knowledge) and estimated\n",
      "learning rate through the remaining opportunities. this\n",
      "observation is corroborated by a strong and significant correlation\n",
      "between iafm student intercepts and iafm student slopes\n",
      "(r=0.78, p<0.0001). one might interpret this to suggest that\n",
      "students who enter into the tutor with greater prior knowledge will\n",
      "be poised to gain more from the tutor (i.e., “the rich get richer”).\n",
      "alternatively, students may have higher overall knowledge\n",
      "because they are fast learners. there may also be individual traitbased variables that positively drive both learning rate and overall\n",
      "achievement.\n",
      "to explore the relationships between measures of traits relevant to\n",
      "learning, we analyzed self-report survey data grouped by three\n",
      "factors (as described in section 3.1): competitiveness, effort, and\n",
      "diligence. the relationship between these measures and the high,\n",
      "medium, and low learning rate estimates from iafm and ibkt\n",
      "are shown in figure 5 (bottom row). there appears to be a\n",
      "relationship between the means of each self-report measure and\n",
      "the general range that the learning rate estimate falls in.\n",
      "we analyzed the continuous relationship between students’ mean\n",
      "self-report rating along each dimension and their iafm learning\n",
      "rate estimates. in a linear regression predicting iafm student\n",
      "slopes, competitiveness and effort were not significant predictors\n",
      "but diligence (β=0.016, p=0.007) was. in a similar linear\n",
      "regression predicting iafm student intercepts, again diligence\n",
      "was the only significant predictor (β=0.02, p=0.04). thus, among\n",
      "self-reported measures, the strongest dimension predicting both\n",
      "student ability/prior knowledge and student learning rate was the\n",
      "diligence measure. future work using causal modeling is\n",
      "warranted to discover the true nature of causality among these\n",
      "student-level constructs.\n",
      "finally, we investigated the degree of variability in estimated\n",
      "learning rate across students. the first quantile of student learning\n",
      "rates from iafm is 0.03 logits and the third quantile of rates from\n",
      "iafm is 0.08 logits. these can be conceptualized as canonical\n",
      "“slow” and “fast” learners. if we were to assume starting at\n",
      "around 70% performance (which comes from the model’s global\n",
      "intercept estimate), it would take the “slow” (0.03 logits) student\n",
      "approximately 25 opportunities to reach mastery (defined as 85%,\n",
      "the performance equivalent of a p(know)=0.95, factoring in the\n",
      "guess and slip probabilities we used in the actual tutor). it would\n",
      "take the “fast” (0.08 logits) student approximately 11\n",
      "opportunities to reach the same place.\n",
      "\n",
      "4.4.3 identifying wheel spinners\n",
      "the current definition of “wheel spinning” put forth in the\n",
      "educational data mining community is the “phenomenon in\n",
      "which a student has spent a considerable amount of time\n",
      "practicing a skill, yet displays little or no progress towards\n",
      "mastery” [5]. there has been some controversy around the ideal\n",
      "way to measure mastery (e.g., 3 corrects in a row vs. reaching a\n",
      "certain p(know) in knowledge tracing). furthermore, some\n",
      "students may be classified as wheel spinners based on not\n",
      "mastering in a certain number of opportunities but they may still\n",
      "be making progress.\n",
      "\n",
      "we propose that reliable and validated estimates of individual\n",
      "student learning rate parameters, combined with kc learning rate\n",
      "parameters, could be used to estimate wheel spinning student/kc\n",
      "pairs in way that is agnostic to mastery status. specifically, if the\n",
      "combined student and kc learning rate parameters in iafm\n",
      "predict no improvement or negative improvement across\n",
      "additional practice opportunities, and aren’t already at a high level\n",
      "of performance on their first opportunity (here we considered this\n",
      "to be 80% or above), we could consider the student to be wheel\n",
      "spinning on the kc. this method of estimating wheel spinning\n",
      "would be particularly useful for datasets with sparse data on some\n",
      "student-kc pairs, as it is not performance-dependent after the\n",
      "model has been fit to the full dataset.\n",
      "based on this operationalized definition, we found that\n",
      "approximately 15% of student-kc pairs in the chapter 4 dataset\n",
      "are estimated to be wheel spinning. that is, those students are not\n",
      "making progress on those kcs. this is a substantially lower\n",
      "estimate than the 25% reported by a recent wheel spinning\n",
      "detector in [5]. an interesting route for future work would be to\n",
      "do a direct comparison of the wheel spinning detector presented in\n",
      "[5] and our proposed student/kc learning rate identifier within the\n",
      "same dataset. this would allow for testing the possibility that\n",
      "some students who are still making progress, albeit extremely\n",
      "slowly, may be prematurely labeled as “wheel spinners” by [5].\n",
      "\n",
      "5. summary & limitations\n",
      "previous efforts towards more explanatory, interpretable, and\n",
      "actionable modeling advancements in the realm of\n",
      "skill/knowledge component model discovery have been promising\n",
      "in their potential and demonstrated impact on learning science and\n",
      "education. the present paper represents a novel effort to bring\n",
      "these deeper modeling approaches, focused on ensuring\n",
      "explanatory power, to the realm of individualized studentparameter models.\n",
      "towards improving the reliability and validity of individualized\n",
      "student estimates, we collected two datasets from the same student\n",
      "population. both datasets were “deep” along the dimension of\n",
      "student-kc observations. we fit iafm and ibkt to both datasets\n",
      "and showed that the models outranked their non-individualized\n",
      "counterparts in terms of fit to data and predictive accuracy.\n",
      "importantly, we moved beyond these metrics to show that\n",
      "estimates of student ability were highly reliable (iafm and ibkt\n",
      "yielded strongly correlated estimates) and valid (estimates\n",
      "significantly predicted pretest data).\n",
      "this demonstration of confidence in the student ability estimates\n",
      "from ibkt, but even more so iafm, has promising implications\n",
      "for the possibility of individualizing the student models that\n",
      "determine mastery in intelligent tutoring systems at least in terms\n",
      "of overall student ability/knowledge. our results also suggest that\n",
      "it would be reasonable to fix such student ability parameters, or\n",
      "set priors on them, based on either well-mapped pretest\n",
      "assessment data or prior (deep) data from those students’ learning.\n",
      "we also showed that estimates of student learning rate per\n",
      "practice opportunity were reliable and valid in one of the two\n",
      "datasets (chapter 4). this is the first evidence, to our knowledge,\n",
      "of obtaining both reliable and valid student learning rates through\n",
      "a statistical model with individualized student parameters. we\n",
      "believe that this success is largely related to the amount and\n",
      "quality of per-student data we collected.\n",
      "with the confidence of having reliable and valid parameter\n",
      "estimates, we then proceeded to further investigate potential\n",
      "explanations for differences in student learning rates within the\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "140\n",
      "\n",
      "\f",
      "chapter 4 dataset. we found a strong and significant relationship\n",
      "between student ability and improvement rate as well as an\n",
      "additional effect of diligence, based on self-report measures.\n",
      "further research is warranted to distill the causal relationships\n",
      "between these constructs.\n",
      "knowing that a model’s estimates of individualized student\n",
      "parameters not only fit data well, but are reliable and valid,\n",
      "provides greater confidence for applying the model to (1) interpret\n",
      "the parameter estimates to understand characteristics of students,\n",
      "and (2) use the model to individualize the trajectory of mastery\n",
      "estimation for future students.\n",
      "even though both ibkt and iafm outperformed their nonindividualized counterparts in predicting performance in the\n",
      "chapter 3 dataset, we did not find strong evidence of reliability\n",
      "and validity of the student-specific parameter estimates. thus, we\n",
      "did not rely on that dataset to help us understand individual\n",
      "differences in learning rates. for the same reason, we could not\n",
      "confidently attribute the differences, in estimated student learning\n",
      "rates across the datasets, to true differences in students’ learning\n",
      "rates for the two chapters’ material.\n",
      "although considering reliability and validity of models’ parameter\n",
      "estimates sets a higher bar than predictive accuracy for evaluating\n",
      "modeling advances, we believe those to be important\n",
      "characteristics of a model that is to be explanatory, interpretable,\n",
      "and/or actionable. here, we have demonstrated that with a\n",
      "sufficiently good dataset, iafm and ibkt are individualized\n",
      "student models that can produce reliable and valid parameter\n",
      "estimates.\n",
      "since our present work was limited to two datasets on one\n",
      "population of students, it is unclear the degree to which our\n",
      "modeling results will generalize, especially given that at least\n",
      "iafm does not produce reliable, valid parameter estimates on\n",
      "more sparse datasets [9]. in addition, these results are limited to\n",
      "two specific statistical models produce individualized estimates\n",
      "student-level parameters, with a particular focus on individual\n",
      "differences in learning rate. there are other classes of models that\n",
      "could be extended to estimate differences in learning rate: for\n",
      "example, producing individualized estimates of the differential\n",
      "effects of success versus failure [15]. this would be an interesting\n",
      "focus for future work on this topic.\n",
      "nevertheless, we have laid a foundation of methodology by which\n",
      "reliability and validity of parameter estimates, whether student- or\n",
      "kc-level, can be assessed. we have also demonstrated ways of\n",
      "using the reliable and valid student parameter estimates from\n",
      "iafm and ibkt to yield interesting insights about student\n",
      "learning.\n",
      "\n",
      "6. acknowledgments\n",
      "we thank the institute of education sciences for support to rl\n",
      "(training grant #r305b110003) and the national science\n",
      "foundation for support to carnegie mellon university’s learnlab\n",
      "(#sbe-0836012).\n",
      "\n",
      "7. references\n",
      "[1] aleven, v., sewall, j., mclaren, b.m., and koedinger, k.r.\n",
      "(2006). rapid authoring of intelligent tutors for real-world\n",
      "and experimental use. in proceedings of the 6th icalt.\n",
      "ieee, los alamitos, ca, pp. 847-851.\n",
      "[2] cen, h., koedinger, k.r., & junker, b. (2006). learning\n",
      "factors analysis: a general method for cognitive model\n",
      "evaluation and improvement. intelligent tutoring systems,\n",
      "164-175.\n",
      "\n",
      "[3] corbett, a.t., & anderson, j.r. (1995). knowledge tracing:\n",
      "modeling the acquisition of procedural knowledge. user\n",
      "modeling and user-adapted interaction, 4, 253-278.\n",
      "[4] dietterich, t. g. (1998). approximate statistical tests for\n",
      "comparing supervised classification learning algorithms.\n",
      "neural computation, 10(7), 1895–1923.\n",
      "[5] gong, y. & beck, j. (2015). towards detecting wheelspinning: future failure in mastery learning. in\n",
      "proceedings of learning at scale ’15.\n",
      "[6] koedinger, k.r., corbett, a.c., & perfetti, c. (2012). the\n",
      "knowledge-learning-instruction (kli) framework: bridging\n",
      "the science-practice chasm to enhance robust student\n",
      "learning. cognitive science, 36(5), 757-798.\n",
      "[7] koedinger, k.r., mclaughlin, e.a., & stamper, j.c. (2012).\n",
      "automated student model improvement. 5th international\n",
      "conference on edm.\n",
      "[8] koedinger, k. r., stamper, j. c., mclaughlin, e. a., &\n",
      "nixon, t. (2013). using data-driven discovery of better\n",
      "cognitive models to improve student learning. in h. c. lane,\n",
      "k. yacef, j. mostow, & p. pavlik (eds.), proceedings of the\n",
      "16th international conference on artificial intelligence in\n",
      "education (aied ʼ13), 9–13 july 2013, memphis, tn, usa\n",
      "(pp. 421–430). springer.\n",
      "[9] liu, r., & koedinger, k. r. (2015). variations in learning\n",
      "rate: student classification based on systematic residual error\n",
      "patterns across practice opportunities. in o. c. santos, j. g.\n",
      "boticario, c. romero, m. pechenizkiy, a. merceron, p.\n",
      "mitros, j. m. luna, c. mihaescu, p. moreno, a. hershkovitz,\n",
      "s. ventura, & m. desmarais (eds.), proceedings of the 8th\n",
      "international conference on education data mining\n",
      "(edm2015), 26–29 june 2015, madrid, spain (pp. 420–423).\n",
      "international educational data mining society.\n",
      "[10] liu, r., & koedinger, k. r. (under review). closing the\n",
      "loop: automated data-driven skill model discoveries lead to\n",
      "improved instruction and learning gains.\n",
      "[11] liu, r., koedinger, k. r., & mclaughlin, e. a. (2014).\n",
      "interpreting model discovery and testing generalization to a\n",
      "new dataset. in j. stamper, z. pardos, m. mavrikis, & b. m.\n",
      "mclaren (eds.), proceedings of the 7th international\n",
      "conference on educational data mining (edm2014), 4–7\n",
      "july, london, uk (pp. 107–113). international educational\n",
      "data mining society.\n",
      "[12] lee, j.i., & brunskill, e. (2012). the impact on\n",
      "individualizing student models on necessary practice\n",
      "opportunities. 5th international conference on edm.\n",
      "[13] pardos, z.a., & heffernan, n.t. (2010). modeling\n",
      "individualization in a bayesian networks implementation of\n",
      "knowledge tracing. user modeling, adaptation, and\n",
      "personalization, 255-266.\n",
      "[14] pardos, z. a., trivedi, s., heffernan, n. t., & sárközy, g.\n",
      "n. (2012). clustered knowledge tracing. in s. a. cerri, w. j.\n",
      "clancey, g. papadourakis, k.-k. panourgia (eds.),\n",
      "proceedings of the 11th international conference on\n",
      "intelligent tutoring systems (its 2012), 14–18 june 2012,\n",
      "chania, greece (pp. 405–410). springer.\n",
      "[15] pavlik, p.i., cen, h., & koedinger, k.r. (2009).\n",
      "performance factors analysis–a new alternative to knowledge\n",
      "tracing. aied, 531–538.\n",
      "[16] shmueli, g. (2010). to explain or to predict? statistical\n",
      "science, 25(3), 289–310. doi:10.1214/10-sts330\n",
      "[17] stamper, j., & koedinger, k. r. (2011). human-machine\n",
      "student model discovery and improvement using data.\n",
      "proceedings of the 15th international conference on\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "141\n",
      "\n",
      "\f",
      "artificial intelligence in education (aied ʼ11), 28 june–2\n",
      "july, auckland, new zealand (pp. 353–360). springer.\n",
      "[18] yudelson, m.v., koedinger, k.r., & gordon, g.j. (2013).\n",
      "individualized bayesian knowledge tracing models. aied,\n",
      "171-180.\n",
      "\n",
      "[19] vanlehn, k. (2006). the behavior of tutoring systems.\n",
      "international journal of artificial intelligence in education,\n",
      "16, 227–265.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "142\n",
      "\n",
      "\f",
      "the misidentified identifiability problem of bayesian\n",
      "knowledge tracing\n",
      "shayan doroudi\n",
      "\n",
      "computer science\n",
      "department\n",
      "carnegie mellon university\n",
      "pittsburgh, pa 15206\n",
      "\n",
      "shayand@cs.cmu.edu\n",
      "\n",
      "abstract\n",
      "in this paper, we investigate two purported problems with\n",
      "bayesian knowledge tracing (bkt), a popular statistical\n",
      "model of student learning: identifiability and semantic model\n",
      "degeneracy. in 2007, beck and chang stated that bkt is\n",
      "susceptible to an identifiability problem—various models with\n",
      "different parameters can give rise to the same predictions\n",
      "about student performance. we show that the problem they\n",
      "pointed out was not an identifiability problem, and using an\n",
      "existing result from the identifiability of hidden markov models, we show that under mild conditions on the parameters,\n",
      "bkt is actually identifiable. in the second part of the paper,\n",
      "we discuss a problem that has been conflated with identifiability, but which actually does arise when fitting bkt models,\n",
      "semantic model degeneracy—the model parameters that best\n",
      "fit the data are inconsistent with the conceptual assumptions\n",
      "underlying bkt. we give some intuition for why semantic\n",
      "model degeneracy may arise by showing that bkt models fit\n",
      "to data generated from alternative models of student learning\n",
      "can have semantically degenerate parameters. finally, we\n",
      "discuss the potential implications of these insights.\n",
      "\n",
      "keywords\n",
      "bayesian knowledge tracing, identifiability, semantic model\n",
      "degeneracy\n",
      "\n",
      "1.\n",
      "\n",
      "introduction\n",
      "\n",
      "bayesian knowledge tracing (bkt) is a popular model of\n",
      "student learning that tries to predict the probability that\n",
      "a student knows a skill and the probability that a student\n",
      "will answer questions based on the skill correctly. the bkt\n",
      "model is a two state hidden markov model (hmm) that\n",
      "posits students have either mastered a skill or not, and at\n",
      "every practice opportunity, a student who has not mastered\n",
      "the skill has some chance of attaining mastery. if a student\n",
      "has mastered a skill, they will answer a question correctly\n",
      "unless they “slip” with some (ideally small) probability, and\n",
      "\n",
      "emma brunskill\n",
      "\n",
      "computer science\n",
      "department\n",
      "stanford university\n",
      "stanford, ca 94305\n",
      "\n",
      "ebrun@cs.stanford.edu\n",
      "if the student has not mastered the skill, they can only guess\n",
      "correctly with some (ideally small) probability. in 2007,\n",
      "beck and chang stated that bkt is not identifiable, meaning that different settings of the four bkt parameters can\n",
      "lead to identical predictions about a student’s performance\n",
      "[7]. whether or not bkt is identifiable is an important\n",
      "issue, because if bkt is not identifiable, it means that we\n",
      "would fundamentally need other criteria (beyond accurately\n",
      "modeling student performance data) to fit bkt models.\n",
      "however, in this paper, we show that bkt is actually an\n",
      "identifiable model, under mild conditions on the parameters\n",
      "that should always be satisfied in practical settings. this\n",
      "result follows from bkt being a special case of a hidden\n",
      "markov model and therefore it inherits identifiability results\n",
      "that prior work has proven for hmms. this implies no additional criteria beyond predictive accuracy are needed to\n",
      "identify a single bkt model that best explains observed\n",
      "student performance, under the assumption that learning\n",
      "can accurately be modeled by a bkt. we then describe three\n",
      "potential issues with bkt models that may have been misconstrued as an identifiability problem in the literature. note\n",
      "that our goal is by no means to criticize prior researchers, as\n",
      "such researchers helped identify some important limitations\n",
      "of bayesian knowledge tracing, but these limitations do not\n",
      "stem from a lack of identifiablity.\n",
      "in the second part of this paper, we focus on one of the\n",
      "issues that has been conflated with identifiability, but which\n",
      "actually does arise when fitting bkt models, semantic model\n",
      "degeneracy—the model parameters that best fit the data are\n",
      "inconsistent with the conceptual assumptions underlying\n",
      "bkt. we give a critical look at the types of semantic model\n",
      "degeneracy in the literature and then give some intuition for\n",
      "why this problem may arise by showing that bkt models\n",
      "fit to data generated from alternative models of student\n",
      "learning can have degenerate parameters. we further show\n",
      "that fitting models to sequences of different lengths generated\n",
      "from the same underlying model can result in different forms\n",
      "of semantic degeneracy. we show that these insights can\n",
      "have important implications on how these models should be\n",
      "used.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "143\n",
      "\n",
      "\f",
      "2.\n",
      "\n",
      "bayesian knowledge tracing\n",
      "\n",
      "the bayesian knowledge tracing model is a two-state hidden markov model that keeps track of the probability that a\n",
      "student has mastered a particular skill and the probability\n",
      "that the student will be able to answer a question on that\n",
      "skill correctly over time. at each practice opportunity i ≥ 1\n",
      "(i.e., when a student has to an answer a question corresponding to the skill), the student has a latent knowledge state\n",
      "ki ∈ {0, 1}. if the knowledge state is 0, the student has\n",
      "not mastered the skill, and if it is 1, then the student has\n",
      "mastered it. the student’s answer can either be correct or\n",
      "incorrect: ci ∈ {0, 1} (where 0 corresponds to incorrect and\n",
      "1 corresponds to correct). after each practice opportunity,\n",
      "the student is assumed to master the skill with some probability. the bkt model is parametrized by the following four\n",
      "parameters:\n",
      "• p (l0 ) = p (k1 = 1): the initial probability of knowing the skill (before the student is given any practice\n",
      "opportunities)\n",
      "• p (t ) = p (ki+1 = 1|ki = 0): the probability of mastering a skill at each practice opportunity (if the student\n",
      "has not yet mastered the skill)\n",
      "• p (g) = p (ci = 1|ki = 0): the probability of guessing\n",
      "• p (s) = p (ci = 0|ki = 1): the probability of “slipping” (answering incorrectly despite having mastered\n",
      "the skill)\n",
      "\n",
      "3.\n",
      "\n",
      "identifiability\n",
      "\n",
      "in their 2007 paper, beck and chang claimed that bkt is\n",
      "not identifiable, illustrating this with a particular example of\n",
      "three different bkt models [7]. for concreteness we include\n",
      "these models in table 1. the authors consider the case of\n",
      "predicting the probability of correctness under these three\n",
      "models as the students receive practice opportunities, but in\n",
      "absence of any observation about the student’s performance.\n",
      "they use plots as in figure 1 to claim that the three models\n",
      "make very different predictions about student knowledge\n",
      "(figure 1 (a)), but make identical predictions about student\n",
      "performance (figure 1 (b)). they claim,\n",
      "all three of the sets of parameters instantiate\n",
      "a knowledge tracing model that fit the observed\n",
      "data equally well; statistically there is no justification for preferring one model over another. this\n",
      "problem of multiple (differing) sets of parameter\n",
      "values that make identical predictions is known\n",
      "as identifiability.\n",
      "however, this is not correct since no data was used to fit\n",
      "these curves; the curves are predicting the probability that\n",
      "a student will know the skill or will answer the skill correctly at each practice opportunity i, when we have no prior\n",
      "performance or data on the student. in order to take past\n",
      "data from a student into account, we actually want to predict p (ki = 1|c1 , . . . ci−1 ) and p (ci = 1|c1 , . . . ci−1 ) and\n",
      "this is indeed what we do in practice when doing knowledge\n",
      "tracing; we make predictions based on our past observations.\n",
      "figure 2 shows the curves predicting these conditional probabilities for a particular sequence of correct/incorrect answers\n",
      "for a student (namely we use (1, 0, 0, 0, 0, 0, 0, 1, 1)). we find\n",
      "\n",
      "that even when we condition on a single observation (i.e.,\n",
      "for p (c2 = 1|c1 )), the three models make vastly different\n",
      "predictions, and as we collect more data, the models continue to make very different predictions. in fact, except for\n",
      "p (c1 = 1), the models never agree on the probability that a\n",
      "student would answer the step correctly.\n",
      "formally, a model is said to be identifiable if there are no two\n",
      "distinct sets of model parameters θ and θ0 that can give rise\n",
      "to the same joint probability distribution over observations\n",
      "under that model. as far as inference is concerned, identifiability means that the likelihood function of the model has\n",
      "only one global maximum, so inference of the true model\n",
      "parameters is possible. in the case of bkt, the model would\n",
      "be identifiable if for any two distinct sets of bkt parameters,\n",
      "θ and θ0 ,\n",
      "pθ (c1 , c2 , . . . , cn ) 6= pθ0 (c1 , c2 , . . . , cn )\n",
      "for some n ≥ 1. what beck and chang show is that there can\n",
      "be infinitely many models that share the same set of marginal\n",
      "distributions p (c1 ), p (c2 ), . . . , p (cn ). this does not mean\n",
      "the model is unidentifiable. as we saw from figure 2, the\n",
      "conditional distribution p (cn |c1 , . . . , cn−1 ) is quite different\n",
      "for each model, and so the joint distribution p (c1 , . . . , cn )\n",
      "is also very different for the three models.\n",
      "it turns out there has been a substantial amount of work,\n",
      "going back 50 years and continuing to this day, on finding the\n",
      "conditions for which hidden markov models are identifiable\n",
      "[15, 1, 2, 17, 10]. although much of the literature focuses on\n",
      "particular types of hmms (e.g., stationary, irreducible) that\n",
      "do not include the standard bkt model, anandkumar et al.\n",
      "have recently shown that, subject to some non-degeneracy\n",
      "conditions, a large class of hmms, which includes bkts, is\n",
      "identifiable with just the joint probability distributions for\n",
      "up to three sequential observations [4]. that is, knowing\n",
      "p (c1 ), p (c1 , c2 ), and p (c1 , c2 , c3 ) is enough to infer the\n",
      "unique model parameters, subject to non-degeneracy conditions. in our context, the conditions are that p (l0 ) 6∈ {0, 1},\n",
      "p (t ) 6= 1, and p (g) 6= 1 − p (s). this suggests that as long\n",
      "as we have more than two observations per student, bkt\n",
      "models with reasonable parameters are identifiable and there\n",
      "is a single global maximum to the likelihood function. feng\n",
      "recently independently showed the same result directly for\n",
      "bkt models, except without requiring the condition that\n",
      "p (l0 ) 6= 0 [9]. one advantage of relying on general identifiability results for hmms is that we can use the same results\n",
      "to show the conditions under which related student models\n",
      "that can also be modeled as hmms are identifiable1 .\n",
      "this misuse of the term “identifiability” has lead to multiple\n",
      "subsequent papers in the educational data mining community throughout the past decade which have similarly given a\n",
      "mistaken description of the underlying phenomena [5, 16, 13,\n",
      "12]. two papers, however, have correctly identified that the\n",
      "1\n",
      "for example, for the bkt model with forgetting, where\n",
      "p (f ) = p (ki+1 = 0|ki = 1) 6= 0, we can show that the\n",
      "model is identifiable with the same conditions, except that we\n",
      "require p (t ) 6= 1 − p (f ) instead of p (t ) 6= 1. we can also\n",
      "easily show the conditions under which multi-state extensions\n",
      "of bkt such as the model introduced in section 4.2 are\n",
      "identifiable. these conditions can be derived from condition\n",
      "3.1 and proposition 4.2 of [4]. see also the note under\n",
      "proposition 3.4 of [3].\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "144\n",
      "\n",
      "\f",
      "model\n",
      "parameter\n",
      "\n",
      "knowledge\n",
      "\n",
      "guess\n",
      "\n",
      "reading tutor\n",
      "\n",
      "p (l0 )\n",
      "p (t )\n",
      "p (g)\n",
      "p (s)\n",
      "\n",
      "0.56\n",
      "0.1\n",
      "0\n",
      "0.05\n",
      "\n",
      "0.36\n",
      "0.1\n",
      "0.3\n",
      "0.05\n",
      "\n",
      "0.01\n",
      "0.1\n",
      "0.53\n",
      "0.05\n",
      "\n",
      "table 1: the three bkt models used by beck and chang [7] to claim bkt is unidentifiable. the models are chosen to have\n",
      "very different semantic interpretations. the knowledge model requires the student to master the skill to get it correct, the\n",
      "guess model relies on the student guessing, and the reading tutor model has an even higher probability of guessing, but it was\n",
      "based on models actually used by the reading tutor [14].\n",
      "\n",
      "(a) learning curve\n",
      "\n",
      "(b) performance curve\n",
      "\n",
      "figure 1: hypothetical learning and performance curves for three models from [7], in absence of any data.\n",
      "\n",
      "(a) learning curve\n",
      "\n",
      "(b) performance curve\n",
      "\n",
      "figure 2: learning and performance curves for three models from [7] conditioned on all past observations for a student whose\n",
      "observed trajectory is as follows: (c1 , c2 , c3 , c4 , c5 , c6 , c7 , c8 , c9 ) = (1, 0, 0, 0, 0, 0, 0, 1, 1)\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "145\n",
      "\n",
      "\f",
      "“identifiability problem” is limited to the case where there\n",
      "is no data [18, 11]. even though this is not a statistically\n",
      "precise claim, it does show that some researchers have the correct understanding behind the phenomenon. van de sande\n",
      "distinguishes between the two cases where predictions are\n",
      "made in the absence of data and where they are made in the\n",
      "presence of data, and claims that the source of the identifiability problem in the former case is that the predictions can\n",
      "be completely determined by three parameters, so there is\n",
      "a degree of freedom [18]. when we are making predictions,\n",
      "however he claims there is no identifiability problem, because\n",
      "p (ki |ci ) depends on four parameters [18]. while he has\n",
      "correctly identified the absence of an identifiability problem\n",
      "in the presence of data, we believe that there is still confusion about the identifiability problem in the community (e.g.,\n",
      "some of the papers that show a misunderstanding of the issue\n",
      "are more recent than [18]). we hope to make the absence\n",
      "of an identifiability problem more clear and elucidate the\n",
      "phenomena and misconceptions surrounding it. gweon et\n",
      "al. also distinguish between two cases which they refer to as\n",
      "the bkt model without measurement and the bkt model\n",
      "with measurement, and show, as van de sande did, that the\n",
      "former depends on three parameters (hence the “identifiability problem”) whereas the latter depends on all four [11].\n",
      "however, they claim this does not necessarily mean that\n",
      "the bkt model with measurement does not suffer from an\n",
      "identifiability problem, and actually claim that it still does\n",
      "suffer from an identifiability problem, because empirically,\n",
      "they found that for some data, fitting bkt models many\n",
      "times resulted in a wide spread of possible parameters [11].\n",
      "however, this cannot be due to the presence of an multiple\n",
      "global maxima, which we have shown cannot exist, and hence\n",
      "must be due to multiple local optima.\n",
      "the work closest to ours is feng’s recently published dissertation [9]. the author gives a similar explanation to ours for\n",
      "why beck and chang’s claim was incorrect and also proves\n",
      "that the bkt model is identifiable directly [9]. however,\n",
      "we believe the exposition there is perhaps less accessible to\n",
      "the educational data mining community and will likely not\n",
      "obtain the visibility needed to clear the misunderstandings\n",
      "surrounding the identifiability of bkt. in this paper, we\n",
      "not only focus on identifying the misidentified identifiability\n",
      "problem, but also understanding the confusion surrounding\n",
      "it as well as pointing out actual issues with fitting bkt\n",
      "models that have been conflated with identifiability. this is\n",
      "the focus of the rest of the paper.\n",
      "there are three potential sources of confusion that we believe\n",
      "could be and have been misconstrued as an identifiability\n",
      "problem:\n",
      "1. a priori predictions. that multiple models, which\n",
      "make very different claims about student’s knowledge\n",
      "state over time, could predict the same probability\n",
      "that students answer questions correctly over time in\n",
      "the absence of data. this is the problem that beck\n",
      "and chang conflated with identifiability, and many\n",
      "researchers thereafter also treated as identifiability. as\n",
      "we showed above, van de sande, gweon et al. and\n",
      "feng correctly identified what is happening here [18,\n",
      "11, 9].\n",
      "\n",
      "2. multiple local optima. it is well known that the expectation-maximization algorithm that is commonly\n",
      "used to fit bkt models is suceptible to converging\n",
      "to local optima of the likelihood function rather than\n",
      "converging to the global optimum. while beck and\n",
      "chang clearly did not conflate this with the identifiability issue, we saw that other researchers such as\n",
      "gweon et al. have possibly conflated the two. in order\n",
      "to avoid local optima, one can use a grid search over\n",
      "the entire parameter space or run multiple iterations of\n",
      "the expectation-maximization algorithm with different\n",
      "initializations of the parameters.\n",
      "3. semantic model degeneracy. baker et al. identified another problem with bkt models, which they termed\n",
      "model degeneracy [5]. a model is said to be semantically degenerate2 when it is inconsistent with the\n",
      "conceptual assumptions underlying the bkt model.\n",
      "the problem is when the model that best fits our data\n",
      "is semantically degenerate. even though baker et al.\n",
      "clearly contrasted this to the (supposed) identifiability\n",
      "problem, we claim that this is the problem that beck\n",
      "and chang attempted to fix in their paper. we will\n",
      "now focus on better understanding this problem.\n",
      "\n",
      "4.\n",
      "\n",
      "semantic model degeneracy\n",
      "\n",
      "in their paper, beck and chang propose a way to get around\n",
      "the identifiability problem. they propose using dirichlet priors to encode prior beliefs about the bkt parameters, which\n",
      "will in turn bias the model search towards more reasonable\n",
      "parameters [7]. they motivate their method as follows:\n",
      "we have more knowledge about student learning\n",
      "than the data we use to train our models. as\n",
      "cognitive scientists, we have some notion of what\n",
      "learning “looks like.” for example, if a model\n",
      "suggest that a skill gets worse with practice, it\n",
      "is likely the problem is with the modeling approach, not that the students are actually getting\n",
      "less knowledgeable. the question is how can we\n",
      "encode these prior beliefs about learning?\n",
      "the problem they appear to be describing is that some models\n",
      "have parameters that do not match our intuitions of student\n",
      "learning, i.e., they are exactly describing the issue of semantic\n",
      "model degeneracy (and not that of unidentifiability). baker\n",
      "et al. later provide another solution to tackling semantic\n",
      "model degeneracy by using contextual features to estimate\n",
      "the guess and slip parameters [5]; however, interestingly they\n",
      "did not view beck and chang’s original solution as a way of\n",
      "tackling semantic model degeneracy, treating it as a way to\n",
      "tackle identifiability as the authors originally claimed.\n",
      "having shown that identifiability is not an issue with bkt,\n",
      "and given that there are easy ways to tackle the existence\n",
      "of local optima, we believe semantic model degeneracy is\n",
      "perhaps the most important problem with respect to fitting\n",
      "bkt models that needs to be better understood and tackled.\n",
      "essentially, the problem arises because the bkt is simply a\n",
      "2\n",
      "we refer to this property as semantic model degeneracy to\n",
      "distinguish it from mathematically degenerate parameters\n",
      "that would result in bkt models being unidentifiable, as\n",
      "described above.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "146\n",
      "\n",
      "\f",
      "particular form of a two-state hidden markov model and it\n",
      "will try to fit the best two state hidden markov model it can\n",
      "to the data; our model fitting procedures do not understand\n",
      "that the ki = 1 state is supposed to correspond to mastering\n",
      "a skill, and so it might fit a model that does not match our\n",
      "intuitions of mastery. we will try to understand this in more\n",
      "detail below, but first we aim to characterize the types of\n",
      "semantic model degeneracy that have been pointed out in\n",
      "the literature.\n",
      "\n",
      "4.1\n",
      "\n",
      "types of semantic model degeneracy\n",
      "\n",
      "baker et al. distinguish between two forms of semantic model\n",
      "degeneracy: theoretical degeneracy and empirical degeneracy\n",
      "[5]. they define a model to be theoretically degenerate when\n",
      "either the guess or the slip parameter is greater than 0.5.\n",
      "they define a model to be empirically degenerate if one of\n",
      "two things occur: (1) for some large enough n the model’s\n",
      "estimate of the student having mastered the skill decreases\n",
      "after the student gets the first n skills correct or (2) for some\n",
      "large enough m, the student does not achieve mastery (our\n",
      "estimate of the student having mastered the skill does not go\n",
      "beyond 0.95) even after m consecutive correct responses [5].\n",
      "the authors arbitrarily chose the values n = 3 and m = 10.\n",
      "note that the first form of empirical degeneracy is only\n",
      "possible if 1 − p (s) < p (g) (i.e., the student is more likely\n",
      "to answer a question correctly if they have not mastered a skill\n",
      "than if they have mastered a skill), as was shown by van de\n",
      "sande [18]. this is true, even for n = 1. thus, this first notion\n",
      "of empirical degeneracy is equivalent to p (g) + p (s) > 1,\n",
      "which implies either p (s) > 0.5 or p (g) > 0.5, meaning\n",
      "that it always implies theoretical degeneracy! huang et al.\n",
      "have noted that while p (g) + p (s) > 1 definitely implies\n",
      "semantically degenerate parameters as it contradicts mastery,\n",
      "the condition that p (g) < 0.5 and p (s) < 0.5 may not\n",
      "always be necessary for the parameters to be semantically\n",
      "meaningful, since, for example, there may be some domains\n",
      "where the student can guess the correct answer easily [12].\n",
      "we agree that suggesting p (g) < 0.5 is degenerate does\n",
      "seem somewhat arbitrary depending on the domain; however,\n",
      "we do think p (s) > 0.5 should be characterized as a form\n",
      "semantic degeneracy, because, as baker et al. claimed, it does\n",
      "not make sense for a student who has mastered a skill to\n",
      "answer questions of that skill incorrectly most of the time—\n",
      "that goes against our intuitions of what mastery means.\n",
      "in any case, it does not seem like the distinction between\n",
      "theoretical and empirical degeneracy is a clear one, so we\n",
      "suggest categorizing the forms of semantic model degeneracy\n",
      "by what they suggest about student learning:\n",
      "• forgetting: this is a result of p (g) + p (s) > 1, which\n",
      "suggests that not only are students not learning, but\n",
      "that students have some probability of losing their\n",
      "knowledge over time. another way to view this degeneracy is that the state we would conceptually call the\n",
      "mastery state is now the state where performance is\n",
      "worse.\n",
      "• low performance mastery: this is a result of p (s) >\n",
      "0.5. alternatively, we can set our threshold for low\n",
      "performance mastery to be lower (e.g., p(s) > 0.4).\n",
      "• high performance guessing: this is a result of p (g) >\n",
      "t, where t is some threshold. as mentioned earlier,\n",
      "\n",
      "this seems like a weak form of degeneracy, as students\n",
      "can often guess an answer easily even if they have not\n",
      "mastered a skill, but we can set t to a large enough\n",
      "value, to make this a form of model degeneracy.\n",
      "• high performance 6⇒ learning: this is the second form\n",
      "of empirical degeneracy given by baker et al. [5]: for\n",
      "some choice of m, the probability that the student\n",
      "has achieved mastery is less than some threshold p\n",
      "(typically taken to be 0.95) after m consecutive correct\n",
      "responses\n",
      "\n",
      "4.2 sources of semantic model degeneracy\n",
      "we will now consider a possible explanation for why bkt\n",
      "models are so prone to semantic model degeneracy (which\n",
      "we believe to be part of the reason that researchers look\n",
      "towards identifiability and local optima to explain the strange\n",
      "parameters that result from fitting bkt models). first of all,\n",
      "note that forgetting degeneracy will occur whenever students\n",
      "actually do forget or when they learn misconceptions; it is\n",
      "not unreasonable to believe that students will sometimes\n",
      "learn and reinforce a misconception, causing their knowledge\n",
      "of some skill to decrease over time. thus, while this form\n",
      "of degeneracy technically violates our notion of mastery, it\n",
      "is to be expected if we switch the semantic interpretation\n",
      "of the two states and suppose that students forget instead\n",
      "of learn. we now consider sources of the other forms of\n",
      "semantic model degeneracy. we claim that such forms of\n",
      "semantic model degeneracy can result from not accurately\n",
      "being able to capture the complexity of student learning with\n",
      "a two state hmm. when this is the case, fitting the data\n",
      "with a two state hmm will result in trying to find the best fit\n",
      "of the data for a two state hmm, and not to come up with\n",
      "a model that tries to accurately model the data while also\n",
      "matching our intuitions about what it means for a student\n",
      "to have mastered a skill.\n",
      "to support our claim, suppose student learning is actually\n",
      "governed by a 10-state hmm with ten consecutive states\n",
      "representing different levels of mastery. from each state, the\n",
      "student has some probability of transitioning to the next\n",
      "state (slightly increasing in mastery), and from each state,\n",
      "the student has a probability of answering questions correctly,\n",
      "and this probability strictly increases as the student’s level of\n",
      "mastery increases. specifically consider the model presented\n",
      "in table 2. now suppose we try to use a standard bkt\n",
      "model to fit data generated from this alternative model of\n",
      "student learning. the first two columns of table 3 show the\n",
      "parameters of bkt models fit to 500 sequences of 20 practice\n",
      "opportunities or 100 sequences of 200 practice opportunities,\n",
      "both generated from the the model in table 2. notice that\n",
      "the model fits (nearly) degenerate parameters in both cases.\n",
      "when we only have 20 observations per student, the model\n",
      "estimates a very high slip parameter; this is because it has\n",
      "to somehow aggregate the different latent states which correspond to different levels of mastery, and since not many\n",
      "students would have reached the highest levels of mastery\n",
      "in 20 steps, it is going to predict that students who have\n",
      "“mastered” the skill are often getting it wrong. however,\n",
      "what’s more interesting is that for the same model, if we\n",
      "simply increase the number of observations per student from\n",
      "20 to 200, we find that the slip parameter is reasonably small,\n",
      "but now the guess probability is 0.49! this is because, by\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "147\n",
      "\n",
      "\f",
      "state i\n",
      "parameter\n",
      "p (k0 = k)\n",
      "p (ci = 1|ki = k)\n",
      "p (ki = k + 1|ki = k)\n",
      "\n",
      "0\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "8\n",
      "\n",
      "9\n",
      "\n",
      "0.1\n",
      "0.0\n",
      "0.4\n",
      "\n",
      "0.1\n",
      "0.1\n",
      "0.3\n",
      "\n",
      "0.1\n",
      "0.2\n",
      "0.2\n",
      "\n",
      "0.2\n",
      "0.3\n",
      "0.1\n",
      "\n",
      "0.2\n",
      "0.4\n",
      "0.05\n",
      "\n",
      "0.3\n",
      "0.5\n",
      "0.05\n",
      "\n",
      "0\n",
      "0.6\n",
      "0.05\n",
      "\n",
      "0\n",
      "0.7\n",
      "0.05\n",
      "\n",
      "0\n",
      "0.8\n",
      "0.05\n",
      "\n",
      "0\n",
      "0.9\n",
      "-\n",
      "\n",
      "table 2: alternative model of student learning where there are ten levels of mastery.\n",
      "\n",
      "10-state hmm\n",
      "\n",
      "afm\n",
      "\n",
      "parameter\n",
      "\n",
      "20\n",
      "\n",
      "200\n",
      "\n",
      "20\n",
      "\n",
      "200\n",
      "\n",
      "p (l0 )\n",
      "p (t )\n",
      "p (g)\n",
      "p (s)\n",
      "\n",
      "0.30\n",
      "0.05\n",
      "0.27\n",
      "0.44\n",
      "\n",
      "0.001\n",
      "0.02\n",
      "0.49\n",
      "0.13\n",
      "\n",
      "0.09\n",
      "0.05\n",
      "0.14\n",
      "0.46\n",
      "\n",
      "0.001\n",
      "0.05\n",
      "0.28\n",
      "0.03\n",
      "\n",
      "table 3: bkt models fit to data generated from the model\n",
      "described in figure 2 and an additive factors model described\n",
      "in the text. the first column for each model is fit to 500\n",
      "sequences of 20 practice opportunities, while the second\n",
      "column is fit to 100 sequences of 200 practice opportunities.\n",
      "the models were fit using brute-force grid search over the\n",
      "entire parameter space in 0.01 increments for the parameters\n",
      "using the bkt brute force model fitting code [6].\n",
      "\n",
      "this point most students have actually reached the highest\n",
      "level of mastery, so to compensate for the varying levels of\n",
      "mastery that occurred earlier in student trajectories, the\n",
      "model will have to estimate a high guess parameter. so we\n",
      "find that not only can alternative models of student learning\n",
      "lead to fitting (near) degenerate parameters, but varying\n",
      "the number of observations can lead to different forms of\n",
      "degeneracy! this is a counterintuitive phenomenon that we\n",
      "believe is not the result of not having enough data (students)\n",
      "to fit the models well, but rather the result of the mismatch\n",
      "between the true form of student learning and the model we\n",
      "are using the fit student learning.\n",
      "we find similar results if we fit a bkt model to data generated from another alternative model of student learning that\n",
      "is commonly used in the educational data mining community,\n",
      "the additive factors model (afm) [8]. in particular, we used\n",
      "the model\n",
      "p (ci = 1) =\n",
      "\n",
      "1\n",
      "1 + exp(−θ + 2 − 0.1i)\n",
      "\n",
      "where θ ∼ n (0, 1) is the student’s ability3 . the second two\n",
      "columns of table 3 show the parameters of bkt models fit\n",
      "to data generated from this model. we again find that when\n",
      "using only data with 20 practice opportunities, we fit a high\n",
      "slip parameter, but when we using data with 200 practice\n",
      "opportunities, we fit a higher guess parameter and a very\n",
      "small slip parameter.\n",
      "additionally, notice that for the parameters fit to the 10state hmm, the probability of transitioning to mastery is\n",
      "3\n",
      "this model suggests that students who are two standard\n",
      "deviations above the mean initially will answer correctly half\n",
      "the time, and after 20 practice opportunities the average\n",
      "student will answer correctly half the time.\n",
      "\n",
      "very small when we fit to sequences with 200 practice opportunities. since the transition probability is small and the\n",
      "guess probability is large, we also have high performance 6⇒\n",
      "learning degeneracy for this model for m = 10. that is,\n",
      "p (k11 = 1|c1 = 1, c2 = 1, . . . , c10 = 1) ≈ .89 < 0.95\n",
      "this is yet another form of degeneracy that does not exist\n",
      "in the model fit to sequences of 20 practice opportunities.\n",
      "furthermore, notice that when we have 200 observations,\n",
      "the probability of transitioning to mastery is smaller than\n",
      "p (ki = k + 1|ki = k) for all states i in the model that\n",
      "generated the data (table 2). again, this is because the best\n",
      "fitting bkt model will aggregate low performing states and\n",
      "high performing states, so a single transition in the bkt\n",
      "model between these two aggregate states will have to loosely\n",
      "correspond to the student transitioning several times in the\n",
      "actual 10-state hmm. thus, while the learned bkt model\n",
      "makes it appear as though learning happens very slowly,\n",
      "according to the true student model, learning actually occurs\n",
      "much more often but in more progressive increments. this\n",
      "suggests that if we use some automated technique to detect\n",
      "if a skill is useful for student learning, we may conclude it is\n",
      "not, if we do not allow for the possibility that students are\n",
      "learning progressively.\n",
      "these observations have important implications for how\n",
      "learned models can be used in practice. using such a bkt\n",
      "model to predict student mastery can lead to problematic inferences. for example, for the first model in table 3, the bkt\n",
      "model assumes that when a student has reached mastery,\n",
      "they have a 56% chance of answering a question correctly,\n",
      "whereas a student who has actually mastered the skill will\n",
      "have a 90% chance of answering correctly (see table 2). thus,\n",
      "an intelligent tutoring system that uses such a bkt model\n",
      "to determine when a student has had sufficient practice on a\n",
      "problem, will likely give far fewer problems to the student\n",
      "than they actually need in order to reach mastery!\n",
      "there are several potential ways that future work can proceed in light of these findings. one is that we should be\n",
      "giving our model fitting procedures more domain knowledge\n",
      "about the kind of model we want it to fit. this is essentially\n",
      "what beck and chang did by using dirichlet priors [7] and\n",
      "what baker et al. did by estimating the guess and slip parameters using context [5]. but perhaps there are other ways of\n",
      "doing this where we do not need to give context-dependent\n",
      "domain knowledge to the model per se, but rather come up\n",
      "with a model that realizes the difference between a student\n",
      "having mastered a skill or not (which the bkt model cannot\n",
      "do). however, this may not be ideal in some cases where\n",
      "student learning cannot accurately be modeled by bkt with\n",
      "semantically plausible parameters. for example when we\n",
      "have forgetting degeneracy, we should probably not force\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "148\n",
      "\n",
      "\f",
      "the parameters to suggest learning is occurring when it may\n",
      "not be. another way to proceed is to consider alternative\n",
      "student models, which is an active area of educational data\n",
      "mining research. perhaps, obtaining semantically degenerate\n",
      "parameters from a fit should signal that our students may\n",
      "be learning in more complicated ways than the simple bkt\n",
      "model can predict, and so we should try to find alternative\n",
      "models that fit our data better without yielding semantically\n",
      "degenerate parameters. finally, even if our model is semantically degenerate, it does not necessarily make the bkt\n",
      "model useless. the result of fitting a bkt model is that we\n",
      "get the best fit of the data given that we are modeling the\n",
      "data with a two-state hmm (if we disregard local optima).\n",
      "presumably, such a model can give us some insights about\n",
      "student learning even if it is not modeling student mastery.\n",
      "so perhaps we can use such semantically degenerate models\n",
      "to understand student learning rather than to predict student\n",
      "mastery.\n",
      "\n",
      "5.\n",
      "\n",
      "conclusion\n",
      "\n",
      "we have explored the issues of identifiability and semantic\n",
      "model degeneracy in bayesian knowledge tracing. we have\n",
      "shown that what researchers posited was an identifiability\n",
      "problem is actually not an identifiability problem, and by\n",
      "using a result from the literature on learning hidden markov\n",
      "models, we showed that an identifiability problem does not\n",
      "exist for bkt models (with the exception of some mathematically degenerate cases that should not come up in practice).\n",
      "we then examined the various issues with fitting bkt models that have been conflated with identifiability. we offered\n",
      "what we believe to be new insights on one potential source of\n",
      "semantic model degeneracy. we believe analyzing the sources\n",
      "of semantic model degeneracy in more detail can be a fruitful\n",
      "direction for future research. for example, it could be useful\n",
      "to know what bkt parameters result from fitting various\n",
      "other popular models of student learning. it would also be\n",
      "informative to see if we can find automated ways of detecting\n",
      "which assumptions of bkt are not met in our data (e.g., the\n",
      "number of levels of mastery, the independence of different\n",
      "skills). such analyses could help in devising better student\n",
      "models, and ultimately may lead to a better understanding\n",
      "of student learning.\n",
      "\n",
      "6.\n",
      "\n",
      "acknowledgements\n",
      "\n",
      "the research reported here was supported, in whole or in part,\n",
      "by the institute of education sciences, u.s. department of\n",
      "education, through grants r305a130215 and r305b150008\n",
      "to carnegie mellon university. the opinions expressed are\n",
      "those of the authors and do not represent views of the institute or the u.s. dept. of education.\n",
      "\n",
      "7.\n",
      "\n",
      "references\n",
      "\n",
      "[1] e. s. allman, c. matias, and j. a. rhodes.\n",
      "identifiability of parameters in latent structure models\n",
      "with many observed variables. the annals of statistics,\n",
      "pages 3099–3132, 2009.\n",
      "[2] y. an, y. hu, j. hopkins, and m. shum. identifiability\n",
      "and inference of hidden markov models. technical\n",
      "report, technical report, 2013.\n",
      "[3] a. anandkumar, r. ge, d. j. hsu, s. m. kakade, and\n",
      "m. telgarsky. tensor decompositions for learning latent\n",
      "variable models. journal of machine learning research,\n",
      "\n",
      "15(1):2773–2832, 2014.\n",
      "[4] a. anandkumar, d. hsu, and s. m. kakade. a method\n",
      "of moments for mixture models and hidden markov\n",
      "models. in conference on learning theory, pages 33–1,\n",
      "2012.\n",
      "[5] r. s. baker, a. t. corbett, and v. aleven. improving\n",
      "contextual models of guessing and slipping with a\n",
      "truncated training set. human-computer interaction\n",
      "institute, page 17, 2008.\n",
      "[6] r. s. baker, a. t. corbett, s. m. gowda, a. z.\n",
      "wagner, b. a. maclaren, l. r. kauffman, a. p.\n",
      "mitchell, and s. giguere. contextual slip and\n",
      "prediction of student performance after use of an\n",
      "intelligent tutor. in international conference on user\n",
      "modeling, adaptation, and personalization, pages\n",
      "52–63. springer, 2010.\n",
      "[7] j. e. beck and k.-m. chang. identifiability: a\n",
      "fundamental problem of student modeling. in\n",
      "international conference on user modeling, pages\n",
      "137–146. springer, 2007.\n",
      "[8] h. cen. generalized learning factors analysis:\n",
      "improving cognitive models with machine learning.\n",
      "carnegie mellon university, 2009.\n",
      "[9] j. feng. essays on learning through practice. phd\n",
      "thesis, the university of chicago, 2017.\n",
      "[10] é. gassiat, a. cleynen, and s. robin. inference in\n",
      "finite state space non parametric hidden markov\n",
      "models and applications. statistics and computing,\n",
      "26(1-2):61–71, 2016.\n",
      "[11] g.-h. gweon, h.-s. lee, c. dorsey, r. tinker,\n",
      "w. finzer, and d. damelin. tracking student progress\n",
      "in a game-like learning environment with a monte carlo\n",
      "bayesian knowledge tracing model. in proceedings of\n",
      "the fifth international conference on learning\n",
      "analytics and knowledge, pages 166–170. acm, 2015.\n",
      "[12] y. huang, j. gonzalez-brenes, r. kumar, and\n",
      "p. brusilovsky. a framework for multifaceted\n",
      "evaluation of student models. in proceedings of the 8th\n",
      "international conference on educational data mining.\n",
      "university of pittsburgh, 2015.\n",
      "[13] j. i. lee and e. brunskill. the impact on\n",
      "individualizing student models on necessary practice\n",
      "opportunities. international educational data mining\n",
      "society, 2012.\n",
      "[14] j. mostow and g. aist. smart machines in education.\n",
      "chapter evaluating tutors that listen: an overview\n",
      "of project listen, pages 169–234. mit press,\n",
      "cambridge, ma, usa, 2001.\n",
      "[15] t. petrie. probabilistic functions of finite state markov\n",
      "chains. the annals of mathematical statistics,\n",
      "40(1):97–115, 1969.\n",
      "[16] s. ritter, t. k. harris, t. nixon, d. dickison, r. c.\n",
      "murray, and b. towle. reducing the knowledge tracing\n",
      "space. international working group on educational\n",
      "data mining, 2009.\n",
      "[17] p. tune, h. x. nguyen, and m. roughan. hidden\n",
      "markov model identifiability via tensors. in information\n",
      "theory proceedings (isit), 2013 ieee international\n",
      "symposium on, pages 2299–2303. ieee, 2013.\n",
      "[18] b. van de sande. properties of the bayesian knowledge\n",
      "tracing model. jedm-journal of educational data\n",
      "mining, 5(2):1–10, 2013.\n",
      "\n",
      "proceedings of the 10th international conference on educational data mining\n",
      "\n",
      "149\n",
      "\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4) because we don't want to deal with upper case / lower case issues\n",
    "# we are going to lower case everything:\n",
    "# Try using a list comprehension to accomplish this task\n",
    "pages = [x.lower() for x in pages]\n",
    "print (pages[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i,page in enumerate(pages):\n",
    "    #pages[i] = page.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pages[0][200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Now we would like to join pages if they below to the same paper. Can you think of keywords we could like for to decided if the current page is starting a new paper? Write down two ideas:\n",
    "1. ###Abstract\n",
    "2. ###Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6) create a new list called \"papers\", which is going to contain \n",
    "# all the papers we have. Iterate through all the pages and \n",
    "# add a new element to the list when you have a full paper\n",
    "# Using a for loop to iterate over all the pages, try to think of a conditional statement to check whether a page\n",
    "# represents a new 'paper'. I.e. what is a common aspect of all papers? \n",
    "papers = []\n",
    "current_paper = ''\n",
    "pages = data.split('Proceedings of the 10th International Conference on Educational Data Mining')\n",
    "pages = [x.lower() for x in pages]\n",
    "\n",
    "for page in pages: \n",
    "    if 'introduction' in page and 'abstract' in page:\n",
    "            papers.append(current_paper)\n",
    "            current_paper = ''\n",
    "            current_paper = current_paper + page\n",
    "    else:\n",
    "            current_paper = current_paper + page\n",
    "\n",
    "del papers[0]\n",
    "\n",
    "# iterate through the pages and add each paper to the list \"papers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "31\n",
      "\n",
      "\f",
      "analysis of problem-solving behavior in open-ended\n",
      "scientific-discovery game challenges\n",
      "aaron bauer\n",
      "\n",
      "awb@cs.washington.edu\n",
      "\n",
      "jeff flatten\n",
      "\n",
      "jflat06@cs.washington.edu\n",
      "\n",
      "zoran popović\n",
      "\n",
      "zoran@cs.washington.edu\n",
      "\n",
      "center for game science, computer science and engineering\n",
      "university of washington\n",
      "seattle, wa 98195, usa\n",
      "\n",
      "abstract\n",
      "\n",
      "problem-solving skills in creative, open-ended domains are both\n",
      "important and little understood. these domains are generally illstructured, have extremely large exploration spaces, and require\n",
      "high levels of specialized skill in order to produce quality solutions.\n",
      "we investigate problem-solving behavior in one such domain, the\n",
      "scientific-discovery game foldit. our goal is to discover differentiating patterns and understand what distinguishes high and low levels\n",
      "of problem-solving skill. to address the challenges posed by the\n",
      "scale, complexity, and ill-structuredness of foldit solver behavior\n",
      "data, we devise an iterative visualization-based methodology and use\n",
      "this methodology to design a concise, meaning-rich visualization of\n",
      "the problem-solving process in foldit. we use this visualization to\n",
      "identify key patterns in problem-solving approaches, and report how\n",
      "these patterns distinguish high-performing solvers in this domain.\n",
      "\n",
      "keywords\n",
      "\n",
      "problem solving; scientific-discovery games; visualization\n",
      "\n",
      "1.\n",
      "\n",
      "introduction\n",
      "\n",
      "as efforts in scalable online education expand, interest continues\n",
      "to increase in moving beyond small, highly constrained tasks, such\n",
      "as multiple choice or short answer questions, and incorporating\n",
      "creative, open-ended activities [7, 14]. existing research supports\n",
      "this move, showing that problem-based learning can enhance students’ problem-solving and metacognitive skills [11]. scaling such\n",
      "activities poses significant challenges, however, in terms of both assessment and feedback. it will be vital to devise scalable techniques\n",
      "not only to assess students’ final products, but also to understand\n",
      "their progress through complex and heterogeneous problem-solving\n",
      "spaces. these techniques will apply to a broad range of education\n",
      "settings, from purely online programs like udacity’s nanodegrees\n",
      "to more traditional settings where new standards like the common\n",
      "core emphasize strategic problem solving.\n",
      "a growing body of work has found that educational and serious\n",
      "games are fertile ground for assessing students’ capabilities and\n",
      "problem-solving skills [6, 10]. our work continues this general\n",
      "line of inquiry by examining creative, problem-solving behavior\n",
      "among players in the scientific-discovery game foldit. by modeling\n",
      "the functions of proteins, the workhorses of living cells, foldit\n",
      "challenges players, hereafter referred to as solvers, to resolve the\n",
      "shape of proteins as a 3d puzzle. these puzzles are completely\n",
      "open and often under-specified, making it a highly suitable setting\n",
      "in which to gain insight into student progress through complex\n",
      "solution spaces. in the foldit scientific-discovery community, the\n",
      "focus is on developing people from novices to experts that are\n",
      "eventually capable of solving protein structure problems that are\n",
      "\n",
      "currently unsolved by the scientific community. in fact, solutions\n",
      "produced in foldit have led to three results published in nature [3,\n",
      "5, 16]. foldit is an attractive learning space domain because its\n",
      "solvers are capable of contributing to state-of-the-art biochemistry\n",
      "results, and the vast majority of best performing solvers had no\n",
      "exposure to biochemistry prior to joining foldit community. hence,\n",
      "solver behavior in foldit represents development of highly effective\n",
      "problem-solving in an open-ended domain over long time horizons.\n",
      "in this work, we identify six strategic patterns employed by foldit\n",
      "solvers and show how these patterns differentiate between successful\n",
      "and less successful solvers. these patterns cover instances where\n",
      "solvers investigate multiple hypotheses, explore more greedily or\n",
      "more inquisitively, try to escape local optima, and make structured\n",
      "use of the manual or automated tools available in foldit.\n",
      "the aspects of the foldit environment that make it an attractive\n",
      "setting in which to study problem solving also present significant\n",
      "challenges. problems in foldit share many of the properties jonassen\n",
      "attributes to design problems, which they describe as “among the\n",
      "most complex and ill-structured kinds of problems that are encountered in practice” [13]. these properties include a vague goal with\n",
      "few constraints (in foldit, the goal is often entirely open-ended:\n",
      "find a good configuration of the protein), answers that are neither\n",
      "right or wrong, only better or worse, and limited feedback (in foldit,\n",
      "real-time feedback and solution evaluation are limited to a single\n",
      "numerical score corresponding to the protein’s current energy state,\n",
      "and solvers frequently must progress through many low-scoring\n",
      "states to reach a good configuration; more nuanced feedback from\n",
      "biochemists is sometimes available, but on a timescale of weeks).\n",
      "the ill-structured nature of problems posed in foldit necessarily\n",
      "deprives us of the structures, such as clear goal states and straightforward relationships between intermediate states and goal states,\n",
      "that typically form the basis of existing detailed and quantitative\n",
      "analyses of problem-solving behavior.\n",
      "the size and complexity of foldit’s problem space presents another\n",
      "major challenge. even though the logs of solver interactions consist\n",
      "only of regular snapshots of a solver’s current solution (along with\n",
      "attendant metadata), the record of a single solver’s performance on\n",
      "a given problem frequently consists of thousands of such snapshots\n",
      "(which in turn are just a sparse sampling of the actual solving process). furthermore, the nature of the solution state, the configuration\n",
      "of hundreds of components in continuous three-dimensional space,\n",
      "renders collapsing the state space by directly comparing solution\n",
      "states impractical. compounding the size of the problem space is\n",
      "the complexity of the actions available to foldit solvers. in addition\n",
      "to manual manipulation of the protein configuration, solvers can\n",
      "invoke various low-level automated optimization routines (some\n",
      "\n",
      "\n",
      "\n",
      "32\n",
      "\n",
      "\f",
      "of which run until the solver terminates them) and place different\n",
      "kinds of constraints on the protein configuration (rubber bands in\n",
      "foldit parlance) that restrict its modification in a variety of ways.\n",
      "solvers can also deploy many of these tools programmatically via\n",
      "lua scripts called recipes. taken together these challenges of illstructuredness, size, and complexity threaten to make analysis of\n",
      "high-level problem-solving behavior in foldit intractable.\n",
      "to overcome these obstacles, we devise a visualization-based methodology capable of producing tractable representations of foldit solvers’\n",
      "problem-solving behavior while maintaining the key encodings necessary for analysis of high-level strategic behavior. a process of\n",
      "iterative summarization forms the core of this methodology, and\n",
      "ensures that the transformations applied to the raw data do not\n",
      "elide structures potentially relevant to understanding solvers’ unique\n",
      "strategic behavior. using this methodology, we examine solver activity logs from 11 foldit puzzles, representing 970 distinct solvers and\n",
      "nearly 3 million solution snapshots. leveraging metadata present\n",
      "in the solution snapshots, we represent solving behavior as a tree,\n",
      "and apply our methodology to visualize a summarized tree showing\n",
      "where they branched off to investigate multiple hypotheses, how\n",
      "they employed some of the automated tools available to them, and\n",
      "other salient problem-solving behavior. we use these depictions to\n",
      "determine key distinguishing features of this exploration process.\n",
      "we subsequently use these features to better understand the patterns\n",
      "of expert-level problem solving.\n",
      "our work focuses on the following research questions: (1) how\n",
      "can we visually represent an open-ended exploration towards a\n",
      "high-quality solution in a large, ill-structured problem space? (2)\n",
      "what are the key patterns of problem-solving behavior exhibited\n",
      "by individuals?, and (3) what are the key differences along these\n",
      "patterns between high-performing and lower-performing solvers in\n",
      "an open-ended domain like foldit? in addressing these questions we\n",
      "find that high-performing solvers explore the solution space more\n",
      "broadly. in particular, they pursue more hypotheses and actively\n",
      "avoid getting stuck in local minima. we also found that both highand lower-performing solvers have similar proportion of manual and\n",
      "automated tool actions, indicating that better performance on openended challenges stems from the quality of the action intermixing\n",
      "rather than aggregate quantity.\n",
      "\n",
      "2.\n",
      "\n",
      "related work\n",
      "\n",
      "while automated grading has mostly been explored for well-specified\n",
      "tasks where the correct answer has a straightforward and concise\n",
      "description, some previous work has developed techniques for more\n",
      "complex activities. some achieve scalability through a crowdsourcing framework such as udacity’s system for hiring external\n",
      "experts as project reviewers [14]. other work has demonstrated\n",
      "automated approaches that leverage machine learning to enable scalable grading of more complex assignments. for example, geigle et\n",
      "al. describe an application of online active learning to minimize the\n",
      "training set a human grader must produce [7] when automatically\n",
      "grading an assignment where students must analyze medical cases.\n",
      "our work does not focus on grading problem-solving behavior, but\n",
      "instead approaches the issue of scalability at a more fundamental\n",
      "level: understanding fine-grained problem-solving strategies and\n",
      "how they contribute to success in an open-ended domain.\n",
      "a robust body of prior work has addressed the challenge of both\n",
      "visualizing and gleaning insight from player activity in educational\n",
      "and serious games. andersen et al. developed playtracer, a general method for visualizing players’ progress through a game’s\n",
      "\n",
      "state space when a spatial relationship between the player and the\n",
      "virtual environment is not available [1]. wallner and kriglstein provide a thorough review of visualization-based analysis of gameplay\n",
      "data [21]. prior work has analyzed gameplay data without visualization as well. falakmasir et al. propose a data analysis pipeline\n",
      "for modeling player behavior in educational games. this system\n",
      "can produce a simple, interpretable model of in-game actions that\n",
      "can predict learning outcomes [6]. our work differs in its aims from\n",
      "this prior work. we do not seek to develop a general visualization\n",
      "technique, but instead to design and leverage a domain-specific\n",
      "visualization to analyze problem-solving behavior. we are also\n",
      "not predicting player behavior, nor modeling players in terms of\n",
      "low-level actions, but rather identifying higher-level strategy use.\n",
      "the work most similar to ours is that which focuses on problemsolving behavior, including both the long-running efforts in educational psychology to develop general theories and more recent\n",
      "work data-driven on understanding the problem-solving process.\n",
      "our formulation of solving behavior in foldit as a search through\n",
      "a problem space follows from classic information-processing theories of problem solving (e.g., [9, 19]). gick reviews research on\n",
      "both problem-solving strategies and the differences in strategy use\n",
      "between experts and novices [8]. our work complements the existing literature by focusing on understanding problem solving in\n",
      "the little-studied domain of scientific-discovery games, and on the\n",
      "ill-structured problems present in foldit. our findings on the differences in strategy use between high- and lower-performing solvers in\n",
      "foldit are consistent with the consensus in the literature that expert’s\n",
      "knowledge allows them to effectively use strategies that are poorly\n",
      "or infrequently used by less-skilled solvers. we also contribute a\n",
      "granular understanding of the specific strategies and differences at\n",
      "work in the foldit domain.\n",
      "significant recent work has investigated problem-solving behavior\n",
      "in educational games and intelligent tutoring systems using a variety\n",
      "of techniques. tóth et al. used clustering to characterize problemsolving behavior on tasks related to understanding a system of linear\n",
      "structural equations. the clusters distinguished between students\n",
      "that used a vary-one-thing-at-a-time strategy (both more and less\n",
      "efficiently) and those that used other strategies [20]. through a\n",
      "combination of automated detectors, path analysis, and classroom\n",
      "studies, rowe et al. investigated the relationship between a set\n",
      "of six strategic moves in a newtonian physics simulation game\n",
      "and performance on pre- and post-assessments. they found that\n",
      "the use of some moves mediated the relationship between prior\n",
      "achievement and post scores [18]. eagle et al. discuss several applications of using interaction networks to visualize and categorize\n",
      "problem-solving behavior in education games and intelligent tutoring systems. these networks offer insight for hint generation\n",
      "and a flexible method for visualizing student work in rule-using\n",
      "problem solving environments [4] . using decision trees to build\n",
      "separate models for optimal and non-optimal student performance,\n",
      "malkiewich et al. gained insight into how learning environments\n",
      "can encourage elegant problem solving [17]. our primary contribution is to extend analysis of problem-solving behavior to a more\n",
      "complex and open-ended domain that those studied in similar previous work. the size and complexity of foldit’s problem space,\n",
      "the volume of data necessary to capture exploration in this space,\n",
      "and the ill-structured nature of the foldit problems all pose unique\n",
      "challenges. we devise a visualization-based methodology focused\n",
      "on iterative summarization, and successfully apply it to identify key\n",
      "problem-solving patterns exhibited by foldit solvers.\n",
      "\n",
      "\n",
      "\n",
      "33\n",
      "\n",
      "\f",
      "3.\n",
      "\n",
      "foldit\n",
      "\n",
      "foldit is a scientific-discovery game that crowdsources protein folding. it presents solvers with a 3d representation of a protein and\n",
      "tasks them with manipulating it into the lowest energy configuration. each protein posed to the solvers is called a puzzle. solvers’\n",
      "solutions to each puzzle are scored according to their energy configuration, and solvers compete to produce the highest scoring results.\n",
      "\n",
      "figure 1: the foldit interface. foldit solvers use a variety of\n",
      "tools to interactively reshape proteins. in this figure, a solver\n",
      "uses rubber bands to pull together two sheets, long flat regions\n",
      "of the protein.\n",
      "solvers have many tools at their disposal when solving foldit puzzles. they can manipulate and constrain the structure in various\n",
      "ways, employ low-level automated optimization (e.g., a wiggle tool\n",
      "makes small, rapid, local adjustments to try and improve the score),\n",
      "and trigger solver-created automated scripts called recipes that can\n",
      "programmatically use the other tools. there is, however, a subset of\n",
      "the basic actions that cannot be used by recipes. we will call these\n",
      "manual-only actions. previous work analyzing solver behavior in\n",
      "foldit has focused primarily on recipe use and dissemination [2] and\n",
      "recipe authoring [15].\n",
      "foldit has several different types of puzzles for solvers to solve. in\n",
      "this work, we focus on the most common type of puzzle, prediction\n",
      "puzzles. these are puzzles in which biochemists know the amino\n",
      "acids that compose the protein in question, but do not know how\n",
      "the particular protein folds up in 3d space. this is in contrast to\n",
      "design puzzles in which solvers insert and delete which amino acids\n",
      "compose the protein to satisfy a variety of scientific goals, including\n",
      "designing new materials and targeting problematic molecules in\n",
      "diseases. we focus on prediction puzzles in this work to simplify\n",
      "our analysis by having a consistent objective (i.e., maximize score)\n",
      "across the problem-solving behavior we analyze.\n",
      "\n",
      "4.\n",
      "\n",
      "methodology\n",
      "\n",
      "prior work has demonstrated the power of visualization to support\n",
      "understanding of problem-solving behavior (e.g., [12]). hence, we\n",
      "devise a methodology capable of producing concise, meaning-rich\n",
      "visualizations of the problem-solving process in foldit, and then\n",
      "leverage these visualizations to identify key patterns of solver behavior. we are specifically interested in how solvers navigate from\n",
      "a puzzle’s start state to a high-quality solution, what states they\n",
      "pass through in between, and what other avenues they explored.\n",
      "\n",
      "since solving a foldit puzzle can be represented as a directed search\n",
      "through a problem space, the clear encoding of parent-child relationships between nodes offered by a tree make it well-suited for\n",
      "visualizing these aspects of the solving process.\n",
      "the scale of the foldit data necessitates significant transformation\n",
      "of the raw data in order to render concise visualizations. without\n",
      "any transformation, meaningful patterns are overwhelmed by sparse,\n",
      "repetitive data and would be far more challenging to identify. while\n",
      "there are many existing techniques for large-scale tree visualization,\n",
      "we find clear benefits to developing a visualization tailored to the\n",
      "foldit domain. specifically, preserving the semantics of our visual\n",
      "encoding is crucial for allowing us to connect patterns in the visualization to concrete strategic behavior in foldit. to accomplish this,\n",
      "the process by which concise visualization are constructed must\n",
      "be carefully designed to maintain these links. hence, we devise a\n",
      "design methodology focused on iterative summarization.\n",
      "this process begins by visualizing the raw data. this is followed\n",
      "by iteratively building and refining a set of transformations to summarize the raw data while preserving meaning. the design of these\n",
      "transformations should be guided by frequently occurring structures.\n",
      "that is, those structures that the transformations can condense without eliding structures corresponding to unique strategic behavior.\n",
      "in parallel to this iterative design, a set of visual encodings are developed to represent the solving process as richly as possible. key\n",
      "to this entire process is frequent consultation with domain experts,\n",
      "in our case experts on foldit and its community. by applying this\n",
      "iterative methodology for several cycles, we designed a domainspecific visualization that we use to identify patterns of strategic\n",
      "behavior among foldit solvers. we follow up on these patterns with\n",
      "computational investigation, and quantify their application by highand lower-performing solvers.\n",
      "\n",
      "4.1\n",
      "\n",
      "data\n",
      "\n",
      "for our analysis, we selected 11 prediction puzzles spanning the\n",
      "range of time for which the necessary data is available. though\n",
      "foldit has been in continuous use since 2010, the data necessary to\n",
      "track a solver’s progress through the problem space has only been\n",
      "collected since mid-2015. our chosen dataset represents 970 unique\n",
      "solvers and nearly 3 million solution snapshots. these 11 puzzles are\n",
      "just a small subset of the available foldit data. we chose a subset of\n",
      "similar puzzles (i.e., a subtype of relatively less complex prediction\n",
      "puzzles) in order to make common solving-behavior patterns easier\n",
      "to identify. the size of the subset was also guided by practical\n",
      "constraints, as each puzzle constitutes a large amount of data (20-60\n",
      "gb for the data from all players on a single puzzle).\n",
      "the data logged by foldit primarily consists of snapshots of solver\n",
      "solutions as they play, stored as text files using the protein data\n",
      "bank (pdb) format. these snapshots include the current protein\n",
      "pose, a timestamp, the solution’s score, the number of times the\n",
      "solver has invoked each action and recipe, and a record of the intermediate states that led up to the solution at the time of the snapshot.\n",
      "this record, or solution history, is a list of unique identifiers each\n",
      "corresponding to a previous solution state. this list is extended\n",
      "every time the solver undoes an action or reloads a previous solution.\n",
      "hence, by comparing the histories of two snapshots from the same\n",
      "solver, we can answer questions about their relationship (e.g., does\n",
      "one snapshot represent the predecessor of another; where did two\n",
      "related snapshots diverge). the key relationship for the purposes of\n",
      "this analysis is the direct parent-child relationship, which we use to\n",
      "generate trees that represent a solver’s solving process.\n",
      "\n",
      "\n",
      "\n",
      "34\n",
      "\n",
      "\f",
      "4.2\n",
      "\n",
      "visualizing solution trees\n",
      "\n",
      "we applied our methodology to our chosen subset of foldit data to\n",
      "design a visualization of an individual’s problem-solving process\n",
      "as a solution tree. several key principles guided this design. first,\n",
      "since our goal is to discover key patterns, the visualization needs\n",
      "to highlight distinctly different strategies and approaches. these\n",
      "differences cannot be buried amidst enormous structures, nor destroyed by graph transformations. second, the visualization must\n",
      "depict the closeness of each step to the ultimate solution in both time\n",
      "and quality to give a sense of the solver’s progression. third, the\n",
      "solver’s use of automation in the form of recipes should be apparent\n",
      "since the use of automation is an important part of foldit.\n",
      "the fundamental organization of the visualization is that each node\n",
      "corresponds to a solution state encountered while solving. using the\n",
      "solution history present in the logged snapshots of solver solutions,\n",
      "we establish parent-child relationships between solutions. if solution\n",
      "β is a child of solution α, it indicates that β was generated when\n",
      "the solver performed actions on α. one crucial limitation, however,\n",
      "is that a snapshot of the solver’s current solution is captured far less\n",
      "often (only once every two minutes) than the solver takes actions.\n",
      "this means that our data is sparsely distributed along a solution’s\n",
      "history going back to the puzzle’s starting state. hence, when naively\n",
      "constructing the tree from the logged solution histories, it ends up\n",
      "dominated by vast quantities of nodes with no associated data.\n",
      "we address this issue by performing summarization on the solution\n",
      "trees, condensing them into concise representations amenable to\n",
      "analysis for important features. this summarization takes place\n",
      "in two stages. the first stage trims out nodes that (1) do not have\n",
      "corresponding data and (2) have zero children. this eliminates\n",
      "large numbers of leaf nodes that we are unable to reason about\n",
      "given that we lack the corresponding data. this stage also combines\n",
      "sequences of nodes each with only one child into a single node. for\n",
      "the median tree, this stage reduced the number of nodes by an order\n",
      "of magnitude from over 12,000 nodes to about 1,600.\n",
      "the second stage consists of four phases, each informed by our\n",
      "observations of common patterns in trees produced by the first stage\n",
      "that would benefit from summarization. the first phase, called\n",
      "prune, focuses on simplifying uninteresting branches. we observed\n",
      "many of the branches preserved by the first stage were small, with\n",
      "at most three children, and only continued the tree from one of\n",
      "those children. prune removes the leaf children of these branches\n",
      "from the tree. collapse, the second phase, transforms each of the\n",
      "sequences of single-child nodes left behind after prune into single\n",
      "nodes. the third phase, condense, targets another common pattern\n",
      "where a sequence of branches feed into each other, with a child of\n",
      "each branch the parent of the next branch. these sequences are\n",
      "summarized into a single node labeled cascade along with the\n",
      "depth (number of branches) and width (average branching factor)\n",
      "of the summarized branches. see figure 2 for an example of the\n",
      "features summarized by these three phases. the final phase, clean,\n",
      "targets the ubiquitous empty nodes (i.e., nodes for which we lack\n",
      "associated data) shown in black in figure 2. we eliminate them by\n",
      "merging them with their parent node, doing so repeatedly until they\n",
      "all have been merged into nodes that contain data. in addition to\n",
      "making the trees more concise, this step allows us to reason more\n",
      "fully over the trees since all nodes are guaranteed to contain data.\n",
      "this second stage of summarization further reduced the number of\n",
      "nodes in the median tree by another order of magnitude to about\n",
      "300 nodes. summarization similarly reduces the space required to\n",
      "store the data by two orders of magnitude.\n",
      "\n",
      "figure 2: a solution tree after only the first stage of summarization. the non-black node color represents the score of the\n",
      "solution at that node (red is worse). the black nodes are empty\n",
      "in that we do not have solution data corresponding to that node.\n",
      "this figure also shows examples of the features targeted by the\n",
      "second summarization stage: prune and collapse eliminate long\n",
      "chains like the one on the right, and condense combines sequences of branches like those going down to left in single cascade nodes.\n",
      "child-parent relationships are not the only part of the data we visually encoded in the solution trees. nodes are colored on a continuous\n",
      "gradient from red to blue according to the score of the solution represented by that node (red is low-scoring, blue is high-scoring). the\n",
      "best-scoring node is highlighted as a yellow star. edges are colored\n",
      "on a continuous gradient from light to dark green according to the\n",
      "time the corresponding transition took place, and the children of\n",
      "each node are arranged left to right in chronological order. finally,\n",
      "use of automation via recipes is an important aspect of problemsolving in foldit. since the logged solution snapshots contain a\n",
      "record of which recipes have been used at that point, we can use this\n",
      "to annotate nodes where a recipe was triggered. the annotations\n",
      "consist of the id of that recipe (a 4 to 6 digit number) and the number\n",
      "of times it was started.\n",
      "one major weakness in the data available to us is the lack of a consistent way to determine when the execution of a recipe ended (some\n",
      "recipes save and restore, possibly being responsible for multiple\n",
      "nodes in the graph beyond where they were triggered). we partially\n",
      "address this by further annotating a node with the label manual\n",
      "whenever the solver took a manual-only action at that node. this\n",
      "indicates that no previously triggered recipe continued past that node\n",
      "because no recipe could have performed the manual-only action.\n",
      "since nodes in the summarized trees can represent many individual\n",
      "steps, it is possible for them to have several of these recipe and\n",
      "manual action annotations.\n",
      "\n",
      "5.\n",
      "\n",
      "results\n",
      "\n",
      "using visualized solution trees for a large set of solvers across our\n",
      "sample of 11 puzzles, we identify a set of six prominent patterns in\n",
      "solvers’ problem-solving behavior. these patterns do not encompass\n",
      "all solving behavior in foldit, but instead capture key instances of\n",
      "strategic behavior in three categories: exploration, optimization, and\n",
      "human-computer collaboration. future work is needed to generate\n",
      "a comprehensive survey of the strategic patterns in these and other\n",
      "categories. in this analysis, our focus is on identifying a small,\n",
      "diverse set of commonly occurring patterns to both provide initial\n",
      "\n",
      "\n",
      "\n",
      "35\n",
      "\n",
      "\f",
      "insight into problem-solving behavior, and to demonstrate the potential of our approach. in addition to identification, we also perform\n",
      "a quantitative comparison of how these patterns are employed by\n",
      "high-performing and lower-performing solvers to gain an understanding of how these patterns contribute to success in an open-end\n",
      "environment like foldit.\n",
      "\n",
      "5.1\n",
      "\n",
      "has a high-scoring node with a low-scoring child, and then chooses\n",
      "to explore from the low-scoring child. the solver was willing to\n",
      "ignore the short-term drop in score to try and reach a more beneficial\n",
      "state in the long-term. figure 5 gives an example of this pattern.\n",
      "\n",
      "problem-solving patterns\n",
      "\n",
      "exploration. foldit solvers are confronted with a highly discon-\n",
      "\n",
      "tinuous solution space with many local optima, creating a trade-off\n",
      "between narrowly focusing their efforts or taking the time to explore\n",
      "a broader range of possibilities. in our first two patterns, we examine the broader exploration side of this trade-off at two different\n",
      "scales. taking the macro-scale first, we identify a pattern where\n",
      "solvers make significant progress on distinct branches of the tree\n",
      "(see figure 3 for an example). we interpret this pattern as the solver\n",
      "investigating multiple hypotheses about the puzzle solution, using\n",
      "multiple instances of the game client or foldit’s save and restore features to deeply explore them all. we call this the multiple hypotheses\n",
      "pattern.\n",
      "\n",
      "figure 5: an example of the optima escape pattern. the solver\n",
      "transitions from a relatively high-scoring (i.e., blue) state in the\n",
      "upper left to a low-scoring (i.e., red) state. what makes this\n",
      "an example of the pattern is that exploration from the lowscoring state. in this case, the perseverance paid off as the\n",
      "solver reaches even higher-scoring states in the lower right.\n",
      "in the other direction, we identify the greedy pattern in which solvers\n",
      "exclusively explore from the best-scoring of the available options.\n",
      "obviously, some amount of greedy exploration is necessary in order\n",
      "to refine solutions, but in its extreme form deserves recognition\n",
      "as a pattern with significant potential impact on problem-solving\n",
      "success. naturally, these two patterns do not cover all the ways\n",
      "solvers explore the problem space, but they do characterize specific\n",
      "strategic behavior of interest in this analysis.\n",
      "\n",
      "figure 3: an example of the multiple hypotheses pattern. the\n",
      "two hypotheses branch out one of the nodes at the top and continue to the left (a) and right (b).\n",
      "at the micro-scale, solvers very frequently generate a large number\n",
      "of possible next steps (i.e., a branch with a large number of children),\n",
      "but most often proceed to explore only one of them further. this is\n",
      "natural given the iterative refinement needed to successfully participate in foldit. hence, solvers that exhibit a pattern of much more\n",
      "frequently exploring multiple local possibilities demonstrate an unusual effort to explore more broadly. we call this the inquisitive\n",
      "pattern. figure 4 shows an example of this behavior.\n",
      "\n",
      "figure 6: an example of the repeated recipe pattern. at three\n",
      "points in this solution tree snippet, the solver applies recipe\n",
      "49233 to every child of a node.\n",
      "\n",
      "human-computer collaboration. human-computer collabo-\n",
      "\n",
      "figure 4: an example of the inquisitive pattern. note how frequently multiple children of the same node are explored when\n",
      "compared to the tree in figure 3.\n",
      "\n",
      "optimization. navigating the extremely heterogeneous solution\n",
      "\n",
      "space is the primary challenge in foldit, so we look closely at how\n",
      "solvers attempt to optimize their solutions, digging deeper into\n",
      "solvers’ approach to exploration than the previous two patterns.\n",
      "we identify two related patterns describing solvers’ fine-grained\n",
      "approach to optimization. the solution spaces of foldit puzzles\n",
      "contain numerous local optima that solvers must escape, and we\n",
      "identify an optima escape pattern highly suggestive of a deliberate\n",
      "attempt to escape a local optima. this pattern occurs when a solver\n",
      "\n",
      "ration is a vital part of foldit, and managing the trade-off between\n",
      "automation and manual intervention is a key feature of solving\n",
      "foldit puzzles. we identify two patterns that each focus on one\n",
      "side of this trade-off. the first, the manual pattern, corresponds to\n",
      "extended sections of exclusively manual exploration. since recipe\n",
      "use is very common, extended manual exploration represents a significant investment in the manual intervention side of the trade-off.\n",
      "limitations with foldit logging data prevent us from capturing all\n",
      "the manual exploration (i.e., it is not always possible to determine\n",
      "whether an action was performed by a solver manually or triggered\n",
      "as part of an automated recipe), but what can be captured is still an\n",
      "important dimension of variance among problem-solving behavior.\n",
      "our final pattern concerns recipe use. some solvers apply a recipe\n",
      "to every child of a node periodically throughout their solution tree,\n",
      "using it as a clean-up or refinement step before continuing on (see\n",
      "figure 6). we call this the repeated recipe pattern. recipe use is\n",
      "very diverse and frequently doesn’t display any specific structure,\n",
      "making this pattern interesting for its regimented way of managing\n",
      "some of the automation while solving.\n",
      "\n",
      "\n",
      "\n",
      "36\n",
      "\n",
      "\f",
      "figure 7: the number of hypotheses pursued in each solution\n",
      "tree for high- and lower-performing solvers. high-performing\n",
      "solvers frequently pursue two or more hypotheses, whereas\n",
      "lower-performing solvers most often pursue just one. red circles show the distribution of individual solvers.\n",
      "\n",
      "5.2\n",
      "\n",
      "problem-solving patterns and\n",
      "solver performance\n",
      "\n",
      "to understand how the patterns we identify relate to skillful problemsolving in an open-ended domain like foldit, we compare their use\n",
      "among high-performing solvers to that among lower-performing\n",
      "solvers. specifically, we analyze the occurrence of these patterns in\n",
      "the 15 best-scoring solutions from each puzzle and compare that to\n",
      "the occurrence in solutions from each puzzle ranked from 36th to\n",
      "50th. though it varies somewhat between puzzles, in general the\n",
      "solutions ranked 36th to 50th represent a middle ground in terms\n",
      "of quality. they fall outside the puzzle’s state-of-the-art solutions,\n",
      "but remain well above the least successful efforts. throughout these\n",
      "comparisons we use non-parametric mann-whitney u tests with\n",
      "α = 0.008 confidence (bonferroni correction for six comparisons,\n",
      "α = 0.05/6), as our data is not normally distributed. for each test,\n",
      "we report the test statistic u, the two-tailed significance p, and the\n",
      "rank-biserial correlation measure of effect size r. in addition, since\n",
      "some of the metrics we compute may not apply to all solution trees\n",
      "(e.g., the tree contains no branches where the inquisitive pattern\n",
      "can be evaluated), we report the number of solvers involved in the\n",
      "comparison n for each test (the full sample is n = 330).\n",
      "we find high-performing solvers explore more broadly than lowerperforming solvers. for the multiple hypotheses pattern, highperforming solvers pursued significantly more hypotheses than\n",
      "lower-performing solvers (u = 10569, p = 0.000014, r = 0.217,\n",
      "n = 330) (see figure 7). for the inquisitive pattern, we compute\n",
      "the proportion of each solver’s exploration that matches the pattern\n",
      "(i.e., of all the branches in a solver’s solution tree, in what fraction of them did the solver explore more than one child) and find\n",
      "high-performing solvers explore inquisitively more often than lowerperforming solvers (u = 9343, p = 0.000295, r = 0.231, n = 313)\n",
      "\n",
      "figure 8: the proportion of all the branches in a solver’s solution tree in which the solver explored more than one child\n",
      "for high- and lower-performing solvers. red circles show the\n",
      "distribution of individual solvers.\n",
      "(see figure 8).\n",
      "we also find high-performing solvers work harder to avoid local\n",
      "optima. for the optima escape pattern, we compute the number of times this behavior occurs in each solution and find that\n",
      "high-performing solvers engage in this behavior more than lowerperforming solvers (u = 11183.5, p = 0.00185, r = 0.173, n = 330)\n",
      "(see figure 9). for the greedy pattern, we compute the proportion of each solver’s exploration that matches the pattern (i.e., of\n",
      "all the branches in a solver’s solution tree, in what fraction of\n",
      "them did the solver only explore the best-scoring child). while\n",
      "high-performing solvers engaged in greedy optimization less often\n",
      "than lower-performing solvers, the difference was not significant\n",
      "(u = 9079, p = 0.0158, r = −0.163, n = 295) (see figure 10).\n",
      "finally, we find no significant difference between high- and lowerperforming solvers in the frequency they manually explore and\n",
      "employ recipes. for the manual pattern, we compute the number of\n",
      "manual exploration sections in each solution and find no significant\n",
      "difference between high- and lower-performing solvers (u = 13334,\n",
      "p = 0.789, r = 0.014, n = 330). for the repeated recipe pattern,\n",
      "we computed the median frequency of recipe use along all paths\n",
      "in the solution (i.e., for each path from the root to a leaf, in what\n",
      "fraction of the nodes did the solver trigger at least one recipe) and\n",
      "though lower-performing solvers used recipes more frequently, the\n",
      "difference between high- and lower-performing solvers was not\n",
      "significant (u = 11342, p = 0.0140, r = −0.157, n = 329).\n",
      "\n",
      "6.\n",
      "\n",
      "discussion\n",
      "\n",
      "the results from our analysis of our solution tree visualizations illuminate some key problem-solving patterns exhibited by individual\n",
      "foldit solvers. namely, how broadly an individual explores, both\n",
      "on a macro- and micro-scale, how actively an individual avoids\n",
      "\n",
      "\n",
      "\n",
      "37\n",
      "\n",
      "\f",
      "figure 9: the number of times in each solution a solver engages in optima escape behavior for high- and lower-performing\n",
      "solvers. red circles show the distribution of individual solvers.\n",
      "\n",
      "local optima by engaging in less greedy optimization and actively\n",
      "pursuing locally suboptimal lines of inquiry, and how an individual\n",
      "manages the interplay between automation and manual intervention.\n",
      "comparing high- and lower-performing solvers in their application of these patterns suggests that skillful problem-solving in an\n",
      "open-end domain like foldit involves broader exploration and more\n",
      "conscious avoidance of local minima. this finding that a key feature\n",
      "of high-skill solving behaviors is not being enamored by the current\n",
      "best solution and possessing strategies for avoiding myopic thinking\n",
      "had implications for the strategies that should be taught to develop\n",
      "successful problem solvers. further work is required on other large\n",
      "open-ended domains to confirm this trend.\n",
      "the finding that solvers of different skill use greedy exploration,\n",
      "manual exploration, and automation in similar amounts suggests\n",
      "skillful deployment of non-greedy exploration, automation, and\n",
      "manual intervention takes place at a more fine-grained level than\n",
      "overall quantity. though this work focuses on the presence or\n",
      "absence of specific solving behavior, the timing and sequencing of\n",
      "strategic moves are likely to be critical to success. further work is\n",
      "needed to investigate what differentiates effective and ineffective\n",
      "use of specific solving strategies.\n",
      "the foldit dataset itself presented significant challenges for our\n",
      "analysis, and we addressed these through an iterative visualizationbased methodology. this process served as a design method for\n",
      "generating a visual grammar to describe a complex problem-solving\n",
      "process. we do not study the generalization of this approach to\n",
      "other datasets and domains in this work, but the prerequisites for\n",
      "its application to other open-ended problem-solving domains can\n",
      "be concisely enumerated: (1) the logs of solver activity establish\n",
      "clear temporal relationships between solution states such that those\n",
      "states can be visualized as a progression through the solution space,\n",
      "\n",
      "figure 10: the proportion of all the branches in a solver’s solution tree in which the solver explored only the best-scoring\n",
      "child for high- and lower-performing solvers. the fact that the\n",
      "median for both categories of solver is above 0.5 indicates that\n",
      "this pattern in an important part of refining solutions in foldit.\n",
      "red circles show the distribution of individual solvers.\n",
      "(2) the solution state or associated metadata is amenable to visual\n",
      "encoding, so that the visualized progressions can represent finegrained details of the solving process, and (3) deep problem-solving\n",
      "domain expertise is available to provide the necessary context for\n",
      "interpreting and summarizing the visualized structures.\n",
      "our chosen subset of foldit data represents only a small fraction\n",
      "of the total available data. in particular, we limited our analysis\n",
      "to a sample of similar prediction puzzles, and compared specific\n",
      "ranges of high- and lower-performing solvers. though these choices\n",
      "are well-motivated, it is an important question for future work as\n",
      "to whether our results hold across different datasets and groups of\n",
      "comparison. more broadly, foldit supports numerous variations\n",
      "on the prediction and design puzzle archetypes, which offers an\n",
      "exciting opportunity to study problem solving across a number of\n",
      "related contexts with varying goals, constraints, inputs, and tools.\n",
      "\n",
      "7.\n",
      "\n",
      "conclusion\n",
      "\n",
      "gaining a better understanding of key patterns in problem-solving\n",
      "behavior in complex, open-ended environments is important for deploying this kind of activity in an educational setting at scale. in this\n",
      "work, we identified six key patterns in problem-solving behavior\n",
      "among solvers of foldit. the protein folding challenges in foldit\n",
      "present rich, completely open, heterogeneous solution spaces, making them a compelling domain in which to analyze these patterns.\n",
      "to facilitate the identification of these patterns, we used an iterative\n",
      "methodology to design visualizations of solvers’ problem-solving\n",
      "activity as solution trees. the size and complexity of the foldit data\n",
      "required us to develop domain-specific techniques to summarize the\n",
      "solution trees and render them tractable for analysis while preserving the salient problem-solving behaviors. finally, we compared the\n",
      "\n",
      "\n",
      "\n",
      "38\n",
      "\n",
      "\f",
      "occurrence of the patterns we identified between high- and lowerperforming solvers. we found that high-performing solvers explore\n",
      "more broadly and more aggressively avoid local optima. we also\n",
      "found that both categories of solvers employ automation and manual\n",
      "intervention in similar quantities, inviting future work to study how\n",
      "these tools are used at a more fine-grained level.\n",
      "we have only scratched the surface in our analysis of a subset of\n",
      "foldit data. two integral aspects of the foldit environment are\n",
      "not within the scope of this work: collaboration and expert feedback. we only considered solutions produced by individual solvers,\n",
      "but foldit solver can also take solutions produced by others and\n",
      "try and improve them. this collaborative framework may involve\n",
      "specialization and unique solving strategies, and deserves careful\n",
      "study. expert feedback comes into play for design puzzles, where\n",
      "biochemists will select a small number of the solutions to try and\n",
      "synthesize in the lab. experts will also impose additional constraints\n",
      "on future design puzzles to try and guide solutions toward more\n",
      "promising designs. the interaction of these channels for expert\n",
      "feedback and problem-solving behavior is an important topic for\n",
      "future research. also outside the scope of this work is how individual solvers change their problem-solving behavior over time. many\n",
      "solvers have been participating in the foldit community for many\n",
      "years, and studying how their behavior evolves could yield insights\n",
      "into the acquisition of high-level problem-solving skills.\n",
      "looking more broadly at the impact of this work, our methodology\n",
      "and analysis can serve as a first step toward discovering the scaffolding necessary to develop high-level problem-solving skills. these\n",
      "results could contribute to a hint generation system, where solvers\n",
      "could be guided toward known effective strategies, or a meta-planner\n",
      "component in foldit that could tailor the parameters of particular\n",
      "puzzles to optimize the quality of the scientific results. in all of\n",
      "these cases, this work contributes to the necessary foundational\n",
      "understanding of the problem-solving behavior involved.\n",
      "\n",
      "8.\n",
      "\n",
      "acknowledgements\n",
      "\n",
      "this work was supported by the national institutes of health grant\n",
      "1uh2ca203780, rosettacommons, and amazon. this material\n",
      "is based upon work supported by the national science foundation\n",
      "under grant no. 1629879.\n",
      "\n",
      "9.\n",
      "\n",
      "[6]\n",
      "\n",
      "[7]\n",
      "\n",
      "[8]\n",
      "[9]\n",
      "[10]\n",
      "\n",
      "[11]\n",
      "[12]\n",
      "\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "\n",
      "[16]\n",
      "\n",
      "references\n",
      "\n",
      "[1] e. andersen, y.-e. liu, e. apter, f. boucher-genesse, and\n",
      "z. popović. gameplay analysis through state projection. in\n",
      "proceedings of the fifth international conference on the\n",
      "foundations of digital games, pages 1–8. acm, 2010.\n",
      "[2] s. cooper, f. khatib, i. makedon, h. lu, j. barbero, d. baker,\n",
      "j. fogarty, z. popović, et al. analysis of social gameplay\n",
      "macros in the foldit cookbook. in proceedings of the 6th\n",
      "international conference on foundations of digital games,\n",
      "pages 9–14. acm, 2011.\n",
      "[3] s. cooper, f. khatib, a. treuille, j. barbero, j. lee,\n",
      "m. beenen, a. leaver-fay, d. baker, z. popović, et al.\n",
      "predicting protein structures with a multiplayer online game.\n",
      "nature, 466(7307):756–760, 2010.\n",
      "[4] m. eagle, d. hicks, b. peddycord iii, and t. barnes.\n",
      "exploring networks of problem-solving interactions. in\n",
      "proceedings of the 5th conference on learning analytics and\n",
      "knowledge. acm, 2015.\n",
      "[5] c. b. eiben, j. b. siegel, j. b. bale, s. cooper, f. khatib,\n",
      "\n",
      "[17]\n",
      "\n",
      "[18]\n",
      "[19]\n",
      "[20]\n",
      "\n",
      "[21]\n",
      "\n",
      "b. w. shen, b. l. stoddard, z. popovic, and d. baker.\n",
      "increased diels-alderase activity through backbone\n",
      "remodeling guided by foldit players. nature biotechnology,\n",
      "30(2):190–192, 2012.\n",
      "m. h. falakmasir, j. p. gonzalez-brenes, g. j. gordon, and\n",
      "k. e. dicerbo. a data-driven approach for inferring student\n",
      "proficiency from game activity logs. in proceedings of the\n",
      "third (2016) acm conference on learning@ scale, pages\n",
      "341–349. acm, 2016.\n",
      "c. geigle, c. zhai, and d. c. ferguson. an exploration of\n",
      "automated grading of complex assignments. in proceedings of\n",
      "the third (2016) acm conference on learning@ scale, pages\n",
      "351–360. acm, 2016.\n",
      "m. l. gick. problem-solving strategies. educational\n",
      "psychologist, 21(1-2):99–120, 1986.\n",
      "j. g. greeno. natures of problem-solving abilities. handbook\n",
      "of learning and cognitive processes, 5:239–270, 1978.\n",
      "e. harpstead, c. j. maclellan, k. r. koedinger, v. aleven,\n",
      "s. p. dow, and b. myers. investigating the solution space of\n",
      "an open-ended educational game using conceptual feature\n",
      "extraction. in proceedings of the 6th conference on\n",
      "educational data mining, 2013.\n",
      "w. hung, d. h. jonassen, r. liu, et al. problem-based\n",
      "learning. handbook of research on educational\n",
      "communications and technology, 3:485–506, 2008.\n",
      "m. johnson, m. eagle, and t. barnes. invis: an interactive\n",
      "visualization tool for exploring interaction networks. in\n",
      "proceedings of the 6th conference on educational data\n",
      "mining, 2013.\n",
      "d. h. jonassen. toward a design theory of problem solving.\n",
      "educational technology research and development,\n",
      "48(4):63–85, dec 2000.\n",
      "d. a. joyner. expert evaluation of 300 projects per day. in\n",
      "proceedings of the third (2016) acm conference on\n",
      "learning@ scale, pages 121–124. acm, 2016.\n",
      "f. khatib, s. cooper, m. d. tyka, k. xu, i. makedon,\n",
      "z. popović, and d. baker. algorithm discovery by protein\n",
      "folding game players. proceedings of the national academy\n",
      "of sciences, 108(47):18949–18953, 2011.\n",
      "f. khatib, f. dimaio, s. cooper, m. kazmierczyk, m. gilski,\n",
      "s. krzywda, h. zabranska, i. pichova, j. thompson,\n",
      "z. popović, et al. crystal structure of a monomeric retroviral\n",
      "protease solved by protein folding game players. nature\n",
      "structural & molecular biology, 18(10):1175–1177, 2011.\n",
      "l. malkiewich, r. s. baker, v. shute, s. kai, and l. paquette.\n",
      "classifying behavior to elucidate elegant problem solving in\n",
      "an educational game. in proceedings of the 9th conference on\n",
      "educational data mining, 2016.\n",
      "e. rowe, r. s. baker, and j. asbell-clarke. strategic game\n",
      "moves mediate implicit science learning. in proceedings of\n",
      "the 8th conference on educational data mining, 2015.\n",
      "h. a. simon. information-processing theory of human\n",
      "problem solving. handbook of learning and cognitive\n",
      "processes, 5:271–295, 1978.\n",
      "k. tóth, h. rölke, s. greiff, and s. wüstenberg. discovering\n",
      "students’ complex problem solving strategies in educational\n",
      "assessment. in proceedings of the 7th conference on\n",
      "educational data mining, 2014.\n",
      "g. wallner and s. kriglstein. visualization-based analysis of\n",
      "gameplay data–a review of literature. entertainment\n",
      "computing, 4(3):143–155, 2013.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (papers[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) print how many files you have in the \"papers\" list:\n",
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- First paper ---\n",
      " \f",
      "zone out no more: mitigating mind wandering during\n",
      "computerized reading\n",
      "sidney k. d’mello, caitlin mills, robert bixler, & nigel bosch\n",
      "university of notre dame\n",
      "118 haggar hall\n",
      "notre dame, in 46556, usa\n",
      "sdmello@nd.edu\n",
      "\n",
      "abstract\n",
      "mind wandering, defined as shifts in attention from task-related\n",
      "process\n",
      "--- Second paper ---\n",
      " \n",
      "\n",
      "15\n",
      "\n",
      "\f",
      "measuring similarity of educational items using data on\n",
      "learners’ performance\n",
      "jiří řihák\n",
      "\n",
      "faculty of informatics\n",
      "masaryk university\n",
      "brno, czech republic\n",
      "\n",
      "thran@mail.muni.cz\n",
      "abstract\n",
      "educational systems typically contain a large pool of items\n",
      "(questions, problems). using data mining techniqu\n"
     ]
    }
   ],
   "source": [
    "# 8) print the content of the first two paper to make sure it worked\n",
    "# (only print the first 300 characters)\n",
    "print(\"---- First paper ---\\n\", papers[0][:300])\n",
    "print(\"--- Second paper ---\\n\", papers[1][:300])\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 9) create a new folder called papers; this is where we are \n",
    "# going to save each paper into a separate text file\n",
    "# hint: google \"how to create a new folder with python\"\n",
    "\n",
    "newpath = \"./Papers\"\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.ipynb_checkpoints',\n",
       " 'Folder',\n",
       " 'fullpapers.pdf',\n",
       " 'fullpapers.txt',\n",
       " 'Papers',\n",
       " 'Week 4 - data cleaning - starter code-complete.ipynb']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9)\n",
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paper0.txt',\n",
       " 'paper1.txt',\n",
       " 'paper10.txt',\n",
       " 'paper11.txt',\n",
       " 'paper12.txt',\n",
       " 'paper13.txt',\n",
       " 'paper14.txt',\n",
       " 'paper15.txt',\n",
       " 'paper16.txt',\n",
       " 'paper2.txt',\n",
       " 'paper3.txt',\n",
       " 'paper4.txt',\n",
       " 'paper5.txt',\n",
       " 'paper6.txt',\n",
       " 'paper7.txt',\n",
       " 'paper8.txt',\n",
       " 'paper9.txt']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"Papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving paper 0 to .\\Papers\\paper0.txt\n",
      "Saving paper 1 to .\\Papers\\paper1.txt\n",
      "Saving paper 2 to .\\Papers\\paper2.txt\n",
      "Saving paper 3 to .\\Papers\\paper3.txt\n",
      "Saving paper 4 to .\\Papers\\paper4.txt\n",
      "Saving paper 5 to .\\Papers\\paper5.txt\n",
      "Saving paper 6 to .\\Papers\\paper6.txt\n",
      "Saving paper 7 to .\\Papers\\paper7.txt\n",
      "Saving paper 8 to .\\Papers\\paper8.txt\n",
      "Saving paper 9 to .\\Papers\\paper9.txt\n",
      "Saving paper 10 to .\\Papers\\paper10.txt\n",
      "Saving paper 11 to .\\Papers\\paper11.txt\n",
      "Saving paper 12 to .\\Papers\\paper12.txt\n",
      "Saving paper 13 to .\\Papers\\paper13.txt\n",
      "Saving paper 14 to .\\Papers\\paper14.txt\n",
      "Saving paper 15 to .\\Papers\\paper15.txt\n",
      "Saving paper 16 to .\\Papers\\paper16.txt\n"
     ]
    }
   ],
   "source": [
    "# 10) save each paper into its unique file in the \"Papers\" folder\n",
    "# we created above\n",
    "# Hint: \"enumerate\" can provide you with the index of the paper in the list\n",
    "# Feel free to use the following filename for the first paper in the list:\n",
    "# ./Papers/paper0.txt on mac and .\\Papers\\paper0.txt on windows\n",
    "i = 0\n",
    "path = \".\\Papers\\paper\"\n",
    "for paper in papers:\n",
    "    file_path = os.path.join(path+str(i)+\".txt\")\n",
    "    print (\"Saving paper\", str(i),\"to\", file_path)\n",
    "    with open(file_path, 'w', encoding=\"utf8\") as f:\n",
    "        f.write(paper)\n",
    "        f.close()\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper0.txt\n",
      "paper1.txt\n",
      "paper10.txt\n",
      "paper11.txt\n",
      "paper12.txt\n",
      "paper13.txt\n",
      "paper14.txt\n",
      "paper15.txt\n",
      "paper16.txt\n",
      "paper2.txt\n",
      "paper3.txt\n",
      "paper4.txt\n",
      "paper5.txt\n",
      "paper6.txt\n",
      "paper7.txt\n",
      "paper8.txt\n",
      "paper9.txt\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(\"./Papers\"):  \n",
    "    for filename in files:\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be asking yourself why we need to save the data into text files (instead of just using the list of papers above). One answer is that when we work with large datastsets, it's useful to save snapshots of our data that is \"clean\". This way we don't have to re-run all the code above and we save time. It also allows us to share data between different notebooks for other types of analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Papers\\\\paper0.txt', './Papers\\\\paper1.txt', './Papers\\\\paper10.txt', './Papers\\\\paper11.txt', './Papers\\\\paper12.txt', './Papers\\\\paper13.txt', './Papers\\\\paper14.txt', './Papers\\\\paper15.txt', './Papers\\\\paper16.txt', './Papers\\\\paper2.txt', './Papers\\\\paper3.txt', './Papers\\\\paper4.txt', './Papers\\\\paper5.txt', './Papers\\\\paper6.txt', './Papers\\\\paper7.txt', './Papers\\\\paper8.txt', './Papers\\\\paper9.txt']\n"
     ]
    }
   ],
   "source": [
    "# 11) We are going to practice your \"glob\" skills - find all the \n",
    "# text files in the \"Papers\" folder with a glob command!\n",
    "import glob \n",
    "import pandas as pd\n",
    "\n",
    "path = './Papers'\n",
    "txtfiles = glob.glob('./Papers/**/*.txt', recursive=True)\n",
    "\n",
    "print(txtfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 12) iterate through each of the text files and read their contents in the variable below:\n",
    "# Using a for loop, iterate over all the files in the directory, and add them to the list below\n",
    "import os\n",
    "import glob\n",
    "text_list = []\n",
    "for file in txtfiles:\n",
    "    with open(file, 'r', encoding='utf-8') as content_file:\n",
    "        content = content_file.read()\n",
    "        text_list.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\f",
      "zone out no more: mitigating mind wandering during\n",
      "computerized reading\n",
      "sidney k. d’mello, caitlin mills, robert bixler, & nigel bosch\n",
      "university of notre dame\n",
      "118 haggar hall\n",
      "notre dame, in 46556, usa\n",
      "sdmello@nd.edu\n",
      "\n",
      "abstract\n",
      "mind wandering, defined as shifts in attention from task-related\n",
      "processing to task-unrelated thoughts, is a ubiquitous\n",
      "phenomenon that has a negative influence on performance and\n",
      "productivity in many contexts, including learning. we propose\n",
      "that next-generation learning technologies should have some\n",
      "mechanism to detect and respond to mind wandering in real-time.\n",
      "towards this end, we developed a technology that automatically\n",
      "detects mind wandering from eye-gaze during learning from\n",
      "instructional texts. when mind wandering is detected, the\n",
      "technology intervenes by posing just-in-time questions and\n",
      "encouraging re-reading as needed. after multiple rounds of\n",
      "iterative refinement, we summatively compared the technology to\n",
      "a yoked-control in an experiment with 104 participants. the key\n",
      "dependent variable was performance on a post-reading\n",
      "comprehension assessment. our results suggest that the\n",
      "technology was successful in correcting comprehension deficits\n",
      "attributed to mind wandering (d = .47 sigma) under specific\n",
      "conditions, thereby highlighting the potential to improve learning\n",
      "by “attending to attention.”\n",
      "\n",
      "keywords\n",
      "mind wandering; gaze tracking; student modeling; attentionaware.\n",
      "\n",
      "1. introduction\n",
      "despite our best efforts to write a clear and engaging paper,\n",
      "chances are high that within the next 10 pages you might fall prey\n",
      "to what is referred to as zoning out, daydreaming, or mind\n",
      "wandering [45]. despite your best intention to concentrate on our\n",
      "paper, at some point your attention might drift away to unrelated\n",
      "thoughts of lunch, childcare, or an upcoming trip. this prediction\n",
      "is not based on some negative or cynical opinion of the\n",
      "reader/reviewer (we read and review papers too), but on what is\n",
      "known about attentional control, vigilance, and concentration\n",
      "while individuals are engaged in complex comprehension\n",
      "activities, such as reading for understanding.\n",
      "one recent study tracked mind wandering of 5,000 individuals\n",
      "from 83 countries with a smartphone app that prompted people\n",
      "with thought-probes at random intervals throughout the day [24].\n",
      "people reported mind wandering for 46.9% of the prompts, which\n",
      "confirmed lab studies on the pervasiveness of mind wandering\n",
      "(see [45] for a review). mind wandering is more than merely\n",
      "incidental; a recent meta-analysis of 88 samples indicated a\n",
      "negative correlation between mind wandering and performance\n",
      "across a variety of tasks [34], a correlation which increases with\n",
      "task complexity. when compounded with its high frequency,\n",
      "mind wandering can have serious consequences on the\n",
      "performance and productivity of society at large.\n",
      "\n",
      "of learning with technology. traditional learning technologies\n",
      "rely on the assumption that students are attending to the learning\n",
      "session, although this is not always the case. for example, it has\n",
      "been estimated that students mind wander approximately 40% of\n",
      "the time when engaging with online lectures [38], which are an\n",
      "important component of moocs. some advanced technologies\n",
      "do aim to detect and respond to affective states like boredom, but\n",
      "evidence for their effectiveness is still equivocal (see [9] for a\n",
      "review). further, boredom is related to but not the same as\n",
      "attention [12]. there are technologies that aim to prevent mind\n",
      "wandering by engendering a highly immersive learning\n",
      "experience and have achieved some success in this regard [40,\n",
      "41]. but what is to be done when attentional focus inevitably\n",
      "wanes as the session progresses and the novelty of the system and\n",
      "content fades?\n",
      "our central thesis is that next-generation learning technologies\n",
      "should include mechanisms to model and respond to learners’\n",
      "attention in real-time [8]. such attention-aware technologies can\n",
      "model various aspects of learner attention (e.g., divided attention,\n",
      "alternating attention). here, we focus on detecting and mitigating\n",
      "mind wandering, a quintessential signal of waning engagement.\n",
      "we situate our work in the context of reading because reading is\n",
      "a common activity shared across multiple learning technologies,\n",
      "thereby increasing the generalizability of our results. further,\n",
      "students mind wander approximately 30% of the time during\n",
      "computerized reading [44]. and although mind wandering can\n",
      "facilitate certain cognitive processes like future planning and\n",
      "divergent thinking [2, 28], it negatively correlates with\n",
      "comprehension and learning (reviewed in [31, 45]), suggesting\n",
      "that it is important to address mind wandering during learning.\n",
      "towards this end, we developed and validated a closed-loop\n",
      "attention-aware learning technology that combines a machinelearned mind wandering detector with a real-time interpolated\n",
      "testing and re-study intervention. our attention-aware technology\n",
      "works as follows. learners read a text on a computer screen using\n",
      "a self-paced screen-by-screen (also called page-by-page) reading\n",
      "paradigm. we track eye-gaze during reading using a remote eye\n",
      "tracker that does not restrict head movements. we focus on eyegaze for mind wandering detection due to decades of research\n",
      "suggesting a tight coupling between attentional focus and eye\n",
      "movements during reading [36]. when mind wandering is\n",
      "detected, the system intervenes in an attempt to redirect\n",
      "attentional focus and correct any comprehension deficits that\n",
      "might arise due to mind wandering. the interventions consist of\n",
      "asking comprehension question on pages where mind wandering\n",
      "was detected and providing opportunities to re-read based on\n",
      "learners’ responses. in this paper, we discuss the mind wandering\n",
      "\n",
      "mind wandering is also unfortunately an under-addressed\n",
      "problem in education and is yet to be deeply studied in the context\n",
      "\n",
      "\n",
      "\n",
      "8\n",
      "\n",
      "\f",
      "detector, intervention approach, and results of a summative\n",
      "evaluation study 1.\n",
      "\n",
      "1.1 related work\n",
      "the idea of attention-aware user interfaces is not new, but was\n",
      "proposed almost a decade ago by roda and thomas [39]. there\n",
      "was even an article on futuristic applications of attention-aware\n",
      "systems in educational contexts [35]. prior to this, gluck, et al.\n",
      "[15] discussed the use of eye tracking to increase the bandwidth\n",
      "of information available to an intelligent tutoring system (its).\n",
      "similarly, anderson [1] followed up on some of these ideas by\n",
      "demonstrating how particular beneficial instructional strategies\n",
      "could only be launched via a real-time analysis of eye gaze.\n",
      "most of the recent work has been on leveraging eye gaze to\n",
      "increase the bandwidth of learner models [22, 23, 29]. conati, et\n",
      "al. [5] provide an excellent review of much of the existing work\n",
      "in this area. we can group the research into three categories: (1)\n",
      "offline-analyses of eye gaze to study attentional processes, (2)\n",
      "computational modeling of attentional states, and (3) closed-loop\n",
      "systems that respond to attention in real-time. offline-analysis of\n",
      "eye movements has received considerable attention in cognitive\n",
      "and educational psychology for several decades [e.g., 16, 19], so\n",
      "this area of research is relatively healthy. online computational\n",
      "models of learner attention are just beginning to emerge [e.g., 6,\n",
      "11], while closed-loop attention-aware systems are few and far\n",
      "between (see [7, 15, 42, 48] for a more or less exhaustive list).\n",
      "two known examples, gazetutor and attentivereview, are\n",
      "discussed below.\n",
      "gazetutor [7] is a learning technology for biology. it has an\n",
      "animated conversational agent that provides spoken explanations\n",
      "on biology topics which are synchronized with images. the\n",
      "system uses a tobii t60 eye tracker to detect inattention, which\n",
      "is assumed to occur when learners’ gaze is not on the tutor agent\n",
      "or image for at least five consecutive seconds. when this occurs,\n",
      "the system interrupts its speech mid utterance, directs learners to\n",
      "reorient their attention (e.g., “i’m over here you know”), and\n",
      "repeats speaking from the start of the current utterance. in an\n",
      "evaluation study, 48 learners (undergraduate students) completed\n",
      "a learning session on four biology topics with the attention-aware\n",
      "components enabled (experimental group) or disabled (control\n",
      "group). the results indicated that gazetutor was successful in\n",
      "dynamically reorienting learners’ attentional patterns towards the\n",
      "interface. importantly, learning gains for deep reasoning\n",
      "questions were significantly higher for the experimental vs.\n",
      "control group, but only for high aptitude learners. the results\n",
      "suggest that even the most basic attention-aware technology can\n",
      "be effective in improving learning, at least for a subset of learners.\n",
      "however, a key limitation is that the researchers simply assumed\n",
      "that off-screen gaze corresponded to inattention, but did not test\n",
      "this assumption (e.g., students could have been concentrating\n",
      "with their eyes closed and this would have been perceived as\n",
      "being inattentive).\n",
      "attentivereview [32] is a closed-loop system for mooc learning\n",
      "on mobile phones. the system uses video-based\n",
      "photoplethysmography (ppg) to detect a learners’ heart rate from\n",
      "the back camera of a smartphone while they view mooc-like\n",
      "lectures on the phone. attentivereview ranks the lectures based\n",
      "1\n",
      "\n",
      "on its estimates of learners’ “perceived difficulty,” selecting the\n",
      "most difficult lecture for subsequent review (called adaptive\n",
      "review). in a 32-participant between-subjects evaluation study,\n",
      "the authors found that learning gains obtained from the adaptive\n",
      "review condition were statistically on par with a full review\n",
      "condition, but were achieved in 66.7% less review time. although\n",
      "this result suggests that attentivereview increased learning\n",
      "efficiency, there is the question as to whether the system should\n",
      "even be considered to be an “attention-aware” technology. this is\n",
      "because it is arguable if the system has anything to do with\n",
      "attention (except for “attention” appearing in its name) as it\n",
      "selects items for review based on a model of “perceived\n",
      "difficulty” and not on learners’ “attentional state.” the two might\n",
      "be related, but are clearly not the same.\n",
      "\n",
      "1.2 novelty\n",
      "our paper focuses on closing the loop between research on\n",
      "educational data and learning outcomes by developing and\n",
      "validating the first (in our view) real-time learning technology\n",
      "that detects and mitigates mind wandering during computerized\n",
      "reading. although automated detection of complex mental states\n",
      "with the goal of developing intelligent learning technologies that\n",
      "respond to the sensed states is an active research area (see reviews\n",
      "by [9, 18]), mind wandering has rarely been explored as an aspect\n",
      "of a learner’s mental state that warrants detection and corrective\n",
      "action. and while there has been some work on modeling the\n",
      "locus of learner attention (see review by [5]), mind wandering is\n",
      "inherently different than more commonly studied forms of\n",
      "attention (e.g., selective attention, distraction), because it involves\n",
      "more covert forms of involuntary attentional lapses spawned by\n",
      "self-generated internal thought [45]. simply put, mind wandering\n",
      "is a form of “looking without seeing” because the eyes might be\n",
      "fixated on the appropriate external stimulus, but very little is\n",
      "being processed as the mind is consumed by stimulusindependent internal thoughts. offline automated approaches to\n",
      "detect mind wandering have been developed (e.g., [3, 11, 27, 33]),\n",
      "but these detectors have not yet been used to trigger online\n",
      "interventions. here, we adapt an offline gaze-based automated\n",
      "mind wandering detector [13] to trigger real-time interventions to\n",
      "address mind wandering during reading. we conduct a\n",
      "randomized control trial to evaluate the efficacy of our attentionaware learning technology in improving learning.\n",
      "\n",
      "2. mind wandering detection\n",
      "we adopted a supervised learning approach for mind wandering\n",
      "detection. below we provide a high-level overview of the\n",
      "approach; readers are directed to [3, 13] for a detailed discussion\n",
      "of the general approach used to build gaze-based detectors of\n",
      "mind wandering.\n",
      "\n",
      "2.1 training data\n",
      "we obtained training data from a previous study [26] that\n",
      "involved 98 undergraduate students reading a 57-page text on the\n",
      "surface tension of liquids [4] on a computer screen for an average\n",
      "of 28 minutes. the text contained around 6500 words, with an\n",
      "average of 115 words per page, and was displayed on a computer\n",
      "screen with courier new typeface. we recorded eye-gaze with a\n",
      "tobii tx300 eye tracker set to a sampling frequency of 120 hz.\n",
      "\n",
      "this paper reports updated results of an earlier version [10] presented\n",
      "as a “late-breaking work” (lbw) poster at the 2016 acm chi\n",
      "conference. lbw “extended abstracts” are not included in the main\n",
      "conference proceedings and copyright is retained by the authors.\n",
      "\n",
      "\n",
      "\n",
      "9\n",
      "\n",
      "\f",
      "participants could read normally and were free to move or gesture\n",
      "as they pleased.\n",
      "participants were instructed to report mind wandering (during\n",
      "reading) by pressing a predetermined key when they found\n",
      "themselves “thinking about the task itself but not the actual\n",
      "content of the text” or when they were “thinking about anything\n",
      "else besides the task.” this is consistent with contemporary\n",
      "approaches (see [45]) that rely on self-reporting because mind\n",
      "wandering is an internal conscious phenomena. further, selfreports of mind wandering have been linked to predictable\n",
      "patterns in physiology [43], pupillometry [14], eye-gaze [37], and\n",
      "task performance [34], providing validity for this approach.\n",
      "\n",
      "on the page, we classified the page as a positive instance of mind\n",
      "wandering. this was done because analyses indicated that\n",
      "participants were more likely to be mind wandering in those cases\n",
      "(but see [13] for alternate strategies to handle missing instances).\n",
      "\n",
      "on average, we received mind wandering reports for 32% of the\n",
      "pages (sd = 20%), although there was considerable variability\n",
      "among participants (ranging from 0% to 82%). self-reported\n",
      "mind wandering negatively correlated (r = -.23, p < .05) with\n",
      "scores on a subsequent comprehension assessment [26], which\n",
      "provides evidence for the predictive validity of the self-reports.\n",
      "\n",
      "2.2 model building\n",
      "the stream of eye-gaze data was filtered to produce a series of\n",
      "fixations, saccades, and blinks, from which global eye gaze\n",
      "features were extracted (see figure 1). global features are\n",
      "independent of the words being read and are therefore more\n",
      "generalizable than so-called local features. a full list of 62 global\n",
      "features along with detailed descriptions is provided in [13], but\n",
      "briefly the features can be grouped into the following four\n",
      "categories: (1) eye movement descriptive features (n = 48) were\n",
      "statistical functionals (e.g., min, median) for fixation duration,\n",
      "saccade duration, saccade amplitude, saccade velocity, and\n",
      "relative and absolute saccade angle distributions; (2) pupil\n",
      "diameter descriptive features were statistical functionals (n = 8)\n",
      "computed from participant-level z-score standardized estimates\n",
      "of pupil diameter; (3) blink features (n = 2) consisted of the\n",
      "number of blinks and the mean blink duration; (4) miscellaneous\n",
      "gaze features (n = 4) consisted of the number of saccades,\n",
      "horizontal saccade proportion, fixation dispersion, and the\n",
      "fixation duration/saccade duration ratio. we proceeded with a\n",
      "subset of 32 features after eliminating features exhibiting\n",
      "multicollinearity.\n",
      "features were calculated from only a certain amount of gaze data\n",
      "from each page, called the window. the end of the window was\n",
      "positioned 3 seconds before a self-report so as to not overlap with\n",
      "the key-press. the average amount of time between self-reports\n",
      "and the beginning of the page was 16 seconds. we used this time\n",
      "point as the end of the window for pages with no self-report.\n",
      "pages that were shorter than the target window size were\n",
      "discarded, as were pages with windows that contained fewer than\n",
      "five gaze fixations as there was insufficient data to compute some\n",
      "of the features. there were a total of 4,225 windows with\n",
      "sufficient data for supervised classification.\n",
      "we experimented with a number of supervised classifiers on\n",
      "window sizes of 4, 8, and 12 seconds to discriminate positive\n",
      "(pages with a self-report = 32%) from negative (pages without a\n",
      "self-report) instances of mind wandering. the training data were\n",
      "downsampled to achieve a 50% base rate; testing data were\n",
      "unaltered. a leave-one-participant-out validation approach was\n",
      "adopted where models were built on data from n-1 participants\n",
      "and evaluated on the held-out participant. the process was\n",
      "repeated for all participants. model validation was conducted in a\n",
      "way to simulate a real-time system by analyzing data from every\n",
      "page. when classification was not possible due to a lack of valid\n",
      "gaze data and/or because participants did not spend enough time\n",
      "\n",
      "figure 1: gaze fixations during mind wandering (top)\n",
      "and normal reading (bottom)\n",
      "\n",
      "2.3 detector accuracy\n",
      "the best model was a support vector machine that used global\n",
      "features and operated on a window size of 8-seconds. the area\n",
      "under the roc curve (auc or auroc or a’) was .66, which\n",
      "exceeds the 0.5 chance threshold [17].\n",
      "we assigned each instance as mind wandering or not mind\n",
      "wandering based on whether the detector’s predicted likelihood\n",
      "of mind wandering (ranges from 0 to 1) was below or above 0.5\n",
      "we adopted the default 0.5 threshold as it led to a higher rate of\n",
      "true positives while maintaining a moderate rate of true negatives.\n",
      "this resulted in the following confusion matrix shown in table 1.\n",
      "the model had a weighted precision of 72.2% and a weighted\n",
      "recall of 67.4%, which we deemed to be sufficiently accurate for\n",
      "intervention.\n",
      "table 1: proportionalized confusion matrix for mind\n",
      "wandering detection\n",
      "predicted mind wandering (mw)\n",
      "actual mw\n",
      "\n",
      "yes\n",
      "\n",
      "no\n",
      "\n",
      "yes\n",
      "\n",
      "0.715 (hit)\n",
      "\n",
      "0.285 (miss)\n",
      "\n",
      "no\n",
      "\n",
      "0.346 (false positive)\n",
      "\n",
      "0.654 (correct rejection)\n",
      "\n",
      "3. intervention to address mind wandering\n",
      "our intervention approach is grounded in the basic idea that\n",
      "learning of conceptual information involves creating and\n",
      "maintaining an internal model (mental model) by integrating\n",
      "information from the text with prior knowledge from memory\n",
      "[25]. this integration process relies on attentional focus and\n",
      "breaks down during mind wandering because information from\n",
      "the external environment is no longer being integrated into the\n",
      "internal mental model. this results in an impaired model which\n",
      "leads to less effective suppression of off-task thoughts. this\n",
      "increase in mind wandering further impairs the mental model,\n",
      "\n",
      "\n",
      "\n",
      "10\n",
      "\n",
      "\f",
      "resulting in a vicious cycle. our intervention targets this vicious\n",
      "cycle by redirecting attention to the primary task and attempting\n",
      "to correct for comprehension deficits attributed to mind\n",
      "wandering. based on research demonstrating the effectiveness of\n",
      "interpolated testing [47], we propose that asking questions on\n",
      "pages where mind wandering is detected and encouraging rereading in response to incorrect responses will aid in re-directing\n",
      "attention to the text and correct knowledge deficits.\n",
      "\n",
      "page regardless of whether the second question was answered\n",
      "correctly, so as not to be overly burdensome.\n",
      "\n",
      "3.1 intervention implementation\n",
      "our initial intervention was implemented for the same text used\n",
      "to create the mind wandering detector (although it could be\n",
      "applied to any text). the text was integrated into the computer\n",
      "reading interface. mind wandering detection occurred when the\n",
      "learner navigated to the next page using the right arrow key. in\n",
      "order to address ambiguity in mind wandering detection, we used\n",
      "the detector’s mind wandering likelihood to probabilistically\n",
      "determine when to intervene. for example, if the mind wandering\n",
      "likelihood was 70%, then there was a 70% chance of intervention\n",
      "on any given page (all else being equal). we did not intervene for\n",
      "the first three pages in order to allow the learner to become\n",
      "familiar with the text and interface. to reduce disruption, there\n",
      "was a 50% reduced probability of intervening on adjacent pages,\n",
      "and the maximum number of interventions was capped at 1/3 ×\n",
      "the number of pages (19 for the present 57-page text). table 2\n",
      "presents pseudo code for when to launch an intervention.\n",
      "table 2: pseudo code for intervention strategy\n",
      "launch_intervention:\n",
      "if current_page >= waitpages\n",
      "and\n",
      "total_interventions < maxintrv)\n",
      "and\n",
      "gaze_likelihood > random(0,1)\n",
      "and\n",
      "(!has_intervened(previous_page)\n",
      "or 0.5 < random (0,1)):\n",
      "do_intervention()\n",
      "else:\n",
      "show_next_page()\n",
      "do_intervention:\n",
      "answer1 = show_question1()\n",
      "if answer1 is correct:\n",
      "show_positive_feedback()\n",
      "show_next_page()\n",
      "else:\n",
      "show_neg_feedback()\n",
      "suggest_rereading()\n",
      "if page advance detected:\n",
      "answer2 = show_question2();\n",
      "show_next_page()\n",
      "\n",
      "figure 2 presents an outline of the intervention strategy. the\n",
      "intervention itself relied on two multiple choice questions for\n",
      "each page (screen) of the text. when the system decided to\n",
      "intervene, one of the questions (randomly selected) was presented\n",
      "to the learner. if the learner answered this online question\n",
      "correctly, positive feedback was provided, and the learner could\n",
      "advance to the next page. if the learner answered incorrectly,\n",
      "negative feedback was provided, and the system encouraged the\n",
      "learner to re-read the page. the learner was then provided with a\n",
      "second (randomly selected) online question, which could either\n",
      "be the same or the alternate question for that page. feedback was\n",
      "not provided and the learner was allowed to advance to the next\n",
      "\n",
      "figure 2: outline of intervention strategy\n",
      "\n",
      "3.2 iterative refinement\n",
      "the technology was refined through multiple rounds of formative\n",
      "testing with 67 participants, recruited from the same institution\n",
      "used to build the detector. participants were observed while\n",
      "interacting with the technology, their responses were analyzed,\n",
      "and they were interviewed about their experience. we used the\n",
      "feedback gleaned from these tests to refine the intervention\n",
      "parameters (i.e., when to launch, how many interventions to\n",
      "launch, whether to launch interventions on subsequent pages),\n",
      "intervention questions themselves, and instructions on how to\n",
      "attend to the intervention. for example, earlier versions of the\n",
      "intervention used a fixed threshold (instead of the aforementioned\n",
      "probabilistic approach) to trigger an intervention. despite many\n",
      "attempts to set this threshold, the end result was that some\n",
      "participants received many interventions while others received\n",
      "almost no interventions. this issue was corrected by\n",
      "probabilistically rather than deterministically launching the\n",
      "intervention. additional testing/refinement of the comprehension\n",
      "questions used in the intervention was done using crowdsourcing\n",
      "platforms, specifically amazon’s mechanical turk (mturk).\n",
      "\n",
      "4. evaluation study\n",
      "we conducted a randomized controlled trial to evaluate the\n",
      "technology. the experiment had two conditions: an intervention\n",
      "condition and a yoked control condition (as described below). the\n",
      "yoked control was needed to verify that any learning benefits are\n",
      "attributed to the technology being sensitive to mind wandering\n",
      "and not merely to the added opportunities to answer online\n",
      "questions and re-read. this is because we know that interpolated\n",
      "testing itself has beneficial comprehension effects [47].\n",
      "\n",
      "4.1 method\n",
      "participants (n = 104) were a new set of undergraduate students\n",
      "who participated to fulfill research credit requirements. they\n",
      "were recruited from the same university used to build the mw\n",
      "detector and for the iterative testing and refinement cycles.\n",
      "we did not use a pretest because we expected participants to be\n",
      "unfamiliar with the topic. participants were not informed that the\n",
      "interface would be tracking their mind wandering (until the\n",
      "\n",
      "\n",
      "\n",
      "11\n",
      "\n",
      "\f",
      "debriefing at the end), instead, they were instructed as follows:\n",
      "“while reading the text, you will occasionally be asked some\n",
      "questions about the page you just read. depending on your\n",
      "answer, you will re-read the same page and you will be asked\n",
      "another question that may or may not be the same question.”\n",
      "participants in the intervention condition received the\n",
      "intervention as described above (i.e., based on detected mind\n",
      "wandering likelihoods). each participant in the yoked control\n",
      "condition was paired with a participant in the intervention\n",
      "condition. he or she received an intervention question on the\n",
      "same pages as their paired intervention participant regardless of\n",
      "mind wandering likelihood. for example, if participant a (i.e.,\n",
      "intervention condition) received questions on pages 5, 7, 10, and\n",
      "25, participant b (i.e., yoked control condition) would receive\n",
      "intervention questions on the same pages. however, if the yoked\n",
      "participant answered incorrectly, then (s)he had the opportunity\n",
      "to re-read and answer another question regardless of the outcome\n",
      "of their intervention-condition partner.\n",
      "after reading, participants completed a 38-item multiple choice\n",
      "comprehension assessment to measure learning. the questions\n",
      "were randomly selected from the 57 pages (one per page) with the\n",
      "exception that a higher selection priority was given to pages that\n",
      "were re-read on account of the intervention. participants in the\n",
      "yoked control condition received the same posttest questions as\n",
      "their intervention condition counterparts.\n",
      "\n",
      "4.2 results\n",
      "participants received an average of 16 (min of 7 and max of 19)\n",
      "interventions. they spent an average of 27.5 seconds on each\n",
      "screen prior to receiving an intervention. there was no significant\n",
      "difference across conditions (p = .998), suggesting that reading\n",
      "time was not a confound. in what follows, we compared each\n",
      "intervention participant to his/her yoked control with a two-tailed\n",
      "paired-samples t-test and a 0.05 criteria for statistical\n",
      "significance.\n",
      "mind wandering detection. the detector’s likelihood of mind\n",
      "wandering was slightly higher for participants in the yokedcontrol condition (m = .431; sd = .170) compared to the\n",
      "intervention condition (m = .404; sd = .112), but the difference\n",
      "was not statistically significant (p = .348). this was unsurprising\n",
      "as participants in both groups received the same interventions,\n",
      "which itself was expected to reduce mind wandering. importantly,\n",
      "mind wandering likelihoods were negatively correlated with\n",
      "performance on the online questions (r = -.296, p = .033) as well\n",
      "as on posttest questions (r = -.319, p = .021). this provides\n",
      "evidence for the validity of the mind wandering detector when\n",
      "applied to a new set of learners and under different conditions\n",
      "(i.e., reading interspersed with online questions compared to\n",
      "uninterrupted reading).\n",
      "comprehension assessment. there was some overlap between\n",
      "the online questions and the posttest questions. to obtain an\n",
      "unbiased estimate of learning, we only analyzed performance on\n",
      "previously unseen posttest questions. that is, questions that were\n",
      "used as part of the intervention were first removed before\n",
      "computing posttest scores.\n",
      "there were no significant condition differences on overall\n",
      "posttest scores (p = .846). the intervention condition answered\n",
      "57.6% (sd = .157) of the questions correctly while the yoked\n",
      "control condition answered 58.1% (sd = .129) correctly. this\n",
      "finding was not surprising as both conditions received the exact\n",
      "same treatment except that the interventions were triggered based\n",
      "\n",
      "on detected mind wandering in the intervention condition but not\n",
      "the control condition.\n",
      "next, we examined posttest performance as a function of mind\n",
      "wandering during reading. each page was designated as a low or\n",
      "high mind wandering page based on a median split of mind\n",
      "wandering likelihoods (medians = .35 and .36 on a 0 to 1 scale for\n",
      "intervention and control conditions, respectively). we then\n",
      "analyzed performance on posttest questions corresponding to\n",
      "pages with low vs. high likelihoods of mind wandering (during\n",
      "reading). the results are shown in table 3.\n",
      "we found no significant posttest differences on pages where both\n",
      "the intervention and control participants had low (p = .759) or\n",
      "high (p = .922) mind wandering likelihoods (first and last rows in\n",
      "table 3, respectively). there was also no significant posttest\n",
      "difference (p = .630) for pages where the intervention condition\n",
      "had high mind wandering likelihoods but the control condition\n",
      "had low mind wandering likelihoods (row 3). however, the\n",
      "intervention condition significantly (p = .003, d = .47 sigma)\n",
      "outperformed the control condition for pages where the\n",
      "intervention participants had low likelihoods of mind wandering\n",
      "but control participants had high mind wandering likelihoods\n",
      "(row 2). these last two finding suggests that the intervention had\n",
      "the intended effect of reducing comprehension deficits\n",
      "attributable to mind wandering because it led to equitable\n",
      "performance when mind wandering was high and improved\n",
      "performance when it was low.\n",
      "table 3: posttest performance (proportion of correct\n",
      "responses) as a function of mind wandering during reading.\n",
      "standard deviations in parenthesis.\n",
      "mind\n",
      "wandering\n",
      "\n",
      "posttest\n",
      "\n",
      "n\n",
      "\n",
      "int.\n",
      "\n",
      "cntrl.\n",
      "\n",
      "int.\n",
      "\n",
      "cntrl.\n",
      "\n",
      "43\n",
      "\n",
      "low\n",
      "\n",
      "low\n",
      "\n",
      ".604 (.288)\n",
      "\n",
      ".623 (.287)\n",
      "\n",
      "40\n",
      "\n",
      "low\n",
      "\n",
      "high\n",
      "\n",
      ".643 (.263)\n",
      "\n",
      ".489 (.298)\n",
      "\n",
      "43\n",
      "\n",
      "high\n",
      "\n",
      "low\n",
      "\n",
      ".535 (.295)\n",
      "\n",
      ".566 (.305)\n",
      "\n",
      "45\n",
      "\n",
      "high\n",
      "\n",
      "high\n",
      "\n",
      ".522 (.312)\n",
      "\n",
      ".515 (.291)\n",
      "\n",
      "scores\n",
      "\n",
      "note. int. = intervention. cntrl. = control. bolded cells represent a\n",
      "statistically significant difference. n = number of pairs (out of 52) in each\n",
      "analysis. it differs slightly across analyses as not all participants were\n",
      "assigned to each mind wandering group.\n",
      "\n",
      "after-task interview. we interviewed a subset of the participants\n",
      "in order to gauge their subjective experience with the\n",
      "intervention. a few key themes emerged. participants reported\n",
      "paying closer attention to the text after realizing they would be\n",
      "periodically answering multiple-choice questions. this was good.\n",
      "however, participants also reported that they adapted their\n",
      "reading strategies in one of two ways in response to the questions.\n",
      "since the questions targeted factual information (sometimes\n",
      "verbatim) from the text, some participants paid more attention to\n",
      "details and precise wordings instead of the broader concepts being\n",
      "discussed in the text. more discouragingly, some participants\n",
      "reported adopting a preemptive skimming strategy in that they\n",
      "would only look for keywords that they expected to appear in a\n",
      "subsequent question.\n",
      "participants were encouraged to re-read text when they answered\n",
      "incorrectly before receiving another question (or the same\n",
      "question in some cases). many participants reported simply\n",
      "scanning the text (when re-reading) to locate keywords from the\n",
      "question before moving on. since the scanning strategy was often\n",
      "\n",
      "\n",
      "\n",
      "12\n",
      "\n",
      "\f",
      "successful to answer the subsequent question, participants\n",
      "reported that the questions were too easy and it took relatively\n",
      "little effort to locate the correct answer compared to re-reading.\n",
      "they suggested that it may have been better if the questions had\n",
      "targeted key concepts rather than facts.\n",
      "finally, participants reported difficulties with re-engaging with\n",
      "the text after answering an online question because the text was\n",
      "cleared when an intervention question was displayed; an item that\n",
      "can be easily corrected in subsequent versions.\n",
      "\n",
      "5. discussion\n",
      "we developed the first educational technology capable of realtime mind wandering detection and dynamic intervention during\n",
      "computerized reading. in the remainder of this section, we discuss\n",
      "the significance of our main findings, limitations, and avenues for\n",
      "future work.\n",
      "\n",
      "5.1 significance of main findings\n",
      "we have three main findings. first, we demonstrated that a\n",
      "machine-learned mind wandering detector built in one context\n",
      "can be applied to a different (albeit related) interaction context.\n",
      "specifically, the detector was trained on a data set involving\n",
      "participants silently reading and self-reporting mind wandering,\n",
      "but was applied to an interactive context involving interpolated\n",
      "assessments, which engendered different reading strategies.\n",
      "further, self-reports of mind wandering were not collected in this\n",
      "interactive context, which might have influenced mind wandering\n",
      "rates in and of itself. despite these differences, we were able to\n",
      "demonstrate the predictive validity of the detector by showing\n",
      "that it negatively correlated with both online and offline\n",
      "comprehension scores when evaluated on new participants.\n",
      "second, we showed promising effects for our intervention\n",
      "approach despite a very conservative experimental design, which\n",
      "ensured that the intervention and control groups were equated\n",
      "along all respects, except that the intervention was triggered based\n",
      "on the mind wandering detector (key manipulation). further, we\n",
      "used a probabilistic approach to trigger an intervention, because\n",
      "the detector is inherently imperfect. as a result, participants could\n",
      "have received an intervention when they were not mind\n",
      "wandering and/or could have failed to receive one when they were\n",
      "mind wandering. therefore, it was essential to compare the two\n",
      "groups under conditions when the mind wandering levels\n",
      "differed. this more nuanced analysis revealed that although the\n",
      "intervention itself did not lead to a boost in overall comprehension\n",
      "(because it is remedial), it equated comprehension scores when\n",
      "mind wandering was high (i.e., scores for the intervention group\n",
      "were comparable when the control group was low on mind\n",
      "wandering). it also demonstrated the cost of not intervening\n",
      "during mind wandering (i.e., scores for the intervention group\n",
      "were greater when the control group was high on mind\n",
      "wandering). in other words, the intervention was successful in\n",
      "mitigating the negative effects of mind wandering.\n",
      "third, despite the advantages articulated above, the intervention\n",
      "itself was reactive and engendered several unintended (and\n",
      "presumably suboptimal) behaviors. in particular, students altered\n",
      "their reading strategies in response to the interpolated questions,\n",
      "which were a critical part of the intervention. in a sense, they\n",
      "attempted to “game the intervention” by attempting to proactively\n",
      "predict the types of questions they might receive and then\n",
      "adopting a complementary reading strategy consisting of\n",
      "skimming and/or focusing on factual information. this reliance\n",
      "on surface- rather than deeper-levels of processing was\n",
      "incongruent with our goal of promoting deep comprehension.\n",
      "\n",
      "5.2 limitations\n",
      "there are a number of methodological limitations with this work\n",
      "that go beyond limitations with the intervention (as discussed\n",
      "above). first, we focused on a single text that is perceived as\n",
      "being quite dull and consequently triggers rather high levels of\n",
      "mind wandering [26]. this raises the question of whether the\n",
      "detector will generalize to different texts. we expect some level\n",
      "of generalizability in terms of features used because the detector\n",
      "only used content- and position- (on the screen) free global gaze\n",
      "features. however, given that several supervised classifiers are\n",
      "very sensitive to differences in base rates, the detector might overor under- predict mind wandering when applied to texts that\n",
      "engender different rates of mind wandering. therefore, retraining\n",
      "the detector with a more diverse set of texts is warranted.\n",
      "another limitation is the scalability of our learning technology.\n",
      "the eye tracker we used was a cost-prohibitive tobii tx300 that\n",
      "will not scale beyond the laboratory. fortunately, commercialoff-the-shelf (cots) eye trackers, such as eye tribe and tobii\n",
      "eyex, can be used to surpass this limitation. it is an open question\n",
      "as to whether the mind wandering detector can operate with\n",
      "similar fidelity with these cots eye trackers. our use of global\n",
      "gaze features which do not require high-precision eye tracking\n",
      "holds considerable promise in this regard. nevertheless,\n",
      "replication with scalable eye trackers and/or scalable alternatives\n",
      "to eye tracking (e.g., facial-feature tracking [46] or monitoring\n",
      "reading patterns [27]) is an important next step (see section 5.3).\n",
      "our use of surface-level questions for both the intervention and\n",
      "the subsequent comprehension assessment is also a limitation as\n",
      "is the lack of a delayed comprehension assessment. it might be\n",
      "the case that the intervention effects manifest as richer encodings\n",
      "in long-term memory, a possibility that cannot be addressed in the\n",
      "current experiment that only assessed immediate learning.\n",
      "other limitations include a limited student sample (i.e.\n",
      "undergraduates from a private midwestern college) and a\n",
      "laboratory setup. it is possible that the results would not\n",
      "generalize to a more diverse student population or in more\n",
      "ecological environments (but see below for evidence of\n",
      "generalizability of the detector in classroom environments).\n",
      "replication with data from more diverse populations and\n",
      "environments would be a necessary next step to increase the\n",
      "ecological validity of this work.\n",
      "\n",
      "5.3 future work\n",
      "our future work is progressing along two main fronts. one is to\n",
      "address limitations in the intervention and design of the\n",
      "experimental evaluation as discussed above. accordingly, we are\n",
      "exploring alternative intervention strategies, such as: (a) tagging\n",
      "items for future re-study rather than interrupting participants\n",
      "during reading; (b) highlighting specific portions of the text as an\n",
      "overt cue to facilitate comprehension of critical information; (c)\n",
      "asking fewer intervention questions, but selecting inference\n",
      "questions that target deeper levels of comprehension and that span\n",
      "multiple pages of the text; and (d) asking learners to engage in\n",
      "reflection by providing written self-explanations of the textual\n",
      "content. we are currently evaluating one such redesigned\n",
      "intervention – open-ended questions targeting deeper levels of\n",
      "comprehension (item c). our revised experimental design taps\n",
      "both surface- and inference-level comprehension and assesses\n",
      "comprehension immediately after reading (to measure learning)\n",
      "and after a one-week delay (to measure retention).\n",
      "we are also developing attention-aware versions of more\n",
      "interactive interfaces, such as learning with an intelligent tutoring\n",
      "\n",
      "\n",
      "\n",
      "13\n",
      "\n",
      "\f",
      "system called gurututor [30]. this project also addresses some\n",
      "of the scalability concerns by replacing expensive research-grade\n",
      "eye tracking with cost-effective cots eye tracking (e.g., the eye\n",
      "tribe or tobii eyex) and provides evidence for real-world\n",
      "generalizability by collecting data in classrooms rather than the\n",
      "lab. we recently tested our implementation on 135 students (total)\n",
      "in a noisy computer-enabled high-school classroom where eyegaze of entire classes of students was collected during their\n",
      "normal class periods [20]. using a similar approach to the present\n",
      "work, we used the data to build and validate a studentindependent gaze-based mind wandering detector. the resultant\n",
      "mind wandering detection accuracy (f1 of 0.59) was substantially\n",
      "greater than chance (f1 of 0.24) and outperformed earlier work on\n",
      "the same domain [21]. the next step is to develop interventions\n",
      "that redirect attention and correct learning deficiencies\n",
      "attributable to mind wandering and to test the interventions in\n",
      "real-world environments. by doing so, we hope to advance our\n",
      "foundational vision of developing next-generation technologies\n",
      "that enhance the process and products of learning by “attending\n",
      "to attention.”\n",
      "\n",
      "[6]\n",
      "\n",
      "[7]\n",
      "\n",
      "[8]\n",
      "\n",
      "[9]\n",
      "\n",
      "[10]\n",
      "\n",
      "[11]\n",
      "\n",
      "[12]\n",
      "figure 3: guru tutor interface overlaid with eye-gaze\n",
      "obtained via the eyetribe\n",
      "\n",
      "[13]\n",
      "\n",
      "6. acknowledgements\n",
      "this research was supported by the national science foundation\n",
      "(nsf) (drl 1235958 and iis 1523091). the authors are grateful\n",
      "to kris kopp and jenny wu for their contributions to the study.\n",
      "any opinions, findings and conclusions, or recommendations\n",
      "expressed in this paper are those of the authors and do not\n",
      "necessarily reflect the views of nsf.\n",
      "\n",
      "[14]\n",
      "\n",
      "[15]\n",
      "\n",
      "7. references\n",
      "[1] anderson, j.r. 2002. spanning seven orders of magnitude:\n",
      "a challenge for cognitive modeling. cognitive science, 26\n",
      "(1), 85-112.\n",
      "[2] baird, b., smallwood, j., mrazek, m.d., kam, j.w.,\n",
      "franklin, m.s. and schooler, j.w. 2012. inspired by\n",
      "distraction mind wandering facilitates creative incubation.\n",
      "psychological science, 23 (10), 1117-1122.\n",
      "[3] bixler, r. and d'mello, s.k. 2016. automatic gaze-based\n",
      "user-independent detection of mind wandering during\n",
      "computerized reading. user modeling & user-adapted\n",
      "interaction, 26, 33-68.\n",
      "[4] boys, c.v. 1895. soap bubbles, their colours and the forces\n",
      "which mold them. society for promoting christian\n",
      "knowledge.\n",
      "[5] conati, c., aleven, v. and mitrovic, a. 2013. eye-tracking\n",
      "for student modelling in intelligent tutoring systems. in\n",
      "sottilare, r., graesser, a., hu, x. and holden, h. eds.\n",
      "design recommendations for intelligent tutoring systems -\n",
      "\n",
      "[16]\n",
      "\n",
      "[17]\n",
      "\n",
      "[18]\n",
      "\n",
      "[19]\n",
      "\n",
      "volume 1: learner modeling, army research laboratory,\n",
      "orlando, fl.\n",
      "conati, c. and merten, c. 2007. eye-tracking for user\n",
      "modeling in exploratory learning environments: an\n",
      "empirical evaluation. knowledge-based systems, 20 (6),\n",
      "557-574.\n",
      "d'mello, s., olney, a., williams, c. and hays, p. 2012.\n",
      "gaze tutor: a gaze-reactive intelligent tutoring system.\n",
      "international journal of human-computer studies, 70 (5),\n",
      "377-398.\n",
      "d'mello, s.k. 2016. giving eyesight to the blind: towards\n",
      "attention-aware aied. international journal of artificial\n",
      "intelligence in education, 26 (2), 645-659.\n",
      "d'mello, s.k., blanchard, n., baker, r., ocumpaugh, j. and\n",
      "brawner, k. 2014. i feel your pain: a selective review of\n",
      "affect-sensitive instructional strategies. in sottilare, r.,\n",
      "graesser, a., hu, x. and goldberg, b. eds. design\n",
      "recommendations for adaptive intelligent tutoring\n",
      "systems: adaptive instructional strategies (volume 2), us\n",
      "army research laboratory, orlando, fl.\n",
      "d'mello, s.k., kopp, k., bixler, r. and bosch, n. 2016.\n",
      "attending to attention: detecting and combating mind\n",
      "wandering during computerized reading in extended\n",
      "abstracts of the acm sigchi conference on human\n",
      "factors in computing systems (chi 2016), acm, new\n",
      "york.\n",
      "drummond, j. and litman, d. 2010. in the zone: towards\n",
      "detecting student zoning out using supervised machine\n",
      "learning. in aleven, v., kay, j. and mostow, j. eds.\n",
      "intelligent tutoring systems., springer-verlag, berlin /\n",
      "heidelberg.\n",
      "eastwood, j.d., frischen, a., fenske, m.j. and smilek, d.\n",
      "2012. the unengaged mind: defining boredom in terms of\n",
      "attention. perspectives on psychological science, 7 (5), 482495.\n",
      "faber, m., bixler, r. and d'mello, s.k. in press. an\n",
      "automated behavioral measure of mind wandering during\n",
      "computerized reading. behavior research methods.\n",
      "franklin, m.s., broadway, j.m., mrazek, m.d., smallwood,\n",
      "j. and schooler, j.w. 2013. window to the wandering mind:\n",
      "pupillometry of spontaneous thought while reading. the\n",
      "quarterly journal of experimental psychology, 66 (12),\n",
      "2289-2294.\n",
      "gluck, k.a., anderson, j.r. and douglass, s.a. 2000.\n",
      "broader bandwidth in student modeling: what if its were\n",
      "“eye” ts? in gauthier, c., frasson, c. and vanlehn, k. eds.\n",
      "proceedings of the 5th international conference on\n",
      "intelligent tutoring systems, springer, berlin.\n",
      "graesser, a., lu, s., olde, b., cooper-pye, e. and whitten,\n",
      "s. 2005. question asking and eye tracking during cognitive\n",
      "disequilibrium: comprehending illustrated texts on devices\n",
      "when the devices break down. memory and cognition, 33,\n",
      "1235-1247.\n",
      "hanley, j.a. and mcneil, b.j. 1982. the meaning and use\n",
      "of the area under a receiver operating characteristic (roc)\n",
      "curve. radiology, 143 (1), 29-36.\n",
      "harley, j.m., lajoie, s.p., frasson, c. and hall, n.c. in\n",
      "press. developing emotion-aware, advanced learning\n",
      "technologies: a taxonomy of approaches and features.\n",
      "international journal of artificial intelligence in education.\n",
      "hegarty, m. and just, m. 1993. constructing mental models\n",
      "of machines from text and diagrams. journal of memory and\n",
      "language, 32 (6), 717-742.\n",
      "\n",
      "\n",
      "\n",
      "14\n",
      "\n",
      "\f",
      "[20] hutt, s., mills, c., bosch, n., krasich, k., brockmole, j.r.\n",
      "and d'mello, s.k. in review. out of the fr-eye- ing pan:\n",
      "towards gaze-based models of attention during learning\n",
      "with technology in the classroom.\n",
      "[21] hutt, s., mills, c., white, s., donnelly, p.j. and d’mello,\n",
      "s.k. 2016. the eyes have it: gaze-based detection of mind\n",
      "wandering during learning with an intelligent tutoring\n",
      "system. in proceedings of the 9th international conference\n",
      "on educational data mining (edm 2016), international\n",
      "educational data mining society.\n",
      "[22] jaques, n., conati, c., harley, j.m. and azevedo, r. year.\n",
      "predicting affect from gaze data during interaction with an\n",
      "intelligent tutoring system. in intelligent tutoring systems,\n",
      "(2014), springer, 29-38.\n",
      "[23] kardan, s. and conati, c. 2012. exploring gaze data for\n",
      "determining user learning with an interactive simulation. in\n",
      "carberry, s., weibelzahl, s., micarelli, a. and semeraro, g.\n",
      "eds. proceedings of the 20th international conference on\n",
      "user modeling, adaptation, and personalization (umap\n",
      "2012), springer, berlin.\n",
      "[24] killingsworth, m.a. and gilbert, d.t. 2010. a wandering\n",
      "mind is an unhappy mind. science, 330 (6006), 932-932.\n",
      "[25] kintsch, w. 1998. comprehension: a paradigm for\n",
      "cognition. cambridge university press, new york.\n",
      "[26] kopp, k., d’mello, s. and mills, c. 2015. influencing the\n",
      "occurrence of mind wandering while reading. consciousness\n",
      "and cognition, 34 (1), 52-62.\n",
      "[27] mills, c. and d’mello, s.k. 2015. toward a real-time (day)\n",
      "dreamcatcher: detecting mind wandering episodes during\n",
      "online reading. in romero, c., pechenizkiy, m., boticario,\n",
      "j. and santos, o. eds. proceedings of the 8th international\n",
      "conference on educational data mining (edm 2015),\n",
      "international educational data mining society.\n",
      "[28] mooneyham, b.w. and schooler, j.w. 2013. the costs and\n",
      "benefits of mind-wandering: a review. canadian journal of\n",
      "experimental psychology/revue canadienne de psychologie\n",
      "expérimentale, 67 (1), 11.\n",
      "[29] muir, m. and conati, c. 2012. an analysis of attention to\n",
      "student–adaptive hints in an educational game. in cerri,\n",
      "s.a., clancey, w.j., papadourakis, g. and panourgia, k.\n",
      "eds. proceedings of the international conference on\n",
      "intelligent tutoring systems, springer, berlin.\n",
      "[30] olney, a., d'mello, a., person, n., cade, w., hays, p.,\n",
      "williams, c., lehman, b. and graesser, a. 2012. guru: a\n",
      "computer tutor that models expert human tutors. in cerri, s.,\n",
      "clancey, w., papadourakis, g. and panourgia, k. eds.\n",
      "proceedings of the 11th international conference on\n",
      "intelligent\n",
      "tutoring\n",
      "systems,\n",
      "springer-verlag,\n",
      "berlin/heidelberg.\n",
      "[31] olney, a., risko, e.f., d'mello, s.k. and graesser, a.c.\n",
      "2015. attention in educational contexts: the role of the\n",
      "learning task in guiding attention. in fawcett, j., risko, e.f.\n",
      "and kingstone, a. eds. the handbook of attention, mit\n",
      "press, cambridge, ma.\n",
      "[32] pham, p. and wang, j. 2016. adaptive review for mobile\n",
      "mooc learning via implicit physiological signal sensing.\n",
      "in proceedings of the 18th acm international conference\n",
      "on multimodal interaction (icmi 2016), acm, new york,\n",
      "ny.\n",
      "[33] pham, p. and wang, j. 2015. attentivelearner: improving\n",
      "mobile mooc learning via implicit heart rate tracking. in\n",
      "international conference on artificial intelligence in\n",
      "education, springer, berlin heidelberg.\n",
      "\n",
      "[34] randall, j.g., oswald, f.l. and beier, m.e. 2014. mindwandering, cognition, and performance: a theory-driven\n",
      "meta-analysis of attention regulation. psychological\n",
      "bulletin, 140 (6), 1411-1431.\n",
      "[35] rapp, d.n. 2006. the value of attention aware systems in\n",
      "educational settings. computers in human behavior, 22 (4),\n",
      "603-614.\n",
      "[36] rayner, k. 1998. eye movements in reading and information\n",
      "processing: 20 years of research. psychological bulletin, 124\n",
      "(3), 372-422.\n",
      "[37] reichle, e.d., reineberg, a.e. and schooler, j.w. 2010. eye\n",
      "movements during mindless reading. psychological science,\n",
      "21 (9), 1300.\n",
      "[38] risko, e.f., buchanan, d., medimorec, s. and kingstone, a.\n",
      "2013. everyday attention: mind wandering and computer\n",
      "use during lectures. computers & education, 68 (1), 275283.\n",
      "[39] roda, c. and thomas, j. 2006. attention aware systems:\n",
      "theories, applications, and research agenda. computers in\n",
      "human behavior, 22 (4), 557-587.\n",
      "[40] rowe, j., mott, b., mcquiggan, s., robison, j., lee, s. and\n",
      "lester, j. year. crystal island: a narrative-centered learning\n",
      "environment for eighth grade microbiology. in workshop on\n",
      "intelligent educational games at the 14th international\n",
      "conference on artificial intelligence in education,\n",
      "brighton, uk, (2009), 11-20.\n",
      "[41] shute, v.j., ventura, m., bauer, m. and zapata-rivera, d.\n",
      "2009. melding the power of serious games and embedded\n",
      "assessment to monitor and foster learning: flow and grow.\n",
      "in ritterfeld, u., cody, m. and vorderer, p. eds. serious\n",
      "games: mechanisms and effects, routledge, taylor and\n",
      "francis, mahwah, nj.\n",
      "[42] sibert, j.l., gokturk, m. and lavine, r.a. 2000. the reading\n",
      "assistant: eye gaze triggered auditory prompting for reading\n",
      "remediation. in proceedings of the 13th annual acm\n",
      "symposium on user interface software and technology,\n",
      "acm, new york, ny.\n",
      "[43] smallwood, j., davies, j.b., heim, d., finnigan, f.,\n",
      "sudberry, m., o'connor, r. and obonsawin, m. 2004.\n",
      "subjective experience and the attentional lapse: task\n",
      "engagement and disengagement during sustained attention.\n",
      "consciousness and cognition, 13 (4), 657-690.\n",
      "[44] smallwood, j., fishman, d.j. and schooler, j.w. 2007.\n",
      "counting the cost of an absent mind: mind wandering as an\n",
      "underrecognized influence on educational performance.\n",
      "psychonomic bulletin & review, 14 (2), 230-236.\n",
      "[45] smallwood, j. and schooler, j.w. 2015. the science of mind\n",
      "wandering: empirically navigating the stream of\n",
      "consciousness. annu. rev. psychol, 66, 487-518.\n",
      "[46] stewart, a., bosch, p., chen, h., donnelly, p.j. and\n",
      "d’mello, s.k. 2016. where's your mind at? video-based\n",
      "mind wandering detection during film viewing. in aroyo,\n",
      "l., d'mello, s., vassileva, j. and blustein, j. eds.\n",
      "proceedings of the 2016 acm on international conference\n",
      "on user modeling, adaptation, & personalization (acm\n",
      "umap 2016), acm, new york.\n",
      "[47] szpunar, k.k., khan, n.y. and schacter, d.l. 2013.\n",
      "interpolated memory tests reduce mind wandering and\n",
      "improve learning of online lectures. proceedings of the\n",
      "national academy of sciences, 110 (16), 6313-6317.\n",
      "[48] wang, h., chignell, m. and ishizuka, m. 2006. empathic\n",
      "tutoring software agents using real-time eye tracking. in\n",
      "proceedings of the 2006 symposium on eye tracking\n",
      "research &applications, acm, new york.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 13) Now we are going to compute the frequency of each word across all \n",
    "# documents. Feel free to use the link below to help you!\n",
    "# hint: https://www.datacamp.com/community/tutorials/absolute-weighted-word-frequency\n",
    "# (look at the first block of code in the article)\n",
    "# Using the text_list we create in the cell above, iterate over all words and count their frequencies\n",
    "# If uncomfortable with dictionaries, google python dict\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "word_freq = defaultdict(int)\n",
    "\n",
    "for text in text_list:\n",
    "    for word in text.split():\n",
    "        word_freq[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>5663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>3402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>2704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>2406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>2028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     abs_freq\n",
       "the      5663\n",
       "of       3402\n",
       "and      2704\n",
       "to       2406\n",
       "a        2028"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 14) If you haven't done so already, create a dataframe from the dictionary\n",
    "# and print the head of the dataframe\n",
    "# Just as we did last week with Pandas, we can do this in only a few lines\n",
    "\n",
    "#already did it in #13 for creating a dataframe\n",
    "df = pd.DataFrame.from_dict(word_freq, orient='index').sort_values(0, ascending=False).rename(columns={0: 'abs_freq'})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's a problem with the dataframe above? Is there data meaningful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 15) We are going to remove the following stop words, so that we see more interesting \n",
    "# keywors. Feel free to use the list and hint below to help you:\n",
    "# hint: https://stackoverflow.com/questions/43716402/remove-row-index-dataframe-pandas\n",
    "# the .drop() function could prove useful here\n",
    "STOPWORDS = ['a','able','about','across','after','all','almost','also','am','among',\n",
    "             'an','and','any','are','as','at','be','because','been','but','by','can',\n",
    "             'cannot','could','dear','did','do','does','either','else','ever','every',\n",
    "             'for','from','get','got','had','has','have','he','her','hers','him','his',\n",
    "             'how','however','i','if','in','into','is','it','its','just','least','let',\n",
    "             'like','likely','may','me','might','most','must','my','neither','no','nor',\n",
    "           'not','of','off','often','on','only','or','other','our','own','rather','said',\n",
    "             'say','says','she','should','since','so','some','than','that','the','their',\n",
    "             'them','then','there','these','they','this','tis','to','too','twas','us',\n",
    "             'wants','was','we','were','what','when','where','which','while','who',\n",
    "             'whom','why','will','with','would','yet','you','your']\n",
    "\n",
    "\n",
    "for word in STOPWORDS: \n",
    "    if word in df.index:\n",
    "        df = df.drop(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             abs_freq\n",
      "learning          638\n",
      "data              512\n",
      "students          421\n",
      "student           407\n",
      "=                 393\n",
      "each              350\n",
      "model             345\n",
      "more              310\n",
      "using             278\n",
      "used              258\n",
      "performance       241\n",
      "between           231\n",
      "number            213\n",
      "two               207\n",
      "based             198\n",
      "set               184\n",
      "different         179\n",
      "educational       173\n",
      "models            172\n",
      "results           171\n"
     ]
    }
   ],
   "source": [
    "# 16) print the top 20 words of your new dataframe: we can do this with a list slice \n",
    "top20 = df[:20]\n",
    "print (top20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>students</th>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>=</th>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>each</th>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more</th>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>using</th>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>used</th>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>performance</th>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>between</th>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>based</th>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>different</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educational</th>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results</th>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knowledge</th>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analysis</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>figure</th>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mind</th>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.32</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(.41)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.76</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(.51)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5),</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>establishing</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stays</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>display).</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action,</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agreed</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agent,</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one)2.</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session).</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utters</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“continue”</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>panel,</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point.</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gains.3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“stay</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“yes”,</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opening</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short).</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monitorrecommend</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delivered,</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writing.</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15782 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  abs_freq\n",
       "learning               638\n",
       "data                   512\n",
       "students               421\n",
       "student                407\n",
       "=                      393\n",
       "each                   350\n",
       "model                  345\n",
       "more                   310\n",
       "using                  278\n",
       "used                   258\n",
       "performance            241\n",
       "between                231\n",
       "number                 213\n",
       "two                    207\n",
       "based                  198\n",
       "set                    184\n",
       "different              179\n",
       "educational            173\n",
       "models                 172\n",
       "results                171\n",
       "features               168\n",
       "knowledge              160\n",
       "analysis               154\n",
       "work                   154\n",
       "time                   154\n",
       "figure                 149\n",
       ",                      148\n",
       "table                  148\n",
       "use                    148\n",
       "mind                   146\n",
       "...                    ...\n",
       ".32                      1\n",
       "21.4                     1\n",
       "(.41)                    1\n",
       ".76                      1\n",
       "(.51)                    1\n",
       "5),                      1\n",
       "establishing             1\n",
       "stays                    1\n",
       "123                      1\n",
       "15.3                     1\n",
       "18.6                     1\n",
       "display).                1\n",
       "action,                  1\n",
       "agreed                   1\n",
       "agent,                   1\n",
       "one)2.                   1\n",
       "session).                1\n",
       "utters                   1\n",
       "“continue”               1\n",
       "panel,                   1\n",
       "point.                   1\n",
       "gains.3                  1\n",
       "“stay                    1\n",
       "“yes”,                   1\n",
       "122                      1\n",
       "opening                  1\n",
       "short).                  1\n",
       "monitorrecommend         1\n",
       "delivered,               1\n",
       "writing.                 1\n",
       "\n",
       "[15782 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={0: 'abs_freq'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.rename(columns={list(df)[0]:'frequency'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>students</th>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>=</th>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          frequency\n",
       "learning        638\n",
       "data            512\n",
       "students        421\n",
       "student         407\n",
       "=               393"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15782 entries, learning to writing.\n",
      "Data columns (total 1 columns):\n",
      "frequency    15782 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 246.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you tell from this historgram? What do EDM researchers seem to care about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bd69b88470>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAFTCAYAAADWRBB6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bd69bbd390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 17 plot the top 20 results above as a histogram: \n",
    "top20.T.plot.hist(bins=20, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bd69c5cf98>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAFFCAYAAADijCboAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bd69c356a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 17 plot the top 20 results above as a histogram:\n",
    "top20.T.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bd6da82b70>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqk7ybuYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bd6d50cfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 17 plot the top 20 results above as a histogram: \n",
    "top20.plot(bins=20, kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are improvements you could add to our data cleaning process? Write at least three things:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count word frequencies per paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the previous section gave us an overall description of the word frequency for all the papers, it would be interesting to look at each individual paper. This is what we are going to do below, by focusing on the top 30 terms used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning\n",
      "data\n",
      "students\n",
      "student\n",
      "=\n",
      "each\n",
      "model\n",
      "more\n",
      "using\n",
      "used\n",
      "performance\n",
      "between\n",
      "number\n",
      "two\n",
      "based\n",
      "set\n",
      "different\n",
      "educational\n",
      "models\n",
      "results\n",
      "features\n",
      "knowledge\n",
      "analysis\n",
      "work\n",
      "time\n",
      "figure\n",
      ",\n",
      "table\n",
      "use\n",
      "mind\n"
     ]
    }
   ],
   "source": [
    "# 18) save the top 30 words from the dataframe above \n",
    "# in a new variable called \"top_words\"\n",
    "top_words = df[:30]\n",
    "\n",
    "#i=0\n",
    "#for freq in top_words['abs_freq']:\n",
    "#    print (top_words.index[i], \":\",freq)\n",
    "#    i=i+1\n",
    "\n",
    "for word in top_words.T:\n",
    "    print (word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 19) We are now going to construct a new dataframe where each row is a paper, \n",
    "# each column is one of the top 30 words used and each cell is a count of this word. \n",
    "# NOTE: make sure you add another field called \"text\" where you're going to store the \n",
    "# actual text of the paper. \n",
    "# Hint: build a list of dataframes (one for each papers), \n",
    "# and use the concat function from pandas to concatenate them!\n",
    "d = []\n",
    "\n",
    "for text in text_list:\n",
    "    dic = {}\n",
    "    dic['text'] = text\n",
    "    for word in top_words:\n",
    "        dic[word] = text.split().count(word)\n",
    "    d.append(pd.DataFrame([dic]))\n",
    "\n",
    "freq_df = pd.concat(d, ignore_index=True)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>zone out no more: mitigating mind wandering d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n15\\n\\n\f",
       "measuring similarity of educational...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n87\\n\\n\f",
       "generalizability of face-based mind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>\\n\\n95\\n\\n\f",
       "addressing student behavior and aff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>\\n\\n103\\n\\n\f",
       "epistemic network analysis and top...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n\\n111\\n\\n\f",
       "towards closing the loop: bridging...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n\\n119\\n\\n\f",
       "on the influence on learning of st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\n127\\n\\n\f",
       "assessing computer literacy of adu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n134\\n\\n\f",
       "towards reliable and valid measure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n23\\n\\n\f",
       "adaptive sequential recommendation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n\\n31\\n\\n\f",
       "analysis of problem-solving behavio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>\\n\\n39\\n\\n\f",
       "the antecedents of and associations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n47\\n\\n\f",
       "grade prediction with temporal cour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>\\n\\n55\\n\\n\f",
       "toward the automatic labeling of co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n63\\n\\n\f",
       "behavior-based latent variable mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n71\\n\\n\f",
       "efficient feature embeddings for st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n79\\n\\n\f",
       "predicting short- and long-term voc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    frequency                                               text\n",
       "0           1  \n",
       "zone out no more: mitigating mind wandering d...\n",
       "1           0  \\n\\n15\\n\\n\n",
       "measuring similarity of educational...\n",
       "2           0  \\n\\n87\\n\\n\n",
       "generalizability of face-based mind...\n",
       "3           6  \\n\\n95\\n\\n\n",
       "addressing student behavior and aff...\n",
       "4           3  \\n\\n103\\n\\n\n",
       "epistemic network analysis and top...\n",
       "5           2  \\n\\n111\\n\\n\n",
       "towards closing the loop: bridging...\n",
       "6           2  \\n\\n119\\n\\n\n",
       "on the influence on learning of st...\n",
       "7           1  \\n\\n127\\n\\n\n",
       "assessing computer literacy of adu...\n",
       "8           0  \\n\\n134\\n\\n\n",
       "towards reliable and valid measure...\n",
       "9           0  \\n\\n23\\n\\n\n",
       "adaptive sequential recommendation ...\n",
       "10          2  \\n\\n31\\n\\n\n",
       "analysis of problem-solving behavio...\n",
       "11          3  \\n\\n39\\n\\n\n",
       "the antecedents of and associations...\n",
       "12          0  \\n\\n47\\n\\n\n",
       "grade prediction with temporal cour...\n",
       "13         11  \\n\\n55\\n\\n\n",
       "toward the automatic labeling of co...\n",
       "14          0  \\n\\n63\\n\\n\n",
       "behavior-based latent variable mode...\n",
       "15          0  \\n\\n71\\n\\n\n",
       "efficient feature embeddings for st...\n",
       "16          0  \\n\\n79\\n\\n\n",
       "predicting short- and long-term voc..."
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'learning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2392\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2393\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2394\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5239)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5085)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20405)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20359)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'learning'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-1182f0b35007>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 20) create a scatter plot of the words 'learning' and 'data'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# what can you say from it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfreq_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'learning'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'scatter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[0;32m   2618\u001b[0m                           \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolormap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolormap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2619\u001b[0m                           \u001b[0myerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecondary_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2620\u001b[1;33m                           sort_columns=sort_columns, **kwds)\n\u001b[0m\u001b[0;32m   2621\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36mplot_frame\u001b[1;34m(data, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[0;32m   1855\u001b[0m                  \u001b[0myerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1856\u001b[0m                  \u001b[0msecondary_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort_columns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1857\u001b[1;33m                  **kwds)\n\u001b[0m\u001b[0;32m   1858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m_plot\u001b[1;34m(data, x, y, subplots, ax, kind, **kwds)\u001b[0m\n\u001b[0;32m   1680\u001b[0m         \u001b[0mplot_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubplots\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1682\u001b[1;33m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1683\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1684\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_legend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m_make_plot\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    829\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m         scatter = ax.scatter(data[x].values, data[y].values, c=c_values,\n\u001b[0m\u001b[0;32m    832\u001b[0m                              label=label, cmap=cmap, **self.kwds)\n\u001b[0;32m    833\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2060\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2062\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2063\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2064\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2067\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2068\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2069\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2071\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1532\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1533\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1534\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1535\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3590\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3591\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2393\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2394\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2395\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5239)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5085)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20405)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20359)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'learning'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bd6dd3c438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 20) create a scatter plot of the words 'learning' and 'data'\n",
    "# what can you say from it?\n",
    "freq_df.plot(x='learning', y='data', kind='scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD8CAYAAACSCdTiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/T/BXdEdISNx9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bd6e9220f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 21) annotate each point with the index number of the dataframe\n",
    "# hint: https://www.pythonmembers.club/2018/05/08/matplotlib-scatter-plot-annotate-set-text-at-label-each-point/\n",
    "# plt.txt( ) is going to be helpful for us here\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# simulating a pandas df['type'] column\n",
    "types = ['learning', 'data']\n",
    "x_coords = [10,40]\n",
    "y_coords = [20,50]\n",
    "\n",
    "for i,type in enumerate(types):\n",
    "    x = x_coords[i]\n",
    "    y = y_coords[i]\n",
    "    plt.scatter(x, y, marker='x', color='red')\n",
    "    plt.text(x+0.3, y+0.3, type, fontsize=9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>students</th>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>=</th>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>each</th>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more</th>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>using</th>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>used</th>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>performance</th>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>between</th>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>based</th>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>different</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educational</th>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results</th>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knowledge</th>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analysis</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>figure</th>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mind</th>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.32</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(.41)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.76</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(.51)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5),</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>establishing</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stays</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>display).</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action,</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agreed</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agent,</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one)2.</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session).</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utters</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“continue”</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>panel,</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point.</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gains.3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“stay</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>“yes”,</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opening</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short).</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monitorrecommend</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delivered,</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writing.</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15782 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  frequency\n",
       "learning                638\n",
       "data                    512\n",
       "students                421\n",
       "student                 407\n",
       "=                       393\n",
       "each                    350\n",
       "model                   345\n",
       "more                    310\n",
       "using                   278\n",
       "used                    258\n",
       "performance             241\n",
       "between                 231\n",
       "number                  213\n",
       "two                     207\n",
       "based                   198\n",
       "set                     184\n",
       "different               179\n",
       "educational             173\n",
       "models                  172\n",
       "results                 171\n",
       "features                168\n",
       "knowledge               160\n",
       "analysis                154\n",
       "work                    154\n",
       "time                    154\n",
       "figure                  149\n",
       ",                       148\n",
       "table                   148\n",
       "use                     148\n",
       "mind                    146\n",
       "...                     ...\n",
       ".32                       1\n",
       "21.4                      1\n",
       "(.41)                     1\n",
       ".76                       1\n",
       "(.51)                     1\n",
       "5),                       1\n",
       "establishing              1\n",
       "stays                     1\n",
       "123                       1\n",
       "15.3                      1\n",
       "18.6                      1\n",
       "display).                 1\n",
       "action,                   1\n",
       "agreed                    1\n",
       "agent,                    1\n",
       "one)2.                    1\n",
       "session).                 1\n",
       "utters                    1\n",
       "“continue”                1\n",
       "panel,                    1\n",
       "point.                    1\n",
       "gains.3                   1\n",
       "“stay                     1\n",
       "“yes”,                    1\n",
       "122                       1\n",
       "opening                   1\n",
       "short).                   1\n",
       "monitorrecommend          1\n",
       "delivered,                1\n",
       "writing.                  1\n",
       "\n",
       "[15782 rows x 1 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 22) what are the two extreme papers, \n",
    "# i.e., papers with more occurences for each term on each axis?\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bd71b20a90>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPhWFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bd71af1780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 23) plot the histogram of the paper that had high counts of \"data\"\n",
    "# hint: https://stackoverflow.com/questions/52392728/create-a-histogram-based-on-one-row-of-a-dataframe\n",
    "# .loc is going to be helpful here\n",
    "\n",
    "df.T['data'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bd6dd59390>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAENhJREFUeJzt3X2wXVV9xvHvYxAFqyAmoCZgwAE0rWLxQp2pjm/FAlaj\nbbWgLZVWUyzYqp0p+FJ1xulMFS3WgsbUMoq2ZbQixhqL0KkwrUVIkLegSIoICSpRO1LAQiO//nF2\nlsfb5N5zk7PvScL3M3Mme6+9zrq/NTeTJ2vvffZJVSFJEsDDJl2AJGnXYShIkhpDQZLUGAqSpMZQ\nkCQ1hoIkqTEUJEmNoSBJagwFSVKz16QLmKuFCxfW0qVLJ12GJO1W1q1b9/2qWjRbv90uFJYuXcra\ntWsnXYYk7VaSfHuUfp4+kiQ1hoIkqTEUJEmNoSBJagwFSVLTWygkOT/JXUlu3M7xJPlgkg1Jrk9y\ndF+1SJJG0+dK4WPA8TMcPwE4vHutAD7cYy2SpBH0FgpVdQXwwxm6LAcuqIErgf2TPKGveiRJs5vk\nNYXFwB1D+xu7NknShOwWn2hOsoLBKSYOOeSQCVcjbd85l35zh9/7puOOGGMl0o6Z5EphE3Dw0P6S\nru3/qapVVTVVVVOLFs366A5J0g6aZCisBk7p7kJ6FvCjqvrOBOuRpIe83k4fJfkH4HnAwiQbgXcC\nDweoqpXAGuBEYANwH3BqX7VIkkbTWyhU1cmzHC/g9L5+viRp7vxEsySpMRQkSY2hIElqDAVJUmMo\nSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEU\nJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgK\nkqTGUJAkNb2GQpLjk9ycZEOSs7ZxfL8kn09yXZL1SU7tsx5J0sx6C4UkC4DzgBOAZcDJSZZN63Y6\ncFNVHQU8D3h/kr37qkmSNLM+VwrHAhuq6taqegC4EFg+rU8Bj04S4OeAHwJbeqxJkjSDPkNhMXDH\n0P7Grm3YucBTgTuBG4A/rqoHe6xJkjSDSV9o/lXgWuCJwDOAc5M8ZnqnJCuSrE2ydvPmzfNdoyQ9\nZPQZCpuAg4f2l3Rtw04FLqqBDcC3gKdMH6iqVlXVVFVNLVq0qLeCJemhrs9QuBo4PMmh3cXjk4DV\n0/rcDrwQIMlBwJHArT3WJEmawV59DVxVW5KcAVwCLADOr6r1SU7rjq8E3g18LMkNQIAzq+r7fdUk\nSZpZb6EAUFVrgDXT2lYObd8JvKjPGiRJo5v0hWZJ0i7EUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhI\nkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQk\nSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJzUihkORpfRciSZq8UVcKH0pyVZI/\nTLJfrxVJkiZmpFCoqucArwYOBtYl+fskx/VamSRp3o18TaGqbgHeDpwJPBf4YJJvJPn1voqTJM2v\nUa8pPD3JOcDXgRcAL6mqp3bb5/RYnyRpHo26Uvhr4BrgqKo6vaquAaiqOxmsHrYpyfFJbk6yIclZ\n2+nzvCTXJlmf5PK5TkCSND57jdjvxcCPq+onAEkeBjyyqu6rqk9s6w1JFgDnAccBG4Grk6yuqpuG\n+uwPfAg4vqpuT3LgTsxFkrSTRl0pXAbsM7S/b9c2k2OBDVV1a1U9AFwILJ/W51XARVV1O0BV3TVi\nPZKkHowaCo+sqnu27nTb+87ynsXAHUP7G7u2YUcAj03y5STrkpwyYj2SpB6Mevro3iRHb72WkOSZ\nwI/H9POfCbyQwUrkP5JcWVXfHO6UZAWwAuCQQw4Zw4+VJG3LqKHwRuDTSe4EAjwe+K1Z3rOJweca\ntlrStQ3bCPygqu5lEDxXAEcBPxMKVbUKWAUwNTVVI9YsSZqjkUKhqq5O8hTgyK7p5qr631nedjVw\neJJDGYTBSQyuIQz7HHBukr2AvYFfwltcJWliRl0pABwDLO3ec3QSquqC7XWuqi1JzgAuARYA51fV\n+iSndcdXVtXXk/wzcD3wIPDRqrpxB+ciSdpJI4VCkk8ATwauBX7SNRew3VAAqKo1wJppbSun7Z8N\nnD1ivZKkHo26UpgCllWV5/MlaQ826i2pNzK4uCxJ2oONulJYCNyU5Crg/q2NVfXSXqqSJE3EqKHw\nrj6LkCTtGka9JfXyJE8CDq+qy5Lsy+COIknSHmTUR2e/DvhH4CNd02Lg4r6KkiRNxqgXmk8Hfhm4\nG9oX7vhEU0naw4waCvd3TzoFoPsEsrenStIeZtRQuDzJW4F9uu9m/jTw+f7KkiRNwqihcBawGbgB\n+AMGn1Le7jeuSZJ2T6PeffQg8DfdS5K0hxr12UffYhvXEKrqsLFXJEmamLk8+2irRwKvAA4YfzmS\npEka6ZpCVf1g6LWpqj4AvLjn2iRJ82zU00dHD+0+jMHKYS7fxSBJ2g2M+g/7+4e2twC3Aa8cezWS\npIka9e6j5/ddiCRp8kY9ffTmmY5X1V+OpxxJ0iTN5e6jY4DV3f5LgKuAW/ooSpI0GaOGwhLg6Kr6\nb4Ak7wK+UFW/3VdhkqT5N+pjLg4CHhjaf6BrkyTtQUZdKVwAXJXks93+y4CP91OSJGlSRr376M+T\nfBF4Ttd0alV9rb+yJEmTMOrpI4B9gbur6q+AjUkO7akmSdKEjPp1nO8EzgTe0jU9HPhkX0VJkiZj\n1JXCy4GXAvcCVNWdwKP7KkqSNBmjhsIDVVV0j89O8qj+SpIkTcqoofCpJB8B9k/yOuAy/MIdSdrj\njHr30fu672a+GzgSeEdVXdprZZKkeTdrKCRZAFzWPRTPIJCkPdisp4+q6ifAg0n2m4d6JEkTNOon\nmu8BbkhyKd0dSABV9Ue9VCVJmohRLzRfBPwZcAWwbug1oyTHJ7k5yYYkZ83Q75gkW5L85oj1SJJ6\nMONKIckhVXV7Vc35OUfdtYjzgOOAjcDVSVZX1U3b6Pce4Etz/RmSpPGabaVw8daNJJ+Z49jHAhuq\n6taqegC4EFi+jX5vAD4D3DXH8SVJYzZbKGRo+7A5jr0YuGNof2PX9tPBk8UMPi394TmOLUnqwWyh\nUNvZHpcPAGdW1YMzdUqyIsnaJGs3b97cQxmSJJj97qOjktzNYMWwT7dNt19V9ZgZ3rsJOHhof0nX\nNmwKuDAJwELgxCRbquri4U5VtQpYBTA1NdVHOEmSmCUUqmrBTox9NXB494jtTcBJwKumjd8ev53k\nY8A/TQ8ESdL8GfVzCnNWVVuSnAFcAiwAzq+q9UlO646v7OtnS5J2TG+hAFBVa4A109q2GQZV9Zo+\na5EkzW4u37wmSdrDGQqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWG\ngiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpD\nQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktT0GgpJjk9yc5INSc7axvFXJ7k+\nyQ1JvpLkqD7rkSTNrLdQSLIAOA84AVgGnJxk2bRu3wKeW1VPA94NrOqrHknS7PpcKRwLbKiqW6vq\nAeBCYPlwh6r6SlX9V7d7JbCkx3okSbPoMxQWA3cM7W/s2rbn94EvbutAkhVJ1iZZu3nz5jGWKEka\ntktcaE7yfAahcOa2jlfVqqqaqqqpRYsWzW9xkvQQslePY28CDh7aX9K1/YwkTwc+CpxQVT/osR5J\n0iz6XClcDRye5NAkewMnAauHOyQ5BLgI+J2q+maPtUiSRtDbSqGqtiQ5A7gEWACcX1Xrk5zWHV8J\nvAN4HPChJABbqmqqr5okSTPr8/QRVbUGWDOtbeXQ9muB1/ZZgyRpdLvEhWZJ0q7BUJAkNYaCJKkx\nFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQY\nCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoM\nBUlSYyhIkhpDQZLU9BoKSY5PcnOSDUnO2sbxJPlgd/z6JEf3WY8kaWa9hUKSBcB5wAnAMuDkJMum\ndTsBOLx7rQA+3Fc9kqTZ9blSOBbYUFW3VtUDwIXA8ml9lgMX1MCVwP5JntBjTZKkGfQZCouBO4b2\nN3Ztc+0jSZone026gFEkWcHg9BLAPUlunmQ9O2gh8P1JFzHPnPMcvHnMhcwTf8e7jyeN0qnPUNgE\nHDy0v6Rrm2sfqmoVsGrcBc6nJGuramrSdcwn57zne6jNF/b8Ofd5+uhq4PAkhybZGzgJWD2tz2rg\nlO4upGcBP6qq7/RYkyRpBr2tFKpqS5IzgEuABcD5VbU+yWnd8ZXAGuBEYANwH3BqX/VIkmbX6zWF\nqlrD4B/+4baVQ9sFnN5nDbuQ3fr01w5yznu+h9p8YQ+fcwb/LkuS5GMuJElDDIUdkOS2JDckuTbJ\n2q7tFUnWJ3kwydRQ38cl+dck9yQ5d5Zx35DkG9047+17HnPRx5yTPCPJlVvHTHLsfMxlVHOc83FJ\n1nX91yV5wXbGPCDJpUlu6f587HzNZxQ9zfns7u/19Uk+m2T/+ZrPKPqY81D/P0lSSRb2PY+xqSpf\nc3wBtwELp7U9FTgS+DIwNdT+KODZwGnAuTOM+XzgMuAR3f6Bk57nPMz5S8AJ3faJwJcnPc+dmPMv\nAk/stn8B2LSdMd8LnNVtnwW8Z9LznIc5vwjYq9t+z0Nhzt3xgxncaPPt6ePvyi9XCmNSVV+vqv/3\nobqqureq/g34n1mGeD3wF1V1f/e+u3ooc6zGMOcCHtNt7wfcOeYSx26GOX+tqrbWvx7YJ8kjtjHE\ncuDj3fbHgZf1U+n47Oycq+pLVbWl272SweeRdmlj+D0DnAP8KYO/57sNQ2HHFHBZt3xcMWvv0RwB\nPCfJV5NcnuSYMY07Ln3M+Y3A2UnuAN4HvGVM447Ljs75N4Brtgb8NAfVTz+L813goJ0tcsz6mPOw\n3wO+uMPV9WPsc06ynMEq4rpxFTlfdovHXOyCnl1Vm5IcCFya5BtVdcVOjrkXcADwLOAY4FNJDqtu\nHboL6GPOrwfeVFWfSfJK4G+BX9npSsdnznNO8vMMTpG8aLbBq6qS7Cq/3616m3OStwFbgL8bW7Xj\nMdY5J9kXeOu2ju0OXCnsgKra1P15F/BZBk+E3VkbgYtq4CrgQQbPWNkl9DTn3wUu6rY/PaYxx2au\nc06ypOt3SlX953a6fS/dk4C7P3ep04Q9zZkkrwF+DXj1LvQfHaCXOT8ZOBS4LsltDE6XXZPk8eOs\nuy+GwhwleVSSR2/dZvC/gRvHMPTFDC42k+QIYG92kYdu9TjnO4HndtsvAG4Zw5hjMdc5d3fUfIHB\nReR/n2Ho1QzCkO7Pz42n4p3X15yTHM/g3PpLq+q+8Va9c/qYc1XdUFUHVtXSqlrK4D98R1fVd8c+\ngT5M+kr37vYCDgOu617rgbd17S9n8Mu/H/gecMnQe24Dfgjc0/VZ1rV/lO7OBgYh8EkGfyGvAV4w\n6bnOw5yfDazrxv0q8MxJz3VH5wy8HbgXuHbodeA25vw44F8YBOBlwAGTnus8zHkDg0fkb+2zctJz\n7XvO037GbexGdx/5iWZJUuPpI0lSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJav4POIw7\n3sExeeQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bd6ddd1f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 23) plot the histogram of the paper that had high counts of \"data\"\n",
    "df.T['data'].plot.hist(bins=20, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bd6dec17b8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEkCAYAAAAhJPoXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bd6de7c6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 24) plot the histogram of the paper that had high counts of \"learning\"\n",
    "# .loc is going to be helpful here\n",
    "df.loc['learning'].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 25) what can you observe? \n",
    "Learning occurs more frequently than data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "134\n",
      "\n",
      "\f",
      "towards reliable and valid measurement of individualized\n",
      "student parameters\n",
      "ran liu\n",
      "\n",
      "kenneth r. koedinger\n",
      "\n",
      "human-computer interaction institute\n",
      "carnegie mellon university\n",
      "\n",
      "human-computer interaction institute\n",
      "carnegie mellon university\n",
      "\n",
      "ranliu@cmu.edu\n",
      "\n",
      "koedinger@cmu.edu\n",
      "\n",
      "abstract\n",
      "research in educational data mining could benefit from greater\n",
      "efforts to ensure that models yield reliable, valid, and interpretable\n",
      "parameter estimates. these efforts have especially been lacking\n",
      "for individualized student-parameter models. we collected two\n",
      "datasets from a sizable student population with excellent “depth”\n",
      "– that is, many observations for each skill for each student. we fit\n",
      "two models, the individualized-slope additive factors model\n",
      "(iafm) and individualized bayesian knowledge tracing (ibkt),\n",
      "both of which individualize for student ability and student\n",
      "learning rate. estimates of student ability were reliable and valid:\n",
      "they were consistent across both models and across both datasets,\n",
      "and they significantly predicted out-of-tutor pretest data. in one of\n",
      "the datasets, estimates of student learning rate were reliable and\n",
      "valid: consistent across models and significantly predictive of\n",
      "pretest-posttest gains. this is the first demonstration that\n",
      "statistical models of data resulting from students’ use of learning\n",
      "technology can produce reliable and valid estimates of individual\n",
      "student learning rates. further, we sought to interpret and\n",
      "understand what differentiates a student with a high estimated\n",
      "learning rate from a student with a low one. we found that\n",
      "learning rate is significantly related to estimates of student ability\n",
      "(prior knowledge) and self-reported measures of diligence.\n",
      "finally, we suggest a variety of possible applications of models\n",
      "with reliable estimates of individualized student parameters,\n",
      "including a more novel, straightforward way of identifying wheel\n",
      "spinning.\n",
      "\n",
      "keywords\n",
      "explanatory models, model interpretability, individualized\n",
      "parameters, 3, additive factors model, individualized bayesian\n",
      "knowledge tracing\n",
      "\n",
      "1. introduction\n",
      "in educational data mining, statistical models are typically\n",
      "evaluated based on fit to overall data and/or predictive accuracy\n",
      "on test data. while this is an important initial step in evaluating\n",
      "the contributions of advancements in statistical and cognitive\n",
      "modeling, research in the field could benefit from greater efforts\n",
      "to ensure that models are reliable and valid. more reliable and\n",
      "valid models offer more explanatory power, contributing to the\n",
      "advancement of learning science. they also inspire greater\n",
      "confidence that deploying model advancements in future tutoring\n",
      "systems will genuine result in the hypothesized improvements to\n",
      "learning.\n",
      "some recent work has been done towards interpreting, validating,\n",
      "and acting upon cognitive/skill modeling improvements [7, 8, 10,\n",
      "11, 17]. educational data mining efforts oriented around\n",
      "personalizing student constructs [3, 12, 13, 14, 18], however, have\n",
      "remained focused on improving predictive accuracy and/or\n",
      "demonstrating hypothetical time savings. little has been done to\n",
      "\n",
      "validate or understand the estimates that models with\n",
      "individualized or clustered student parameters produce.\n",
      "anecdotally, efforts to do so have shown that these individualized\n",
      "student parameter estimates, or discovered student clusters, are\n",
      "often difficult to interpret.\n",
      "it is especially critical to examine the reliability and validity of\n",
      "parameter estimates for modeling advancements that dramatically\n",
      "increase the parameter count, as is generally true for\n",
      "individualized student-parameter models. more parameters create\n",
      "greater degrees of freedom and increase the likelihood that the\n",
      "model may be underdetermined by the data.\n",
      "we focus on the question: to what degree can we trust a model’s\n",
      "parameter estimates to correctly represent the constructs they are\n",
      "supposed to?\n",
      "key to expecting reliable, valid estimates of student-level\n",
      "constructs is not just big data in the “long” sense, but big data in\n",
      "the “deep” sense. oftentimes, the datasets used in secondary\n",
      "analyses in edm are large in terms of total number of students (or\n",
      "total observations) but highly sparse in terms of observations per\n",
      "skill, per student. these features make it difficult to get reliable\n",
      "measurements of constructs at the individual student level,\n",
      "particularly constructs related to learning over time.\n",
      "here, we collected two datasets from a sizable student population\n",
      "(196 students) with excellent “depth” – that is, many observations\n",
      "for each skill for each student. we then fit two models that\n",
      "individualize for student ability and student learning rate (the\n",
      "individualized-slope additive factors model [9] and\n",
      "individualized bayesian knowledge tracing [18]). we assess the\n",
      "models’ fit to data and predictive accuracy. we also move beyond\n",
      "these metrics to examine the reliability of the models’ estimates of\n",
      "student ability and student learning rate. additionally, we\n",
      "externally validate the parameter estimates against out-of-tutor\n",
      "assessment data.\n",
      "we further interpret and understand the constructs by visualizing\n",
      "representative student learning trajectories, examining the\n",
      "relationship between estimated student ability and student\n",
      "learning rate, and the relationship between those constructs and\n",
      "self-reported data on motivational attributes. finally, we propose\n",
      "some useful applications of reliable and valid individualized\n",
      "student-parameter models, including a new way to detect wheel\n",
      "spinning.\n",
      "\n",
      "2. prior work\n",
      "prior work on individualizing student parameters has focused on\n",
      "variants of bayesian knowledge tracing (bkt) [3]. this work\n",
      "includes modeling the parameters separately for each individual\n",
      "student instead of separately for each skill [3], individualizing the\n",
      "p(init) (“initial knowledge”) parameter for each student [13], and\n",
      "individualizing both p(init) and p(learn) (“learning rate”) to the\n",
      "\n",
      "\n",
      "\n",
      "135\n",
      "\n",
      "\f",
      "base bkt model [18]. these models have generally focused on\n",
      "assessing predictive accuracy improvements relative to their\n",
      "respective non-individualized baseline models.\n",
      "\n",
      "“general education” classrooms designed to provide the\n",
      "opportunity for individuals with disabilities and special needs to\n",
      "learn alongside their non-disabled peers.\n",
      "\n",
      "there have also been some “time savings” analyses [12, 18] that\n",
      "evaluate the hypothetical real world impact that individualizing\n",
      "statistical model fits could have. these analyses report the effect\n",
      "of fitting individualized bkt models, compared to traditional\n",
      "bkt, on the hypothetical number of under- and over- practice\n",
      "attempts that would be predicted for each student. results\n",
      "generally have indicated that many more practice opportunities\n",
      "are needed for models to infer the same level of knowledge when\n",
      "using whole-population parameters rather than individual student\n",
      "parameters. these analyses show that individualized models differ\n",
      "in their hypothetical decision points if they were to be applied to\n",
      "drive mastery-based learning, but they do not in and of themselves\n",
      "interpret the individualized parameter estimates, nor do they\n",
      "assess the reliability and validity of such estimates.\n",
      "\n",
      "students spent five consecutive days participating in each study\n",
      "during their regular geometry class periods. on the first and last\n",
      "days, they took a computerized pretest and posttest, respectively.\n",
      "during the middle three days, they worked within an intelligent\n",
      "tutoring system [19] designed to give them practice on their\n",
      "current chapter’s content. this procedure applied to both studies,\n",
      "one of which covered the students’ chapter 3 content (parallel\n",
      "lines cut by a transversal, angles & parallel lines, finding\n",
      "slopes of lines, slope-intercept form, point-slope form) and the\n",
      "other of which covered the students’ chapter 4 content\n",
      "(classifying triangles, finding measures of triangle sides &\n",
      "angles, triangle congruence properties). figure 1 shows an\n",
      "example problem interface from the intelligent tutoring system,\n",
      "which was designed using cognitive tutor authoring tools [1].\n",
      "\n",
      "in a previous effort to better understand individualized student\n",
      "learning rate parameters [9], we examined predictive accuracy and\n",
      "parameter reliability in an extension of the additive factors\n",
      "model [2] applied to existing educational datasets. we did not\n",
      "find evidence that individualizing student rate parameters\n",
      "consistently improved predictive accuracy improvements, nor\n",
      "could we validate the parameter estimates on out-of-tutor\n",
      "assessment data. however, the datasets we analyzed either\n",
      "contained a small number of students or were largely sparse in\n",
      "observations for student-skill pairs, with the exception of two\n",
      "datasets. these two datasets happened to be the ones on which the\n",
      "individualized-slope additive factors model did achieve higher\n",
      "predictive accuracy. thus, we wondered if the sparsity of the\n",
      "datasets were the primary limitation, rather than the modeling\n",
      "advancement itself. this idea is corroborated by the fact that\n",
      "pooling students into “groups” rather than generating\n",
      "individualized estimates worked well on those datasets [9].\n",
      "for the present modeling work, we collected our own data in\n",
      "order to ensure the data features that we believe are necessary for\n",
      "reliable, valid, and potentially meaningful estimates of constructs\n",
      "at the individual student level.\n",
      "\n",
      "3. methods\n",
      "it is common in edm to do secondary analyses across multiple\n",
      "datasets. however, it can be difficult to find datasets that (1)\n",
      "contain a sizable number of students, (2) contain many\n",
      "observations for each skill for each student (i.e., are not sparse),\n",
      "(3) contain students spanning a range of abilities in the domain\n",
      "covered by the tutor, and (4) contain data from out-of-tutor\n",
      "assessment data that is well-mapped to the content in the tutor.\n",
      "for the present work, we wanted to use as close to an “ideal”\n",
      "dataset as possible for estimating student parameters. we\n",
      "collected our own dataset with a sizable number of students (196),\n",
      "many observations (5-50, depending on the skill) for each skill for\n",
      "each student. in addition, we ensured that a wide range of student\n",
      "ability levels was represented in our data to allow for the\n",
      "possibility that models could capture this variability.\n",
      "\n",
      "3.1 data collection\n",
      "196 students, spanning 10 classes taught by three different\n",
      "teachers, enrolled in high school geometry participated in two\n",
      "studies conducted about a month apart. a range of student\n",
      "abilities were included in the study. two of the 10 classes were\n",
      "“honors” and three of the 10 classes were “inclusion”. honors\n",
      "classrooms are intended for students who have strong theoretical\n",
      "interests and abilities in mathematics. inclusion classrooms are\n",
      "\n",
      "figure 1. example problem interface from the intelligent\n",
      "tutoring system used for data collection.\n",
      "we also collected self-report survey data on motivational factors\n",
      "falling along three dimensions. these were competitiveness (e.g.,\n",
      "“in this unit, i am striving to do well compared to other students”\n",
      "and “in this unit, i am striving to avoid performing worse than\n",
      "others”), effort (e.g., “i am striving to understand the content of\n",
      "this unit as thoroughly as possible” and “i work hard to do well in\n",
      "this class even if i don't like what we are doing”), and diligence\n",
      "(e.g., “when class work is difficult, i give up or only study the\n",
      "easy parts” [inverted scale] and “i am diligent”). self-report\n",
      "measures were indicated on a likert scale from 1-7.\n",
      "a key reason we collected two datasets, covering two distinct\n",
      "chapters of the curriculum, is that we were interested in\n",
      "investigating the consistency of student-level parameter estimates\n",
      "across different content, time, and contexts. we discuss this\n",
      "further, along with preliminary results, in section 4.4.1.\n",
      "\n",
      "3.2 statistical models\n",
      "3.2.1 the individualized-slope additive factors\n",
      "model (iafm)\n",
      "the additive factors model (afm) [2] is a logistic regression\n",
      "model that extends item response theory by incorporating a\n",
      "growth or learning term.\n",
      "ln\n",
      "\n",
      "!!\"\n",
      "!-!!\"\n",
      "\n",
      "= θ! +\n",
      "\n",
      "\n",
      "\n",
      "!∈!\"# q !\" (β!\n",
      "\n",
      "+ γ! t!\" )\n",
      "\n",
      "(1)\n",
      "\n",
      "136\n",
      "\n",
      "\f",
      "this statistical model (equation 1) gives the probability 𝑝!\" that a\n",
      "student i will get a problem step j correct based on the student’s\n",
      "baseline ability (𝜃! ), the baseline easiness (𝛽! ) of the required\n",
      "knowledge components on that problem step (𝑄!\" ), and the\n",
      "improvement (𝛾! ) in each required knowledge component (kc)\n",
      "with each additional practice opportunity. this kc slope, or\n",
      "“learning rate,” parameter is multiplied by the number of practice\n",
      "opportunities (𝑇!\" ) the student already had on it. knowledge\n",
      "components (kcs) are the underlying facts, skills, and concepts\n",
      "required to solve problems [6].\n",
      "\n",
      "literal comparison between the predictive accuracies of the two\n",
      "classes of models due to differences in whether they use incoming\n",
      "test data towards their predictions on later test data (bkt/ibkt\n",
      "do, and afm/iafm do not).\n",
      "\n",
      "individualized-slope afm (iafm) builds upon this baseline\n",
      "model by adding a per-student learning rate parameter (𝛿! ). this\n",
      "parameter represents the improvement (𝛿! ) by student i with every\n",
      "additional practice opportunity with the kcs required on problem\n",
      "step j.\n",
      "\n",
      "counter to the majority of findings reported in [9], iafm\n",
      "achieved higher predictive accuracy than afm in both datasets\n",
      "here. this further supports the idea that the “depth” of the dataset\n",
      "is a critical factor in whether an individualized student-parameter\n",
      "model can explain unique variance in the data.\n",
      "\n",
      "ln\n",
      "\n",
      "!!\"\n",
      "!!!!\"\n",
      "\n",
      "= 𝜃! +\n",
      "\n",
      "!∈!\"# 𝑄!\" (𝛽!\n",
      "\n",
      "+ 𝛾! 𝑇!\" + 𝛿! 𝑇!\" )\n",
      "\n",
      "(2)\n",
      "\n",
      "the kc and student learning rate parameters are both multiplied\n",
      "by the number of opportunities (𝑇!\" ) the student already had to\n",
      "practice that kc.\n",
      "\n",
      "both iafm and ibkt outperform their non-individualized\n",
      "counterparts by all metrics, with the exception of bkt having a\n",
      "better bic value than ibkt for the chapter 4 dataset. this is not\n",
      "surprising, as bic is known to over-penalize for added\n",
      "parameters. we recommend cross validation as a better indicator\n",
      "that ibkt is the true better fitting model in this case.\n",
      "\n",
      "table 1. summary of model fit and predictive accuracy\n",
      "metrics comparing afm vs. iafm and bkt vs. ibkt. crossvalidation values are mean rmse values across 10 runs, with\n",
      "standard deviations included in parentheses.\n",
      "data\n",
      "set\n",
      "\n",
      "3.2.2 individualized bayesian knowledge tracing\n",
      "(ibkt)\n",
      "bayesian knowledge tracing (bkt [3]) is an algorithm that\n",
      "models student knowledge as a latent variable using a hidden\n",
      "markov model. the goal of bkt is to infer, for each skill,\n",
      "whether a student has mastered it or not based on his/her sequence\n",
      "of performance on items requiring that skill. it assumes a twostate learning model whereby each skill is either known or\n",
      "unknown. there are four parameters that are estimated in a bkt\n",
      "model: the initial probability of knowing a skill a priori – p(init),\n",
      "the probability of a skill transitioning from not known to known\n",
      "state after an opportunity to practice it – p(learn), the probability\n",
      "of slipping when applying a known skill – p(slip), and the\n",
      "probability of correctly guessing without knowing the required\n",
      "skill – p(guess). fitting bkt produces estimates for each of these\n",
      "four parameters for every skill in a given dataset. bkt models are\n",
      "usually fit using the expectation maximization method (em),\n",
      "conjugate gradient search, or discretized brute-force search.\n",
      "individualized bayesian knowledge tracing (ibkt [18]) builds\n",
      "upon this baseline bkt model by individualizing the estimate of\n",
      "the probability of initially knowing a skill, p(init), and the\n",
      "transition probability, p(learn), for each student. to accomplish\n",
      "the student-level individualization of these parameters, each of\n",
      "them is split into skill- and student-based components that are\n",
      "summed and passed through a logistic transform to yield the final\n",
      "parameter estimate. details on the decomposition of p(init) and\n",
      "p(learn) into skill- and student-based components are described\n",
      "in [18].\n",
      "\n",
      "4. results\n",
      "4.1 model fit & predictive accuracy\n",
      "as a first pass evaluation of the two individualized models, we\n",
      "assessed them using akaike information criterion (aic) and\n",
      "bayesian information criterion (bic), which are standard metrics\n",
      "for model comparison, and 10 independent runs of split-halves\n",
      "cross validation (cv). although 10-fold cross validation has been\n",
      "popular in the field, [4] showed that it has a high type-i error due\n",
      "to high overlap among training sets and recommended at least 5\n",
      "replications of 2-fold cv instead.\n",
      "here, the comparison of interest is each individualized model\n",
      "against its non-individualized counterpart. we do not encourage a\n",
      "\n",
      "ch. 3\n",
      "\n",
      "ch. 4\n",
      "\n",
      "model\n",
      "\n",
      "aic\n",
      "\n",
      "bic\n",
      "\n",
      "afm\n",
      "\n",
      "57229\n",
      "\n",
      "57283\n",
      "\n",
      "cv test rmse\n",
      "(10-run average)\n",
      "0.38440 (0.0039)\n",
      "\n",
      "iafm\n",
      "\n",
      "55931\n",
      "\n",
      "56003\n",
      "\n",
      "0.37868 (0.0044)\n",
      "\n",
      "bkt\n",
      "\n",
      "66714\n",
      "\n",
      "67473\n",
      "\n",
      "0.4222 (0.0005)\n",
      "\n",
      "ibkt\n",
      "\n",
      "56325\n",
      "\n",
      "60479\n",
      "\n",
      "0.3777 (0.0006)\n",
      "\n",
      "afm\n",
      "\n",
      "18059\n",
      "\n",
      "18106\n",
      "\n",
      "0.41037 (0.0048)\n",
      "\n",
      "iafm\n",
      "\n",
      "17863\n",
      "\n",
      "17925\n",
      "\n",
      "0.40789 (0.0050)\n",
      "\n",
      "bkt\n",
      "\n",
      "19908\n",
      "\n",
      "20376\n",
      "\n",
      "0.44091 (0.0014)\n",
      "\n",
      "ibkt\n",
      "\n",
      "18285\n",
      "\n",
      "21809\n",
      "\n",
      "0.40725 (0.0018)\n",
      "\n",
      "4.2 reliability of student parameters\n",
      "next, we examined the degree to which we can rely on these\n",
      "parameters to reasonably estimate the constructs that they should\n",
      "be estimating. we believe that a strong relationship between the\n",
      "parameter estimates of two statistical models with entirely\n",
      "different architectures is a high bar for testing reliability. that is,\n",
      "if a student genuinely displayed evidence of high overall ability in\n",
      "a dataset (relative to his/her peers), then both iafm and ibkt\n",
      "should estimate that to be the case.\n",
      "because of known and observed nonlinear relationships between\n",
      "logistic regression and bayesian knowledge tracing parameter\n",
      "estimates, we measured correlation based on spearman’s\n",
      "coefficient (rs), which is based on rank order.\n",
      "we observed strong and statistically significant correlations\n",
      "between iafm student intercept and ibkt student p(init)\n",
      "parameter estimates (figure 2, top row). we also observed a\n",
      "strong and statistically significant correlation between iafm\n",
      "student slope and ibkt student p(learn) parameter estimates for\n",
      "one of the two datasets (chapter 4). this correlation was much\n",
      "milder, though still significant, for the other dataset (chapter 3).\n",
      "we hypothesize that this difference between datasets may be due\n",
      "to the presence of more difficult kcs in chapter 4. a dataset with\n",
      "more difficult items should provide more sensitive measures of\n",
      "individual differences in improvement, since it avoids ceiling\n",
      "effects. indeed, this was the case: the mean kc easiness parameter\n",
      "estimate (𝛽! ) for chapter 4 was 0.799 (which translates to a\n",
      "\n",
      "\n",
      "\n",
      "137\n",
      "\n",
      "\f",
      "probability of 0.69), compared to 1.253 for chapter 3 (which\n",
      "translates to a probability of 0.78). when students are practicing\n",
      "many opportunities at ceiling (which was the case in particular for\n",
      "chapter 3, based on exploratory analyses of the data), the\n",
      "individualized models will often assign them a lower “learning\n",
      "rate” due to an essentially flat learning trajectory.\n",
      "\n",
      "this has several interesting implications for educational\n",
      "applications. first, it suggests that formative assessment via\n",
      "modeling of process data as learning unfolds is a reasonable\n",
      "method of assessment.\n",
      "it also suggests that detailed assessment data (e.g., from a pretest)\n",
      "could be used to reasonable effect to improve different students’\n",
      "“on-line” estimates of students’ knowledge of kcs. for example,\n",
      "combining kc parameter estimates (derived from model-fitting to\n",
      "prior domain-relevant data) with student intercept priors based on\n",
      "pretest assessment data would allow a model like afm to\n",
      "generate individualized predictions of how much each student\n",
      "needs to practice to reach mastery.\n",
      "in addition, these results suggest that individualized bkt models\n",
      "could use pretest assessment data to “set” reasonably valid\n",
      "student-specific p(init) values before collecting any within-tutor\n",
      "data from those students.\n",
      "in considering the degree to which these results may generalize, it\n",
      "is important to note that the pretests in the present datasets were\n",
      "specifically designed to map closely to the practice problems in\n",
      "the intelligent tutor. pretests contained 1-2 questions for each kc\n",
      "that was practiced in the tutor, and the items were similar to those\n",
      "encountered within the tutor.\n",
      "\n",
      "figure 2. relationships between iafm student intercept and\n",
      "ibkt student p(init) parameter estimates (top row), and\n",
      "between iafm student slope and ibkt student p(learn)\n",
      "parameter estimates (bottom row), for the two datasets.\n",
      "\n",
      "4.3 validity of student parameters\n",
      "\n",
      "to assess the validity of student parameter estimates, we related\n",
      "them to out-of-tutor assessments of the relevant student\n",
      "constructs. in this case, we validated parameter estimates using\n",
      "pretest and posttest assessment data collected in the study.\n",
      "\n",
      "4.3.1 estimates of student ability\n",
      "the student intercept (𝜃! ) parameter of iafm and the student\n",
      "p(init) parameter of bkt are designed to estimate baseline\n",
      "student ability, as least for the knowledge domain represented in\n",
      "the dataset. to validate the models’ estimates of this construct, we\n",
      "examined relationships between the model estimates and students’\n",
      "pretest scores, which are an out-of-tutor assessment of student\n",
      "initial ability for the skills covered by the tutor.\n",
      "we report standard pearson correlation coefficients here, since the\n",
      "relationships between pretest scores and the parameter estimates\n",
      "did not appear to be particularly nonlinear.\n",
      "figure 3 illustrates a summary of these relationships. both\n",
      "models’ estimates of the student ability construct were strongly\n",
      "and significantly correlated with pretest scores.\n",
      "in addition, adding an individualized student slope improved the\n",
      "validity of the model’s estimate of student ability (a parameter\n",
      "that’s modeled in both afm and iafm). we compared the\n",
      "correlations between afm’s intercept estimates to pretest scores\n",
      "(chapter 3: r = 0.62, p < 0.0001, chapter 4: r = 0.58, p < 0.0001)\n",
      "to iafm’s intercept estimate / pretest score correlations (chapter\n",
      "3: 0.74, p < 0.0001, chapter 4: r = 0.66, p < 0.0001).\n",
      "\n",
      "figure 3. relationships between out-of-tutor pretest scores\n",
      "and iafm/ibkt estimates of student ability based on withintutor data.\n",
      "\n",
      "4.3.2 estimates of student learning rate\n",
      "given that the only external assessment data collected were a\n",
      "pretest and posttest, we sought to validate the construct of student\n",
      "learning rate (as estimated by the models) on pretest-posttest\n",
      "gains. students were given roughly the same amount of time to\n",
      "engage with the tutors, so those with accelerated learning rates\n",
      "might be expected to gain more knowledge in the time available.\n",
      "thus, we examined the degree to which student learning rate\n",
      "estimates predicted pretest-posttest gains while controlling for\n",
      "pretest scores. we controlled for pretest scores because they have\n",
      "been shown to negatively predict learning gains due to assessment\n",
      "\n",
      "\n",
      "\n",
      "138\n",
      "\n",
      "\f",
      "ceiling effects. that is, students who start out performing well on\n",
      "the pretest have less “room for improvement”.\n",
      "\n",
      "model estimates of the student ability and student learning rate\n",
      "constructs across units?\n",
      "\n",
      "for the chapter 3 dataset, iafm student slope (𝛿! ) estimates did\n",
      "not significantly predict learning gains. in a linear regression\n",
      "predicting pretest-posttest gains, pretest scores were a significant\n",
      "predictor (β=-0.189, p=0.005) and student slope estimates were\n",
      "not (β=0.396, p=0.144). ibkt student p(learn) estimates did not\n",
      "significant predict learning gains. in a linear regression predicting\n",
      "pretest-posttest gains, pretest scores were a significant predictor\n",
      "(β=-0.226, p=0.005) and student slope estimates were not\n",
      "(β=0.062, p=0.218).\n",
      "\n",
      "figure 4 summarizes this relationship. estimates of student ability\n",
      "are fairly consistent, especially as estimated by iafm. it seems\n",
      "sensible to interpret this as suggesting that overall student ability\n",
      "on chapter 3 content is strongly related to overall student ability\n",
      "on chapter 4 content, as we have shown estimates of student\n",
      "ability to be both reliable and valid.\n",
      "\n",
      "for the chapter 4 dataset, iafm student slope (𝛿! ) estimates\n",
      "significantly predict learning gains. in a linear regression\n",
      "predicting pretest-posttest gains, pretest scores (β=-0.641,\n",
      "p<0.0001) and student slope estimates (β=0.576, p=0.007) were\n",
      "both significant predictors. ibkt student p(learn) estimates also\n",
      "significantly predict learning gains. in a linear regression\n",
      "predicting pretest-posttest gains, pretest scores (β=-0.645,\n",
      "p<0.0001) and p(learn) estimates (β=0.133, p=0.004) were both\n",
      "significant predictors.\n",
      "for one of the two units (chapter 4), we observed that student\n",
      "learning rate estimates were validated on external assessments of\n",
      "learning gain. interestingly, this is the same unit for which we\n",
      "observed a strong cross-model reliability in student learning rate\n",
      "estimates. thus, we have converging evidence that student\n",
      "learning rates estimates for the chapter 4 dataset are both reliable\n",
      "and valid.\n",
      "\n",
      "estimates of student learning rate are less consistent. this may\n",
      "either be due to the fact that chapter 3 estimates of student\n",
      "learning rate were neither very reliable nor very valid.\n",
      "alternatively, the differences in student learning rate estimates\n",
      "across the two chapters may also be due to the fact that students\n",
      "genuinely learn different material at different rates. unfortunately,\n",
      "we cannot resolve this question with the present data. we are\n",
      "currently collecting more datasets from this same group of\n",
      "students. if we obtain more reliable and valid student learning rate\n",
      "estimates in future data from this group of students, we can more\n",
      "confidently address this question in future research.\n",
      "\n",
      "4.4.2 understanding student learning rate estimates\n",
      "given that we established the reliability and validity of iafm and\n",
      "ibkt’s parameter estimates for the chapter 4 dataset were\n",
      "reasonably reliable and valid, we sought to dig deeper into the\n",
      "explanatory power of these estimates. to this end, we conducted\n",
      "exploratory analyses on the chapter 4 data to (1) visualize the\n",
      "learning trajectories of students with the highest vs. lowest\n",
      "estimated learning rates, (2) understand the relationships between\n",
      "estimated learning rates and prior-knowledge and motivational\n",
      "factors, and (3) understand the degree of variability in estimated\n",
      "learning rate across students.\n",
      "\n",
      "first attempt success\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "\n",
      "first attempt success\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "\n",
      "1.0\n",
      "\n",
      "ibkt student p(learn) estimate\n",
      "\n",
      "1.0\n",
      "\n",
      "iafm student slope estimate\n",
      "\n",
      "4\n",
      "6\n",
      "8\n",
      "# practice opportunities\n",
      "\n",
      "10\n",
      "\n",
      "0\n",
      "\n",
      "4.4 towards understanding & using student\n",
      "parameter estimates\n",
      "4.4.1 consistency of individual student constructs\n",
      "across datasets\n",
      "a core motivating question for collecting two datasets on the\n",
      "same group of students was: how consistent are iafm and ibkt\n",
      "\n",
      "4\n",
      "6\n",
      "8\n",
      "# practice opportunities\n",
      "\n",
      "10\n",
      "\n",
      "6\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "top 25% ibkt learning rates\n",
      "middle 50% ibkt learning rates\n",
      "bottom 25% ibkt learning rates\n",
      "\n",
      "0\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "likert scale\n",
      "\n",
      "4\n",
      "3\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "likert scale\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "top 25% iafm learning rates\n",
      "middle 50% iafm learning rates\n",
      "bottom 25% iafm learning rates\n",
      "\n",
      "0\n",
      "\n",
      "figure 4. relationships between student parameter estimates\n",
      "across the two datasets (same student population).\n",
      "\n",
      "2\n",
      "\n",
      "7\n",
      "\n",
      "2\n",
      "\n",
      "7\n",
      "\n",
      "0\n",
      "\n",
      "0.2\n",
      "\n",
      "0.2\n",
      "\n",
      "top 25%\n",
      "middle 50%\n",
      "bottom 25%\n",
      "\n",
      "competitiveness\n",
      "\n",
      "effort\n",
      "\n",
      "diligence\n",
      "\n",
      "competitiveness\n",
      "\n",
      "effort\n",
      "\n",
      "diligence\n",
      "\n",
      "figure 5. top row: early-opportunity learning trajectories of\n",
      "students, grouped based on iafm (left) and ibkt (right)\n",
      "estimated learning rates. solid lines are actual data; dotted\n",
      "lines are each respective model’s predicted performance.\n",
      "bottom row: mean self-report likert scale ratings of\n",
      "questions measuring dimensions of competitiveness, effort,\n",
      "and diligence. grouped based on iafm (left) or ibkt (right)\n",
      "estimated learning rates. error bars show standard errors on\n",
      "the means.\n",
      "\n",
      "\n",
      "\n",
      "139\n",
      "\n",
      "\f",
      "figure 5 (top row) shows the aggregate learning trajectories for\n",
      "students split based either on their iafm student slope estimates\n",
      "(top left) or their ibkt student p(learn) estimates (top right). the\n",
      "top 25% of student parameter estimates are plotted in blue, the\n",
      "middle 50% (between 1st and 3rd quartiles) are plotted in red, and\n",
      "the lower 25% are plotted in black. dotted lines represent each\n",
      "respective model’s predicted earning trajectories.\n",
      "one striking pattern, especially in the iafm learning trajectories\n",
      "(top left), is the apparent relationship between average success on\n",
      "initial practice opportunities (i.e., prior knowledge) and estimated\n",
      "learning rate through the remaining opportunities. this\n",
      "observation is corroborated by a strong and significant correlation\n",
      "between iafm student intercepts and iafm student slopes\n",
      "(r=0.78, p<0.0001). one might interpret this to suggest that\n",
      "students who enter into the tutor with greater prior knowledge will\n",
      "be poised to gain more from the tutor (i.e., “the rich get richer”).\n",
      "alternatively, students may have higher overall knowledge\n",
      "because they are fast learners. there may also be individual traitbased variables that positively drive both learning rate and overall\n",
      "achievement.\n",
      "to explore the relationships between measures of traits relevant to\n",
      "learning, we analyzed self-report survey data grouped by three\n",
      "factors (as described in section 3.1): competitiveness, effort, and\n",
      "diligence. the relationship between these measures and the high,\n",
      "medium, and low learning rate estimates from iafm and ibkt\n",
      "are shown in figure 5 (bottom row). there appears to be a\n",
      "relationship between the means of each self-report measure and\n",
      "the general range that the learning rate estimate falls in.\n",
      "we analyzed the continuous relationship between students’ mean\n",
      "self-report rating along each dimension and their iafm learning\n",
      "rate estimates. in a linear regression predicting iafm student\n",
      "slopes, competitiveness and effort were not significant predictors\n",
      "but diligence (β=0.016, p=0.007) was. in a similar linear\n",
      "regression predicting iafm student intercepts, again diligence\n",
      "was the only significant predictor (β=0.02, p=0.04). thus, among\n",
      "self-reported measures, the strongest dimension predicting both\n",
      "student ability/prior knowledge and student learning rate was the\n",
      "diligence measure. future work using causal modeling is\n",
      "warranted to discover the true nature of causality among these\n",
      "student-level constructs.\n",
      "finally, we investigated the degree of variability in estimated\n",
      "learning rate across students. the first quantile of student learning\n",
      "rates from iafm is 0.03 logits and the third quantile of rates from\n",
      "iafm is 0.08 logits. these can be conceptualized as canonical\n",
      "“slow” and “fast” learners. if we were to assume starting at\n",
      "around 70% performance (which comes from the model’s global\n",
      "intercept estimate), it would take the “slow” (0.03 logits) student\n",
      "approximately 25 opportunities to reach mastery (defined as 85%,\n",
      "the performance equivalent of a p(know)=0.95, factoring in the\n",
      "guess and slip probabilities we used in the actual tutor). it would\n",
      "take the “fast” (0.08 logits) student approximately 11\n",
      "opportunities to reach the same place.\n",
      "\n",
      "4.4.3 identifying wheel spinners\n",
      "the current definition of “wheel spinning” put forth in the\n",
      "educational data mining community is the “phenomenon in\n",
      "which a student has spent a considerable amount of time\n",
      "practicing a skill, yet displays little or no progress towards\n",
      "mastery” [5]. there has been some controversy around the ideal\n",
      "way to measure mastery (e.g., 3 corrects in a row vs. reaching a\n",
      "certain p(know) in knowledge tracing). furthermore, some\n",
      "students may be classified as wheel spinners based on not\n",
      "mastering in a certain number of opportunities but they may still\n",
      "be making progress.\n",
      "\n",
      "we propose that reliable and validated estimates of individual\n",
      "student learning rate parameters, combined with kc learning rate\n",
      "parameters, could be used to estimate wheel spinning student/kc\n",
      "pairs in way that is agnostic to mastery status. specifically, if the\n",
      "combined student and kc learning rate parameters in iafm\n",
      "predict no improvement or negative improvement across\n",
      "additional practice opportunities, and aren’t already at a high level\n",
      "of performance on their first opportunity (here we considered this\n",
      "to be 80% or above), we could consider the student to be wheel\n",
      "spinning on the kc. this method of estimating wheel spinning\n",
      "would be particularly useful for datasets with sparse data on some\n",
      "student-kc pairs, as it is not performance-dependent after the\n",
      "model has been fit to the full dataset.\n",
      "based on this operationalized definition, we found that\n",
      "approximately 15% of student-kc pairs in the chapter 4 dataset\n",
      "are estimated to be wheel spinning. that is, those students are not\n",
      "making progress on those kcs. this is a substantially lower\n",
      "estimate than the 25% reported by a recent wheel spinning\n",
      "detector in [5]. an interesting route for future work would be to\n",
      "do a direct comparison of the wheel spinning detector presented in\n",
      "[5] and our proposed student/kc learning rate identifier within the\n",
      "same dataset. this would allow for testing the possibility that\n",
      "some students who are still making progress, albeit extremely\n",
      "slowly, may be prematurely labeled as “wheel spinners” by [5].\n",
      "\n",
      "5. summary & limitations\n",
      "previous efforts towards more explanatory, interpretable, and\n",
      "actionable modeling advancements in the realm of\n",
      "skill/knowledge component model discovery have been promising\n",
      "in their potential and demonstrated impact on learning science and\n",
      "education. the present paper represents a novel effort to bring\n",
      "these deeper modeling approaches, focused on ensuring\n",
      "explanatory power, to the realm of individualized studentparameter models.\n",
      "towards improving the reliability and validity of individualized\n",
      "student estimates, we collected two datasets from the same student\n",
      "population. both datasets were “deep” along the dimension of\n",
      "student-kc observations. we fit iafm and ibkt to both datasets\n",
      "and showed that the models outranked their non-individualized\n",
      "counterparts in terms of fit to data and predictive accuracy.\n",
      "importantly, we moved beyond these metrics to show that\n",
      "estimates of student ability were highly reliable (iafm and ibkt\n",
      "yielded strongly correlated estimates) and valid (estimates\n",
      "significantly predicted pretest data).\n",
      "this demonstration of confidence in the student ability estimates\n",
      "from ibkt, but even more so iafm, has promising implications\n",
      "for the possibility of individualizing the student models that\n",
      "determine mastery in intelligent tutoring systems at least in terms\n",
      "of overall student ability/knowledge. our results also suggest that\n",
      "it would be reasonable to fix such student ability parameters, or\n",
      "set priors on them, based on either well-mapped pretest\n",
      "assessment data or prior (deep) data from those students’ learning.\n",
      "we also showed that estimates of student learning rate per\n",
      "practice opportunity were reliable and valid in one of the two\n",
      "datasets (chapter 4). this is the first evidence, to our knowledge,\n",
      "of obtaining both reliable and valid student learning rates through\n",
      "a statistical model with individualized student parameters. we\n",
      "believe that this success is largely related to the amount and\n",
      "quality of per-student data we collected.\n",
      "with the confidence of having reliable and valid parameter\n",
      "estimates, we then proceeded to further investigate potential\n",
      "explanations for differences in student learning rates within the\n",
      "\n",
      "\n",
      "\n",
      "140\n",
      "\n",
      "\f",
      "chapter 4 dataset. we found a strong and significant relationship\n",
      "between student ability and improvement rate as well as an\n",
      "additional effect of diligence, based on self-report measures.\n",
      "further research is warranted to distill the causal relationships\n",
      "between these constructs.\n",
      "knowing that a model’s estimates of individualized student\n",
      "parameters not only fit data well, but are reliable and valid,\n",
      "provides greater confidence for applying the model to (1) interpret\n",
      "the parameter estimates to understand characteristics of students,\n",
      "and (2) use the model to individualize the trajectory of mastery\n",
      "estimation for future students.\n",
      "even though both ibkt and iafm outperformed their nonindividualized counterparts in predicting performance in the\n",
      "chapter 3 dataset, we did not find strong evidence of reliability\n",
      "and validity of the student-specific parameter estimates. thus, we\n",
      "did not rely on that dataset to help us understand individual\n",
      "differences in learning rates. for the same reason, we could not\n",
      "confidently attribute the differences, in estimated student learning\n",
      "rates across the datasets, to true differences in students’ learning\n",
      "rates for the two chapters’ material.\n",
      "although considering reliability and validity of models’ parameter\n",
      "estimates sets a higher bar than predictive accuracy for evaluating\n",
      "modeling advances, we believe those to be important\n",
      "characteristics of a model that is to be explanatory, interpretable,\n",
      "and/or actionable. here, we have demonstrated that with a\n",
      "sufficiently good dataset, iafm and ibkt are individualized\n",
      "student models that can produce reliable and valid parameter\n",
      "estimates.\n",
      "since our present work was limited to two datasets on one\n",
      "population of students, it is unclear the degree to which our\n",
      "modeling results will generalize, especially given that at least\n",
      "iafm does not produce reliable, valid parameter estimates on\n",
      "more sparse datasets [9]. in addition, these results are limited to\n",
      "two specific statistical models produce individualized estimates\n",
      "student-level parameters, with a particular focus on individual\n",
      "differences in learning rate. there are other classes of models that\n",
      "could be extended to estimate differences in learning rate: for\n",
      "example, producing individualized estimates of the differential\n",
      "effects of success versus failure [15]. this would be an interesting\n",
      "focus for future work on this topic.\n",
      "nevertheless, we have laid a foundation of methodology by which\n",
      "reliability and validity of parameter estimates, whether student- or\n",
      "kc-level, can be assessed. we have also demonstrated ways of\n",
      "using the reliable and valid student parameter estimates from\n",
      "iafm and ibkt to yield interesting insights about student\n",
      "learning.\n",
      "\n",
      "6. acknowledgments\n",
      "we thank the institute of education sciences for support to rl\n",
      "(training grant #r305b110003) and the national science\n",
      "foundation for support to carnegie mellon university’s learnlab\n",
      "(#sbe-0836012).\n",
      "\n",
      "7. references\n",
      "[1] aleven, v., sewall, j., mclaren, b.m., and koedinger, k.r.\n",
      "(2006). rapid authoring of intelligent tutors for real-world\n",
      "and experimental use. in proceedings of the 6th icalt.\n",
      "ieee, los alamitos, ca, pp. 847-851.\n",
      "[2] cen, h., koedinger, k.r., & junker, b. (2006). learning\n",
      "factors analysis: a general method for cognitive model\n",
      "evaluation and improvement. intelligent tutoring systems,\n",
      "164-175.\n",
      "\n",
      "[3] corbett, a.t., & anderson, j.r. (1995). knowledge tracing:\n",
      "modeling the acquisition of procedural knowledge. user\n",
      "modeling and user-adapted interaction, 4, 253-278.\n",
      "[4] dietterich, t. g. (1998). approximate statistical tests for\n",
      "comparing supervised classification learning algorithms.\n",
      "neural computation, 10(7), 1895–1923.\n",
      "[5] gong, y. & beck, j. (2015). towards detecting wheelspinning: future failure in mastery learning. in\n",
      "proceedings of learning at scale ’15.\n",
      "[6] koedinger, k.r., corbett, a.c., & perfetti, c. (2012). the\n",
      "knowledge-learning-instruction (kli) framework: bridging\n",
      "the science-practice chasm to enhance robust student\n",
      "learning. cognitive science, 36(5), 757-798.\n",
      "[7] koedinger, k.r., mclaughlin, e.a., & stamper, j.c. (2012).\n",
      "automated student model improvement. 5th international\n",
      "conference on edm.\n",
      "[8] koedinger, k. r., stamper, j. c., mclaughlin, e. a., &\n",
      "nixon, t. (2013). using data-driven discovery of better\n",
      "cognitive models to improve student learning. in h. c. lane,\n",
      "k. yacef, j. mostow, & p. pavlik (eds.), proceedings of the\n",
      "16th international conference on artificial intelligence in\n",
      "education (aied ʼ13), 9–13 july 2013, memphis, tn, usa\n",
      "(pp. 421–430). springer.\n",
      "[9] liu, r., & koedinger, k. r. (2015). variations in learning\n",
      "rate: student classification based on systematic residual error\n",
      "patterns across practice opportunities. in o. c. santos, j. g.\n",
      "boticario, c. romero, m. pechenizkiy, a. merceron, p.\n",
      "mitros, j. m. luna, c. mihaescu, p. moreno, a. hershkovitz,\n",
      "s. ventura, & m. desmarais (eds.), proceedings of the 8th\n",
      "international conference on education data mining\n",
      "(edm2015), 26–29 june 2015, madrid, spain (pp. 420–423).\n",
      "international educational data mining society.\n",
      "[10] liu, r., & koedinger, k. r. (under review). closing the\n",
      "loop: automated data-driven skill model discoveries lead to\n",
      "improved instruction and learning gains.\n",
      "[11] liu, r., koedinger, k. r., & mclaughlin, e. a. (2014).\n",
      "interpreting model discovery and testing generalization to a\n",
      "new dataset. in j. stamper, z. pardos, m. mavrikis, & b. m.\n",
      "mclaren (eds.), proceedings of the 7th international\n",
      "conference on educational data mining (edm2014), 4–7\n",
      "july, london, uk (pp. 107–113). international educational\n",
      "data mining society.\n",
      "[12] lee, j.i., & brunskill, e. (2012). the impact on\n",
      "individualizing student models on necessary practice\n",
      "opportunities. 5th international conference on edm.\n",
      "[13] pardos, z.a., & heffernan, n.t. (2010). modeling\n",
      "individualization in a bayesian networks implementation of\n",
      "knowledge tracing. user modeling, adaptation, and\n",
      "personalization, 255-266.\n",
      "[14] pardos, z. a., trivedi, s., heffernan, n. t., & sárközy, g.\n",
      "n. (2012). clustered knowledge tracing. in s. a. cerri, w. j.\n",
      "clancey, g. papadourakis, k.-k. panourgia (eds.),\n",
      "proceedings of the 11th international conference on\n",
      "intelligent tutoring systems (its 2012), 14–18 june 2012,\n",
      "chania, greece (pp. 405–410). springer.\n",
      "[15] pavlik, p.i., cen, h., & koedinger, k.r. (2009).\n",
      "performance factors analysis–a new alternative to knowledge\n",
      "tracing. aied, 531–538.\n",
      "[16] shmueli, g. (2010). to explain or to predict? statistical\n",
      "science, 25(3), 289–310. doi:10.1214/10-sts330\n",
      "[17] stamper, j., & koedinger, k. r. (2011). human-machine\n",
      "student model discovery and improvement using data.\n",
      "proceedings of the 15th international conference on\n",
      "\n",
      "\n",
      "\n",
      "141\n",
      "\n",
      "\f",
      "artificial intelligence in education (aied ʼ11), 28 june–2\n",
      "july, auckland, new zealand (pp. 353–360). springer.\n",
      "[18] yudelson, m.v., koedinger, k.r., & gordon, g.j. (2013).\n",
      "individualized bayesian knowledge tracing models. aied,\n",
      "171-180.\n",
      "\n",
      "[19] vanlehn, k. (2006). the behavior of tutoring systems.\n",
      "international journal of artificial intelligence in education,\n",
      "16, 227–265.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "3\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\f",
      "\n",
      "t\n",
      "o\n",
      "w\n",
      "a\n",
      "r\n",
      "d\n",
      "s\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      "\n",
      "\n",
      "r\n",
      "a\n",
      "n\n",
      " \n",
      "l\n",
      "i\n",
      "u\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "k\n",
      "e\n",
      "n\n",
      "n\n",
      "e\n",
      "t\n",
      "h\n",
      " \n",
      "r\n",
      ".\n",
      " \n",
      "k\n",
      "o\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "h\n",
      "u\n",
      "m\n",
      "a\n",
      "n\n",
      "-\n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "u\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      "s\n",
      "t\n",
      "i\n",
      "t\n",
      "u\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "c\n",
      "a\n",
      "r\n",
      "n\n",
      "e\n",
      "g\n",
      "i\n",
      "e\n",
      " \n",
      "m\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n",
      "n\n",
      " \n",
      "u\n",
      "n\n",
      "i\n",
      "v\n",
      "e\n",
      "r\n",
      "s\n",
      "i\n",
      "t\n",
      "y\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "h\n",
      "u\n",
      "m\n",
      "a\n",
      "n\n",
      "-\n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "u\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      "s\n",
      "t\n",
      "i\n",
      "t\n",
      "u\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "c\n",
      "a\n",
      "r\n",
      "n\n",
      "e\n",
      "g\n",
      "i\n",
      "e\n",
      " \n",
      "m\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n",
      "n\n",
      " \n",
      "u\n",
      "n\n",
      "i\n",
      "v\n",
      "e\n",
      "r\n",
      "s\n",
      "i\n",
      "t\n",
      "y\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "r\n",
      "a\n",
      "n\n",
      "l\n",
      "i\n",
      "u\n",
      "@\n",
      "c\n",
      "m\n",
      "u\n",
      ".\n",
      "e\n",
      "d\n",
      "u\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "k\n",
      "o\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      "@\n",
      "c\n",
      "m\n",
      "u\n",
      ".\n",
      "e\n",
      "d\n",
      "u\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "a\n",
      "b\n",
      "s\n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "c\n",
      "h\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "e\n",
      "d\n",
      "u\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "m\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "c\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "b\n",
      "e\n",
      "n\n",
      "e\n",
      "f\n",
      "i\n",
      "t\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "g\n",
      "r\n",
      "e\n",
      "a\n",
      "t\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "e\n",
      "f\n",
      "f\n",
      "o\n",
      "r\n",
      "t\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "e\n",
      "n\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "y\n",
      "i\n",
      "e\n",
      "l\n",
      "d\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      ",\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "e\n",
      "f\n",
      "f\n",
      "o\n",
      "r\n",
      "t\n",
      "s\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "p\n",
      "e\n",
      "c\n",
      "i\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      " \n",
      "b\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "l\n",
      "a\n",
      "c\n",
      "k\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "l\n",
      "l\n",
      "e\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      "\n",
      "\n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "i\n",
      "z\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "o\n",
      "p\n",
      "u\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "e\n",
      "x\n",
      "c\n",
      "e\n",
      "l\n",
      "l\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "“\n",
      "d\n",
      "e\n",
      "p\n",
      "t\n",
      "h\n",
      "”\n",
      "\n",
      "\n",
      "–\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      ",\n",
      " \n",
      "m\n",
      "a\n",
      "n\n",
      "y\n",
      " \n",
      "o\n",
      "b\n",
      "s\n",
      "e\n",
      "r\n",
      "v\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "f\n",
      "i\n",
      "t\n",
      "\n",
      "\n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      "-\n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      " \n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "s\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "\n",
      "\n",
      "(\n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      ")\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "a\n",
      "y\n",
      "e\n",
      "s\n",
      "i\n",
      "a\n",
      "n\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "(\n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      ")\n",
      ",\n",
      "\n",
      "\n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      ".\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      ":\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      "y\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "i\n",
      "s\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "a\n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "y\n",
      " \n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      "l\n",
      "y\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "u\n",
      "t\n",
      "-\n",
      "o\n",
      "f\n",
      "-\n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "o\n",
      "n\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      ",\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      ":\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "i\n",
      "s\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      "l\n",
      "y\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      "-\n",
      "p\n",
      "o\n",
      "s\n",
      "t\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      "s\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "f\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "d\n",
      "e\n",
      "m\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "u\n",
      "l\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      "’\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "t\n",
      "e\n",
      "c\n",
      "h\n",
      "n\n",
      "o\n",
      "l\n",
      "o\n",
      "g\n",
      "y\n",
      " \n",
      "c\n",
      "a\n",
      "n\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "d\n",
      "u\n",
      "c\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "f\n",
      "u\n",
      "r\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "s\n",
      "o\n",
      "u\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "u\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "w\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "a\n",
      " \n",
      "h\n",
      "i\n",
      "g\n",
      "h\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "a\n",
      " \n",
      "l\n",
      "o\n",
      "w\n",
      " \n",
      "o\n",
      "n\n",
      "e\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "f\n",
      "o\n",
      "u\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      "l\n",
      "y\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      "\n",
      "\n",
      "(\n",
      "p\n",
      "r\n",
      "i\n",
      "o\n",
      "r\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      ")\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      "-\n",
      "r\n",
      "e\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "d\n",
      "i\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      ".\n",
      "\n",
      "\n",
      "f\n",
      "i\n",
      "n\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "s\n",
      "u\n",
      "g\n",
      "g\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "a\n",
      " \n",
      "v\n",
      "a\n",
      "r\n",
      "i\n",
      "e\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "p\n",
      "o\n",
      "s\n",
      "s\n",
      "i\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "p\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      "\n",
      "\n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "c\n",
      "l\n",
      "u\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      " \n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "n\n",
      "o\n",
      "v\n",
      "e\n",
      "l\n",
      ",\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "a\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      "f\n",
      "o\n",
      "r\n",
      "w\n",
      "a\n",
      "r\n",
      "d\n",
      " \n",
      "w\n",
      "a\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "f\n",
      "y\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "e\n",
      "l\n",
      "\n",
      "\n",
      "s\n",
      "p\n",
      "i\n",
      "n\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "k\n",
      "e\n",
      "y\n",
      "w\n",
      "o\n",
      "r\n",
      "d\n",
      "s\n",
      "\n",
      "\n",
      "e\n",
      "x\n",
      "p\n",
      "l\n",
      "a\n",
      "n\n",
      "a\n",
      "t\n",
      "o\n",
      "r\n",
      "y\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      ",\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      ",\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      ",\n",
      " \n",
      "3\n",
      ",\n",
      " \n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "s\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      ",\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "a\n",
      "y\n",
      "e\n",
      "s\n",
      "i\n",
      "a\n",
      "n\n",
      "\n",
      "\n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "r\n",
      "o\n",
      "d\n",
      "u\n",
      "c\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      " \n",
      "e\n",
      "d\n",
      "u\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "m\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      ",\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "t\n",
      "y\n",
      "p\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      "\n",
      "\n",
      "e\n",
      "v\n",
      "a\n",
      "l\n",
      "u\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "f\n",
      "i\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "l\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "/\n",
      "o\n",
      "r\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "c\n",
      "u\n",
      "r\n",
      "a\n",
      "c\n",
      "y\n",
      "\n",
      "\n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      ".\n",
      " \n",
      "w\n",
      "h\n",
      "i\n",
      "l\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "a\n",
      "n\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "a\n",
      "l\n",
      " \n",
      "s\n",
      "t\n",
      "e\n",
      "p\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "e\n",
      "v\n",
      "a\n",
      "l\n",
      "u\n",
      "a\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "r\n",
      "i\n",
      "b\n",
      "u\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "a\n",
      "d\n",
      "v\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "c\n",
      "o\n",
      "g\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      ",\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "c\n",
      "h\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "f\n",
      "i\n",
      "e\n",
      "l\n",
      "d\n",
      " \n",
      "c\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "b\n",
      "e\n",
      "n\n",
      "e\n",
      "f\n",
      "i\n",
      "t\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "g\n",
      "r\n",
      "e\n",
      "a\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "f\n",
      "f\n",
      "o\n",
      "r\n",
      "t\n",
      "s\n",
      "\n",
      "\n",
      "t\n",
      "o\n",
      " \n",
      "e\n",
      "n\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      ".\n",
      " \n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      " \n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "e\n",
      "x\n",
      "p\n",
      "l\n",
      "a\n",
      "n\n",
      "a\n",
      "t\n",
      "o\n",
      "r\n",
      "y\n",
      " \n",
      "p\n",
      "o\n",
      "w\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "r\n",
      "i\n",
      "b\n",
      "u\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "a\n",
      "d\n",
      "v\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "c\n",
      "i\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "y\n",
      " \n",
      "a\n",
      "l\n",
      "s\n",
      "o\n",
      " \n",
      "i\n",
      "n\n",
      "s\n",
      "p\n",
      "i\n",
      "r\n",
      "e\n",
      " \n",
      "g\n",
      "r\n",
      "e\n",
      "a\n",
      "t\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "f\n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "d\n",
      "e\n",
      "p\n",
      "l\n",
      "o\n",
      "y\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "a\n",
      "d\n",
      "v\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "f\n",
      "u\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "s\n",
      "y\n",
      "s\n",
      "t\n",
      "e\n",
      "m\n",
      "s\n",
      " \n",
      "w\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "g\n",
      "e\n",
      "n\n",
      "u\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "u\n",
      "l\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "h\n",
      "y\n",
      "p\n",
      "o\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      ".\n",
      "\n",
      "\n",
      "s\n",
      "o\n",
      "m\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "c\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "k\n",
      " \n",
      "h\n",
      "a\n",
      "s\n",
      " \n",
      "b\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "d\n",
      "o\n",
      "n\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      "w\n",
      "a\n",
      "r\n",
      "d\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      ",\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "a\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      ",\n",
      "\n",
      "\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "u\n",
      "p\n",
      "o\n",
      "n\n",
      " \n",
      "c\n",
      "o\n",
      "g\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      "/\n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "[\n",
      "7\n",
      ",\n",
      " \n",
      "8\n",
      ",\n",
      " \n",
      "1\n",
      "0\n",
      ",\n",
      "\n",
      "\n",
      "1\n",
      "1\n",
      ",\n",
      " \n",
      "1\n",
      "7\n",
      "]\n",
      ".\n",
      " \n",
      "e\n",
      "d\n",
      "u\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "m\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "e\n",
      "f\n",
      "f\n",
      "o\n",
      "r\n",
      "t\n",
      "s\n",
      " \n",
      "o\n",
      "r\n",
      "i\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "a\n",
      "r\n",
      "o\n",
      "u\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "p\n",
      "e\n",
      "r\n",
      "s\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      "s\n",
      " \n",
      "[\n",
      "3\n",
      ",\n",
      " \n",
      "1\n",
      "2\n",
      ",\n",
      " \n",
      "1\n",
      "3\n",
      ",\n",
      " \n",
      "1\n",
      "4\n",
      ",\n",
      " \n",
      "1\n",
      "8\n",
      "]\n",
      ",\n",
      " \n",
      "h\n",
      "o\n",
      "w\n",
      "e\n",
      "v\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "m\n",
      "a\n",
      "i\n",
      "n\n",
      "e\n",
      "d\n",
      " \n",
      "f\n",
      "o\n",
      "c\n",
      "u\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "c\n",
      "u\n",
      "r\n",
      "a\n",
      "c\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "/\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "d\n",
      "e\n",
      "m\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "a\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "h\n",
      "y\n",
      "p\n",
      "o\n",
      "t\n",
      "h\n",
      "e\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      " \n",
      "t\n",
      "i\n",
      "m\n",
      "e\n",
      " \n",
      "s\n",
      "a\n",
      "v\n",
      "i\n",
      "n\n",
      "g\n",
      "s\n",
      ".\n",
      " \n",
      "l\n",
      "i\n",
      "t\n",
      "t\n",
      "l\n",
      "e\n",
      " \n",
      "h\n",
      "a\n",
      "s\n",
      " \n",
      "b\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "d\n",
      "o\n",
      "n\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "o\n",
      "r\n",
      " \n",
      "u\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "r\n",
      " \n",
      "c\n",
      "l\n",
      "u\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "d\n",
      "u\n",
      "c\n",
      "e\n",
      ".\n",
      "\n",
      "\n",
      "a\n",
      "n\n",
      "e\n",
      "c\n",
      "d\n",
      "o\n",
      "t\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      ",\n",
      " \n",
      "e\n",
      "f\n",
      "f\n",
      "o\n",
      "r\n",
      "t\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "d\n",
      "o\n",
      " \n",
      "s\n",
      "o\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "o\n",
      "r\n",
      " \n",
      "d\n",
      "i\n",
      "s\n",
      "c\n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "c\n",
      "l\n",
      "u\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      ",\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "o\n",
      "f\n",
      "t\n",
      "e\n",
      "n\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "i\n",
      "c\n",
      "u\n",
      "l\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      ".\n",
      "\n",
      "\n",
      "i\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "e\n",
      "s\n",
      "p\n",
      "e\n",
      "c\n",
      "i\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      " \n",
      "c\n",
      "r\n",
      "i\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "e\n",
      "x\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "d\n",
      "v\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "d\n",
      "r\n",
      "a\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "c\n",
      "r\n",
      "e\n",
      "a\n",
      "s\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "c\n",
      "o\n",
      "u\n",
      "n\n",
      "t\n",
      ",\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "g\n",
      "e\n",
      "n\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      " \n",
      "t\n",
      "r\n",
      "u\n",
      "e\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      ".\n",
      " \n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      " \n",
      "c\n",
      "r\n",
      "e\n",
      "a\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "g\n",
      "r\n",
      "e\n",
      "a\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "d\n",
      "e\n",
      "g\n",
      "r\n",
      "e\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "f\n",
      "r\n",
      "e\n",
      "e\n",
      "d\n",
      "o\n",
      "m\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      "c\n",
      "r\n",
      "e\n",
      "a\n",
      "s\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "l\n",
      "i\n",
      "k\n",
      "e\n",
      "l\n",
      "i\n",
      "h\n",
      "o\n",
      "o\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "m\n",
      "a\n",
      "y\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "u\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "d\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "m\n",
      "i\n",
      "n\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      ".\n",
      "\n",
      "\n",
      "w\n",
      "e\n",
      " \n",
      "f\n",
      "o\n",
      "c\n",
      "u\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "q\n",
      "u\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ":\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "w\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "d\n",
      "e\n",
      "g\n",
      "r\n",
      "e\n",
      "e\n",
      " \n",
      "c\n",
      "a\n",
      "n\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "u\n",
      "s\n",
      "t\n",
      " \n",
      "a\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "’\n",
      "s\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "r\n",
      "e\n",
      "c\n",
      "t\n",
      "l\n",
      "y\n",
      " \n",
      "r\n",
      "e\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "y\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "s\n",
      "u\n",
      "p\n",
      "p\n",
      "o\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      "?\n",
      "\n",
      "\n",
      "k\n",
      "e\n",
      "y\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "e\n",
      "x\n",
      "p\n",
      "e\n",
      "c\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      ",\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      "l\n",
      "e\n",
      "v\n",
      "e\n",
      "l\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      "s\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      " \n",
      "j\n",
      "u\n",
      "s\n",
      "t\n",
      " \n",
      "b\n",
      "i\n",
      "g\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "“\n",
      "l\n",
      "o\n",
      "n\n",
      "g\n",
      "”\n",
      " \n",
      "s\n",
      "e\n",
      "n\n",
      "s\n",
      "e\n",
      ",\n",
      " \n",
      "b\n",
      "u\n",
      "t\n",
      " \n",
      "b\n",
      "i\n",
      "g\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "i\n",
      "n\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "“\n",
      "d\n",
      "e\n",
      "e\n",
      "p\n",
      "”\n",
      " \n",
      "s\n",
      "e\n",
      "n\n",
      "s\n",
      "e\n",
      ".\n",
      " \n",
      "o\n",
      "f\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "m\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "s\n",
      "e\n",
      "c\n",
      "o\n",
      "n\n",
      "d\n",
      "a\n",
      "r\n",
      "y\n",
      "\n",
      "\n",
      "a\n",
      "n\n",
      "a\n",
      "l\n",
      "y\n",
      "s\n",
      "e\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "e\n",
      "d\n",
      "m\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "l\n",
      "a\n",
      "r\n",
      "g\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "e\n",
      "r\n",
      "m\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "o\n",
      "t\n",
      "a\n",
      "l\n",
      " \n",
      "n\n",
      "u\n",
      "m\n",
      "b\n",
      "e\n",
      "r\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "(\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "t\n",
      "o\n",
      "t\n",
      "a\n",
      "l\n",
      " \n",
      "o\n",
      "b\n",
      "s\n",
      "e\n",
      "r\n",
      "v\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ")\n",
      " \n",
      "b\n",
      "u\n",
      "t\n",
      " \n",
      "h\n",
      "i\n",
      "g\n",
      "h\n",
      "l\n",
      "y\n",
      " \n",
      "s\n",
      "p\n",
      "a\n",
      "r\n",
      "s\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "e\n",
      "r\n",
      "m\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "o\n",
      "b\n",
      "s\n",
      "e\n",
      "r\n",
      "v\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "p\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      ",\n",
      " \n",
      "p\n",
      "e\n",
      "r\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "f\n",
      "e\n",
      "a\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "m\n",
      "a\n",
      "k\n",
      "e\n",
      " \n",
      "i\n",
      "t\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "i\n",
      "c\n",
      "u\n",
      "l\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "g\n",
      "e\n",
      "t\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      "\n",
      "\n",
      "m\n",
      "e\n",
      "a\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      "s\n",
      " \n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "v\n",
      "e\n",
      "l\n",
      ",\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "t\n",
      "i\n",
      "c\n",
      "u\n",
      "l\n",
      "a\n",
      "r\n",
      "l\n",
      "y\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      "s\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      " \n",
      "t\n",
      "i\n",
      "m\n",
      "e\n",
      ".\n",
      "\n",
      "\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "l\n",
      "l\n",
      "e\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "i\n",
      "z\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "o\n",
      "p\n",
      "u\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "(\n",
      "1\n",
      "9\n",
      "6\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      ")\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "e\n",
      "x\n",
      "c\n",
      "e\n",
      "l\n",
      "l\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "“\n",
      "d\n",
      "e\n",
      "p\n",
      "t\n",
      "h\n",
      "”\n",
      " \n",
      "–\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      ",\n",
      " \n",
      "m\n",
      "a\n",
      "n\n",
      "y\n",
      " \n",
      "o\n",
      "b\n",
      "s\n",
      "e\n",
      "r\n",
      "v\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "\n",
      "\n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "n\n",
      " \n",
      "f\n",
      "i\n",
      "t\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "(\n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      "-\n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      " \n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "s\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "[\n",
      "9\n",
      "]\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "a\n",
      "y\n",
      "e\n",
      "s\n",
      "i\n",
      "a\n",
      "n\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "[\n",
      "1\n",
      "8\n",
      "]\n",
      ")\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      "’\n",
      " \n",
      "f\n",
      "i\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "c\n",
      "u\n",
      "r\n",
      "a\n",
      "c\n",
      "y\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "a\n",
      "l\n",
      "s\n",
      "o\n",
      " \n",
      "m\n",
      "o\n",
      "v\n",
      "e\n",
      " \n",
      "b\n",
      "e\n",
      "y\n",
      "o\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "m\n",
      "e\n",
      "t\n",
      "r\n",
      "i\n",
      "c\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "e\n",
      "x\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      "’\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      ".\n",
      " \n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      "\n",
      "\n",
      "e\n",
      "x\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      "s\n",
      "t\n",
      " \n",
      "o\n",
      "u\n",
      "t\n",
      "-\n",
      "o\n",
      "f\n",
      "-\n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      ".\n",
      "\n",
      "\n",
      "w\n",
      "e\n",
      " \n",
      "f\n",
      "u\n",
      "r\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "u\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      "s\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "v\n",
      "i\n",
      "s\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "j\n",
      "e\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "i\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "e\n",
      "x\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "s\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      "-\n",
      "r\n",
      "e\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "m\n",
      "o\n",
      "t\n",
      "i\n",
      "v\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "a\n",
      "t\n",
      "t\n",
      "r\n",
      "i\n",
      "b\n",
      "u\n",
      "t\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "f\n",
      "i\n",
      "n\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "p\n",
      "o\n",
      "s\n",
      "e\n",
      "\n",
      "\n",
      "s\n",
      "o\n",
      "m\n",
      "e\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      "f\n",
      "u\n",
      "l\n",
      " \n",
      "a\n",
      "p\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      ",\n",
      " \n",
      "i\n",
      "n\n",
      "c\n",
      "l\n",
      "u\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      " \n",
      "n\n",
      "e\n",
      "w\n",
      " \n",
      "w\n",
      "a\n",
      "y\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "d\n",
      "e\n",
      "t\n",
      "e\n",
      "c\n",
      "t\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "e\n",
      "l\n",
      "\n",
      "\n",
      "s\n",
      "p\n",
      "i\n",
      "n\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      ".\n",
      " \n",
      "p\n",
      "r\n",
      "i\n",
      "o\n",
      "r\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "k\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "i\n",
      "o\n",
      "r\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "k\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      " \n",
      "h\n",
      "a\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "c\n",
      "u\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "v\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "b\n",
      "a\n",
      "y\n",
      "e\n",
      "s\n",
      "i\n",
      "a\n",
      "n\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "(\n",
      "b\n",
      "k\n",
      "t\n",
      ")\n",
      " \n",
      "[\n",
      "3\n",
      "]\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "k\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "c\n",
      "l\n",
      "u\n",
      "d\n",
      "e\n",
      "s\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      " \n",
      "s\n",
      "e\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "l\n",
      "y\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      "s\n",
      "t\n",
      "e\n",
      "a\n",
      "d\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "e\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "l\n",
      "y\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "[\n",
      "3\n",
      "]\n",
      ",\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "p\n",
      "(\n",
      "i\n",
      "n\n",
      "i\n",
      "t\n",
      ")\n",
      " \n",
      "(\n",
      "“\n",
      "i\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "a\n",
      "l\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      "”\n",
      ")\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "[\n",
      "1\n",
      "3\n",
      "]\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "p\n",
      "(\n",
      "i\n",
      "n\n",
      "i\n",
      "t\n",
      ")\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "p\n",
      "(\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      ")\n",
      " \n",
      "(\n",
      "“\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "”\n",
      ")\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "3\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\f",
      "\n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      " \n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "[\n",
      "1\n",
      "8\n",
      "]\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      " \n",
      "g\n",
      "e\n",
      "n\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      " \n",
      "f\n",
      "o\n",
      "c\n",
      "u\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "c\n",
      "u\n",
      "r\n",
      "a\n",
      "c\n",
      "y\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "s\n",
      "p\n",
      "e\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "n\n",
      "o\n",
      "n\n",
      "-\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "“\n",
      "g\n",
      "e\n",
      "n\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      " \n",
      "e\n",
      "d\n",
      "u\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "”\n",
      " \n",
      "c\n",
      "l\n",
      "a\n",
      "s\n",
      "s\n",
      "r\n",
      "o\n",
      "o\n",
      "m\n",
      "s\n",
      " \n",
      "d\n",
      "e\n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "i\n",
      "d\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "s\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "d\n",
      "i\n",
      "s\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "p\n",
      "e\n",
      "c\n",
      "i\n",
      "a\n",
      "l\n",
      " \n",
      "n\n",
      "e\n",
      "e\n",
      "d\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      " \n",
      "a\n",
      "l\n",
      "o\n",
      "n\n",
      "g\n",
      "s\n",
      "i\n",
      "d\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      " \n",
      "n\n",
      "o\n",
      "n\n",
      "-\n",
      "d\n",
      "i\n",
      "s\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      "d\n",
      " \n",
      "p\n",
      "e\n",
      "e\n",
      "r\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      " \n",
      "a\n",
      "l\n",
      "s\n",
      "o\n",
      " \n",
      "b\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "s\n",
      "o\n",
      "m\n",
      "e\n",
      " \n",
      "“\n",
      "t\n",
      "i\n",
      "m\n",
      "e\n",
      " \n",
      "s\n",
      "a\n",
      "v\n",
      "i\n",
      "n\n",
      "g\n",
      "s\n",
      "”\n",
      " \n",
      "a\n",
      "n\n",
      "a\n",
      "l\n",
      "y\n",
      "s\n",
      "e\n",
      "s\n",
      " \n",
      "[\n",
      "1\n",
      "2\n",
      ",\n",
      " \n",
      "1\n",
      "8\n",
      "]\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      "\n",
      "\n",
      "e\n",
      "v\n",
      "a\n",
      "l\n",
      "u\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "h\n",
      "y\n",
      "p\n",
      "o\n",
      "t\n",
      "h\n",
      "e\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      " \n",
      "r\n",
      "e\n",
      "a\n",
      "l\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "l\n",
      "d\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "a\n",
      "c\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "f\n",
      "i\n",
      "t\n",
      "s\n",
      " \n",
      "c\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "a\n",
      "l\n",
      "y\n",
      "s\n",
      "e\n",
      "s\n",
      " \n",
      "r\n",
      "e\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "e\n",
      "f\n",
      "f\n",
      "e\n",
      "c\n",
      "t\n",
      "\n",
      "\n",
      "o\n",
      "f\n",
      " \n",
      "f\n",
      "i\n",
      "t\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      ",\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "a\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "d\n",
      "i\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "b\n",
      "k\n",
      "t\n",
      ",\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "h\n",
      "y\n",
      "p\n",
      "o\n",
      "t\n",
      "h\n",
      "e\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      " \n",
      "n\n",
      "u\n",
      "m\n",
      "b\n",
      "e\n",
      "r\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "u\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "-\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "-\n",
      " \n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      "\n",
      "\n",
      "a\n",
      "t\n",
      "t\n",
      "e\n",
      "m\n",
      "p\n",
      "t\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "w\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      ".\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "u\n",
      "l\n",
      "t\n",
      "s\n",
      "\n",
      "\n",
      "g\n",
      "e\n",
      "n\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "c\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "m\n",
      "a\n",
      "n\n",
      "y\n",
      " \n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "n\n",
      "e\n",
      "e\n",
      "d\n",
      "e\n",
      "d\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "i\n",
      "n\n",
      "f\n",
      "e\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "l\n",
      "e\n",
      "v\n",
      "e\n",
      "l\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "n\n",
      "\n",
      "\n",
      "u\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "w\n",
      "h\n",
      "o\n",
      "l\n",
      "e\n",
      "-\n",
      "p\n",
      "o\n",
      "p\n",
      "u\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "a\n",
      "l\n",
      "y\n",
      "s\n",
      "e\n",
      "s\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "w\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      " \n",
      "h\n",
      "y\n",
      "p\n",
      "o\n",
      "t\n",
      "h\n",
      "e\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      " \n",
      "d\n",
      "e\n",
      "c\n",
      "i\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "p\n",
      "o\n",
      "i\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "i\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "y\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "a\n",
      "p\n",
      "p\n",
      "l\n",
      "i\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      "\n",
      "\n",
      "d\n",
      "r\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "m\n",
      "a\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "y\n",
      "-\n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      ",\n",
      " \n",
      "b\n",
      "u\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "y\n",
      " \n",
      "d\n",
      "o\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "s\n",
      "e\n",
      "l\n",
      "v\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "n\n",
      "o\n",
      "r\n",
      " \n",
      "d\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "y\n",
      "\n",
      "\n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "u\n",
      "c\n",
      "h\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "s\n",
      "p\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "f\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "e\n",
      "c\n",
      "u\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "y\n",
      "s\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "t\n",
      "i\n",
      "c\n",
      "i\n",
      "p\n",
      "a\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "y\n",
      "\n",
      "\n",
      "d\n",
      "u\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      " \n",
      "r\n",
      "e\n",
      "g\n",
      "u\n",
      "l\n",
      "a\n",
      "r\n",
      " \n",
      "g\n",
      "e\n",
      "o\n",
      "m\n",
      "e\n",
      "t\n",
      "r\n",
      "y\n",
      " \n",
      "c\n",
      "l\n",
      "a\n",
      "s\n",
      "s\n",
      " \n",
      "p\n",
      "e\n",
      "r\n",
      "i\n",
      "o\n",
      "d\n",
      "s\n",
      ".\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "f\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "l\n",
      "a\n",
      "s\n",
      "t\n",
      "\n",
      "\n",
      "d\n",
      "a\n",
      "y\n",
      "s\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "y\n",
      " \n",
      "t\n",
      "o\n",
      "o\n",
      "k\n",
      " \n",
      "a\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "u\n",
      "t\n",
      "e\n",
      "r\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "p\n",
      "o\n",
      "s\n",
      "t\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      ",\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "p\n",
      "e\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      "l\n",
      "y\n",
      ".\n",
      "\n",
      "\n",
      "d\n",
      "u\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "m\n",
      "i\n",
      "d\n",
      "d\n",
      "l\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "r\n",
      "e\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "y\n",
      "s\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "y\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "k\n",
      "e\n",
      "d\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "l\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "y\n",
      "s\n",
      "t\n",
      "e\n",
      "m\n",
      " \n",
      "[\n",
      "1\n",
      "9\n",
      "]\n",
      " \n",
      "d\n",
      "e\n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "g\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      " \n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      "\n",
      "\n",
      "c\n",
      "u\n",
      "r\n",
      "r\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      "’\n",
      "s\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "c\n",
      "e\n",
      "d\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "a\n",
      "p\n",
      "p\n",
      "l\n",
      "i\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "i\n",
      "e\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      "o\n",
      "n\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "c\n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      "’\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "3\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "(\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "l\n",
      "l\n",
      "e\n",
      "l\n",
      "\n",
      "\n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "s\n",
      " \n",
      "c\n",
      "u\n",
      "t\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "a\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "n\n",
      "s\n",
      "v\n",
      "e\n",
      "r\n",
      "s\n",
      "a\n",
      "l\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "g\n",
      "l\n",
      "e\n",
      "s\n",
      " \n",
      "&\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "l\n",
      "l\n",
      "e\n",
      "l\n",
      " \n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "f\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      "-\n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "c\n",
      "e\n",
      "p\n",
      "t\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      ",\n",
      " \n",
      "p\n",
      "o\n",
      "i\n",
      "n\n",
      "t\n",
      "-\n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      ")\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "o\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "c\n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      "’\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "4\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "(\n",
      "c\n",
      "l\n",
      "a\n",
      "s\n",
      "s\n",
      "i\n",
      "f\n",
      "y\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "r\n",
      "i\n",
      "a\n",
      "n\n",
      "g\n",
      "l\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "f\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "r\n",
      "i\n",
      "a\n",
      "n\n",
      "g\n",
      "l\n",
      "e\n",
      " \n",
      "s\n",
      "i\n",
      "d\n",
      "e\n",
      "s\n",
      " \n",
      "&\n",
      "\n",
      "\n",
      "a\n",
      "n\n",
      "g\n",
      "l\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "t\n",
      "r\n",
      "i\n",
      "a\n",
      "n\n",
      "g\n",
      "l\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "g\n",
      "r\n",
      "u\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "p\n",
      "e\n",
      "r\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      ")\n",
      ".\n",
      " \n",
      "f\n",
      "i\n",
      "g\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "1\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "w\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "\n",
      "\n",
      "e\n",
      "x\n",
      "a\n",
      "m\n",
      "p\n",
      "l\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "l\n",
      "e\n",
      "m\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "f\n",
      "a\n",
      "c\n",
      "e\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "l\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "y\n",
      "s\n",
      "t\n",
      "e\n",
      "m\n",
      ",\n",
      "\n",
      "\n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "w\n",
      "a\n",
      "s\n",
      " \n",
      "d\n",
      "e\n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "e\n",
      "d\n",
      " \n",
      "u\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "c\n",
      "o\n",
      "g\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      " \n",
      "a\n",
      "u\n",
      "t\n",
      "h\n",
      "o\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "o\n",
      "o\n",
      "l\n",
      "s\n",
      " \n",
      "[\n",
      "1\n",
      "]\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "v\n",
      "i\n",
      "o\n",
      "u\n",
      "s\n",
      " \n",
      "e\n",
      "f\n",
      "f\n",
      "o\n",
      "r\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "u\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      " \n",
      "[\n",
      "9\n",
      "]\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "e\n",
      "x\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "e\n",
      "d\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "c\n",
      "u\n",
      "r\n",
      "a\n",
      "c\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      "n\n",
      " \n",
      "e\n",
      "x\n",
      "t\n",
      "e\n",
      "n\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "s\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "[\n",
      "2\n",
      "]\n",
      " \n",
      "a\n",
      "p\n",
      "p\n",
      "l\n",
      "i\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "e\n",
      "x\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "e\n",
      "d\n",
      "u\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "d\n",
      "i\n",
      "d\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      "\n",
      "\n",
      "f\n",
      "i\n",
      "n\n",
      "d\n",
      " \n",
      "e\n",
      "v\n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "i\n",
      "s\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      "l\n",
      "y\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "d\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "c\n",
      "u\n",
      "r\n",
      "a\n",
      "c\n",
      "y\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      ",\n",
      " \n",
      "n\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "u\n",
      "t\n",
      "-\n",
      "o\n",
      "f\n",
      "-\n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      ".\n",
      " \n",
      "h\n",
      "o\n",
      "w\n",
      "e\n",
      "v\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "a\n",
      "l\n",
      "y\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "e\n",
      "i\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "a\n",
      "i\n",
      "n\n",
      "e\n",
      "d\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "m\n",
      "a\n",
      "l\n",
      "l\n",
      " \n",
      "n\n",
      "u\n",
      "m\n",
      "b\n",
      "e\n",
      "r\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "o\n",
      "r\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "l\n",
      "a\n",
      "r\n",
      "g\n",
      "e\n",
      "l\n",
      "y\n",
      " \n",
      "s\n",
      "p\n",
      "a\n",
      "r\n",
      "s\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "\n",
      "\n",
      "o\n",
      "b\n",
      "s\n",
      "e\n",
      "r\n",
      "v\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "p\n",
      "a\n",
      "i\n",
      "r\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "e\n",
      "x\n",
      "c\n",
      "e\n",
      "p\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      "\n",
      "\n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "h\n",
      "a\n",
      "p\n",
      "p\n",
      "e\n",
      "n\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "o\n",
      "n\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      "-\n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      " \n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "s\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "d\n",
      "i\n",
      "d\n",
      " \n",
      "a\n",
      "c\n",
      "h\n",
      "i\n",
      "e\n",
      "v\n",
      "e\n",
      " \n",
      "h\n",
      "i\n",
      "g\n",
      "h\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "c\n",
      "u\n",
      "r\n",
      "a\n",
      "c\n",
      "y\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "u\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "w\n",
      "o\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "p\n",
      "a\n",
      "r\n",
      "s\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "i\n",
      "m\n",
      "a\n",
      "r\n",
      "y\n",
      " \n",
      "l\n",
      "i\n",
      "m\n",
      "i\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "a\n",
      "d\n",
      "v\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "i\n",
      "t\n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "i\n",
      "d\n",
      "e\n",
      "a\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "r\n",
      "o\n",
      "b\n",
      "o\n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      "\n",
      "\n",
      "p\n",
      "o\n",
      "o\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "o\n",
      " \n",
      "“\n",
      "g\n",
      "r\n",
      "o\n",
      "u\n",
      "p\n",
      "s\n",
      "”\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "n\n",
      " \n",
      "g\n",
      "e\n",
      "n\n",
      "e\n",
      "r\n",
      "a\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "k\n",
      "e\n",
      "d\n",
      " \n",
      "w\n",
      "e\n",
      "l\n",
      "l\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "s\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "[\n",
      "9\n",
      "]\n",
      ".\n",
      "\n",
      "\n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "k\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "l\n",
      "l\n",
      "e\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "u\n",
      "r\n",
      " \n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "i\n",
      "n\n",
      "\n",
      "\n",
      "o\n",
      "r\n",
      "d\n",
      "e\n",
      "r\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "e\n",
      "n\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "f\n",
      "e\n",
      "a\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "b\n",
      "e\n",
      "l\n",
      "i\n",
      "e\n",
      "v\n",
      "e\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "n\n",
      "e\n",
      "c\n",
      "e\n",
      "s\n",
      "s\n",
      "a\n",
      "r\n",
      "y\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      ",\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "p\n",
      "o\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      "f\n",
      "u\n",
      "l\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      "s\n",
      "\n",
      "\n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "v\n",
      "e\n",
      "l\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      ".\n",
      " \n",
      "m\n",
      "e\n",
      "t\n",
      "h\n",
      "o\n",
      "d\n",
      "s\n",
      "\n",
      "\n",
      "i\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "m\n",
      "o\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "e\n",
      "d\n",
      "m\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "d\n",
      "o\n",
      " \n",
      "s\n",
      "e\n",
      "c\n",
      "o\n",
      "n\n",
      "d\n",
      "a\n",
      "r\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "a\n",
      "l\n",
      "y\n",
      "s\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      " \n",
      "m\n",
      "u\n",
      "l\n",
      "t\n",
      "i\n",
      "p\n",
      "l\n",
      "e\n",
      "\n",
      "\n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      ".\n",
      " \n",
      "h\n",
      "o\n",
      "w\n",
      "e\n",
      "v\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "i\n",
      "t\n",
      " \n",
      "c\n",
      "a\n",
      "n\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "i\n",
      "c\n",
      "u\n",
      "l\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "f\n",
      "i\n",
      "n\n",
      "d\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "(\n",
      "1\n",
      ")\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "a\n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "i\n",
      "z\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "n\n",
      "u\n",
      "m\n",
      "b\n",
      "e\n",
      "r\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      ",\n",
      " \n",
      "(\n",
      "2\n",
      ")\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "a\n",
      "i\n",
      "n\n",
      " \n",
      "m\n",
      "a\n",
      "n\n",
      "y\n",
      "\n",
      "\n",
      "o\n",
      "b\n",
      "s\n",
      "e\n",
      "r\n",
      "v\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "(\n",
      "i\n",
      ".\n",
      "e\n",
      ".\n",
      ",\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      " \n",
      "s\n",
      "p\n",
      "a\n",
      "r\n",
      "s\n",
      "e\n",
      ")\n",
      ",\n",
      "\n",
      "\n",
      "(\n",
      "3\n",
      ")\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "a\n",
      "i\n",
      "n\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "s\n",
      "p\n",
      "a\n",
      "n\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      " \n",
      "r\n",
      "a\n",
      "n\n",
      "g\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "o\n",
      "m\n",
      "a\n",
      "i\n",
      "n\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "(\n",
      "4\n",
      ")\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "a\n",
      "i\n",
      "n\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "o\n",
      "u\n",
      "t\n",
      "-\n",
      "o\n",
      "f\n",
      "-\n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      "l\n",
      "l\n",
      "-\n",
      "m\n",
      "a\n",
      "p\n",
      "p\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      ".\n",
      "\n",
      "\n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "k\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "w\n",
      "a\n",
      "n\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "c\n",
      "l\n",
      "o\n",
      "s\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "a\n",
      "n\n",
      " \n",
      "“\n",
      "i\n",
      "d\n",
      "e\n",
      "a\n",
      "l\n",
      "”\n",
      "\n",
      "\n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "p\n",
      "o\n",
      "s\n",
      "s\n",
      "i\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "l\n",
      "l\n",
      "e\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "u\n",
      "r\n",
      " \n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "i\n",
      "z\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "n\n",
      "u\n",
      "m\n",
      "b\n",
      "e\n",
      "r\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "(\n",
      "1\n",
      "9\n",
      "6\n",
      ")\n",
      ",\n",
      "\n",
      "\n",
      "m\n",
      "a\n",
      "n\n",
      "y\n",
      " \n",
      "o\n",
      "b\n",
      "s\n",
      "e\n",
      "r\n",
      "v\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "(\n",
      "5\n",
      "-\n",
      "5\n",
      "0\n",
      ",\n",
      " \n",
      "d\n",
      "e\n",
      "p\n",
      "e\n",
      "n\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      ")\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "e\n",
      "n\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "a\n",
      " \n",
      "w\n",
      "i\n",
      "d\n",
      "e\n",
      " \n",
      "r\n",
      "a\n",
      "n\n",
      "g\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "l\n",
      "e\n",
      "v\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "w\n",
      "a\n",
      "s\n",
      " \n",
      "r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "o\n",
      "u\n",
      "r\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "a\n",
      "l\n",
      "l\n",
      "o\n",
      "w\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "p\n",
      "o\n",
      "s\n",
      "s\n",
      "i\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "c\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "c\n",
      "a\n",
      "p\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "v\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      ".\n",
      "1\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "c\n",
      "o\n",
      "l\n",
      "l\n",
      "e\n",
      "c\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "1\n",
      "9\n",
      "6\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      ",\n",
      " \n",
      "s\n",
      "p\n",
      "a\n",
      "n\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "1\n",
      "0\n",
      " \n",
      "c\n",
      "l\n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      " \n",
      "t\n",
      "a\n",
      "u\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "t\n",
      "h\n",
      "r\n",
      "e\n",
      "e\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "t\n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      "e\n",
      "r\n",
      "s\n",
      ",\n",
      " \n",
      "e\n",
      "n\n",
      "r\n",
      "o\n",
      "l\n",
      "l\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "h\n",
      "i\n",
      "g\n",
      "h\n",
      " \n",
      "s\n",
      "c\n",
      "h\n",
      "o\n",
      "o\n",
      "l\n",
      " \n",
      "g\n",
      "e\n",
      "o\n",
      "m\n",
      "e\n",
      "t\n",
      "r\n",
      "y\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "t\n",
      "i\n",
      "c\n",
      "i\n",
      "p\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "d\n",
      "u\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "a\n",
      "b\n",
      "o\n",
      "u\n",
      "t\n",
      " \n",
      "a\n",
      " \n",
      "m\n",
      "o\n",
      "n\n",
      "t\n",
      "h\n",
      " \n",
      "a\n",
      "p\n",
      "a\n",
      "r\n",
      "t\n",
      ".\n",
      " \n",
      "a\n",
      " \n",
      "r\n",
      "a\n",
      "n\n",
      "g\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "c\n",
      "l\n",
      "u\n",
      "d\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "y\n",
      ".\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "1\n",
      "0\n",
      " \n",
      "c\n",
      "l\n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "“\n",
      "h\n",
      "o\n",
      "n\n",
      "o\n",
      "r\n",
      "s\n",
      "”\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "r\n",
      "e\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "1\n",
      "0\n",
      " \n",
      "c\n",
      "l\n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "“\n",
      "i\n",
      "n\n",
      "c\n",
      "l\n",
      "u\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      "”\n",
      ".\n",
      " \n",
      "h\n",
      "o\n",
      "n\n",
      "o\n",
      "r\n",
      "s\n",
      "\n",
      "\n",
      "c\n",
      "l\n",
      "a\n",
      "s\n",
      "s\n",
      "r\n",
      "o\n",
      "o\n",
      "m\n",
      "s\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "n\n",
      "d\n",
      "e\n",
      "d\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "w\n",
      "h\n",
      "o\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "o\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "o\n",
      "r\n",
      "e\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "e\n",
      "s\n",
      "t\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "m\n",
      "a\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "c\n",
      "s\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      "c\n",
      "l\n",
      "u\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "c\n",
      "l\n",
      "a\n",
      "s\n",
      "s\n",
      "r\n",
      "o\n",
      "o\n",
      "m\n",
      "s\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "f\n",
      "i\n",
      "g\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "1\n",
      ".\n",
      " \n",
      "e\n",
      "x\n",
      "a\n",
      "m\n",
      "p\n",
      "l\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "l\n",
      "e\n",
      "m\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "f\n",
      "a\n",
      "c\n",
      "e\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "l\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "y\n",
      "s\n",
      "t\n",
      "e\n",
      "m\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "c\n",
      "o\n",
      "l\n",
      "l\n",
      "e\n",
      "c\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ".\n",
      "\n",
      "\n",
      "w\n",
      "e\n",
      " \n",
      "a\n",
      "l\n",
      "s\n",
      "o\n",
      " \n",
      "c\n",
      "o\n",
      "l\n",
      "l\n",
      "e\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      "-\n",
      "r\n",
      "e\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      " \n",
      "s\n",
      "u\n",
      "r\n",
      "v\n",
      "e\n",
      "y\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "m\n",
      "o\n",
      "t\n",
      "i\n",
      "v\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "s\n",
      "\n",
      "\n",
      "f\n",
      "a\n",
      "l\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "l\n",
      "o\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "r\n",
      "e\n",
      "e\n",
      " \n",
      "d\n",
      "i\n",
      "m\n",
      "e\n",
      "n\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "e\n",
      "t\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      "n\n",
      "e\n",
      "s\n",
      "s\n",
      " \n",
      "(\n",
      "e\n",
      ".\n",
      "g\n",
      ".\n",
      ",\n",
      "\n",
      "\n",
      "“\n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      ",\n",
      " \n",
      "i\n",
      " \n",
      "a\n",
      "m\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "i\n",
      "v\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "d\n",
      "o\n",
      " \n",
      "w\n",
      "e\n",
      "l\n",
      "l\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "a\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "o\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      "”\n",
      "\n",
      "\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "“\n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      ",\n",
      " \n",
      "i\n",
      " \n",
      "a\n",
      "m\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "i\n",
      "v\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "a\n",
      "v\n",
      "o\n",
      "i\n",
      "d\n",
      " \n",
      "p\n",
      "e\n",
      "r\n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "s\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "n\n",
      "\n",
      "\n",
      "o\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "s\n",
      "”\n",
      ")\n",
      ",\n",
      " \n",
      "e\n",
      "f\n",
      "f\n",
      "o\n",
      "r\n",
      "t\n",
      " \n",
      "(\n",
      "e\n",
      ".\n",
      "g\n",
      ".\n",
      ",\n",
      " \n",
      "“\n",
      "i\n",
      " \n",
      "a\n",
      "m\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "i\n",
      "v\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "u\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "o\n",
      "f\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "r\n",
      "o\n",
      "u\n",
      "g\n",
      "h\n",
      "l\n",
      "y\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "p\n",
      "o\n",
      "s\n",
      "s\n",
      "i\n",
      "b\n",
      "l\n",
      "e\n",
      "”\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "“\n",
      "i\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "k\n",
      " \n",
      "h\n",
      "a\n",
      "r\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "d\n",
      "o\n",
      " \n",
      "w\n",
      "e\n",
      "l\n",
      "l\n",
      " \n",
      "i\n",
      "n\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "c\n",
      "l\n",
      "a\n",
      "s\n",
      "s\n",
      " \n",
      "e\n",
      "v\n",
      "e\n",
      "n\n",
      " \n",
      "i\n",
      "f\n",
      " \n",
      "i\n",
      " \n",
      "d\n",
      "o\n",
      "n\n",
      "'\n",
      "t\n",
      " \n",
      "l\n",
      "i\n",
      "k\n",
      "e\n",
      " \n",
      "w\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "d\n",
      "o\n",
      "i\n",
      "n\n",
      "g\n",
      "”\n",
      ")\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "d\n",
      "i\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "e\n",
      ".\n",
      "g\n",
      ".\n",
      ",\n",
      " \n",
      "“\n",
      "w\n",
      "h\n",
      "e\n",
      "n\n",
      " \n",
      "c\n",
      "l\n",
      "a\n",
      "s\n",
      "s\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "k\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "i\n",
      "c\n",
      "u\n",
      "l\n",
      "t\n",
      ",\n",
      " \n",
      "i\n",
      " \n",
      "g\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "u\n",
      "p\n",
      " \n",
      "o\n",
      "r\n",
      " \n",
      "o\n",
      "n\n",
      "l\n",
      "y\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "y\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "e\n",
      "a\n",
      "s\n",
      "y\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "t\n",
      "s\n",
      "”\n",
      " \n",
      "[\n",
      "i\n",
      "n\n",
      "v\n",
      "e\n",
      "r\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "c\n",
      "a\n",
      "l\n",
      "e\n",
      "]\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "“\n",
      "i\n",
      " \n",
      "a\n",
      "m\n",
      " \n",
      "d\n",
      "i\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "t\n",
      "”\n",
      ")\n",
      ".\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      "-\n",
      "r\n",
      "e\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "\n",
      "\n",
      "m\n",
      "e\n",
      "a\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "c\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "a\n",
      " \n",
      "l\n",
      "i\n",
      "k\n",
      "e\n",
      "r\n",
      "t\n",
      " \n",
      "s\n",
      "c\n",
      "a\n",
      "l\n",
      "e\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "1\n",
      "-\n",
      "7\n",
      ".\n",
      "\n",
      "\n",
      "a\n",
      " \n",
      "k\n",
      "e\n",
      "y\n",
      " \n",
      "r\n",
      "e\n",
      "a\n",
      "s\n",
      "o\n",
      "n\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "l\n",
      "l\n",
      "e\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      ",\n",
      " \n",
      "c\n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "d\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "n\n",
      "c\n",
      "t\n",
      "\n",
      "\n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "u\n",
      "r\n",
      "r\n",
      "i\n",
      "c\n",
      "u\n",
      "l\n",
      "u\n",
      "m\n",
      ",\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "e\n",
      "s\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "v\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "g\n",
      "a\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "i\n",
      "s\n",
      "t\n",
      "e\n",
      "n\n",
      "c\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      "l\n",
      "e\n",
      "v\n",
      "e\n",
      "l\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "a\n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      ",\n",
      " \n",
      "t\n",
      "i\n",
      "m\n",
      "e\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "x\n",
      "t\n",
      "s\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "d\n",
      "i\n",
      "s\n",
      "c\n",
      "u\n",
      "s\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      "\n",
      "\n",
      "f\n",
      "u\n",
      "r\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "a\n",
      "l\n",
      "o\n",
      "n\n",
      "g\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "m\n",
      "i\n",
      "n\n",
      "a\n",
      "r\n",
      "y\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "u\n",
      "l\n",
      "t\n",
      "s\n",
      ",\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "s\n",
      "e\n",
      "c\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "4\n",
      ".\n",
      "4\n",
      ".\n",
      "1\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      ".\n",
      "2\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      "\n",
      "\n",
      "3\n",
      ".\n",
      "2\n",
      ".\n",
      "1\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      "-\n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      " \n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "s\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "(\n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      ")\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "s\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "(\n",
      "a\n",
      "f\n",
      "m\n",
      ")\n",
      " \n",
      "[\n",
      "2\n",
      "]\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "l\n",
      "o\n",
      "g\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      " \n",
      "r\n",
      "e\n",
      "g\n",
      "r\n",
      "e\n",
      "s\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "e\n",
      "x\n",
      "t\n",
      "e\n",
      "n\n",
      "d\n",
      "s\n",
      " \n",
      "i\n",
      "t\n",
      "e\n",
      "m\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "p\n",
      "o\n",
      "n\n",
      "s\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "o\n",
      "r\n",
      "y\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "i\n",
      "n\n",
      "c\n",
      "o\n",
      "r\n",
      "p\n",
      "o\n",
      "r\n",
      "a\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "\n",
      "\n",
      "g\n",
      "r\n",
      "o\n",
      "w\n",
      "t\n",
      "h\n",
      " \n",
      "o\n",
      "r\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "e\n",
      "r\n",
      "m\n",
      ".\n",
      "\n",
      "\n",
      "l\n",
      "n\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "!\n",
      "!\n",
      "\"\n",
      "\n",
      "\n",
      "!\n",
      "-\n",
      "!\n",
      "!\n",
      "\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=\n",
      " \n",
      "θ\n",
      "!\n",
      " \n",
      "+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "!\n",
      "∈\n",
      "!\n",
      "\"\n",
      "#\n",
      " \n",
      "q\n",
      " \n",
      "!\n",
      "\"\n",
      " \n",
      "(\n",
      "β\n",
      "!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+\n",
      " \n",
      "γ\n",
      "!\n",
      " \n",
      "t\n",
      "!\n",
      "\"\n",
      " \n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "1\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "3\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\f",
      "\n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "(\n",
      "e\n",
      "q\n",
      "u\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "1\n",
      ")\n",
      " \n",
      "g\n",
      "i\n",
      "v\n",
      "e\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "𝑝\n",
      "!\n",
      "\"\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "a\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "i\n",
      " \n",
      "w\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "g\n",
      "e\n",
      "t\n",
      " \n",
      "a\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "l\n",
      "e\n",
      "m\n",
      " \n",
      "s\n",
      "t\n",
      "e\n",
      "p\n",
      " \n",
      "j\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "r\n",
      "e\n",
      "c\n",
      "t\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "’\n",
      "s\n",
      "\n",
      "\n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "(\n",
      "𝜃\n",
      "!\n",
      " \n",
      ")\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "e\n",
      "a\n",
      "s\n",
      "i\n",
      "n\n",
      "e\n",
      "s\n",
      "s\n",
      " \n",
      "(\n",
      "𝛽\n",
      "!\n",
      " \n",
      ")\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "i\n",
      "r\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "o\n",
      "n\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "l\n",
      "e\n",
      "m\n",
      " \n",
      "s\n",
      "t\n",
      "e\n",
      "p\n",
      " \n",
      "(\n",
      "𝑄\n",
      "!\n",
      "\"\n",
      " \n",
      ")\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "(\n",
      "𝛾\n",
      "!\n",
      " \n",
      ")\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "i\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "o\n",
      "n\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "(\n",
      "k\n",
      "c\n",
      ")\n",
      "\n",
      "\n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "y\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "k\n",
      "c\n",
      " \n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      ",\n",
      " \n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "“\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      ",\n",
      "”\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "m\n",
      "u\n",
      "l\n",
      "t\n",
      "i\n",
      "p\n",
      "l\n",
      "i\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "n\n",
      "u\n",
      "m\n",
      "b\n",
      "e\n",
      "r\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      "\n",
      "\n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "(\n",
      "𝑇\n",
      "!\n",
      "\"\n",
      " \n",
      ")\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "l\n",
      "r\n",
      "e\n",
      "a\n",
      "d\n",
      "y\n",
      " \n",
      "h\n",
      "a\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "i\n",
      "t\n",
      ".\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "o\n",
      "n\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "(\n",
      "k\n",
      "c\n",
      "s\n",
      ")\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "u\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "l\n",
      "y\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      "s\n",
      ",\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      "s\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "c\n",
      "e\n",
      "p\n",
      "t\n",
      "s\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "i\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "s\n",
      "o\n",
      "l\n",
      "v\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "l\n",
      "e\n",
      "m\n",
      "s\n",
      " \n",
      "[\n",
      "6\n",
      "]\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "l\n",
      "i\n",
      "t\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "a\n",
      "r\n",
      "i\n",
      "s\n",
      "o\n",
      "n\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "c\n",
      "u\n",
      "r\n",
      "a\n",
      "c\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      "\n",
      "\n",
      "c\n",
      "l\n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "d\n",
      "u\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "y\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "c\n",
      "o\n",
      "m\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "t\n",
      "o\n",
      "w\n",
      "a\n",
      "r\n",
      "d\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "l\n",
      "a\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "(\n",
      "b\n",
      "k\n",
      "t\n",
      "/\n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      "\n",
      "\n",
      "d\n",
      "o\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "a\n",
      "f\n",
      "m\n",
      "/\n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "d\n",
      "o\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      ")\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      "-\n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      " \n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "(\n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      ")\n",
      " \n",
      "b\n",
      "u\n",
      "i\n",
      "l\n",
      "d\n",
      "s\n",
      " \n",
      "u\n",
      "p\n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      " \n",
      "p\n",
      "e\n",
      "r\n",
      "-\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "(\n",
      "𝛿\n",
      "!\n",
      " \n",
      ")\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "r\n",
      "e\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "(\n",
      "𝛿\n",
      "!\n",
      " \n",
      ")\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "i\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "e\n",
      "v\n",
      "e\n",
      "r\n",
      "y\n",
      "\n",
      "\n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "k\n",
      "c\n",
      "s\n",
      " \n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "i\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "l\n",
      "e\n",
      "m\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "e\n",
      "p\n",
      " \n",
      "j\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "u\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "m\n",
      "a\n",
      "j\n",
      "o\n",
      "r\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "f\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "s\n",
      " \n",
      "r\n",
      "e\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "[\n",
      "9\n",
      "]\n",
      ",\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      "\n",
      "\n",
      "a\n",
      "c\n",
      "h\n",
      "i\n",
      "e\n",
      "v\n",
      "e\n",
      "d\n",
      " \n",
      "h\n",
      "i\n",
      "g\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "c\n",
      "u\n",
      "r\n",
      "a\n",
      "c\n",
      "y\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "n\n",
      " \n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      "\n",
      "\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "f\n",
      "u\n",
      "r\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "s\n",
      "u\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "i\n",
      "d\n",
      "e\n",
      "a\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "“\n",
      "d\n",
      "e\n",
      "p\n",
      "t\n",
      "h\n",
      "”\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "\n",
      "\n",
      "i\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "c\n",
      "r\n",
      "i\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      " \n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "a\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "c\n",
      "a\n",
      "n\n",
      " \n",
      "e\n",
      "x\n",
      "p\n",
      "l\n",
      "a\n",
      "i\n",
      "n\n",
      " \n",
      "u\n",
      "n\n",
      "i\n",
      "q\n",
      "u\n",
      "e\n",
      " \n",
      "v\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "l\n",
      "n\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "!\n",
      "!\n",
      "\"\n",
      "\n",
      "\n",
      "!\n",
      "!\n",
      "!\n",
      "!\n",
      "\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=\n",
      " \n",
      "𝜃\n",
      "!\n",
      " \n",
      "+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "!\n",
      "∈\n",
      "!\n",
      "\"\n",
      "#\n",
      " \n",
      "𝑄\n",
      "!\n",
      "\"\n",
      " \n",
      "(\n",
      "𝛽\n",
      "!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+\n",
      " \n",
      "𝛾\n",
      "!\n",
      " \n",
      "𝑇\n",
      "!\n",
      "\"\n",
      " \n",
      "+\n",
      " \n",
      "𝛿\n",
      "!\n",
      " \n",
      "𝑇\n",
      "!\n",
      "\"\n",
      " \n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "2\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "k\n",
      "c\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "m\n",
      "u\n",
      "l\n",
      "t\n",
      "i\n",
      "p\n",
      "l\n",
      "i\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "b\n",
      "y\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "n\n",
      "u\n",
      "m\n",
      "b\n",
      "e\n",
      "r\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "(\n",
      "𝑇\n",
      "!\n",
      "\"\n",
      " \n",
      ")\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "l\n",
      "r\n",
      "e\n",
      "a\n",
      "d\n",
      "y\n",
      " \n",
      "h\n",
      "a\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "k\n",
      "c\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "o\n",
      "u\n",
      "t\n",
      "p\n",
      "e\n",
      "r\n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      " \n",
      "n\n",
      "o\n",
      "n\n",
      "-\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "u\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "p\n",
      "a\n",
      "r\n",
      "t\n",
      "s\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "a\n",
      "l\n",
      "l\n",
      " \n",
      "m\n",
      "e\n",
      "t\n",
      "r\n",
      "i\n",
      "c\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "e\n",
      "x\n",
      "c\n",
      "e\n",
      "p\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "\n",
      "\n",
      "b\n",
      "e\n",
      "t\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "b\n",
      "i\n",
      "c\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "u\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "n\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "4\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      "\n",
      "\n",
      "s\n",
      "u\n",
      "r\n",
      "p\n",
      "r\n",
      "i\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      ",\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "b\n",
      "i\n",
      "c\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "-\n",
      "p\n",
      "e\n",
      "n\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "a\n",
      "d\n",
      "d\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "c\n",
      "o\n",
      "m\n",
      "m\n",
      "e\n",
      "n\n",
      "d\n",
      " \n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "c\n",
      "a\n",
      "t\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "u\n",
      "e\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "f\n",
      "i\n",
      "t\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "c\n",
      "a\n",
      "s\n",
      "e\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "t\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "1\n",
      ".\n",
      " \n",
      "s\n",
      "u\n",
      "m\n",
      "m\n",
      "a\n",
      "r\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "f\n",
      "i\n",
      "t\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "c\n",
      "u\n",
      "r\n",
      "a\n",
      "c\n",
      "y\n",
      "\n",
      "\n",
      "m\n",
      "e\n",
      "t\n",
      "r\n",
      "i\n",
      "c\n",
      "s\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "a\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "v\n",
      "s\n",
      ".\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "v\n",
      "s\n",
      ".\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      ".\n",
      " \n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "u\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "n\n",
      " \n",
      "r\n",
      "m\n",
      "s\n",
      "e\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "u\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      " \n",
      "1\n",
      "0\n",
      " \n",
      "r\n",
      "u\n",
      "n\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "d\n",
      "a\n",
      "r\n",
      "d\n",
      " \n",
      "d\n",
      "e\n",
      "v\n",
      "i\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      "c\n",
      "l\n",
      "u\n",
      "d\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "\n",
      "\n",
      "s\n",
      "e\n",
      "t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      ".\n",
      "2\n",
      ".\n",
      "2\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "a\n",
      "y\n",
      "e\n",
      "s\n",
      "i\n",
      "a\n",
      "n\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "(\n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      ")\n",
      "\n",
      "\n",
      "b\n",
      "a\n",
      "y\n",
      "e\n",
      "s\n",
      "i\n",
      "a\n",
      "n\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "(\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "[\n",
      "3\n",
      "]\n",
      ")\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      " \n",
      "a\n",
      "l\n",
      "g\n",
      "o\n",
      "r\n",
      "i\n",
      "t\n",
      "h\n",
      "m\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "l\n",
      "a\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "v\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "u\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      " \n",
      "h\n",
      "i\n",
      "d\n",
      "d\n",
      "e\n",
      "n\n",
      "\n",
      "\n",
      "m\n",
      "a\n",
      "r\n",
      "k\n",
      "o\n",
      "v\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "g\n",
      "o\n",
      "a\n",
      "l\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "i\n",
      "n\n",
      "f\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      ",\n",
      "\n",
      "\n",
      "w\n",
      "h\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "h\n",
      "a\n",
      "s\n",
      " \n",
      "m\n",
      "a\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "t\n",
      " \n",
      "o\n",
      "r\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "h\n",
      "i\n",
      "s\n",
      "/\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "s\n",
      "e\n",
      "q\n",
      "u\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "\n",
      "\n",
      "o\n",
      "f\n",
      " \n",
      "p\n",
      "e\n",
      "r\n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "i\n",
      "t\n",
      "e\n",
      "m\n",
      "s\n",
      " \n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "i\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      ".\n",
      " \n",
      "i\n",
      "t\n",
      " \n",
      "a\n",
      "s\n",
      "s\n",
      "u\n",
      "m\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      "s\n",
      "t\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "b\n",
      "y\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "e\n",
      "i\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "u\n",
      "n\n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "n\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "f\n",
      "o\n",
      "u\n",
      "r\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      " \n",
      "b\n",
      "k\n",
      "t\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      ":\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "a\n",
      "l\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "a\n",
      " \n",
      "p\n",
      "r\n",
      "i\n",
      "o\n",
      "r\n",
      "i\n",
      " \n",
      "–\n",
      " \n",
      "p\n",
      "(\n",
      "i\n",
      "n\n",
      "i\n",
      "t\n",
      ")\n",
      ",\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "n\n",
      "s\n",
      "i\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "n\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "a\n",
      "f\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "a\n",
      "n\n",
      " \n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      " \n",
      "i\n",
      "t\n",
      " \n",
      "–\n",
      " \n",
      "p\n",
      "(\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      ")\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      "\n",
      "\n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "l\n",
      "i\n",
      "p\n",
      "p\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "n\n",
      " \n",
      "a\n",
      "p\n",
      "p\n",
      "l\n",
      "y\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "–\n",
      " \n",
      "p\n",
      "(\n",
      "s\n",
      "l\n",
      "i\n",
      "p\n",
      ")\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "r\n",
      "e\n",
      "c\n",
      "t\n",
      "l\n",
      "y\n",
      " \n",
      "g\n",
      "u\n",
      "e\n",
      "s\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      "o\n",
      "u\n",
      "t\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "q\n",
      "u\n",
      "i\n",
      "r\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "–\n",
      " \n",
      "p\n",
      "(\n",
      "g\n",
      "u\n",
      "e\n",
      "s\n",
      "s\n",
      ")\n",
      ".\n",
      " \n",
      "f\n",
      "i\n",
      "t\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "d\n",
      "u\n",
      "c\n",
      "e\n",
      "s\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "\n",
      "\n",
      "f\n",
      "o\n",
      "u\n",
      "r\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "v\n",
      "e\n",
      "r\n",
      "y\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      " \n",
      "g\n",
      "i\n",
      "v\n",
      "e\n",
      "n\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      ".\n",
      " \n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "u\n",
      "s\n",
      "u\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      " \n",
      "f\n",
      "i\n",
      "t\n",
      " \n",
      "u\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "e\n",
      "x\n",
      "p\n",
      "e\n",
      "c\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "m\n",
      "a\n",
      "x\n",
      "i\n",
      "m\n",
      "i\n",
      "z\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "m\n",
      "e\n",
      "t\n",
      "h\n",
      "o\n",
      "d\n",
      " \n",
      "(\n",
      "e\n",
      "m\n",
      ")\n",
      ",\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "j\n",
      "u\n",
      "g\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "g\n",
      "r\n",
      "a\n",
      "d\n",
      "i\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "c\n",
      "h\n",
      ",\n",
      " \n",
      "o\n",
      "r\n",
      " \n",
      "d\n",
      "i\n",
      "s\n",
      "c\n",
      "r\n",
      "e\n",
      "t\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "r\n",
      "u\n",
      "t\n",
      "e\n",
      "-\n",
      "f\n",
      "o\n",
      "r\n",
      "c\n",
      "e\n",
      " \n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "c\n",
      "h\n",
      ".\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "a\n",
      "y\n",
      "e\n",
      "s\n",
      "i\n",
      "a\n",
      "n\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "(\n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "[\n",
      "1\n",
      "8\n",
      "]\n",
      ")\n",
      " \n",
      "b\n",
      "u\n",
      "i\n",
      "l\n",
      "d\n",
      "s\n",
      "\n",
      "\n",
      "u\n",
      "p\n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "i\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      ",\n",
      " \n",
      "p\n",
      "(\n",
      "i\n",
      "n\n",
      "i\n",
      "t\n",
      ")\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "t\n",
      "r\n",
      "a\n",
      "n\n",
      "s\n",
      "i\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      ",\n",
      " \n",
      "p\n",
      "(\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      ")\n",
      ",\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      ".\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "a\n",
      "c\n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "l\n",
      "i\n",
      "s\n",
      "h\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      "l\n",
      "e\n",
      "v\n",
      "e\n",
      "l\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      ",\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "o\n",
      "f\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "s\n",
      "p\n",
      "l\n",
      "i\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "o\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      "-\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "o\n",
      "n\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "s\n",
      "u\n",
      "m\n",
      "m\n",
      "e\n",
      "d\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "p\n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "r\n",
      "o\n",
      "u\n",
      "g\n",
      "h\n",
      " \n",
      "a\n",
      " \n",
      "l\n",
      "o\n",
      "g\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "n\n",
      "s\n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "y\n",
      "i\n",
      "e\n",
      "l\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "f\n",
      "i\n",
      "n\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      ".\n",
      " \n",
      "d\n",
      "e\n",
      "t\n",
      "a\n",
      "i\n",
      "l\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "o\n",
      "s\n",
      "i\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "p\n",
      "(\n",
      "i\n",
      "n\n",
      "i\n",
      "t\n",
      ")\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "p\n",
      "(\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      ")\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "o\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      "-\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "o\n",
      "n\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "s\n",
      "c\n",
      "r\n",
      "i\n",
      "b\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      " \n",
      "[\n",
      "1\n",
      "8\n",
      "]\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      ".\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "u\n",
      "l\n",
      "t\n",
      "s\n",
      "\n",
      "\n",
      "4\n",
      ".\n",
      "1\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "f\n",
      "i\n",
      "t\n",
      " \n",
      "&\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "c\n",
      "u\n",
      "r\n",
      "a\n",
      "c\n",
      "y\n",
      "\n",
      "\n",
      "a\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "f\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "p\n",
      "a\n",
      "s\n",
      "s\n",
      " \n",
      "e\n",
      "v\n",
      "a\n",
      "l\n",
      "u\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      "\n",
      "\n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      " \n",
      "u\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "k\n",
      "a\n",
      "i\n",
      "k\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "c\n",
      "r\n",
      "i\n",
      "t\n",
      "e\n",
      "r\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "(\n",
      "a\n",
      "i\n",
      "c\n",
      ")\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "b\n",
      "a\n",
      "y\n",
      "e\n",
      "s\n",
      "i\n",
      "a\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "c\n",
      "r\n",
      "i\n",
      "t\n",
      "e\n",
      "r\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "(\n",
      "b\n",
      "i\n",
      "c\n",
      ")\n",
      ",\n",
      " \n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "d\n",
      "a\n",
      "r\n",
      "d\n",
      " \n",
      "m\n",
      "e\n",
      "t\n",
      "r\n",
      "i\n",
      "c\n",
      "s\n",
      "\n",
      "\n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "a\n",
      "r\n",
      "i\n",
      "s\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "1\n",
      "0\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "e\n",
      "p\n",
      "e\n",
      "n\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "r\n",
      "u\n",
      "n\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "p\n",
      "l\n",
      "i\n",
      "t\n",
      "-\n",
      "h\n",
      "a\n",
      "l\n",
      "v\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "(\n",
      "c\n",
      "v\n",
      ")\n",
      ".\n",
      " \n",
      "a\n",
      "l\n",
      "t\n",
      "h\n",
      "o\n",
      "u\n",
      "g\n",
      "h\n",
      " \n",
      "1\n",
      "0\n",
      "-\n",
      "f\n",
      "o\n",
      "l\n",
      "d\n",
      " \n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "h\n",
      "a\n",
      "s\n",
      " \n",
      "b\n",
      "e\n",
      "e\n",
      "n\n",
      "\n",
      "\n",
      "p\n",
      "o\n",
      "p\n",
      "u\n",
      "l\n",
      "a\n",
      "r\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "f\n",
      "i\n",
      "e\n",
      "l\n",
      "d\n",
      ",\n",
      " \n",
      "[\n",
      "4\n",
      "]\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "w\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "i\n",
      "t\n",
      " \n",
      "h\n",
      "a\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "h\n",
      "i\n",
      "g\n",
      "h\n",
      " \n",
      "t\n",
      "y\n",
      "p\n",
      "e\n",
      "-\n",
      "i\n",
      " \n",
      "e\n",
      "r\n",
      "r\n",
      "o\n",
      "r\n",
      " \n",
      "d\n",
      "u\n",
      "e\n",
      "\n",
      "\n",
      "t\n",
      "o\n",
      " \n",
      "h\n",
      "i\n",
      "g\n",
      "h\n",
      " \n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "l\n",
      "a\n",
      "p\n",
      " \n",
      "a\n",
      "m\n",
      "o\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "r\n",
      "e\n",
      "c\n",
      "o\n",
      "m\n",
      "m\n",
      "e\n",
      "n\n",
      "d\n",
      "e\n",
      "d\n",
      " \n",
      "a\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "s\n",
      "t\n",
      " \n",
      "5\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "2\n",
      "-\n",
      "f\n",
      "o\n",
      "l\n",
      "d\n",
      " \n",
      "c\n",
      "v\n",
      " \n",
      "i\n",
      "n\n",
      "s\n",
      "t\n",
      "e\n",
      "a\n",
      "d\n",
      ".\n",
      "\n",
      "\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "a\n",
      "r\n",
      "i\n",
      "s\n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "\n",
      "\n",
      "a\n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      "s\n",
      "t\n",
      " \n",
      "i\n",
      "t\n",
      "s\n",
      " \n",
      "n\n",
      "o\n",
      "n\n",
      "-\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "c\n",
      "o\n",
      "u\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "p\n",
      "a\n",
      "r\n",
      "t\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "d\n",
      "o\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      " \n",
      "e\n",
      "n\n",
      "c\n",
      "o\n",
      "u\n",
      "r\n",
      "a\n",
      "g\n",
      "e\n",
      " \n",
      "a\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "c\n",
      "h\n",
      ".\n",
      " \n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "c\n",
      "h\n",
      ".\n",
      " \n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "a\n",
      "i\n",
      "c\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b\n",
      "i\n",
      "c\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "a\n",
      "f\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "7\n",
      "2\n",
      "2\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "7\n",
      "2\n",
      "8\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "c\n",
      "v\n",
      " \n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "r\n",
      "m\n",
      "s\n",
      "e\n",
      "\n",
      "\n",
      "(\n",
      "1\n",
      "0\n",
      "-\n",
      "r\n",
      "u\n",
      "n\n",
      " \n",
      "a\n",
      "v\n",
      "e\n",
      "r\n",
      "a\n",
      "g\n",
      "e\n",
      ")\n",
      "\n",
      "\n",
      "0\n",
      ".\n",
      "3\n",
      "8\n",
      "4\n",
      "4\n",
      "0\n",
      " \n",
      "(\n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "3\n",
      "9\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "5\n",
      "9\n",
      "3\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "6\n",
      "0\n",
      "0\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      ".\n",
      "3\n",
      "7\n",
      "8\n",
      "6\n",
      "8\n",
      " \n",
      "(\n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "4\n",
      "4\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b\n",
      "k\n",
      "t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "6\n",
      "7\n",
      "1\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "7\n",
      "4\n",
      "7\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      ".\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      " \n",
      "(\n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "6\n",
      "3\n",
      "2\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "0\n",
      "4\n",
      "7\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      ".\n",
      "3\n",
      "7\n",
      "7\n",
      "7\n",
      " \n",
      "(\n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "0\n",
      "6\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "a\n",
      "f\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "8\n",
      "0\n",
      "5\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "8\n",
      "1\n",
      "0\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      ".\n",
      "4\n",
      "1\n",
      "0\n",
      "3\n",
      "7\n",
      " \n",
      "(\n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "4\n",
      "8\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "7\n",
      "8\n",
      "6\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "7\n",
      "9\n",
      "2\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      ".\n",
      "4\n",
      "0\n",
      "7\n",
      "8\n",
      "9\n",
      " \n",
      "(\n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b\n",
      "k\n",
      "t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "9\n",
      "9\n",
      "0\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "0\n",
      "3\n",
      "7\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      ".\n",
      "4\n",
      "4\n",
      "0\n",
      "9\n",
      "1\n",
      " \n",
      "(\n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "1\n",
      "4\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "8\n",
      "2\n",
      "8\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "1\n",
      "8\n",
      "0\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      ".\n",
      "4\n",
      "0\n",
      "7\n",
      "2\n",
      "5\n",
      " \n",
      "(\n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "1\n",
      "8\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      ".\n",
      "2\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      "\n",
      "\n",
      "n\n",
      "e\n",
      "x\n",
      "t\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "e\n",
      "x\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "g\n",
      "r\n",
      "e\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "c\n",
      "a\n",
      "n\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "y\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "r\n",
      "e\n",
      "a\n",
      "s\n",
      "o\n",
      "n\n",
      "a\n",
      "b\n",
      "l\n",
      "y\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "y\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      "\n",
      "\n",
      "b\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "b\n",
      "e\n",
      "l\n",
      "i\n",
      "e\n",
      "v\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "o\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "r\n",
      "e\n",
      "l\n",
      "y\n",
      "\n",
      "\n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "r\n",
      "c\n",
      "h\n",
      "i\n",
      "t\n",
      "e\n",
      "c\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "h\n",
      "i\n",
      "g\n",
      "h\n",
      " \n",
      "b\n",
      "a\n",
      "r\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      "i\n",
      "f\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "g\n",
      "e\n",
      "n\n",
      "u\n",
      "i\n",
      "n\n",
      "e\n",
      "l\n",
      "y\n",
      " \n",
      "d\n",
      "i\n",
      "s\n",
      "p\n",
      "l\n",
      "a\n",
      "y\n",
      "e\n",
      "d\n",
      " \n",
      "e\n",
      "v\n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "h\n",
      "i\n",
      "g\n",
      "h\n",
      " \n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "l\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "i\n",
      "n\n",
      "\n",
      "\n",
      "a\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      " \n",
      "(\n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "h\n",
      "i\n",
      "s\n",
      "/\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "p\n",
      "e\n",
      "e\n",
      "r\n",
      "s\n",
      ")\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "n\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      "\n",
      "\n",
      "s\n",
      "h\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "a\n",
      "s\n",
      "e\n",
      ".\n",
      "\n",
      "\n",
      "b\n",
      "e\n",
      "c\n",
      "a\n",
      "u\n",
      "s\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "o\n",
      "b\n",
      "s\n",
      "e\n",
      "r\n",
      "v\n",
      "e\n",
      "d\n",
      " \n",
      "n\n",
      "o\n",
      "n\n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "a\n",
      "r\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      "s\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      "\n",
      "\n",
      "l\n",
      "o\n",
      "g\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      " \n",
      "r\n",
      "e\n",
      "g\n",
      "r\n",
      "e\n",
      "s\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "b\n",
      "a\n",
      "y\n",
      "e\n",
      "s\n",
      "i\n",
      "a\n",
      "n\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "s\n",
      "p\n",
      "e\n",
      "a\n",
      "r\n",
      "m\n",
      "a\n",
      "n\n",
      "’\n",
      "s\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "e\n",
      "f\n",
      "f\n",
      "i\n",
      "c\n",
      "i\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "(\n",
      "r\n",
      "s\n",
      ")\n",
      ",\n",
      " \n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "r\n",
      "a\n",
      "n\n",
      "k\n",
      " \n",
      "o\n",
      "r\n",
      "d\n",
      "e\n",
      "r\n",
      ".\n",
      "\n",
      "\n",
      "w\n",
      "e\n",
      " \n",
      "o\n",
      "b\n",
      "s\n",
      "e\n",
      "r\n",
      "v\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "o\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      " \n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "\n",
      "\n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "c\n",
      "e\n",
      "p\n",
      "t\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "(\n",
      "i\n",
      "n\n",
      "i\n",
      "t\n",
      ")\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "(\n",
      "f\n",
      "i\n",
      "g\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "2\n",
      ",\n",
      " \n",
      "t\n",
      "o\n",
      "p\n",
      " \n",
      "r\n",
      "o\n",
      "w\n",
      ")\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "a\n",
      "l\n",
      "s\n",
      "o\n",
      " \n",
      "o\n",
      "b\n",
      "s\n",
      "e\n",
      "r\n",
      "v\n",
      "e\n",
      "d\n",
      " \n",
      "a\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "r\n",
      "o\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      " \n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "(\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      ")\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "o\n",
      "n\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "(\n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "4\n",
      ")\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "w\n",
      "a\n",
      "s\n",
      " \n",
      "m\n",
      "u\n",
      "c\n",
      "h\n",
      "\n",
      "\n",
      "m\n",
      "i\n",
      "l\n",
      "d\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "u\n",
      "g\n",
      "h\n",
      " \n",
      "s\n",
      "t\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      ",\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "o\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      " \n",
      "(\n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "3\n",
      ")\n",
      ".\n",
      "\n",
      "\n",
      "w\n",
      "e\n",
      " \n",
      "h\n",
      "y\n",
      "p\n",
      "o\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "i\n",
      "z\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "m\n",
      "a\n",
      "y\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "d\n",
      "u\n",
      "e\n",
      "\n",
      "\n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "i\n",
      "c\n",
      "u\n",
      "l\n",
      "t\n",
      " \n",
      "k\n",
      "c\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "4\n",
      ".\n",
      " \n",
      "a\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "i\n",
      "c\n",
      "u\n",
      "l\n",
      "t\n",
      " \n",
      "i\n",
      "t\n",
      "e\n",
      "m\n",
      "s\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "i\n",
      "d\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "s\n",
      "e\n",
      "n\n",
      "s\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      ",\n",
      " \n",
      "s\n",
      "i\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "i\n",
      "t\n",
      " \n",
      "a\n",
      "v\n",
      "o\n",
      "i\n",
      "d\n",
      "s\n",
      " \n",
      "c\n",
      "e\n",
      "i\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "e\n",
      "f\n",
      "f\n",
      "e\n",
      "c\n",
      "t\n",
      "s\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "e\n",
      "e\n",
      "d\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "w\n",
      "a\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "a\n",
      "s\n",
      "e\n",
      ":\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "n\n",
      " \n",
      "k\n",
      "c\n",
      " \n",
      "e\n",
      "a\n",
      "s\n",
      "i\n",
      "n\n",
      "e\n",
      "s\n",
      "s\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "(\n",
      "𝛽\n",
      "!\n",
      " \n",
      ")\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "4\n",
      " \n",
      "w\n",
      "a\n",
      "s\n",
      " \n",
      "0\n",
      ".\n",
      "7\n",
      "9\n",
      "9\n",
      " \n",
      "(\n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "n\n",
      "s\n",
      "l\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "a\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "3\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\f",
      "\n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "0\n",
      ".\n",
      "6\n",
      "9\n",
      ")\n",
      ",\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "a\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "1\n",
      ".\n",
      "2\n",
      "5\n",
      "3\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "3\n",
      " \n",
      "(\n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      "\n",
      "\n",
      "t\n",
      "r\n",
      "a\n",
      "n\n",
      "s\n",
      "l\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "a\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "0\n",
      ".\n",
      "7\n",
      "8\n",
      ")\n",
      ".\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "n\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "m\n",
      "a\n",
      "n\n",
      "y\n",
      " \n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      "t\n",
      " \n",
      "c\n",
      "e\n",
      "i\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "(\n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "w\n",
      "a\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "a\n",
      "s\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "t\n",
      "i\n",
      "c\n",
      "u\n",
      "l\n",
      "a\n",
      "r\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "3\n",
      ",\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "e\n",
      "x\n",
      "p\n",
      "l\n",
      "o\n",
      "r\n",
      "a\n",
      "t\n",
      "o\n",
      "r\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "a\n",
      "l\n",
      "y\n",
      "s\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      ")\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "w\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "o\n",
      "f\n",
      "t\n",
      "e\n",
      "n\n",
      " \n",
      "a\n",
      "s\n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      " \n",
      "a\n",
      " \n",
      "l\n",
      "o\n",
      "w\n",
      "e\n",
      "r\n",
      " \n",
      "“\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "”\n",
      " \n",
      "d\n",
      "u\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "a\n",
      "n\n",
      " \n",
      "e\n",
      "s\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      " \n",
      "f\n",
      "l\n",
      "a\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "j\n",
      "e\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "y\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "h\n",
      "a\n",
      "s\n",
      " \n",
      "s\n",
      "e\n",
      "v\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "d\n",
      "u\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "a\n",
      "p\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ".\n",
      " \n",
      "f\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      ",\n",
      " \n",
      "i\n",
      "t\n",
      " \n",
      "s\n",
      "u\n",
      "g\n",
      "g\n",
      "e\n",
      "s\n",
      "t\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "v\n",
      "i\n",
      "a\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "c\n",
      "e\n",
      "s\n",
      "s\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "u\n",
      "n\n",
      "f\n",
      "o\n",
      "l\n",
      "d\n",
      "s\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "r\n",
      "e\n",
      "a\n",
      "s\n",
      "o\n",
      "n\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      "\n",
      "\n",
      "m\n",
      "e\n",
      "t\n",
      "h\n",
      "o\n",
      "d\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      ".\n",
      "\n",
      "\n",
      "i\n",
      "t\n",
      " \n",
      "a\n",
      "l\n",
      "s\n",
      "o\n",
      " \n",
      "s\n",
      "u\n",
      "g\n",
      "g\n",
      "e\n",
      "s\n",
      "t\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "d\n",
      "e\n",
      "t\n",
      "a\n",
      "i\n",
      "l\n",
      "e\n",
      "d\n",
      " \n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "(\n",
      "e\n",
      ".\n",
      "g\n",
      ".\n",
      ",\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "a\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      ")\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "r\n",
      "e\n",
      "a\n",
      "s\n",
      "o\n",
      "n\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "e\n",
      "f\n",
      "f\n",
      "e\n",
      "c\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      "’\n",
      "\n",
      "\n",
      "“\n",
      "o\n",
      "n\n",
      "-\n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "”\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      "’\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "k\n",
      "c\n",
      "s\n",
      ".\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "x\n",
      "a\n",
      "m\n",
      "p\n",
      "l\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "b\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "k\n",
      "c\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "(\n",
      "d\n",
      "e\n",
      "r\n",
      "i\n",
      "v\n",
      "e\n",
      "d\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "-\n",
      "f\n",
      "i\n",
      "t\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "o\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "i\n",
      "o\n",
      "r\n",
      " \n",
      "d\n",
      "o\n",
      "m\n",
      "a\n",
      "i\n",
      "n\n",
      "-\n",
      "r\n",
      "e\n",
      "l\n",
      "e\n",
      "v\n",
      "a\n",
      "n\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      ")\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "c\n",
      "e\n",
      "p\n",
      "t\n",
      " \n",
      "p\n",
      "r\n",
      "i\n",
      "o\n",
      "r\n",
      "s\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "w\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "a\n",
      "l\n",
      "l\n",
      "o\n",
      "w\n",
      " \n",
      "a\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "l\n",
      "i\n",
      "k\n",
      "e\n",
      " \n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "t\n",
      "o\n",
      "\n",
      "\n",
      "g\n",
      "e\n",
      "n\n",
      "e\n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "h\n",
      "o\n",
      "w\n",
      " \n",
      "m\n",
      "u\n",
      "c\n",
      "h\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "n\n",
      "e\n",
      "e\n",
      "d\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "r\n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "m\n",
      "a\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "y\n",
      ".\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "u\n",
      "l\n",
      "t\n",
      "s\n",
      " \n",
      "s\n",
      "u\n",
      "g\n",
      "g\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "“\n",
      "s\n",
      "e\n",
      "t\n",
      "”\n",
      " \n",
      "r\n",
      "e\n",
      "a\n",
      "s\n",
      "o\n",
      "n\n",
      "a\n",
      "b\n",
      "l\n",
      "y\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      "s\n",
      "p\n",
      "e\n",
      "c\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      " \n",
      "p\n",
      "(\n",
      "i\n",
      "n\n",
      "i\n",
      "t\n",
      ")\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "u\n",
      "e\n",
      "s\n",
      " \n",
      "b\n",
      "e\n",
      "f\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "l\n",
      "l\n",
      "e\n",
      "c\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "n\n",
      "y\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      "-\n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "s\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "i\n",
      "d\n",
      "e\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "g\n",
      "r\n",
      "e\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "u\n",
      "l\n",
      "t\n",
      "s\n",
      " \n",
      "m\n",
      "a\n",
      "y\n",
      " \n",
      "g\n",
      "e\n",
      "n\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      ",\n",
      " \n",
      "i\n",
      "t\n",
      "\n",
      "\n",
      "i\n",
      "s\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "a\n",
      "n\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "s\n",
      "p\n",
      "e\n",
      "c\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      " \n",
      "d\n",
      "e\n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "m\n",
      "a\n",
      "p\n",
      " \n",
      "c\n",
      "l\n",
      "o\n",
      "s\n",
      "e\n",
      "l\n",
      "y\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "l\n",
      "e\n",
      "m\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "l\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      ".\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      "s\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "a\n",
      "i\n",
      "n\n",
      "e\n",
      "d\n",
      " \n",
      "1\n",
      "-\n",
      "2\n",
      " \n",
      "q\n",
      "u\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "k\n",
      "c\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "w\n",
      "a\n",
      "s\n",
      " \n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "i\n",
      "t\n",
      "e\n",
      "m\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "s\n",
      "i\n",
      "m\n",
      "i\n",
      "l\n",
      "a\n",
      "r\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "s\n",
      "e\n",
      "\n",
      "\n",
      "e\n",
      "n\n",
      "c\n",
      "o\n",
      "u\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "f\n",
      "i\n",
      "g\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "2\n",
      ".\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      "s\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "c\n",
      "e\n",
      "p\n",
      "t\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "(\n",
      "i\n",
      "n\n",
      "i\n",
      "t\n",
      ")\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "(\n",
      "t\n",
      "o\n",
      "p\n",
      " \n",
      "r\n",
      "o\n",
      "w\n",
      ")\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "(\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      ")\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "(\n",
      "b\n",
      "o\n",
      "t\n",
      "t\n",
      "o\n",
      "m\n",
      " \n",
      "r\n",
      "o\n",
      "w\n",
      ")\n",
      ",\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      ".\n",
      "3\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "t\n",
      "o\n",
      " \n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "o\n",
      "u\n",
      "t\n",
      "-\n",
      "o\n",
      "f\n",
      "-\n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      " \n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "e\n",
      "v\n",
      "a\n",
      "n\n",
      "t\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      "s\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "c\n",
      "a\n",
      "s\n",
      "e\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "u\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "p\n",
      "o\n",
      "s\n",
      "t\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "c\n",
      "o\n",
      "l\n",
      "l\n",
      "e\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "y\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      ".\n",
      "3\n",
      ".\n",
      "1\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "c\n",
      "e\n",
      "p\n",
      "t\n",
      " \n",
      "(\n",
      "𝜃\n",
      "!\n",
      " \n",
      ")\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "p\n",
      "(\n",
      "i\n",
      "n\n",
      "i\n",
      "t\n",
      ")\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      ",\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "s\n",
      "t\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "d\n",
      "o\n",
      "m\n",
      "a\n",
      "i\n",
      "n\n",
      " \n",
      "r\n",
      "e\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      ".\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      "’\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      "\n",
      "\n",
      "e\n",
      "x\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "e\n",
      "d\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      "s\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      "’\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "s\n",
      "c\n",
      "o\n",
      "r\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      " \n",
      "o\n",
      "u\n",
      "t\n",
      "-\n",
      "o\n",
      "f\n",
      "-\n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      " \n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "a\n",
      "l\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      "s\n",
      " \n",
      "c\n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      ".\n",
      "\n",
      "\n",
      "w\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "d\n",
      "a\n",
      "r\n",
      "d\n",
      " \n",
      "p\n",
      "e\n",
      "a\n",
      "r\n",
      "s\n",
      "o\n",
      "n\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "c\n",
      "o\n",
      "e\n",
      "f\n",
      "f\n",
      "i\n",
      "c\n",
      "i\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      ",\n",
      " \n",
      "s\n",
      "i\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      "s\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "s\n",
      "c\n",
      "o\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "d\n",
      "i\n",
      "d\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      " \n",
      "a\n",
      "p\n",
      "p\n",
      "e\n",
      "a\n",
      "r\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "t\n",
      "i\n",
      "c\n",
      "u\n",
      "l\n",
      "a\n",
      "r\n",
      "l\n",
      "y\n",
      " \n",
      "n\n",
      "o\n",
      "n\n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "a\n",
      "r\n",
      ".\n",
      "\n",
      "\n",
      "f\n",
      "i\n",
      "g\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "3\n",
      " \n",
      "i\n",
      "l\n",
      "l\n",
      "u\n",
      "s\n",
      "t\n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "u\n",
      "m\n",
      "m\n",
      "a\n",
      "r\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      "s\n",
      ".\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      "’\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "o\n",
      "n\n",
      "g\n",
      "l\n",
      "y\n",
      "\n",
      "\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      "l\n",
      "y\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "s\n",
      "c\n",
      "o\n",
      "r\n",
      "e\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "’\n",
      "s\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "(\n",
      "a\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      "’\n",
      "s\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      ")\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "a\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "r\n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "a\n",
      "f\n",
      "m\n",
      "’\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "c\n",
      "e\n",
      "p\n",
      "t\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "s\n",
      "c\n",
      "o\n",
      "r\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "3\n",
      ":\n",
      " \n",
      "r\n",
      " \n",
      "=\n",
      " \n",
      "0\n",
      ".\n",
      "6\n",
      "2\n",
      ",\n",
      " \n",
      "p\n",
      " \n",
      "<\n",
      " \n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      ",\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "4\n",
      ":\n",
      " \n",
      "r\n",
      " \n",
      "=\n",
      " \n",
      "0\n",
      ".\n",
      "5\n",
      "8\n",
      ",\n",
      " \n",
      "p\n",
      " \n",
      "<\n",
      " \n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      ")\n",
      "\n",
      "\n",
      "t\n",
      "o\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      "’\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "c\n",
      "e\n",
      "p\n",
      "t\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "/\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "s\n",
      "c\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "(\n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "3\n",
      ":\n",
      " \n",
      "0\n",
      ".\n",
      "7\n",
      "4\n",
      ",\n",
      " \n",
      "p\n",
      " \n",
      "<\n",
      " \n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      ",\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "4\n",
      ":\n",
      " \n",
      "r\n",
      " \n",
      "=\n",
      " \n",
      "0\n",
      ".\n",
      "6\n",
      "6\n",
      ",\n",
      " \n",
      "p\n",
      " \n",
      "<\n",
      " \n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      ")\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "f\n",
      "i\n",
      "g\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "3\n",
      ".\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      "s\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "o\n",
      "u\n",
      "t\n",
      "-\n",
      "o\n",
      "f\n",
      "-\n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "s\n",
      "c\n",
      "o\n",
      "r\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      "/\n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      ".\n",
      "3\n",
      ".\n",
      "2\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "g\n",
      "i\n",
      "v\n",
      "e\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "o\n",
      "n\n",
      "l\n",
      "y\n",
      " \n",
      "e\n",
      "x\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "c\n",
      "o\n",
      "l\n",
      "l\n",
      "e\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "a\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "p\n",
      "o\n",
      "s\n",
      "t\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "s\n",
      "o\n",
      "u\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "(\n",
      "a\n",
      "s\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      ")\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      "-\n",
      "p\n",
      "o\n",
      "s\n",
      "t\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      "\n",
      "\n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      "s\n",
      ".\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "g\n",
      "i\n",
      "v\n",
      "e\n",
      "n\n",
      " \n",
      "r\n",
      "o\n",
      "u\n",
      "g\n",
      "h\n",
      "l\n",
      "y\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "a\n",
      "m\n",
      "o\n",
      "u\n",
      "n\n",
      "t\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "i\n",
      "m\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      "\n",
      "\n",
      "e\n",
      "n\n",
      "g\n",
      "a\n",
      "g\n",
      "e\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      "s\n",
      ",\n",
      " \n",
      "s\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "s\n",
      "e\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "a\n",
      "c\n",
      "c\n",
      "e\n",
      "l\n",
      "e\n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "m\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "e\n",
      "x\n",
      "p\n",
      "e\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      " \n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "i\n",
      "m\n",
      "e\n",
      " \n",
      "a\n",
      "v\n",
      "a\n",
      "i\n",
      "l\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      ".\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "u\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "e\n",
      "x\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "g\n",
      "r\n",
      "e\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      "-\n",
      "p\n",
      "o\n",
      "s\n",
      "t\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      "s\n",
      " \n",
      "w\n",
      "h\n",
      "i\n",
      "l\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "r\n",
      "o\n",
      "l\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "s\n",
      "c\n",
      "o\n",
      "r\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "r\n",
      "o\n",
      "l\n",
      "l\n",
      "e\n",
      "d\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "s\n",
      "c\n",
      "o\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "b\n",
      "e\n",
      "c\n",
      "a\n",
      "u\n",
      "s\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "y\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      "\n",
      "\n",
      "b\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "n\n",
      "e\n",
      "g\n",
      "a\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      "l\n",
      "y\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      "s\n",
      " \n",
      "d\n",
      "u\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "3\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\f",
      "\n",
      "c\n",
      "e\n",
      "i\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "e\n",
      "f\n",
      "f\n",
      "e\n",
      "c\n",
      "t\n",
      "s\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      ",\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "w\n",
      "h\n",
      "o\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "r\n",
      "t\n",
      " \n",
      "o\n",
      "u\n",
      "t\n",
      " \n",
      "p\n",
      "e\n",
      "r\n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "w\n",
      "e\n",
      "l\n",
      "l\n",
      " \n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      " \n",
      "l\n",
      "e\n",
      "s\n",
      "s\n",
      " \n",
      "“\n",
      "r\n",
      "o\n",
      "o\n",
      "m\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "”\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      "s\n",
      " \n",
      "a\n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      " \n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "s\n",
      "?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "3\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      ",\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      " \n",
      "(\n",
      "𝛿\n",
      "!\n",
      " \n",
      ")\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "d\n",
      "i\n",
      "d\n",
      "\n",
      "\n",
      "n\n",
      "o\n",
      "t\n",
      " \n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      "l\n",
      "y\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      "s\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      " \n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "a\n",
      "r\n",
      " \n",
      "r\n",
      "e\n",
      "g\n",
      "r\n",
      "e\n",
      "s\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      "-\n",
      "p\n",
      "o\n",
      "s\n",
      "t\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      "s\n",
      ",\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "s\n",
      "c\n",
      "o\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      " \n",
      "(\n",
      "β\n",
      "=\n",
      "-\n",
      "0\n",
      ".\n",
      "1\n",
      "8\n",
      "9\n",
      ",\n",
      " \n",
      "p\n",
      "=\n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "5\n",
      ")\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "n\n",
      "o\n",
      "t\n",
      " \n",
      "(\n",
      "β\n",
      "=\n",
      "0\n",
      ".\n",
      "3\n",
      "9\n",
      "6\n",
      ",\n",
      " \n",
      "p\n",
      "=\n",
      "0\n",
      ".\n",
      "1\n",
      "4\n",
      "4\n",
      ")\n",
      ".\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "(\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      ")\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "d\n",
      "i\n",
      "d\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      "\n",
      "\n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      "s\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      " \n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "a\n",
      "r\n",
      " \n",
      "r\n",
      "e\n",
      "g\n",
      "r\n",
      "e\n",
      "s\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      "-\n",
      "p\n",
      "o\n",
      "s\n",
      "t\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      "s\n",
      ",\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "s\n",
      "c\n",
      "o\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "(\n",
      "β\n",
      "=\n",
      "-\n",
      "0\n",
      ".\n",
      "2\n",
      "2\n",
      "6\n",
      ",\n",
      " \n",
      "p\n",
      "=\n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "5\n",
      ")\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      "\n",
      "\n",
      "(\n",
      "β\n",
      "=\n",
      "0\n",
      ".\n",
      "0\n",
      "6\n",
      "2\n",
      ",\n",
      " \n",
      "p\n",
      "=\n",
      "0\n",
      ".\n",
      "2\n",
      "1\n",
      "8\n",
      ")\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "f\n",
      "i\n",
      "g\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "4\n",
      " \n",
      "s\n",
      "u\n",
      "m\n",
      "m\n",
      "a\n",
      "r\n",
      "i\n",
      "z\n",
      "e\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      ".\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      "\n",
      "\n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "f\n",
      "a\n",
      "i\n",
      "r\n",
      "l\n",
      "y\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "i\n",
      "s\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      ",\n",
      " \n",
      "e\n",
      "s\n",
      "p\n",
      "e\n",
      "c\n",
      "i\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      ".\n",
      " \n",
      "i\n",
      "t\n",
      " \n",
      "s\n",
      "e\n",
      "e\n",
      "m\n",
      "s\n",
      "\n",
      "\n",
      "s\n",
      "e\n",
      "n\n",
      "s\n",
      "i\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "s\n",
      "u\n",
      "g\n",
      "g\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "l\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      "\n",
      "\n",
      "o\n",
      "n\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "3\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "o\n",
      "n\n",
      "g\n",
      "l\n",
      "y\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "l\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      "\n",
      "\n",
      "o\n",
      "n\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "4\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      ",\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "4\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      ",\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      " \n",
      "(\n",
      "𝛿\n",
      "!\n",
      " \n",
      ")\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      "l\n",
      "y\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      "s\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      " \n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "a\n",
      "r\n",
      " \n",
      "r\n",
      "e\n",
      "g\n",
      "r\n",
      "e\n",
      "s\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      "-\n",
      "p\n",
      "o\n",
      "s\n",
      "t\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      "s\n",
      ",\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "s\n",
      "c\n",
      "o\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "(\n",
      "β\n",
      "=\n",
      "-\n",
      "0\n",
      ".\n",
      "6\n",
      "4\n",
      "1\n",
      ",\n",
      "\n",
      "\n",
      "p\n",
      "<\n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      ")\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "(\n",
      "β\n",
      "=\n",
      "0\n",
      ".\n",
      "5\n",
      "7\n",
      "6\n",
      ",\n",
      " \n",
      "p\n",
      "=\n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "7\n",
      ")\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "s\n",
      ".\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "(\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      ")\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      "l\n",
      "s\n",
      "o\n",
      "\n",
      "\n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      "l\n",
      "y\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      "s\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      " \n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "a\n",
      "r\n",
      " \n",
      "r\n",
      "e\n",
      "g\n",
      "r\n",
      "e\n",
      "s\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      "-\n",
      "p\n",
      "o\n",
      "s\n",
      "t\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      "s\n",
      ",\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "s\n",
      "c\n",
      "o\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "(\n",
      "β\n",
      "=\n",
      "-\n",
      "0\n",
      ".\n",
      "6\n",
      "4\n",
      "5\n",
      ",\n",
      "\n",
      "\n",
      "p\n",
      "<\n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      ")\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "p\n",
      "(\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      ")\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "(\n",
      "β\n",
      "=\n",
      "0\n",
      ".\n",
      "1\n",
      "3\n",
      "3\n",
      ",\n",
      " \n",
      "p\n",
      "=\n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "4\n",
      ")\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      "\n",
      "\n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "o\n",
      "n\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "s\n",
      " \n",
      "(\n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "4\n",
      ")\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "o\n",
      "b\n",
      "s\n",
      "e\n",
      "r\n",
      "v\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "e\n",
      "x\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      "l\n",
      "y\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "w\n",
      "e\n",
      "\n",
      "\n",
      "o\n",
      "b\n",
      "s\n",
      "e\n",
      "r\n",
      "v\n",
      "e\n",
      "d\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "o\n",
      "n\n",
      "g\n",
      " \n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      "-\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "u\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "v\n",
      "e\n",
      "r\n",
      "g\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "e\n",
      "v\n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "4\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      "\n",
      "\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "l\n",
      "e\n",
      "s\n",
      "s\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "i\n",
      "s\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "m\n",
      "a\n",
      "y\n",
      "\n",
      "\n",
      "e\n",
      "i\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "d\n",
      "u\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "3\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "n\n",
      "e\n",
      "i\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "v\n",
      "e\n",
      "r\n",
      "y\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "n\n",
      "o\n",
      "r\n",
      " \n",
      "v\n",
      "e\n",
      "r\n",
      "y\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      ".\n",
      "\n",
      "\n",
      "a\n",
      "l\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      "l\n",
      "y\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "a\n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m\n",
      "a\n",
      "y\n",
      " \n",
      "a\n",
      "l\n",
      "s\n",
      "o\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "d\n",
      "u\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      "\n",
      "\n",
      "g\n",
      "e\n",
      "n\n",
      "u\n",
      "i\n",
      "n\n",
      "e\n",
      "l\n",
      "y\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "r\n",
      "i\n",
      "a\n",
      "l\n",
      " \n",
      "a\n",
      "t\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "u\n",
      "n\n",
      "f\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "a\n",
      "t\n",
      "e\n",
      "l\n",
      "y\n",
      ",\n",
      "\n",
      "\n",
      "w\n",
      "e\n",
      " \n",
      "c\n",
      "a\n",
      "n\n",
      "n\n",
      "o\n",
      "t\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "o\n",
      "l\n",
      "v\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "q\n",
      "u\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "c\n",
      "u\n",
      "r\n",
      "r\n",
      "e\n",
      "n\n",
      "t\n",
      "l\n",
      "y\n",
      " \n",
      "c\n",
      "o\n",
      "l\n",
      "l\n",
      "e\n",
      "c\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "s\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "g\n",
      "r\n",
      "o\n",
      "u\n",
      "p\n",
      " \n",
      "o\n",
      "f\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      ".\n",
      " \n",
      "i\n",
      "f\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "o\n",
      "b\n",
      "t\n",
      "a\n",
      "i\n",
      "n\n",
      " \n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "f\n",
      "u\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "g\n",
      "r\n",
      "o\n",
      "u\n",
      "p\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "c\n",
      "a\n",
      "n\n",
      " \n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "f\n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "l\n",
      "y\n",
      " \n",
      "a\n",
      "d\n",
      "d\n",
      "r\n",
      "e\n",
      "s\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "q\n",
      "u\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "f\n",
      "u\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "c\n",
      "h\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      ".\n",
      "4\n",
      ".\n",
      "2\n",
      " \n",
      "u\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "g\n",
      "i\n",
      "v\n",
      "e\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "a\n",
      "b\n",
      "l\n",
      "i\n",
      "s\n",
      "h\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      "’\n",
      "s\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "4\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "a\n",
      "s\n",
      "o\n",
      "n\n",
      "a\n",
      "b\n",
      "l\n",
      "y\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "s\n",
      "o\n",
      "u\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "d\n",
      "i\n",
      "g\n",
      " \n",
      "d\n",
      "e\n",
      "e\n",
      "p\n",
      "e\n",
      "r\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "e\n",
      "x\n",
      "p\n",
      "l\n",
      "a\n",
      "n\n",
      "a\n",
      "t\n",
      "o\n",
      "r\n",
      "y\n",
      " \n",
      "p\n",
      "o\n",
      "w\n",
      "e\n",
      "r\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "e\n",
      "n\n",
      "d\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "d\n",
      "u\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "e\n",
      "x\n",
      "p\n",
      "l\n",
      "o\n",
      "r\n",
      "a\n",
      "t\n",
      "o\n",
      "r\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "a\n",
      "l\n",
      "y\n",
      "s\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "4\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "(\n",
      "1\n",
      ")\n",
      " \n",
      "v\n",
      "i\n",
      "s\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "j\n",
      "e\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "h\n",
      "i\n",
      "g\n",
      "h\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "v\n",
      "s\n",
      ".\n",
      " \n",
      "l\n",
      "o\n",
      "w\n",
      "e\n",
      "s\n",
      "t\n",
      "\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "(\n",
      "2\n",
      ")\n",
      " \n",
      "u\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      "s\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      "\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "p\n",
      "r\n",
      "i\n",
      "o\n",
      "r\n",
      "-\n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "m\n",
      "o\n",
      "t\n",
      "i\n",
      "v\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "s\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "(\n",
      "3\n",
      ")\n",
      " \n",
      "u\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "g\n",
      "r\n",
      "e\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "v\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "f\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "a\n",
      "t\n",
      "t\n",
      "e\n",
      "m\n",
      "p\n",
      "t\n",
      " \n",
      "s\n",
      "u\n",
      "c\n",
      "c\n",
      "e\n",
      "s\n",
      "s\n",
      "\n",
      "\n",
      "0\n",
      ".\n",
      "4\n",
      "\n",
      "\n",
      "0\n",
      ".\n",
      "6\n",
      "\n",
      "\n",
      "0\n",
      ".\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "f\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "a\n",
      "t\n",
      "t\n",
      "e\n",
      "m\n",
      "p\n",
      "t\n",
      " \n",
      "s\n",
      "u\n",
      "c\n",
      "c\n",
      "e\n",
      "s\n",
      "s\n",
      "\n",
      "\n",
      "0\n",
      ".\n",
      "4\n",
      "\n",
      "\n",
      "0\n",
      ".\n",
      "6\n",
      "\n",
      "\n",
      "0\n",
      ".\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      ".\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "(\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      ")\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      ".\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "#\n",
      " \n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      ".\n",
      "4\n",
      " \n",
      "t\n",
      "o\n",
      "w\n",
      "a\n",
      "r\n",
      "d\n",
      "s\n",
      " \n",
      "u\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "&\n",
      " \n",
      "u\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "4\n",
      ".\n",
      "4\n",
      ".\n",
      "1\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "i\n",
      "s\n",
      "t\n",
      "e\n",
      "n\n",
      "c\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      "s\n",
      "\n",
      "\n",
      "a\n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      "\n",
      "\n",
      "a\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "t\n",
      "i\n",
      "v\n",
      "a\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "q\n",
      "u\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "c\n",
      "o\n",
      "l\n",
      "l\n",
      "e\n",
      "c\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "s\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "g\n",
      "r\n",
      "o\n",
      "u\n",
      "p\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "w\n",
      "a\n",
      "s\n",
      ":\n",
      " \n",
      "h\n",
      "o\n",
      "w\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "i\n",
      "s\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "#\n",
      " \n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "t\n",
      "o\n",
      "p\n",
      " \n",
      "2\n",
      "5\n",
      "%\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "m\n",
      "i\n",
      "d\n",
      "d\n",
      "l\n",
      "e\n",
      " \n",
      "5\n",
      "0\n",
      "%\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "b\n",
      "o\n",
      "t\n",
      "t\n",
      "o\n",
      "m\n",
      " \n",
      "2\n",
      "5\n",
      "%\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "l\n",
      "i\n",
      "k\n",
      "e\n",
      "r\n",
      "t\n",
      " \n",
      "s\n",
      "c\n",
      "a\n",
      "l\n",
      "e\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "l\n",
      "i\n",
      "k\n",
      "e\n",
      "r\n",
      "t\n",
      " \n",
      "s\n",
      "c\n",
      "a\n",
      "l\n",
      "e\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "t\n",
      "o\n",
      "p\n",
      " \n",
      "2\n",
      "5\n",
      "%\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "m\n",
      "i\n",
      "d\n",
      "d\n",
      "l\n",
      "e\n",
      " \n",
      "5\n",
      "0\n",
      "%\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "b\n",
      "o\n",
      "t\n",
      "t\n",
      "o\n",
      "m\n",
      " \n",
      "2\n",
      "5\n",
      "%\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "f\n",
      "i\n",
      "g\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "4\n",
      ".\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      "s\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "a\n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "(\n",
      "s\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "o\n",
      "p\n",
      "u\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ")\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      ".\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      ".\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "t\n",
      "o\n",
      "p\n",
      " \n",
      "2\n",
      "5\n",
      "%\n",
      "\n",
      "\n",
      "m\n",
      "i\n",
      "d\n",
      "d\n",
      "l\n",
      "e\n",
      " \n",
      "5\n",
      "0\n",
      "%\n",
      "\n",
      "\n",
      "b\n",
      "o\n",
      "t\n",
      "t\n",
      "o\n",
      "m\n",
      " \n",
      "2\n",
      "5\n",
      "%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "e\n",
      "t\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      "n\n",
      "e\n",
      "s\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "e\n",
      "f\n",
      "f\n",
      "o\n",
      "r\n",
      "t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "d\n",
      "i\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "e\n",
      "t\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      "n\n",
      "e\n",
      "s\n",
      "s\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "e\n",
      "f\n",
      "f\n",
      "o\n",
      "r\n",
      "t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "d\n",
      "i\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "f\n",
      "i\n",
      "g\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "5\n",
      ".\n",
      " \n",
      "t\n",
      "o\n",
      "p\n",
      " \n",
      "r\n",
      "o\n",
      "w\n",
      ":\n",
      " \n",
      "e\n",
      "a\n",
      "r\n",
      "l\n",
      "y\n",
      "-\n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "j\n",
      "e\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      ",\n",
      " \n",
      "g\n",
      "r\n",
      "o\n",
      "u\n",
      "p\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "(\n",
      "l\n",
      "e\n",
      "f\n",
      "t\n",
      ")\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "(\n",
      "r\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      ")\n",
      "\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "s\n",
      "o\n",
      "l\n",
      "i\n",
      "d\n",
      " \n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "t\n",
      "u\n",
      "a\n",
      "l\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      ";\n",
      " \n",
      "d\n",
      "o\n",
      "t\n",
      "t\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "p\n",
      "e\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "’\n",
      "s\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "p\n",
      "e\n",
      "r\n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      ".\n",
      "\n",
      "\n",
      "b\n",
      "o\n",
      "t\n",
      "t\n",
      "o\n",
      "m\n",
      " \n",
      "r\n",
      "o\n",
      "w\n",
      ":\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "n\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      "-\n",
      "r\n",
      "e\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      " \n",
      "l\n",
      "i\n",
      "k\n",
      "e\n",
      "r\n",
      "t\n",
      " \n",
      "s\n",
      "c\n",
      "a\n",
      "l\n",
      "e\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      "\n",
      "\n",
      "q\n",
      "u\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "s\n",
      "u\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "d\n",
      "i\n",
      "m\n",
      "e\n",
      "n\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "e\n",
      "t\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      "n\n",
      "e\n",
      "s\n",
      "s\n",
      ",\n",
      " \n",
      "e\n",
      "f\n",
      "f\n",
      "o\n",
      "r\n",
      "t\n",
      ",\n",
      "\n",
      "\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "d\n",
      "i\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      ".\n",
      " \n",
      "g\n",
      "r\n",
      "o\n",
      "u\n",
      "p\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "(\n",
      "l\n",
      "e\n",
      "f\n",
      "t\n",
      ")\n",
      " \n",
      "o\n",
      "r\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "(\n",
      "r\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      ")\n",
      "\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "e\n",
      "r\n",
      "r\n",
      "o\n",
      "r\n",
      " \n",
      "b\n",
      "a\n",
      "r\n",
      "s\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "w\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "d\n",
      "a\n",
      "r\n",
      "d\n",
      " \n",
      "e\n",
      "r\n",
      "r\n",
      "o\n",
      "r\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "n\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "3\n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\f",
      "\n",
      "f\n",
      "i\n",
      "g\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "5\n",
      " \n",
      "(\n",
      "t\n",
      "o\n",
      "p\n",
      " \n",
      "r\n",
      "o\n",
      "w\n",
      ")\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "w\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "a\n",
      "g\n",
      "g\n",
      "r\n",
      "e\n",
      "g\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "j\n",
      "e\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "s\n",
      "p\n",
      "l\n",
      "i\n",
      "t\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "e\n",
      "i\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "t\n",
      "o\n",
      "p\n",
      " \n",
      "l\n",
      "e\n",
      "f\n",
      "t\n",
      ")\n",
      " \n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "(\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      ")\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "(\n",
      "t\n",
      "o\n",
      "p\n",
      " \n",
      "r\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      ")\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "t\n",
      "o\n",
      "p\n",
      " \n",
      "2\n",
      "5\n",
      "%\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "p\n",
      "l\n",
      "o\n",
      "t\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "b\n",
      "l\n",
      "u\n",
      "e\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "m\n",
      "i\n",
      "d\n",
      "d\n",
      "l\n",
      "e\n",
      " \n",
      "5\n",
      "0\n",
      "%\n",
      " \n",
      "(\n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "1\n",
      "s\n",
      "t\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "3\n",
      "r\n",
      "d\n",
      " \n",
      "q\n",
      "u\n",
      "a\n",
      "r\n",
      "t\n",
      "i\n",
      "l\n",
      "e\n",
      "s\n",
      ")\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "p\n",
      "l\n",
      "o\n",
      "t\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "r\n",
      "e\n",
      "d\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "l\n",
      "o\n",
      "w\n",
      "e\n",
      "r\n",
      " \n",
      "2\n",
      "5\n",
      "%\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "p\n",
      "l\n",
      "o\n",
      "t\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "b\n",
      "l\n",
      "a\n",
      "c\n",
      "k\n",
      ".\n",
      " \n",
      "d\n",
      "o\n",
      "t\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "s\n",
      " \n",
      "r\n",
      "e\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "s\n",
      "p\n",
      "e\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "’\n",
      "s\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "j\n",
      "e\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "i\n",
      "e\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "o\n",
      "n\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "i\n",
      "k\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "p\n",
      "a\n",
      "t\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      ",\n",
      " \n",
      "e\n",
      "s\n",
      "p\n",
      "e\n",
      "c\n",
      "i\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "j\n",
      "e\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "i\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "t\n",
      "o\n",
      "p\n",
      " \n",
      "l\n",
      "e\n",
      "f\n",
      "t\n",
      ")\n",
      ",\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "a\n",
      "p\n",
      "p\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "a\n",
      "v\n",
      "e\n",
      "r\n",
      "a\n",
      "g\n",
      "e\n",
      " \n",
      "s\n",
      "u\n",
      "c\n",
      "c\n",
      "e\n",
      "s\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "a\n",
      "l\n",
      " \n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "(\n",
      "i\n",
      ".\n",
      "e\n",
      ".\n",
      ",\n",
      " \n",
      "p\n",
      "r\n",
      "i\n",
      "o\n",
      "r\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      ")\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "r\n",
      "o\n",
      "u\n",
      "g\n",
      "h\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "m\n",
      "a\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      "\n",
      "\n",
      "o\n",
      "b\n",
      "s\n",
      "e\n",
      "r\n",
      "v\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "r\n",
      "o\n",
      "b\n",
      "o\n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "o\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "c\n",
      "e\n",
      "p\n",
      "t\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "(\n",
      "r\n",
      "=\n",
      "0\n",
      ".\n",
      "7\n",
      "8\n",
      ",\n",
      " \n",
      "p\n",
      "<\n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      ")\n",
      ".\n",
      " \n",
      "o\n",
      "n\n",
      "e\n",
      " \n",
      "m\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "s\n",
      "u\n",
      "g\n",
      "g\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "w\n",
      "h\n",
      "o\n",
      " \n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "g\n",
      "r\n",
      "e\n",
      "a\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "p\n",
      "r\n",
      "i\n",
      "o\n",
      "r\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "w\n",
      "i\n",
      "l\n",
      "l\n",
      "\n",
      "\n",
      "b\n",
      "e\n",
      " \n",
      "p\n",
      "o\n",
      "i\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      " \n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      " \n",
      "(\n",
      "i\n",
      ".\n",
      "e\n",
      ".\n",
      ",\n",
      " \n",
      "“\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "g\n",
      "e\n",
      "t\n",
      " \n",
      "r\n",
      "i\n",
      "c\n",
      "h\n",
      "e\n",
      "r\n",
      "”\n",
      ")\n",
      ".\n",
      "\n",
      "\n",
      "a\n",
      "l\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      "l\n",
      "y\n",
      ",\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "m\n",
      "a\n",
      "y\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      " \n",
      "h\n",
      "i\n",
      "g\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "l\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      "\n",
      "\n",
      "b\n",
      "e\n",
      "c\n",
      "a\n",
      "u\n",
      "s\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "y\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "f\n",
      "a\n",
      "s\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "e\n",
      "r\n",
      "s\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "m\n",
      "a\n",
      "y\n",
      " \n",
      "a\n",
      "l\n",
      "s\n",
      "o\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "i\n",
      "t\n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "p\n",
      "o\n",
      "s\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      "l\n",
      "y\n",
      " \n",
      "d\n",
      "r\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "l\n",
      "\n",
      "\n",
      "a\n",
      "c\n",
      "h\n",
      "i\n",
      "e\n",
      "v\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      ".\n",
      "\n",
      "\n",
      "t\n",
      "o\n",
      " \n",
      "e\n",
      "x\n",
      "p\n",
      "l\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      "s\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "i\n",
      "t\n",
      "s\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "e\n",
      "v\n",
      "a\n",
      "n\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "a\n",
      "l\n",
      "y\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      "-\n",
      "r\n",
      "e\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      " \n",
      "s\n",
      "u\n",
      "r\n",
      "v\n",
      "e\n",
      "y\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "g\n",
      "r\n",
      "o\n",
      "u\n",
      "p\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "t\n",
      "h\n",
      "r\n",
      "e\n",
      "e\n",
      "\n",
      "\n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "s\n",
      " \n",
      "(\n",
      "a\n",
      "s\n",
      " \n",
      "d\n",
      "e\n",
      "s\n",
      "c\n",
      "r\n",
      "i\n",
      "b\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "s\n",
      "e\n",
      "c\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "3\n",
      ".\n",
      "1\n",
      ")\n",
      ":\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "e\n",
      "t\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      "n\n",
      "e\n",
      "s\n",
      "s\n",
      ",\n",
      " \n",
      "e\n",
      "f\n",
      "f\n",
      "o\n",
      "r\n",
      "t\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "d\n",
      "i\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "h\n",
      "i\n",
      "g\n",
      "h\n",
      ",\n",
      "\n",
      "\n",
      "m\n",
      "e\n",
      "d\n",
      "i\n",
      "u\n",
      "m\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "l\n",
      "o\n",
      "w\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      "\n",
      "\n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "f\n",
      "i\n",
      "g\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "5\n",
      " \n",
      "(\n",
      "b\n",
      "o\n",
      "t\n",
      "t\n",
      "o\n",
      "m\n",
      " \n",
      "r\n",
      "o\n",
      "w\n",
      ")\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "a\n",
      "p\n",
      "p\n",
      "e\n",
      "a\n",
      "r\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "a\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "n\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      "-\n",
      "r\n",
      "e\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "g\n",
      "e\n",
      "n\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      " \n",
      "r\n",
      "a\n",
      "n\n",
      "g\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "f\n",
      "a\n",
      "l\n",
      "l\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      ".\n",
      "\n",
      "\n",
      "w\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "a\n",
      "l\n",
      "y\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "i\n",
      "n\n",
      "u\n",
      "o\n",
      "u\n",
      "s\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      "’\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "n\n",
      "\n",
      "\n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      "-\n",
      "r\n",
      "e\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "l\n",
      "o\n",
      "n\n",
      "g\n",
      " \n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "d\n",
      "i\n",
      "m\n",
      "e\n",
      "n\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      " \n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "a\n",
      "r\n",
      " \n",
      "r\n",
      "e\n",
      "g\n",
      "r\n",
      "e\n",
      "s\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "s\n",
      "l\n",
      "o\n",
      "p\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "e\n",
      "t\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      "n\n",
      "e\n",
      "s\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "e\n",
      "f\n",
      "f\n",
      "o\n",
      "r\n",
      "t\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      " \n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "s\n",
      "\n",
      "\n",
      "b\n",
      "u\n",
      "t\n",
      " \n",
      "d\n",
      "i\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "(\n",
      "β\n",
      "=\n",
      "0\n",
      ".\n",
      "0\n",
      "1\n",
      "6\n",
      ",\n",
      " \n",
      "p\n",
      "=\n",
      "0\n",
      ".\n",
      "0\n",
      "0\n",
      "7\n",
      ")\n",
      " \n",
      "w\n",
      "a\n",
      "s\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "i\n",
      "m\n",
      "i\n",
      "l\n",
      "a\n",
      "r\n",
      " \n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "a\n",
      "r\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "g\n",
      "r\n",
      "e\n",
      "s\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "c\n",
      "e\n",
      "p\n",
      "t\n",
      "s\n",
      ",\n",
      " \n",
      "a\n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      " \n",
      "d\n",
      "i\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "\n",
      "\n",
      "w\n",
      "a\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "o\n",
      "n\n",
      "l\n",
      "y\n",
      " \n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      " \n",
      "(\n",
      "β\n",
      "=\n",
      "0\n",
      ".\n",
      "0\n",
      "2\n",
      ",\n",
      " \n",
      "p\n",
      "=\n",
      "0\n",
      ".\n",
      "0\n",
      "4\n",
      ")\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "u\n",
      "s\n",
      ",\n",
      " \n",
      "a\n",
      "m\n",
      "o\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      "-\n",
      "r\n",
      "e\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "o\n",
      "n\n",
      "g\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "d\n",
      "i\n",
      "m\n",
      "e\n",
      "n\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      "/\n",
      "p\n",
      "r\n",
      "i\n",
      "o\n",
      "r\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "w\n",
      "a\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "d\n",
      "i\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      ".\n",
      " \n",
      "f\n",
      "u\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "k\n",
      " \n",
      "u\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "c\n",
      "a\n",
      "u\n",
      "s\n",
      "a\n",
      "l\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "i\n",
      "s\n",
      "\n",
      "\n",
      "w\n",
      "a\n",
      "r\n",
      "r\n",
      "a\n",
      "n\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "d\n",
      "i\n",
      "s\n",
      "c\n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "u\n",
      "e\n",
      " \n",
      "n\n",
      "a\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "c\n",
      "a\n",
      "u\n",
      "s\n",
      "a\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "a\n",
      "m\n",
      "o\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      "l\n",
      "e\n",
      "v\n",
      "e\n",
      "l\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "f\n",
      "i\n",
      "n\n",
      "a\n",
      "l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l\n",
      "y\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "v\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "g\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "g\n",
      "r\n",
      "e\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "v\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "f\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "q\n",
      "u\n",
      "a\n",
      "n\n",
      "t\n",
      "i\n",
      "l\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "0\n",
      ".\n",
      "0\n",
      "3\n",
      " \n",
      "l\n",
      "o\n",
      "g\n",
      "i\n",
      "t\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "r\n",
      "d\n",
      " \n",
      "q\n",
      "u\n",
      "a\n",
      "n\n",
      "t\n",
      "i\n",
      "l\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      "\n",
      "\n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "0\n",
      ".\n",
      "0\n",
      "8\n",
      " \n",
      "l\n",
      "o\n",
      "g\n",
      "i\n",
      "t\n",
      "s\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "c\n",
      "a\n",
      "n\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "c\n",
      "e\n",
      "p\n",
      "t\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "c\n",
      "a\n",
      "n\n",
      "o\n",
      "n\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "“\n",
      "s\n",
      "l\n",
      "o\n",
      "w\n",
      "”\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "“\n",
      "f\n",
      "a\n",
      "s\n",
      "t\n",
      "”\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "e\n",
      "r\n",
      "s\n",
      ".\n",
      " \n",
      "i\n",
      "f\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "a\n",
      "s\n",
      "s\n",
      "u\n",
      "m\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "r\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "t\n",
      "\n",
      "\n",
      "a\n",
      "r\n",
      "o\n",
      "u\n",
      "n\n",
      "d\n",
      " \n",
      "7\n",
      "0\n",
      "%\n",
      " \n",
      "p\n",
      "e\n",
      "r\n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "(\n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "e\n",
      "s\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "’\n",
      "s\n",
      " \n",
      "g\n",
      "l\n",
      "o\n",
      "b\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "c\n",
      "e\n",
      "p\n",
      "t\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      ")\n",
      ",\n",
      " \n",
      "i\n",
      "t\n",
      " \n",
      "w\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "t\n",
      "a\n",
      "k\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "“\n",
      "s\n",
      "l\n",
      "o\n",
      "w\n",
      "”\n",
      " \n",
      "(\n",
      "0\n",
      ".\n",
      "0\n",
      "3\n",
      " \n",
      "l\n",
      "o\n",
      "g\n",
      "i\n",
      "t\n",
      "s\n",
      ")\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "a\n",
      "p\n",
      "p\n",
      "r\n",
      "o\n",
      "x\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "l\n",
      "y\n",
      " \n",
      "2\n",
      "5\n",
      " \n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "r\n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "m\n",
      "a\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "y\n",
      " \n",
      "(\n",
      "d\n",
      "e\n",
      "f\n",
      "i\n",
      "n\n",
      "e\n",
      "d\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "8\n",
      "5\n",
      "%\n",
      ",\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "e\n",
      "r\n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "e\n",
      "q\n",
      "u\n",
      "i\n",
      "v\n",
      "a\n",
      "l\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "a\n",
      " \n",
      "p\n",
      "(\n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      ")\n",
      "=\n",
      "0\n",
      ".\n",
      "9\n",
      "5\n",
      ",\n",
      " \n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "g\n",
      "u\n",
      "e\n",
      "s\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "l\n",
      "i\n",
      "p\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "t\n",
      "u\n",
      "a\n",
      "l\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      ")\n",
      ".\n",
      " \n",
      "i\n",
      "t\n",
      " \n",
      "w\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      "\n",
      "\n",
      "t\n",
      "a\n",
      "k\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "“\n",
      "f\n",
      "a\n",
      "s\n",
      "t\n",
      "”\n",
      " \n",
      "(\n",
      "0\n",
      ".\n",
      "0\n",
      "8\n",
      " \n",
      "l\n",
      "o\n",
      "g\n",
      "i\n",
      "t\n",
      "s\n",
      ")\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "p\n",
      "p\n",
      "r\n",
      "o\n",
      "x\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "l\n",
      "y\n",
      " \n",
      "1\n",
      "1\n",
      "\n",
      "\n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "r\n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "p\n",
      "l\n",
      "a\n",
      "c\n",
      "e\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      ".\n",
      "4\n",
      ".\n",
      "3\n",
      " \n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "f\n",
      "y\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "e\n",
      "l\n",
      " \n",
      "s\n",
      "p\n",
      "i\n",
      "n\n",
      "n\n",
      "e\n",
      "r\n",
      "s\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "u\n",
      "r\n",
      "r\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "d\n",
      "e\n",
      "f\n",
      "i\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "“\n",
      "w\n",
      "h\n",
      "e\n",
      "e\n",
      "l\n",
      " \n",
      "s\n",
      "p\n",
      "i\n",
      "n\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      "”\n",
      " \n",
      "p\n",
      "u\n",
      "t\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      "t\n",
      "h\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "e\n",
      "d\n",
      "u\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "m\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "m\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "“\n",
      "p\n",
      "h\n",
      "e\n",
      "n\n",
      "o\n",
      "m\n",
      "e\n",
      "n\n",
      "o\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      "\n",
      "\n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "h\n",
      "a\n",
      "s\n",
      " \n",
      "s\n",
      "p\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "i\n",
      "d\n",
      "e\n",
      "r\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "m\n",
      "o\n",
      "u\n",
      "n\n",
      "t\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "i\n",
      "m\n",
      "e\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      ",\n",
      " \n",
      "y\n",
      "e\n",
      "t\n",
      " \n",
      "d\n",
      "i\n",
      "s\n",
      "p\n",
      "l\n",
      "a\n",
      "y\n",
      "s\n",
      " \n",
      "l\n",
      "i\n",
      "t\n",
      "t\n",
      "l\n",
      "e\n",
      " \n",
      "o\n",
      "r\n",
      " \n",
      "n\n",
      "o\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "g\n",
      "r\n",
      "e\n",
      "s\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      "w\n",
      "a\n",
      "r\n",
      "d\n",
      "s\n",
      "\n",
      "\n",
      "m\n",
      "a\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "y\n",
      "”\n",
      " \n",
      "[\n",
      "5\n",
      "]\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "h\n",
      "a\n",
      "s\n",
      " \n",
      "b\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "s\n",
      "o\n",
      "m\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "s\n",
      "y\n",
      " \n",
      "a\n",
      "r\n",
      "o\n",
      "u\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "i\n",
      "d\n",
      "e\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "w\n",
      "a\n",
      "y\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "m\n",
      "a\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "y\n",
      " \n",
      "(\n",
      "e\n",
      ".\n",
      "g\n",
      ".\n",
      ",\n",
      " \n",
      "3\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "r\n",
      "e\n",
      "c\n",
      "t\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      " \n",
      "r\n",
      "o\n",
      "w\n",
      " \n",
      "v\n",
      "s\n",
      ".\n",
      " \n",
      "r\n",
      "e\n",
      "a\n",
      "c\n",
      "h\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "\n",
      "\n",
      "c\n",
      "e\n",
      "r\n",
      "t\n",
      "a\n",
      "i\n",
      "n\n",
      " \n",
      "p\n",
      "(\n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      ")\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "i\n",
      "n\n",
      "g\n",
      ")\n",
      ".\n",
      " \n",
      "f\n",
      "u\n",
      "r\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      ",\n",
      " \n",
      "s\n",
      "o\n",
      "m\n",
      "e\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "m\n",
      "a\n",
      "y\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "c\n",
      "l\n",
      "a\n",
      "s\n",
      "s\n",
      "i\n",
      "f\n",
      "i\n",
      "e\n",
      "d\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "e\n",
      "l\n",
      " \n",
      "s\n",
      "p\n",
      "i\n",
      "n\n",
      "n\n",
      "e\n",
      "r\n",
      "s\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      "\n",
      "\n",
      "m\n",
      "a\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      " \n",
      "c\n",
      "e\n",
      "r\n",
      "t\n",
      "a\n",
      "i\n",
      "n\n",
      " \n",
      "n\n",
      "u\n",
      "m\n",
      "b\n",
      "e\n",
      "r\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "b\n",
      "u\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "y\n",
      " \n",
      "m\n",
      "a\n",
      "y\n",
      " \n",
      "s\n",
      "t\n",
      "i\n",
      "l\n",
      "l\n",
      "\n",
      "\n",
      "b\n",
      "e\n",
      " \n",
      "m\n",
      "a\n",
      "k\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "g\n",
      "r\n",
      "e\n",
      "s\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "w\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "p\n",
      "o\n",
      "s\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      ",\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "b\n",
      "i\n",
      "n\n",
      "e\n",
      "d\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "k\n",
      "c\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      ",\n",
      " \n",
      "c\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "e\n",
      "l\n",
      " \n",
      "s\n",
      "p\n",
      "i\n",
      "n\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "/\n",
      "k\n",
      "c\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "i\n",
      "r\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "w\n",
      "a\n",
      "y\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "a\n",
      "g\n",
      "n\n",
      "o\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "m\n",
      "a\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "y\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "t\n",
      "u\n",
      "s\n",
      ".\n",
      " \n",
      "s\n",
      "p\n",
      "e\n",
      "c\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      ",\n",
      " \n",
      "i\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "b\n",
      "i\n",
      "n\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "k\n",
      "c\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      " \n",
      "n\n",
      "o\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "o\n",
      "r\n",
      " \n",
      "n\n",
      "e\n",
      "g\n",
      "a\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      "\n",
      "\n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      "’\n",
      "t\n",
      " \n",
      "a\n",
      "l\n",
      "r\n",
      "e\n",
      "a\n",
      "d\n",
      "y\n",
      " \n",
      "a\n",
      "t\n",
      " \n",
      "a\n",
      " \n",
      "h\n",
      "i\n",
      "g\n",
      "h\n",
      " \n",
      "l\n",
      "e\n",
      "v\n",
      "e\n",
      "l\n",
      "\n",
      "\n",
      "o\n",
      "f\n",
      " \n",
      "p\n",
      "e\n",
      "r\n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      " \n",
      "f\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "(\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "i\n",
      "d\n",
      "e\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      "\n",
      "\n",
      "t\n",
      "o\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "8\n",
      "0\n",
      "%\n",
      " \n",
      "o\n",
      "r\n",
      " \n",
      "a\n",
      "b\n",
      "o\n",
      "v\n",
      "e\n",
      ")\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "i\n",
      "d\n",
      "e\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "e\n",
      "l\n",
      "\n",
      "\n",
      "s\n",
      "p\n",
      "i\n",
      "n\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "k\n",
      "c\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "m\n",
      "e\n",
      "t\n",
      "h\n",
      "o\n",
      "d\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "e\n",
      "l\n",
      " \n",
      "s\n",
      "p\n",
      "i\n",
      "n\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "w\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "t\n",
      "i\n",
      "c\n",
      "u\n",
      "l\n",
      "a\n",
      "r\n",
      "l\n",
      "y\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      "f\n",
      "u\n",
      "l\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "s\n",
      "p\n",
      "a\n",
      "r\n",
      "s\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "s\n",
      "o\n",
      "m\n",
      "e\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      "k\n",
      "c\n",
      " \n",
      "p\n",
      "a\n",
      "i\n",
      "r\n",
      "s\n",
      ",\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "i\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      " \n",
      "p\n",
      "e\n",
      "r\n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      "-\n",
      "d\n",
      "e\n",
      "p\n",
      "e\n",
      "n\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "f\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "h\n",
      "a\n",
      "s\n",
      " \n",
      "b\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "f\n",
      "i\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "f\n",
      "u\n",
      "l\n",
      "l\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      ".\n",
      "\n",
      "\n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "o\n",
      "p\n",
      "e\n",
      "r\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "d\n",
      "e\n",
      "f\n",
      "i\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "f\n",
      "o\n",
      "u\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      "\n",
      "\n",
      "a\n",
      "p\n",
      "p\n",
      "r\n",
      "o\n",
      "x\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "l\n",
      "y\n",
      " \n",
      "1\n",
      "5\n",
      "%\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      "k\n",
      "c\n",
      " \n",
      "p\n",
      "a\n",
      "i\n",
      "r\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "4\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "\n",
      "\n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "e\n",
      "l\n",
      " \n",
      "s\n",
      "p\n",
      "i\n",
      "n\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "s\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      "\n",
      "\n",
      "m\n",
      "a\n",
      "k\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "g\n",
      "r\n",
      "e\n",
      "s\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "s\n",
      "e\n",
      " \n",
      "k\n",
      "c\n",
      "s\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "u\n",
      "b\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "t\n",
      "i\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      " \n",
      "l\n",
      "o\n",
      "w\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "2\n",
      "5\n",
      "%\n",
      " \n",
      "r\n",
      "e\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "a\n",
      " \n",
      "r\n",
      "e\n",
      "c\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "e\n",
      "l\n",
      " \n",
      "s\n",
      "p\n",
      "i\n",
      "n\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "d\n",
      "e\n",
      "t\n",
      "e\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "[\n",
      "5\n",
      "]\n",
      ".\n",
      " \n",
      "a\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "o\n",
      "u\n",
      "t\n",
      "e\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "f\n",
      "u\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "k\n",
      " \n",
      "w\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      "\n",
      "\n",
      "d\n",
      "o\n",
      " \n",
      "a\n",
      " \n",
      "d\n",
      "i\n",
      "r\n",
      "e\n",
      "c\n",
      "t\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "a\n",
      "r\n",
      "i\n",
      "s\n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "e\n",
      "l\n",
      " \n",
      "s\n",
      "p\n",
      "i\n",
      "n\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "d\n",
      "e\n",
      "t\n",
      "e\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      "\n",
      "\n",
      "[\n",
      "5\n",
      "]\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "o\n",
      "u\n",
      "r\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "p\n",
      "o\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "/\n",
      "k\n",
      "c\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "f\n",
      "i\n",
      "e\n",
      "r\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "s\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "w\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "a\n",
      "l\n",
      "l\n",
      "o\n",
      "w\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "o\n",
      "s\n",
      "s\n",
      "i\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      "\n",
      "\n",
      "s\n",
      "o\n",
      "m\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "w\n",
      "h\n",
      "o\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "m\n",
      "a\n",
      "k\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "g\n",
      "r\n",
      "e\n",
      "s\n",
      "s\n",
      ",\n",
      " \n",
      "a\n",
      "l\n",
      "b\n",
      "e\n",
      "i\n",
      "t\n",
      " \n",
      "e\n",
      "x\n",
      "t\n",
      "r\n",
      "e\n",
      "m\n",
      "e\n",
      "l\n",
      "y\n",
      "\n",
      "\n",
      "s\n",
      "l\n",
      "o\n",
      "w\n",
      "l\n",
      "y\n",
      ",\n",
      " \n",
      "m\n",
      "a\n",
      "y\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      "l\n",
      "y\n",
      " \n",
      "l\n",
      "a\n",
      "b\n",
      "e\n",
      "l\n",
      "e\n",
      "d\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "“\n",
      "w\n",
      "h\n",
      "e\n",
      "e\n",
      "l\n",
      " \n",
      "s\n",
      "p\n",
      "i\n",
      "n\n",
      "n\n",
      "e\n",
      "r\n",
      "s\n",
      "”\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "[\n",
      "5\n",
      "]\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      ".\n",
      " \n",
      "s\n",
      "u\n",
      "m\n",
      "m\n",
      "a\n",
      "r\n",
      "y\n",
      " \n",
      "&\n",
      " \n",
      "l\n",
      "i\n",
      "m\n",
      "i\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "e\n",
      "v\n",
      "i\n",
      "o\n",
      "u\n",
      "s\n",
      " \n",
      "e\n",
      "f\n",
      "f\n",
      "o\n",
      "r\n",
      "t\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      "w\n",
      "a\n",
      "r\n",
      "d\n",
      "s\n",
      " \n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "e\n",
      "x\n",
      "p\n",
      "l\n",
      "a\n",
      "n\n",
      "a\n",
      "t\n",
      "o\n",
      "r\n",
      "y\n",
      ",\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "d\n",
      "v\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "a\n",
      "l\n",
      "m\n",
      " \n",
      "o\n",
      "f\n",
      "\n",
      "\n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      "/\n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "o\n",
      "n\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "d\n",
      "i\n",
      "s\n",
      "c\n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "y\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      " \n",
      "b\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "m\n",
      "i\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      " \n",
      "p\n",
      "o\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "a\n",
      "l\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "d\n",
      "e\n",
      "m\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "a\n",
      "c\n",
      "t\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "c\n",
      "i\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "e\n",
      "d\n",
      "u\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "a\n",
      "p\n",
      "e\n",
      "r\n",
      " \n",
      "r\n",
      "e\n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "n\n",
      "o\n",
      "v\n",
      "e\n",
      "l\n",
      " \n",
      "e\n",
      "f\n",
      "f\n",
      "o\n",
      "r\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "b\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "e\n",
      "p\n",
      "e\n",
      "r\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "p\n",
      "p\n",
      "r\n",
      "o\n",
      "a\n",
      "c\n",
      "h\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "f\n",
      "o\n",
      "c\n",
      "u\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "e\n",
      "n\n",
      "s\n",
      "u\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "e\n",
      "x\n",
      "p\n",
      "l\n",
      "a\n",
      "n\n",
      "a\n",
      "t\n",
      "o\n",
      "r\n",
      "y\n",
      " \n",
      "p\n",
      "o\n",
      "w\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "a\n",
      "l\n",
      "m\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "t\n",
      "o\n",
      "w\n",
      "a\n",
      "r\n",
      "d\n",
      "s\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "l\n",
      "l\n",
      "e\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "p\n",
      "o\n",
      "p\n",
      "u\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ".\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "“\n",
      "d\n",
      "e\n",
      "e\n",
      "p\n",
      "”\n",
      " \n",
      "a\n",
      "l\n",
      "o\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "i\n",
      "m\n",
      "e\n",
      "n\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "f\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      "k\n",
      "c\n",
      " \n",
      "o\n",
      "b\n",
      "s\n",
      "e\n",
      "r\n",
      "v\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "f\n",
      "i\n",
      "t\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      "\n",
      "\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "w\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "o\n",
      "u\n",
      "t\n",
      "r\n",
      "a\n",
      "n\n",
      "k\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      " \n",
      "n\n",
      "o\n",
      "n\n",
      "-\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "u\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "p\n",
      "a\n",
      "r\n",
      "t\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "e\n",
      "r\n",
      "m\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "f\n",
      "i\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "c\n",
      "u\n",
      "r\n",
      "a\n",
      "c\n",
      "y\n",
      ".\n",
      "\n",
      "\n",
      "i\n",
      "m\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "a\n",
      "n\n",
      "t\n",
      "l\n",
      "y\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "v\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "e\n",
      "y\n",
      "o\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "m\n",
      "e\n",
      "t\n",
      "r\n",
      "i\n",
      "c\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "w\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      "\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "h\n",
      "i\n",
      "g\n",
      "h\n",
      "l\n",
      "y\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "(\n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      "\n",
      "\n",
      "y\n",
      "i\n",
      "e\n",
      "l\n",
      "d\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "o\n",
      "n\n",
      "g\n",
      "l\n",
      "y\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ")\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      " \n",
      "(\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      "l\n",
      "y\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      ")\n",
      ".\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "d\n",
      "e\n",
      "m\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "f\n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      ",\n",
      " \n",
      "b\n",
      "u\n",
      "t\n",
      " \n",
      "e\n",
      "v\n",
      "e\n",
      "n\n",
      " \n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "s\n",
      "o\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      ",\n",
      " \n",
      "h\n",
      "a\n",
      "s\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "m\n",
      "i\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "\n",
      "\n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "o\n",
      "s\n",
      "s\n",
      "i\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      "\n",
      "\n",
      "d\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "m\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "m\n",
      "a\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "y\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "l\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "y\n",
      "s\n",
      "t\n",
      "e\n",
      "m\n",
      "s\n",
      " \n",
      "a\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "s\n",
      "t\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "e\n",
      "r\n",
      "m\n",
      "s\n",
      "\n",
      "\n",
      "o\n",
      "f\n",
      " \n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "l\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      "/\n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      ".\n",
      " \n",
      "o\n",
      "u\n",
      "r\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "u\n",
      "l\n",
      "t\n",
      "s\n",
      " \n",
      "a\n",
      "l\n",
      "s\n",
      "o\n",
      " \n",
      "s\n",
      "u\n",
      "g\n",
      "g\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      "\n",
      "\n",
      "i\n",
      "t\n",
      " \n",
      "w\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "a\n",
      "s\n",
      "o\n",
      "n\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "f\n",
      "i\n",
      "x\n",
      " \n",
      "s\n",
      "u\n",
      "c\n",
      "h\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      ",\n",
      " \n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "s\n",
      "e\n",
      "t\n",
      " \n",
      "p\n",
      "r\n",
      "i\n",
      "o\n",
      "r\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "m\n",
      ",\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "e\n",
      "i\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "w\n",
      "e\n",
      "l\n",
      "l\n",
      "-\n",
      "m\n",
      "a\n",
      "p\n",
      "p\n",
      "e\n",
      "d\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      "\n",
      "\n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "o\n",
      "r\n",
      " \n",
      "p\n",
      "r\n",
      "i\n",
      "o\n",
      "r\n",
      " \n",
      "(\n",
      "d\n",
      "e\n",
      "e\n",
      "p\n",
      ")\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "s\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      "’\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      ".\n",
      "\n",
      "\n",
      "w\n",
      "e\n",
      " \n",
      "a\n",
      "l\n",
      "s\n",
      "o\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "w\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "p\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "o\n",
      "n\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      "\n",
      "\n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "(\n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "4\n",
      ")\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "f\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "e\n",
      "v\n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      ",\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "o\n",
      "u\n",
      "r\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      "o\n",
      "f\n",
      " \n",
      "o\n",
      "b\n",
      "t\n",
      "a\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "r\n",
      "o\n",
      "u\n",
      "g\n",
      "h\n",
      "\n",
      "\n",
      "a\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      "\n",
      "\n",
      "b\n",
      "e\n",
      "l\n",
      "i\n",
      "e\n",
      "v\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "s\n",
      "u\n",
      "c\n",
      "c\n",
      "e\n",
      "s\n",
      "s\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "l\n",
      "a\n",
      "r\n",
      "g\n",
      "e\n",
      "l\n",
      "y\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "a\n",
      "m\n",
      "o\n",
      "u\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "q\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "p\n",
      "e\n",
      "r\n",
      "-\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "l\n",
      "l\n",
      "e\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      ".\n",
      "\n",
      "\n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "f\n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "n\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "c\n",
      "e\n",
      "e\n",
      "d\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "f\n",
      "u\n",
      "r\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "i\n",
      "n\n",
      "v\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "g\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "p\n",
      "o\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "e\n",
      "x\n",
      "p\n",
      "l\n",
      "a\n",
      "n\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "4\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\f",
      "\n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "4\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "f\n",
      "o\n",
      "u\n",
      "n\n",
      "d\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "o\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "i\n",
      "g\n",
      "n\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "n\n",
      "t\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      "\n",
      "\n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      "l\n",
      "l\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "\n",
      "\n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "e\n",
      "f\n",
      "f\n",
      "e\n",
      "c\n",
      "t\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "d\n",
      "i\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      ",\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      "-\n",
      "r\n",
      "e\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      " \n",
      "m\n",
      "e\n",
      "a\n",
      "s\n",
      "u\n",
      "r\n",
      "e\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "f\n",
      "u\n",
      "r\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "a\n",
      "r\n",
      "c\n",
      "h\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "w\n",
      "a\n",
      "r\n",
      "r\n",
      "a\n",
      "n\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "d\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "c\n",
      "a\n",
      "u\n",
      "s\n",
      "a\n",
      "l\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      "s\n",
      "\n",
      "\n",
      "b\n",
      "e\n",
      "t\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "a\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "’\n",
      "s\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      " \n",
      "o\n",
      "n\n",
      "l\n",
      "y\n",
      " \n",
      "f\n",
      "i\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "w\n",
      "e\n",
      "l\n",
      "l\n",
      ",\n",
      " \n",
      "b\n",
      "u\n",
      "t\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      ",\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "i\n",
      "d\n",
      "e\n",
      "s\n",
      " \n",
      "g\n",
      "r\n",
      "e\n",
      "a\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "f\n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "a\n",
      "p\n",
      "p\n",
      "l\n",
      "y\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "(\n",
      "1\n",
      ")\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "u\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "e\n",
      "r\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "(\n",
      "2\n",
      ")\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "j\n",
      "e\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "m\n",
      "a\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "y\n",
      "\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "f\n",
      "u\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "e\n",
      "v\n",
      "e\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "u\n",
      "g\n",
      "h\n",
      " \n",
      "b\n",
      "o\n",
      "t\n",
      "h\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "o\n",
      "u\n",
      "t\n",
      "p\n",
      "e\n",
      "r\n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      " \n",
      "n\n",
      "o\n",
      "n\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "c\n",
      "o\n",
      "u\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "p\n",
      "a\n",
      "r\n",
      "t\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "p\n",
      "e\n",
      "r\n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "3\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "d\n",
      "i\n",
      "d\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      " \n",
      "f\n",
      "i\n",
      "n\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "r\n",
      "o\n",
      "n\n",
      "g\n",
      " \n",
      "e\n",
      "v\n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      "\n",
      "\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      "s\n",
      "p\n",
      "e\n",
      "c\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "u\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      "\n",
      "\n",
      "d\n",
      "i\n",
      "d\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "y\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "h\n",
      "e\n",
      "l\n",
      "p\n",
      " \n",
      "u\n",
      "s\n",
      " \n",
      "u\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "a\n",
      "s\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "c\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "f\n",
      "i\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "l\n",
      "y\n",
      " \n",
      "a\n",
      "t\n",
      "t\n",
      "r\n",
      "i\n",
      "b\n",
      "u\n",
      "t\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      ",\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "r\n",
      "u\n",
      "e\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      "’\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      "’\n",
      " \n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "r\n",
      "i\n",
      "a\n",
      "l\n",
      ".\n",
      "\n",
      "\n",
      "a\n",
      "l\n",
      "t\n",
      "h\n",
      "o\n",
      "u\n",
      "g\n",
      "h\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "s\n",
      "i\n",
      "d\n",
      "e\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      "’\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "h\n",
      "i\n",
      "g\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "b\n",
      "a\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "n\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "c\n",
      "u\n",
      "r\n",
      "a\n",
      "c\n",
      "y\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "e\n",
      "v\n",
      "a\n",
      "l\n",
      "u\n",
      "a\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "d\n",
      "v\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "b\n",
      "e\n",
      "l\n",
      "i\n",
      "e\n",
      "v\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "s\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "a\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "c\n",
      "h\n",
      "a\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "e\n",
      "r\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "a\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "e\n",
      "x\n",
      "p\n",
      "l\n",
      "a\n",
      "n\n",
      "a\n",
      "t\n",
      "o\n",
      "r\n",
      "y\n",
      ",\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      "a\n",
      "n\n",
      "d\n",
      "/\n",
      "o\n",
      "r\n",
      " \n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      ".\n",
      " \n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "m\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "a\n",
      "\n",
      "\n",
      "s\n",
      "u\n",
      "f\n",
      "f\n",
      "i\n",
      "c\n",
      "i\n",
      "e\n",
      "n\n",
      "t\n",
      "l\n",
      "y\n",
      " \n",
      "g\n",
      "o\n",
      "o\n",
      "d\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      ",\n",
      " \n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "c\n",
      "a\n",
      "n\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "d\n",
      "u\n",
      "c\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "s\n",
      "i\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "u\n",
      "r\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "s\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "k\n",
      " \n",
      "w\n",
      "a\n",
      "s\n",
      " \n",
      "l\n",
      "i\n",
      "m\n",
      "i\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "n\n",
      "e\n",
      "\n",
      "\n",
      "p\n",
      "o\n",
      "p\n",
      "u\n",
      "l\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      ",\n",
      " \n",
      "i\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "u\n",
      "n\n",
      "c\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "g\n",
      "r\n",
      "e\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      " \n",
      "o\n",
      "u\n",
      "r\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "u\n",
      "l\n",
      "t\n",
      "s\n",
      " \n",
      "w\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "g\n",
      "e\n",
      "n\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      ",\n",
      " \n",
      "e\n",
      "s\n",
      "p\n",
      "e\n",
      "c\n",
      "i\n",
      "a\n",
      "l\n",
      "l\n",
      "y\n",
      " \n",
      "g\n",
      "i\n",
      "v\n",
      "e\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "a\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "s\n",
      "t\n",
      "\n",
      "\n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "d\n",
      "o\n",
      "e\n",
      "s\n",
      " \n",
      "n\n",
      "o\n",
      "t\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "d\n",
      "u\n",
      "c\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      ",\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "s\n",
      "p\n",
      "a\n",
      "r\n",
      "s\n",
      "e\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      "s\n",
      " \n",
      "[\n",
      "9\n",
      "]\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      "d\n",
      "d\n",
      "i\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "s\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "u\n",
      "l\n",
      "t\n",
      "s\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "l\n",
      "i\n",
      "m\n",
      "i\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      "\n",
      "\n",
      "t\n",
      "w\n",
      "o\n",
      " \n",
      "s\n",
      "p\n",
      "e\n",
      "c\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "d\n",
      "u\n",
      "c\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      "l\n",
      "e\n",
      "v\n",
      "e\n",
      "l\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "a\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "t\n",
      "i\n",
      "c\n",
      "u\n",
      "l\n",
      "a\n",
      "r\n",
      " \n",
      "f\n",
      "o\n",
      "c\n",
      "u\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "o\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "c\n",
      "l\n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "e\n",
      "x\n",
      "t\n",
      "e\n",
      "n\n",
      "d\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      ":\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "e\n",
      "x\n",
      "a\n",
      "m\n",
      "p\n",
      "l\n",
      "e\n",
      ",\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "d\n",
      "u\n",
      "c\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "d\n",
      "i\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "e\n",
      "f\n",
      "f\n",
      "e\n",
      "c\n",
      "t\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "s\n",
      "u\n",
      "c\n",
      "c\n",
      "e\n",
      "s\n",
      "s\n",
      " \n",
      "v\n",
      "e\n",
      "r\n",
      "s\n",
      "u\n",
      "s\n",
      " \n",
      "f\n",
      "a\n",
      "i\n",
      "l\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "[\n",
      "1\n",
      "5\n",
      "]\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "w\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "f\n",
      "o\n",
      "c\n",
      "u\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "f\n",
      "u\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "k\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      "p\n",
      "i\n",
      "c\n",
      ".\n",
      "\n",
      "\n",
      "n\n",
      "e\n",
      "v\n",
      "e\n",
      "r\n",
      "t\n",
      "h\n",
      "e\n",
      "l\n",
      "e\n",
      "s\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      " \n",
      "l\n",
      "a\n",
      "i\n",
      "d\n",
      " \n",
      "a\n",
      " \n",
      "f\n",
      "o\n",
      "u\n",
      "n\n",
      "d\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "m\n",
      "e\n",
      "t\n",
      "h\n",
      "o\n",
      "d\n",
      "o\n",
      "l\n",
      "o\n",
      "g\n",
      "y\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "w\n",
      "h\n",
      "i\n",
      "c\n",
      "h\n",
      "\n",
      "\n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "i\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "-\n",
      " \n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "k\n",
      "c\n",
      "-\n",
      "l\n",
      "e\n",
      "v\n",
      "e\n",
      "l\n",
      ",\n",
      " \n",
      "c\n",
      "a\n",
      "n\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "a\n",
      "s\n",
      "s\n",
      "e\n",
      "s\n",
      "s\n",
      "e\n",
      "d\n",
      ".\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      " \n",
      "a\n",
      "l\n",
      "s\n",
      "o\n",
      " \n",
      "d\n",
      "e\n",
      "m\n",
      "o\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "w\n",
      "a\n",
      "y\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      "\n",
      "\n",
      "u\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "i\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "t\n",
      "e\n",
      "r\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "f\n",
      "r\n",
      "o\n",
      "m\n",
      "\n",
      "\n",
      "i\n",
      "a\n",
      "f\n",
      "m\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "b\n",
      "k\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "y\n",
      "i\n",
      "e\n",
      "l\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "i\n",
      "n\n",
      "s\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      "s\n",
      " \n",
      "a\n",
      "b\n",
      "o\n",
      "u\n",
      "t\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6\n",
      ".\n",
      " \n",
      "a\n",
      "c\n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      "\n",
      "\n",
      "w\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "n\n",
      "k\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "s\n",
      "t\n",
      "i\n",
      "t\n",
      "u\n",
      "t\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "e\n",
      "d\n",
      "u\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "s\n",
      "c\n",
      "i\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "s\n",
      "u\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "r\n",
      "l\n",
      "\n",
      "\n",
      "(\n",
      "t\n",
      "r\n",
      "a\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "g\n",
      "r\n",
      "a\n",
      "n\n",
      "t\n",
      " \n",
      "#\n",
      "r\n",
      "3\n",
      "0\n",
      "5\n",
      "b\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      ")\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "n\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "s\n",
      "c\n",
      "i\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "\n",
      "\n",
      "f\n",
      "o\n",
      "u\n",
      "n\n",
      "d\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "s\n",
      "u\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "c\n",
      "a\n",
      "r\n",
      "n\n",
      "e\n",
      "g\n",
      "i\n",
      "e\n",
      " \n",
      "m\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n",
      "n\n",
      " \n",
      "u\n",
      "n\n",
      "i\n",
      "v\n",
      "e\n",
      "r\n",
      "s\n",
      "i\n",
      "t\n",
      "y\n",
      "’\n",
      "s\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "l\n",
      "a\n",
      "b\n",
      "\n",
      "\n",
      "(\n",
      "#\n",
      "s\n",
      "b\n",
      "e\n",
      "-\n",
      "0\n",
      "8\n",
      "3\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      ")\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "7\n",
      ".\n",
      " \n",
      "r\n",
      "e\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "s\n",
      "\n",
      "\n",
      "[\n",
      "1\n",
      "]\n",
      " \n",
      "a\n",
      "l\n",
      "e\n",
      "v\n",
      "e\n",
      "n\n",
      ",\n",
      " \n",
      "v\n",
      ".\n",
      ",\n",
      " \n",
      "s\n",
      "e\n",
      "w\n",
      "a\n",
      "l\n",
      "l\n",
      ",\n",
      " \n",
      "j\n",
      ".\n",
      ",\n",
      " \n",
      "m\n",
      "c\n",
      "l\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      ",\n",
      " \n",
      "b\n",
      ".\n",
      "m\n",
      ".\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "k\n",
      "o\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "k\n",
      ".\n",
      "r\n",
      ".\n",
      "\n",
      "\n",
      "(\n",
      "2\n",
      "0\n",
      "0\n",
      "6\n",
      ")\n",
      ".\n",
      " \n",
      "r\n",
      "a\n",
      "p\n",
      "i\n",
      "d\n",
      " \n",
      "a\n",
      "u\n",
      "t\n",
      "h\n",
      "o\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "l\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "r\n",
      "e\n",
      "a\n",
      "l\n",
      "-\n",
      "w\n",
      "o\n",
      "r\n",
      "l\n",
      "d\n",
      "\n",
      "\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "e\n",
      "x\n",
      "p\n",
      "e\n",
      "r\n",
      "i\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "a\n",
      "l\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "c\n",
      "e\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "6\n",
      "t\n",
      "h\n",
      " \n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      "t\n",
      ".\n",
      "\n",
      "\n",
      "i\n",
      "e\n",
      "e\n",
      "e\n",
      ",\n",
      " \n",
      "l\n",
      "o\n",
      "s\n",
      " \n",
      "a\n",
      "l\n",
      "a\n",
      "m\n",
      "i\n",
      "t\n",
      "o\n",
      "s\n",
      ",\n",
      " \n",
      "c\n",
      "a\n",
      ",\n",
      " \n",
      "p\n",
      "p\n",
      ".\n",
      " \n",
      "8\n",
      "4\n",
      "7\n",
      "-\n",
      "8\n",
      "5\n",
      "1\n",
      ".\n",
      "\n",
      "\n",
      "[\n",
      "2\n",
      "]\n",
      " \n",
      "c\n",
      "e\n",
      "n\n",
      ",\n",
      " \n",
      "h\n",
      ".\n",
      ",\n",
      " \n",
      "k\n",
      "o\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "k\n",
      ".\n",
      "r\n",
      ".\n",
      ",\n",
      " \n",
      "&\n",
      " \n",
      "j\n",
      "u\n",
      "n\n",
      "k\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "b\n",
      ".\n",
      " \n",
      "(\n",
      "2\n",
      "0\n",
      "0\n",
      "6\n",
      ")\n",
      ".\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "a\n",
      "l\n",
      "y\n",
      "s\n",
      "i\n",
      "s\n",
      ":\n",
      " \n",
      "a\n",
      " \n",
      "g\n",
      "e\n",
      "n\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      " \n",
      "m\n",
      "e\n",
      "t\n",
      "h\n",
      "o\n",
      "d\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "c\n",
      "o\n",
      "g\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "\n",
      "\n",
      "e\n",
      "v\n",
      "a\n",
      "l\n",
      "u\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "l\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "y\n",
      "s\n",
      "t\n",
      "e\n",
      "m\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      "1\n",
      "6\n",
      "4\n",
      "-\n",
      "1\n",
      "7\n",
      "5\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[\n",
      "3\n",
      "]\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "b\n",
      "e\n",
      "t\n",
      "t\n",
      ",\n",
      " \n",
      "a\n",
      ".\n",
      "t\n",
      ".\n",
      ",\n",
      " \n",
      "&\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      "s\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "j\n",
      ".\n",
      "r\n",
      ".\n",
      " \n",
      "(\n",
      "1\n",
      "9\n",
      "9\n",
      "5\n",
      ")\n",
      ".\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "i\n",
      "n\n",
      "g\n",
      ":\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "a\n",
      "c\n",
      "q\n",
      "u\n",
      "i\n",
      "s\n",
      "i\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "c\n",
      "e\n",
      "d\n",
      "u\n",
      "r\n",
      "a\n",
      "l\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      ".\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      "r\n",
      "-\n",
      "a\n",
      "d\n",
      "a\n",
      "p\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "4\n",
      ",\n",
      " \n",
      "2\n",
      "5\n",
      "3\n",
      "-\n",
      "2\n",
      "7\n",
      "8\n",
      ".\n",
      "\n",
      "\n",
      "[\n",
      "4\n",
      "]\n",
      " \n",
      "d\n",
      "i\n",
      "e\n",
      "t\n",
      "t\n",
      "e\n",
      "r\n",
      "i\n",
      "c\n",
      "h\n",
      ",\n",
      " \n",
      "t\n",
      ".\n",
      " \n",
      "g\n",
      ".\n",
      " \n",
      "(\n",
      "1\n",
      "9\n",
      "9\n",
      "8\n",
      ")\n",
      ".\n",
      " \n",
      "a\n",
      "p\n",
      "p\n",
      "r\n",
      "o\n",
      "x\n",
      "i\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      " \n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      "s\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "a\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "u\n",
      "p\n",
      "e\n",
      "r\n",
      "v\n",
      "i\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "c\n",
      "l\n",
      "a\n",
      "s\n",
      "s\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "l\n",
      "g\n",
      "o\n",
      "r\n",
      "i\n",
      "t\n",
      "h\n",
      "m\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "n\n",
      "e\n",
      "u\n",
      "r\n",
      "a\n",
      "l\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "u\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "1\n",
      "0\n",
      "(\n",
      "7\n",
      ")\n",
      ",\n",
      " \n",
      "1\n",
      "8\n",
      "9\n",
      "5\n",
      "–\n",
      "1\n",
      "9\n",
      "2\n",
      "3\n",
      ".\n",
      "\n",
      "\n",
      "[\n",
      "5\n",
      "]\n",
      " \n",
      "g\n",
      "o\n",
      "n\n",
      "g\n",
      ",\n",
      " \n",
      "y\n",
      ".\n",
      " \n",
      "&\n",
      " \n",
      "b\n",
      "e\n",
      "c\n",
      "k\n",
      ",\n",
      " \n",
      "j\n",
      ".\n",
      " \n",
      "(\n",
      "2\n",
      "0\n",
      "1\n",
      "5\n",
      ")\n",
      ".\n",
      " \n",
      "t\n",
      "o\n",
      "w\n",
      "a\n",
      "r\n",
      "d\n",
      "s\n",
      " \n",
      "d\n",
      "e\n",
      "t\n",
      "e\n",
      "c\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "e\n",
      "l\n",
      "s\n",
      "p\n",
      "i\n",
      "n\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      ":\n",
      " \n",
      "f\n",
      "u\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "f\n",
      "a\n",
      "i\n",
      "l\n",
      "u\n",
      "r\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "m\n",
      "a\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "y\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "o\n",
      "c\n",
      "e\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "t\n",
      " \n",
      "s\n",
      "c\n",
      "a\n",
      "l\n",
      "e\n",
      " \n",
      "’\n",
      "1\n",
      "5\n",
      ".\n",
      "\n",
      "\n",
      "[\n",
      "6\n",
      "]\n",
      " \n",
      "k\n",
      "o\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "k\n",
      ".\n",
      "r\n",
      ".\n",
      ",\n",
      " \n",
      "c\n",
      "o\n",
      "r\n",
      "b\n",
      "e\n",
      "t\n",
      "t\n",
      ",\n",
      " \n",
      "a\n",
      ".\n",
      "c\n",
      ".\n",
      ",\n",
      " \n",
      "&\n",
      " \n",
      "p\n",
      "e\n",
      "r\n",
      "f\n",
      "e\n",
      "t\n",
      "t\n",
      "i\n",
      ",\n",
      " \n",
      "c\n",
      ".\n",
      " \n",
      "(\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      ")\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      "-\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      "-\n",
      "i\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "(\n",
      "k\n",
      "l\n",
      "i\n",
      ")\n",
      " \n",
      "f\n",
      "r\n",
      "a\n",
      "m\n",
      "e\n",
      "w\n",
      "o\n",
      "r\n",
      "k\n",
      ":\n",
      " \n",
      "b\n",
      "r\n",
      "i\n",
      "d\n",
      "g\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "c\n",
      "i\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      "-\n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "s\n",
      "m\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "e\n",
      "n\n",
      "h\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "r\n",
      "o\n",
      "b\n",
      "u\n",
      "s\n",
      "t\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      "\n",
      "\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      ".\n",
      " \n",
      "c\n",
      "o\n",
      "g\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "s\n",
      "c\n",
      "i\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      ",\n",
      " \n",
      "3\n",
      "6\n",
      "(\n",
      "5\n",
      ")\n",
      ",\n",
      " \n",
      "7\n",
      "5\n",
      "7\n",
      "-\n",
      "7\n",
      "9\n",
      "8\n",
      ".\n",
      "\n",
      "\n",
      "[\n",
      "7\n",
      "]\n",
      " \n",
      "k\n",
      "o\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "k\n",
      ".\n",
      "r\n",
      ".\n",
      ",\n",
      " \n",
      "m\n",
      "c\n",
      "l\n",
      "a\n",
      "u\n",
      "g\n",
      "h\n",
      "l\n",
      "i\n",
      "n\n",
      ",\n",
      " \n",
      "e\n",
      ".\n",
      "a\n",
      ".\n",
      ",\n",
      " \n",
      "&\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "m\n",
      "p\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "j\n",
      ".\n",
      "c\n",
      ".\n",
      " \n",
      "(\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      ")\n",
      ".\n",
      "\n",
      "\n",
      "a\n",
      "u\n",
      "t\n",
      "o\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      ".\n",
      " \n",
      "5\n",
      "t\n",
      "h\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "e\n",
      "d\n",
      "m\n",
      ".\n",
      "\n",
      "\n",
      "[\n",
      "8\n",
      "]\n",
      " \n",
      "k\n",
      "o\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "k\n",
      ".\n",
      " \n",
      "r\n",
      ".\n",
      ",\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "m\n",
      "p\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "j\n",
      ".\n",
      " \n",
      "c\n",
      ".\n",
      ",\n",
      " \n",
      "m\n",
      "c\n",
      "l\n",
      "a\n",
      "u\n",
      "g\n",
      "h\n",
      "l\n",
      "i\n",
      "n\n",
      ",\n",
      " \n",
      "e\n",
      ".\n",
      " \n",
      "a\n",
      ".\n",
      ",\n",
      " \n",
      "&\n",
      "\n",
      "\n",
      "n\n",
      "i\n",
      "x\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "t\n",
      ".\n",
      " \n",
      "(\n",
      "2\n",
      "0\n",
      "1\n",
      "3\n",
      ")\n",
      ".\n",
      " \n",
      "u\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "-\n",
      "d\n",
      "r\n",
      "i\n",
      "v\n",
      "e\n",
      "n\n",
      " \n",
      "d\n",
      "i\n",
      "s\n",
      "c\n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "y\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "b\n",
      "e\n",
      "t\n",
      "t\n",
      "e\n",
      "r\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "g\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "h\n",
      ".\n",
      " \n",
      "c\n",
      ".\n",
      " \n",
      "l\n",
      "a\n",
      "n\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      "k\n",
      ".\n",
      " \n",
      "y\n",
      "a\n",
      "c\n",
      "e\n",
      "f\n",
      ",\n",
      " \n",
      "j\n",
      ".\n",
      " \n",
      "m\n",
      "o\n",
      "s\n",
      "t\n",
      "o\n",
      "w\n",
      ",\n",
      " \n",
      "&\n",
      " \n",
      "p\n",
      ".\n",
      " \n",
      "p\n",
      "a\n",
      "v\n",
      "l\n",
      "i\n",
      "k\n",
      " \n",
      "(\n",
      "e\n",
      "d\n",
      "s\n",
      ".\n",
      ")\n",
      ",\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "c\n",
      "e\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "1\n",
      "6\n",
      "t\n",
      "h\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "a\n",
      "r\n",
      "t\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "i\n",
      "a\n",
      "l\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "l\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "\n",
      "\n",
      "e\n",
      "d\n",
      "u\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "(\n",
      "a\n",
      "i\n",
      "e\n",
      "d\n",
      " \n",
      "ʼ\n",
      "1\n",
      "3\n",
      ")\n",
      ",\n",
      " \n",
      "9\n",
      "–\n",
      "1\n",
      "3\n",
      " \n",
      "j\n",
      "u\n",
      "l\n",
      "y\n",
      " \n",
      "2\n",
      "0\n",
      "1\n",
      "3\n",
      ",\n",
      " \n",
      "m\n",
      "e\n",
      "m\n",
      "p\n",
      "h\n",
      "i\n",
      "s\n",
      ",\n",
      " \n",
      "t\n",
      "n\n",
      ",\n",
      " \n",
      "u\n",
      "s\n",
      "a\n",
      "\n",
      "\n",
      "(\n",
      "p\n",
      "p\n",
      ".\n",
      " \n",
      "4\n",
      "2\n",
      "1\n",
      "–\n",
      "4\n",
      "3\n",
      "0\n",
      ")\n",
      ".\n",
      " \n",
      "s\n",
      "p\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      ".\n",
      "\n",
      "\n",
      "[\n",
      "9\n",
      "]\n",
      " \n",
      "l\n",
      "i\n",
      "u\n",
      ",\n",
      " \n",
      "r\n",
      ".\n",
      ",\n",
      " \n",
      "&\n",
      " \n",
      "k\n",
      "o\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "k\n",
      ".\n",
      " \n",
      "r\n",
      ".\n",
      " \n",
      "(\n",
      "2\n",
      "0\n",
      "1\n",
      "5\n",
      ")\n",
      ".\n",
      " \n",
      "v\n",
      "a\n",
      "r\n",
      "i\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      ":\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "c\n",
      "l\n",
      "a\n",
      "s\n",
      "s\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "b\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "s\n",
      "y\n",
      "s\n",
      "t\n",
      "e\n",
      "m\n",
      "a\n",
      "t\n",
      "i\n",
      "c\n",
      " \n",
      "r\n",
      "e\n",
      "s\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      " \n",
      "e\n",
      "r\n",
      "r\n",
      "o\n",
      "r\n",
      "\n",
      "\n",
      "p\n",
      "a\n",
      "t\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      "s\n",
      " \n",
      "a\n",
      "c\n",
      "r\n",
      "o\n",
      "s\n",
      "s\n",
      " \n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "o\n",
      ".\n",
      " \n",
      "c\n",
      ".\n",
      " \n",
      "s\n",
      "a\n",
      "n\n",
      "t\n",
      "o\n",
      "s\n",
      ",\n",
      " \n",
      "j\n",
      ".\n",
      " \n",
      "g\n",
      ".\n",
      "\n",
      "\n",
      "b\n",
      "o\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "r\n",
      "i\n",
      "o\n",
      ",\n",
      " \n",
      "c\n",
      ".\n",
      " \n",
      "r\n",
      "o\n",
      "m\n",
      "e\n",
      "r\n",
      "o\n",
      ",\n",
      " \n",
      "m\n",
      ".\n",
      " \n",
      "p\n",
      "e\n",
      "c\n",
      "h\n",
      "e\n",
      "n\n",
      "i\n",
      "z\n",
      "k\n",
      "i\n",
      "y\n",
      ",\n",
      " \n",
      "a\n",
      ".\n",
      " \n",
      "m\n",
      "e\n",
      "r\n",
      "c\n",
      "e\n",
      "r\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "p\n",
      ".\n",
      "\n",
      "\n",
      "m\n",
      "i\n",
      "t\n",
      "r\n",
      "o\n",
      "s\n",
      ",\n",
      " \n",
      "j\n",
      ".\n",
      " \n",
      "m\n",
      ".\n",
      " \n",
      "l\n",
      "u\n",
      "n\n",
      "a\n",
      ",\n",
      " \n",
      "c\n",
      ".\n",
      " \n",
      "m\n",
      "i\n",
      "h\n",
      "a\n",
      "e\n",
      "s\n",
      "c\n",
      "u\n",
      ",\n",
      " \n",
      "p\n",
      ".\n",
      " \n",
      "m\n",
      "o\n",
      "r\n",
      "e\n",
      "n\n",
      "o\n",
      ",\n",
      " \n",
      "a\n",
      ".\n",
      " \n",
      "h\n",
      "e\n",
      "r\n",
      "s\n",
      "h\n",
      "k\n",
      "o\n",
      "v\n",
      "i\n",
      "t\n",
      "z\n",
      ",\n",
      "\n",
      "\n",
      "s\n",
      ".\n",
      " \n",
      "v\n",
      "e\n",
      "n\n",
      "t\n",
      "u\n",
      "r\n",
      "a\n",
      ",\n",
      " \n",
      "&\n",
      " \n",
      "m\n",
      ".\n",
      " \n",
      "d\n",
      "e\n",
      "s\n",
      "m\n",
      "a\n",
      "r\n",
      "a\n",
      "i\n",
      "s\n",
      " \n",
      "(\n",
      "e\n",
      "d\n",
      "s\n",
      ".\n",
      ")\n",
      ",\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "c\n",
      "e\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "8\n",
      "t\n",
      "h\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "e\n",
      "d\n",
      "u\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "m\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "(\n",
      "e\n",
      "d\n",
      "m\n",
      "2\n",
      "0\n",
      "1\n",
      "5\n",
      ")\n",
      ",\n",
      " \n",
      "2\n",
      "6\n",
      "–\n",
      "2\n",
      "9\n",
      " \n",
      "j\n",
      "u\n",
      "n\n",
      "e\n",
      " \n",
      "2\n",
      "0\n",
      "1\n",
      "5\n",
      ",\n",
      " \n",
      "m\n",
      "a\n",
      "d\n",
      "r\n",
      "i\n",
      "d\n",
      ",\n",
      " \n",
      "s\n",
      "p\n",
      "a\n",
      "i\n",
      "n\n",
      " \n",
      "(\n",
      "p\n",
      "p\n",
      ".\n",
      " \n",
      "4\n",
      "2\n",
      "0\n",
      "–\n",
      "4\n",
      "2\n",
      "3\n",
      ")\n",
      ".\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "e\n",
      "d\n",
      "u\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "m\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n",
      "o\n",
      "c\n",
      "i\n",
      "e\n",
      "t\n",
      "y\n",
      ".\n",
      "\n",
      "\n",
      "[\n",
      "1\n",
      "0\n",
      "]\n",
      " \n",
      "l\n",
      "i\n",
      "u\n",
      ",\n",
      " \n",
      "r\n",
      ".\n",
      ",\n",
      " \n",
      "&\n",
      " \n",
      "k\n",
      "o\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "k\n",
      ".\n",
      " \n",
      "r\n",
      ".\n",
      " \n",
      "(\n",
      "u\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      " \n",
      "r\n",
      "e\n",
      "v\n",
      "i\n",
      "e\n",
      "w\n",
      ")\n",
      ".\n",
      " \n",
      "c\n",
      "l\n",
      "o\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "\n",
      "\n",
      "l\n",
      "o\n",
      "o\n",
      "p\n",
      ":\n",
      " \n",
      "a\n",
      "u\n",
      "t\n",
      "o\n",
      "m\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "-\n",
      "d\n",
      "r\n",
      "i\n",
      "v\n",
      "e\n",
      "n\n",
      " \n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "d\n",
      "i\n",
      "s\n",
      "c\n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "i\n",
      "e\n",
      "s\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      "\n",
      "\n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      "s\n",
      "t\n",
      "r\n",
      "u\n",
      "c\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "g\n",
      "a\n",
      "i\n",
      "n\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "[\n",
      "1\n",
      "1\n",
      "]\n",
      " \n",
      "l\n",
      "i\n",
      "u\n",
      ",\n",
      " \n",
      "r\n",
      ".\n",
      ",\n",
      " \n",
      "k\n",
      "o\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "k\n",
      ".\n",
      " \n",
      "r\n",
      ".\n",
      ",\n",
      " \n",
      "&\n",
      " \n",
      "m\n",
      "c\n",
      "l\n",
      "a\n",
      "u\n",
      "g\n",
      "h\n",
      "l\n",
      "i\n",
      "n\n",
      ",\n",
      " \n",
      "e\n",
      ".\n",
      " \n",
      "a\n",
      ".\n",
      " \n",
      "(\n",
      "2\n",
      "0\n",
      "1\n",
      "4\n",
      ")\n",
      ".\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "p\n",
      "r\n",
      "e\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "d\n",
      "i\n",
      "s\n",
      "c\n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "t\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "g\n",
      "e\n",
      "n\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "a\n",
      "\n",
      "\n",
      "n\n",
      "e\n",
      "w\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "e\n",
      "t\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "j\n",
      ".\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "m\n",
      "p\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "z\n",
      ".\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "d\n",
      "o\n",
      "s\n",
      ",\n",
      " \n",
      "m\n",
      ".\n",
      " \n",
      "m\n",
      "a\n",
      "v\n",
      "r\n",
      "i\n",
      "k\n",
      "i\n",
      "s\n",
      ",\n",
      " \n",
      "&\n",
      " \n",
      "b\n",
      ".\n",
      " \n",
      "m\n",
      ".\n",
      "\n",
      "\n",
      "m\n",
      "c\n",
      "l\n",
      "a\n",
      "r\n",
      "e\n",
      "n\n",
      " \n",
      "(\n",
      "e\n",
      "d\n",
      "s\n",
      ".\n",
      ")\n",
      ",\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "c\n",
      "e\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "7\n",
      "t\n",
      "h\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "c\n",
      "o\n",
      "n\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "e\n",
      "d\n",
      "u\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "m\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "(\n",
      "e\n",
      "d\n",
      "m\n",
      "2\n",
      "0\n",
      "1\n",
      "4\n",
      ")\n",
      ",\n",
      " \n",
      "4\n",
      "–\n",
      "7\n",
      "\n",
      "\n",
      "j\n",
      "u\n",
      "l\n",
      "y\n",
      ",\n",
      " \n",
      "l\n",
      "o\n",
      "n\n",
      "d\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "u\n",
      "k\n",
      " \n",
      "(\n",
      "p\n",
      "p\n",
      ".\n",
      " \n",
      "1\n",
      "0\n",
      "7\n",
      "–\n",
      "1\n",
      "1\n",
      "3\n",
      ")\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "e\n",
      "d\n",
      "u\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "m\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "o\n",
      "c\n",
      "i\n",
      "e\n",
      "t\n",
      "y\n",
      ".\n",
      "\n",
      "\n",
      "[\n",
      "1\n",
      "2\n",
      "]\n",
      " \n",
      "l\n",
      "e\n",
      "e\n",
      ",\n",
      " \n",
      "j\n",
      ".\n",
      "i\n",
      ".\n",
      ",\n",
      " \n",
      "&\n",
      " \n",
      "b\n",
      "r\n",
      "u\n",
      "n\n",
      "s\n",
      "k\n",
      "i\n",
      "l\n",
      "l\n",
      ",\n",
      " \n",
      "e\n",
      ".\n",
      " \n",
      "(\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      ")\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "a\n",
      "c\n",
      "t\n",
      " \n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "n\n",
      "e\n",
      "c\n",
      "e\n",
      "s\n",
      "s\n",
      "a\n",
      "r\n",
      "y\n",
      " \n",
      "p\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "i\n",
      "c\n",
      "e\n",
      "\n",
      "\n",
      "o\n",
      "p\n",
      "p\n",
      "o\n",
      "r\n",
      "t\n",
      "u\n",
      "n\n",
      "i\n",
      "t\n",
      "i\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "5\n",
      "t\n",
      "h\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "e\n",
      "d\n",
      "m\n",
      ".\n",
      "\n",
      "\n",
      "[\n",
      "1\n",
      "3\n",
      "]\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "d\n",
      "o\n",
      "s\n",
      ",\n",
      " \n",
      "z\n",
      ".\n",
      "a\n",
      ".\n",
      ",\n",
      " \n",
      "&\n",
      " \n",
      "h\n",
      "e\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "n\n",
      ",\n",
      " \n",
      "n\n",
      ".\n",
      "t\n",
      ".\n",
      " \n",
      "(\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      ")\n",
      ".\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "a\n",
      " \n",
      "b\n",
      "a\n",
      "y\n",
      "e\n",
      "s\n",
      "i\n",
      "a\n",
      "n\n",
      " \n",
      "n\n",
      "e\n",
      "t\n",
      "w\n",
      "o\n",
      "r\n",
      "k\n",
      "s\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "l\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "f\n",
      "\n",
      "\n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "i\n",
      "n\n",
      "g\n",
      ".\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      "r\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "i\n",
      "n\n",
      "g\n",
      ",\n",
      " \n",
      "a\n",
      "d\n",
      "a\n",
      "p\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      "\n",
      "\n",
      "p\n",
      "e\n",
      "r\n",
      "s\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "2\n",
      "5\n",
      "5\n",
      "-\n",
      "2\n",
      "6\n",
      "6\n",
      ".\n",
      "\n",
      "\n",
      "[\n",
      "1\n",
      "4\n",
      "]\n",
      " \n",
      "p\n",
      "a\n",
      "r\n",
      "d\n",
      "o\n",
      "s\n",
      ",\n",
      " \n",
      "z\n",
      ".\n",
      " \n",
      "a\n",
      ".\n",
      ",\n",
      " \n",
      "t\n",
      "r\n",
      "i\n",
      "v\n",
      "e\n",
      "d\n",
      "i\n",
      ",\n",
      " \n",
      "s\n",
      ".\n",
      ",\n",
      " \n",
      "h\n",
      "e\n",
      "f\n",
      "f\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "n\n",
      ",\n",
      " \n",
      "n\n",
      ".\n",
      " \n",
      "t\n",
      ".\n",
      ",\n",
      " \n",
      "&\n",
      " \n",
      "s\n",
      "á\n",
      "r\n",
      "k\n",
      "ö\n",
      "z\n",
      "y\n",
      ",\n",
      " \n",
      "g\n",
      ".\n",
      "\n",
      "\n",
      "n\n",
      ".\n",
      " \n",
      "(\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      ")\n",
      ".\n",
      " \n",
      "c\n",
      "l\n",
      "u\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "e\n",
      "d\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "i\n",
      "n\n",
      "g\n",
      ".\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "s\n",
      ".\n",
      " \n",
      "a\n",
      ".\n",
      " \n",
      "c\n",
      "e\n",
      "r\n",
      "r\n",
      "i\n",
      ",\n",
      " \n",
      "w\n",
      ".\n",
      " \n",
      "j\n",
      ".\n",
      "\n",
      "\n",
      "c\n",
      "l\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      "y\n",
      ",\n",
      " \n",
      "g\n",
      ".\n",
      " \n",
      "p\n",
      "a\n",
      "p\n",
      "a\n",
      "d\n",
      "o\n",
      "u\n",
      "r\n",
      "a\n",
      "k\n",
      "i\n",
      "s\n",
      ",\n",
      " \n",
      "k\n",
      ".\n",
      "-\n",
      "k\n",
      ".\n",
      " \n",
      "p\n",
      "a\n",
      "n\n",
      "o\n",
      "u\n",
      "r\n",
      "g\n",
      "i\n",
      "a\n",
      " \n",
      "(\n",
      "e\n",
      "d\n",
      "s\n",
      ".\n",
      ")\n",
      ",\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "o\n",
      "c\n",
      "e\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "1\n",
      "1\n",
      "t\n",
      "h\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "l\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "y\n",
      "s\n",
      "t\n",
      "e\n",
      "m\n",
      "s\n",
      " \n",
      "(\n",
      "i\n",
      "t\n",
      "s\n",
      " \n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      ")\n",
      ",\n",
      " \n",
      "1\n",
      "4\n",
      "–\n",
      "1\n",
      "8\n",
      " \n",
      "j\n",
      "u\n",
      "n\n",
      "e\n",
      " \n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      ",\n",
      "\n",
      "\n",
      "c\n",
      "h\n",
      "a\n",
      "n\n",
      "i\n",
      "a\n",
      ",\n",
      " \n",
      "g\n",
      "r\n",
      "e\n",
      "e\n",
      "c\n",
      "e\n",
      " \n",
      "(\n",
      "p\n",
      "p\n",
      ".\n",
      " \n",
      "4\n",
      "0\n",
      "5\n",
      "–\n",
      "4\n",
      "1\n",
      "0\n",
      ")\n",
      ".\n",
      " \n",
      "s\n",
      "p\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      ".\n",
      "\n",
      "\n",
      "[\n",
      "1\n",
      "5\n",
      "]\n",
      " \n",
      "p\n",
      "a\n",
      "v\n",
      "l\n",
      "i\n",
      "k\n",
      ",\n",
      " \n",
      "p\n",
      ".\n",
      "i\n",
      ".\n",
      ",\n",
      " \n",
      "c\n",
      "e\n",
      "n\n",
      ",\n",
      " \n",
      "h\n",
      ".\n",
      ",\n",
      " \n",
      "&\n",
      " \n",
      "k\n",
      "o\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "k\n",
      ".\n",
      "r\n",
      ".\n",
      " \n",
      "(\n",
      "2\n",
      "0\n",
      "0\n",
      "9\n",
      ")\n",
      ".\n",
      "\n",
      "\n",
      "p\n",
      "e\n",
      "r\n",
      "f\n",
      "o\n",
      "r\n",
      "m\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "f\n",
      "a\n",
      "c\n",
      "t\n",
      "o\n",
      "r\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "a\n",
      "l\n",
      "y\n",
      "s\n",
      "i\n",
      "s\n",
      "–\n",
      "a\n",
      " \n",
      "n\n",
      "e\n",
      "w\n",
      " \n",
      "a\n",
      "l\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "t\n",
      "i\n",
      "v\n",
      "e\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      "\n",
      "\n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "i\n",
      "n\n",
      "g\n",
      ".\n",
      " \n",
      "a\n",
      "i\n",
      "e\n",
      "d\n",
      ",\n",
      " \n",
      "5\n",
      "3\n",
      "1\n",
      "–\n",
      "5\n",
      "3\n",
      "8\n",
      ".\n",
      "\n",
      "\n",
      "[\n",
      "1\n",
      "6\n",
      "]\n",
      " \n",
      "s\n",
      "h\n",
      "m\n",
      "u\n",
      "e\n",
      "l\n",
      "i\n",
      ",\n",
      " \n",
      "g\n",
      ".\n",
      " \n",
      "(\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      ")\n",
      ".\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "e\n",
      "x\n",
      "p\n",
      "l\n",
      "a\n",
      "i\n",
      "n\n",
      " \n",
      "o\n",
      "r\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "d\n",
      "i\n",
      "c\n",
      "t\n",
      "?\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "t\n",
      "i\n",
      "s\n",
      "t\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      "\n",
      "\n",
      "s\n",
      "c\n",
      "i\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      ",\n",
      " \n",
      "2\n",
      "5\n",
      "(\n",
      "3\n",
      ")\n",
      ",\n",
      " \n",
      "2\n",
      "8\n",
      "9\n",
      "–\n",
      "3\n",
      "1\n",
      "0\n",
      ".\n",
      " \n",
      "d\n",
      "o\n",
      "i\n",
      ":\n",
      "1\n",
      "0\n",
      ".\n",
      "1\n",
      "2\n",
      "1\n",
      "4\n",
      "/\n",
      "1\n",
      "0\n",
      "-\n",
      "s\n",
      "t\n",
      "s\n",
      "3\n",
      "3\n",
      "0\n",
      "\n",
      "\n",
      "[\n",
      "1\n",
      "7\n",
      "]\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "m\n",
      "p\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "j\n",
      ".\n",
      ",\n",
      " \n",
      "&\n",
      " \n",
      "k\n",
      "o\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "k\n",
      ".\n",
      " \n",
      "r\n",
      ".\n",
      " \n",
      "(\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      ")\n",
      ".\n",
      " \n",
      "h\n",
      "u\n",
      "m\n",
      "a\n",
      "n\n",
      "-\n",
      "m\n",
      "a\n",
      "c\n",
      "h\n",
      "i\n",
      "n\n",
      "e\n",
      "\n",
      "\n",
      "s\n",
      "t\n",
      "u\n",
      "d\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "d\n",
      "i\n",
      "s\n",
      "c\n",
      "o\n",
      "v\n",
      "e\n",
      "r\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "i\n",
      "m\n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "e\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "u\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      ".\n",
      "\n",
      "\n",
      "p\n",
      "r\n",
      "o\n",
      "c\n",
      "e\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "1\n",
      "5\n",
      "t\n",
      "h\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "f\n",
      "e\n",
      "r\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "n\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "4\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\f",
      "\n",
      "a\n",
      "r\n",
      "t\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "i\n",
      "a\n",
      "l\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "l\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "e\n",
      "d\n",
      "u\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "(\n",
      "a\n",
      "i\n",
      "e\n",
      "d\n",
      " \n",
      "ʼ\n",
      "1\n",
      "1\n",
      ")\n",
      ",\n",
      " \n",
      "2\n",
      "8\n",
      " \n",
      "j\n",
      "u\n",
      "n\n",
      "e\n",
      "–\n",
      "2\n",
      "\n",
      "\n",
      "j\n",
      "u\n",
      "l\n",
      "y\n",
      ",\n",
      " \n",
      "a\n",
      "u\n",
      "c\n",
      "k\n",
      "l\n",
      "a\n",
      "n\n",
      "d\n",
      ",\n",
      " \n",
      "n\n",
      "e\n",
      "w\n",
      " \n",
      "z\n",
      "e\n",
      "a\n",
      "l\n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "(\n",
      "p\n",
      "p\n",
      ".\n",
      " \n",
      "3\n",
      "5\n",
      "3\n",
      "–\n",
      "3\n",
      "6\n",
      "0\n",
      ")\n",
      ".\n",
      " \n",
      "s\n",
      "p\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      ".\n",
      "\n",
      "\n",
      "[\n",
      "1\n",
      "8\n",
      "]\n",
      " \n",
      "y\n",
      "u\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "m\n",
      ".\n",
      "v\n",
      ".\n",
      ",\n",
      " \n",
      "k\n",
      "o\n",
      "e\n",
      "d\n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "k\n",
      ".\n",
      "r\n",
      ".\n",
      ",\n",
      " \n",
      "&\n",
      " \n",
      "g\n",
      "o\n",
      "r\n",
      "d\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "g\n",
      ".\n",
      "j\n",
      ".\n",
      " \n",
      "(\n",
      "2\n",
      "0\n",
      "1\n",
      "3\n",
      ")\n",
      ".\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "d\n",
      "i\n",
      "v\n",
      "i\n",
      "d\n",
      "u\n",
      "a\n",
      "l\n",
      "i\n",
      "z\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "a\n",
      "y\n",
      "e\n",
      "s\n",
      "i\n",
      "a\n",
      "n\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n",
      "e\n",
      "d\n",
      "g\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "m\n",
      "o\n",
      "d\n",
      "e\n",
      "l\n",
      "s\n",
      ".\n",
      " \n",
      "a\n",
      "i\n",
      "e\n",
      "d\n",
      ",\n",
      "\n",
      "\n",
      "1\n",
      "7\n",
      "1\n",
      "-\n",
      "1\n",
      "8\n",
      "0\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[\n",
      "1\n",
      "9\n",
      "]\n",
      " \n",
      "v\n",
      "a\n",
      "n\n",
      "l\n",
      "e\n",
      "h\n",
      "n\n",
      ",\n",
      " \n",
      "k\n",
      ".\n",
      " \n",
      "(\n",
      "2\n",
      "0\n",
      "0\n",
      "6\n",
      ")\n",
      ".\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "b\n",
      "e\n",
      "h\n",
      "a\n",
      "v\n",
      "i\n",
      "o\n",
      "r\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "u\n",
      "t\n",
      "o\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "s\n",
      "y\n",
      "s\n",
      "t\n",
      "e\n",
      "m\n",
      "s\n",
      ".\n",
      "\n",
      "\n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      "n\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "j\n",
      "o\n",
      "u\n",
      "r\n",
      "n\n",
      "a\n",
      "l\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "a\n",
      "r\n",
      "t\n",
      "i\n",
      "f\n",
      "i\n",
      "c\n",
      "i\n",
      "a\n",
      "l\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "l\n",
      "l\n",
      "i\n",
      "g\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "e\n",
      "d\n",
      "u\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ",\n",
      "\n",
      "\n",
      "1\n",
      "6\n",
      ",\n",
      " \n",
      "2\n",
      "2\n",
      "7\n",
      "–\n",
      "2\n",
      "6\n",
      "5\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 26) print the first 1000 characters of each paper. \n",
    "\n",
    "\n",
    "\n",
    "for p in paper:\n",
    "    print(p[:1000])\n",
    "# Is your interpretation confirmed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to work with Regex formulas to extract part of the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\f",
      "zone out no more: mitigating mind wandering during\n",
      "computerized reading\n",
      "sidney k. d’mello, caitlin mills, robert bixler, & nigel bosch\n",
      "university of notre dame\n",
      "118 haggar hall\n",
      "notre dame, in 46556, usa\n",
      "sdmello@nd.edu\n",
      "\n",
      "abstract\n",
      "mind wandering, defined as shifts in attention from task-related\n",
      "processing to task-unrelated thoughts, is a ubiquitous\n",
      "phenomenon that has a negative influence on performance and\n",
      "productivity in many contexts, including learning. we propose\n",
      "that next-generation learning technologies should have some\n",
      "mechanism to detect and respond to mind wandering in real-time.\n",
      "towards this end, we developed a technology that automatically\n",
      "detects mind wandering from eye-gaze during learning from\n",
      "instructional texts. when mind wandering is detected, the\n",
      "technology intervenes by posing just-in-time questions and\n",
      "encouraging re-reading as needed. after multiple rounds of\n",
      "iterative refinement, we summatively compared the technology to\n",
      "a yoked-control in an experiment with 104 participants. the key\n",
      "dependent variable was performance on a post-reading\n",
      "comprehension assessment. our results suggest that the\n",
      "technology was successful in correcting comprehension deficits\n",
      "attributed to mind wandering (d = .47 sigma) under specific\n",
      "conditions, thereby highlighting the potential to improve learning\n",
      "by “attending to attention.”\n",
      "\n",
      "keywords\n",
      "mind wandering; gaze tracking; student modeling; attentionaware.\n",
      "\n",
      "1. introduction\n",
      "despite our best efforts to write a clear and engaging paper,\n",
      "chances are high that within the next 10 pages you might fall prey\n",
      "to what is referred to as zoning out, daydreaming, or mind\n",
      "wandering [45]. despite your best intention to concentrate on our\n",
      "paper, at some point your attention might drift away to unrelated\n",
      "thoughts of lunch, childcare, or an upcoming trip. this prediction\n",
      "is not based on some negative or cynical opinion of the\n",
      "reader/reviewer (we read and review papers too), but on what is\n",
      "known about attentional control, vigilance, and concentration\n",
      "while individuals are engaged in complex comprehension\n",
      "activities, such as reading for understanding.\n",
      "one recent study tracked mind wandering of 5,000 individuals\n",
      "from 83 countries with a smartphone app that prompted people\n",
      "with thought-probes at random intervals throughout the day [24].\n",
      "people reported mind wandering for 46.9% of the prompts, which\n",
      "confirmed lab studies on the pervasiveness of mind wandering\n",
      "(see [45] for a review). mind wandering is more than merely\n",
      "incidental; a recent meta-analysis of 88 samples indicated a\n",
      "negative correlation between mind wandering and performance\n",
      "across a variety of tasks [34], a correlation which increases with\n",
      "task complexity. when compounded with its high frequency,\n",
      "mind wandering can have serious consequences on the\n",
      "performance and productivity of society at large.\n",
      "\n",
      "of learning with technology. traditional learning technologies\n",
      "rely on the assumption that students are attending to the learning\n",
      "session, although this is not always the case. for example, it has\n",
      "been estimated that students mind wander approximately 40% of\n",
      "the time when engaging with online lectures [38], which are an\n",
      "important component of moocs. some advanced technologies\n",
      "do aim to detect and respond to affective states like boredom, but\n",
      "evidence for their effectiveness is still equivocal (see [9] for a\n",
      "review). further, boredom is related to but not the same as\n",
      "attention [12]. there are technologies that aim to prevent mind\n",
      "wandering by engendering a highly immersive learning\n",
      "experience and have achieved some success in this regard [40,\n",
      "41]. but what is to be done when attentional focus inevitably\n",
      "wanes as the session progresses and the novelty of the system and\n",
      "content fades?\n",
      "our central thesis is that next-generation learning technologies\n",
      "should include mechanisms to model and respond to learners’\n",
      "attention in real-time [8]. such attention-aware technologies can\n",
      "model various aspects of learner attention (e.g., divided attention,\n",
      "alternating attention). here, we focus on detecting and mitigating\n",
      "mind wandering, a quintessential signal of waning engagement.\n",
      "we situate our work in the context of reading because reading is\n",
      "a common activity shared across multiple learning technologies,\n",
      "thereby increasing the generalizability of our results. further,\n",
      "students mind wander approximately 30% of the time during\n",
      "computerized reading [44]. and although mind wandering can\n",
      "facilitate certain cognitive processes like future planning and\n",
      "divergent thinking [2, 28], it negatively correlates with\n",
      "comprehension and learning (reviewed in [31, 45]), suggesting\n",
      "that it is important to address mind wandering during learning.\n",
      "towards this end, we developed and validated a closed-loop\n",
      "attention-aware learning technology that combines a machinelearned mind wandering detector with a real-time interpolated\n",
      "testing and re-study intervention. our attention-aware technology\n",
      "works as follows. learners read a text on a computer screen using\n",
      "a self-paced screen-by-screen (also called page-by-page) reading\n",
      "paradigm. we track eye-gaze during reading using a remote eye\n",
      "tracker that does not restrict head movements. we focus on eyegaze for mind wandering detection due to decades of research\n",
      "suggesting a tight coupling between attentional focus and eye\n",
      "movements during reading [36]. when mind wandering is\n",
      "detected, the system intervenes in an attempt to redirect\n",
      "attentional focus and correct any comprehension deficits that\n",
      "might arise due to mind wandering. the interventions consist of\n",
      "asking comprehension question on pages where mind wandering\n",
      "was detected and providing opportunities to re-read based on\n",
      "learners’ responses. in this paper, we discuss the mind wandering\n",
      "\n",
      "mind wandering is also unfortunately an under-addressed\n",
      "problem in education and is yet to be deeply studied in the context\n",
      "\n",
      "\n",
      "\n",
      "8\n",
      "\n",
      "\f",
      "detector, intervention approach, and results of a summative\n",
      "evaluation study 1.\n",
      "\n",
      "1.1 related work\n",
      "the idea of attention-aware user interfaces is not new, but was\n",
      "proposed almost a decade ago by roda and thomas [39]. there\n",
      "was even an article on futuristic applications of attention-aware\n",
      "systems in educational contexts [35]. prior to this, gluck, et al.\n",
      "[15] discussed the use of eye tracking to increase the bandwidth\n",
      "of information available to an intelligent tutoring system (its).\n",
      "similarly, anderson [1] followed up on some of these ideas by\n",
      "demonstrating how particular beneficial instructional strategies\n",
      "could only be launched via a real-time analysis of eye gaze.\n",
      "most of the recent work has been on leveraging eye gaze to\n",
      "increase the bandwidth of learner models [22, 23, 29]. conati, et\n",
      "al. [5] provide an excellent review of much of the existing work\n",
      "in this area. we can group the research into three categories: (1)\n",
      "offline-analyses of eye gaze to study attentional processes, (2)\n",
      "computational modeling of attentional states, and (3) closed-loop\n",
      "systems that respond to attention in real-time. offline-analysis of\n",
      "eye movements has received considerable attention in cognitive\n",
      "and educational psychology for several decades [e.g., 16, 19], so\n",
      "this area of research is relatively healthy. online computational\n",
      "models of learner attention are just beginning to emerge [e.g., 6,\n",
      "11], while closed-loop attention-aware systems are few and far\n",
      "between (see [7, 15, 42, 48] for a more or less exhaustive list).\n",
      "two known examples, gazetutor and attentivereview, are\n",
      "discussed below.\n",
      "gazetutor [7] is a learning technology for biology. it has an\n",
      "animated conversational agent that provides spoken explanations\n",
      "on biology topics which are synchronized with images. the\n",
      "system uses a tobii t60 eye tracker to detect inattention, which\n",
      "is assumed to occur when learners’ gaze is not on the tutor agent\n",
      "or image for at least five consecutive seconds. when this occurs,\n",
      "the system interrupts its speech mid utterance, directs learners to\n",
      "reorient their attention (e.g., “i’m over here you know”), and\n",
      "repeats speaking from the start of the current utterance. in an\n",
      "evaluation study, 48 learners (undergraduate students) completed\n",
      "a learning session on four biology topics with the attention-aware\n",
      "components enabled (experimental group) or disabled (control\n",
      "group). the results indicated that gazetutor was successful in\n",
      "dynamically reorienting learners’ attentional patterns towards the\n",
      "interface. importantly, learning gains for deep reasoning\n",
      "questions were significantly higher for the experimental vs.\n",
      "control group, but only for high aptitude learners. the results\n",
      "suggest that even the most basic attention-aware technology can\n",
      "be effective in improving learning, at least for a subset of learners.\n",
      "however, a key limitation is that the researchers simply assumed\n",
      "that off-screen gaze corresponded to inattention, but did not test\n",
      "this assumption (e.g., students could have been concentrating\n",
      "with their eyes closed and this would have been perceived as\n",
      "being inattentive).\n",
      "attentivereview [32] is a closed-loop system for mooc learning\n",
      "on mobile phones. the system uses video-based\n",
      "photoplethysmography (ppg) to detect a learners’ heart rate from\n",
      "the back camera of a smartphone while they view mooc-like\n",
      "lectures on the phone. attentivereview ranks the lectures based\n",
      "1\n",
      "\n",
      "on its estimates of learners’ “perceived difficulty,” selecting the\n",
      "most difficult lecture for subsequent review (called adaptive\n",
      "review). in a 32-participant between-subjects evaluation study,\n",
      "the authors found that learning gains obtained from the adaptive\n",
      "review condition were statistically on par with a full review\n",
      "condition, but were achieved in 66.7% less review time. although\n",
      "this result suggests that attentivereview increased learning\n",
      "efficiency, there is the question as to whether the system should\n",
      "even be considered to be an “attention-aware” technology. this is\n",
      "because it is arguable if the system has anything to do with\n",
      "attention (except for “attention” appearing in its name) as it\n",
      "selects items for review based on a model of “perceived\n",
      "difficulty” and not on learners’ “attentional state.” the two might\n",
      "be related, but are clearly not the same.\n",
      "\n",
      "1.2 novelty\n",
      "our paper focuses on closing the loop between research on\n",
      "educational data and learning outcomes by developing and\n",
      "validating the first (in our view) real-time learning technology\n",
      "that detects and mitigates mind wandering during computerized\n",
      "reading. although automated detection of complex mental states\n",
      "with the goal of developing intelligent learning technologies that\n",
      "respond to the sensed states is an active research area (see reviews\n",
      "by [9, 18]), mind wandering has rarely been explored as an aspect\n",
      "of a learner’s mental state that warrants detection and corrective\n",
      "action. and while there has been some work on modeling the\n",
      "locus of learner attention (see review by [5]), mind wandering is\n",
      "inherently different than more commonly studied forms of\n",
      "attention (e.g., selective attention, distraction), because it involves\n",
      "more covert forms of involuntary attentional lapses spawned by\n",
      "self-generated internal thought [45]. simply put, mind wandering\n",
      "is a form of “looking without seeing” because the eyes might be\n",
      "fixated on the appropriate external stimulus, but very little is\n",
      "being processed as the mind is consumed by stimulusindependent internal thoughts. offline automated approaches to\n",
      "detect mind wandering have been developed (e.g., [3, 11, 27, 33]),\n",
      "but these detectors have not yet been used to trigger online\n",
      "interventions. here, we adapt an offline gaze-based automated\n",
      "mind wandering detector [13] to trigger real-time interventions to\n",
      "address mind wandering during reading. we conduct a\n",
      "randomized control trial to evaluate the efficacy of our attentionaware learning technology in improving learning.\n",
      "\n",
      "2. mind wandering detection\n",
      "we adopted a supervised learning approach for mind wandering\n",
      "detection. below we provide a high-level overview of the\n",
      "approach; readers are directed to [3, 13] for a detailed discussion\n",
      "of the general approach used to build gaze-based detectors of\n",
      "mind wandering.\n",
      "\n",
      "2.1 training data\n",
      "we obtained training data from a previous study [26] that\n",
      "involved 98 undergraduate students reading a 57-page text on the\n",
      "surface tension of liquids [4] on a computer screen for an average\n",
      "of 28 minutes. the text contained around 6500 words, with an\n",
      "average of 115 words per page, and was displayed on a computer\n",
      "screen with courier new typeface. we recorded eye-gaze with a\n",
      "tobii tx300 eye tracker set to a sampling frequency of 120 hz.\n",
      "\n",
      "this paper reports updated results of an earlier version [10] presented\n",
      "as a “late-breaking work” (lbw) poster at the 2016 acm chi\n",
      "conference. lbw “extended abstracts” are not included in the main\n",
      "conference proceedings and copyright is retained by the authors.\n",
      "\n",
      "\n",
      "\n",
      "9\n",
      "\n",
      "\f",
      "participants could read normally and were free to move or gesture\n",
      "as they pleased.\n",
      "participants were instructed to report mind wandering (during\n",
      "reading) by pressing a predetermined key when they found\n",
      "themselves “thinking about the task itself but not the actual\n",
      "content of the text” or when they were “thinking about anything\n",
      "else besides the task.” this is consistent with contemporary\n",
      "approaches (see [45]) that rely on self-reporting because mind\n",
      "wandering is an internal conscious phenomena. further, selfreports of mind wandering have been linked to predictable\n",
      "patterns in physiology [43], pupillometry [14], eye-gaze [37], and\n",
      "task performance [34], providing validity for this approach.\n",
      "\n",
      "on the page, we classified the page as a positive instance of mind\n",
      "wandering. this was done because analyses indicated that\n",
      "participants were more likely to be mind wandering in those cases\n",
      "(but see [13] for alternate strategies to handle missing instances).\n",
      "\n",
      "on average, we received mind wandering reports for 32% of the\n",
      "pages (sd = 20%), although there was considerable variability\n",
      "among participants (ranging from 0% to 82%). self-reported\n",
      "mind wandering negatively correlated (r = -.23, p < .05) with\n",
      "scores on a subsequent comprehension assessment [26], which\n",
      "provides evidence for the predictive validity of the self-reports.\n",
      "\n",
      "2.2 model building\n",
      "the stream of eye-gaze data was filtered to produce a series of\n",
      "fixations, saccades, and blinks, from which global eye gaze\n",
      "features were extracted (see figure 1). global features are\n",
      "independent of the words being read and are therefore more\n",
      "generalizable than so-called local features. a full list of 62 global\n",
      "features along with detailed descriptions is provided in [13], but\n",
      "briefly the features can be grouped into the following four\n",
      "categories: (1) eye movement descriptive features (n = 48) were\n",
      "statistical functionals (e.g., min, median) for fixation duration,\n",
      "saccade duration, saccade amplitude, saccade velocity, and\n",
      "relative and absolute saccade angle distributions; (2) pupil\n",
      "diameter descriptive features were statistical functionals (n = 8)\n",
      "computed from participant-level z-score standardized estimates\n",
      "of pupil diameter; (3) blink features (n = 2) consisted of the\n",
      "number of blinks and the mean blink duration; (4) miscellaneous\n",
      "gaze features (n = 4) consisted of the number of saccades,\n",
      "horizontal saccade proportion, fixation dispersion, and the\n",
      "fixation duration/saccade duration ratio. we proceeded with a\n",
      "subset of 32 features after eliminating features exhibiting\n",
      "multicollinearity.\n",
      "features were calculated from only a certain amount of gaze data\n",
      "from each page, called the window. the end of the window was\n",
      "positioned 3 seconds before a self-report so as to not overlap with\n",
      "the key-press. the average amount of time between self-reports\n",
      "and the beginning of the page was 16 seconds. we used this time\n",
      "point as the end of the window for pages with no self-report.\n",
      "pages that were shorter than the target window size were\n",
      "discarded, as were pages with windows that contained fewer than\n",
      "five gaze fixations as there was insufficient data to compute some\n",
      "of the features. there were a total of 4,225 windows with\n",
      "sufficient data for supervised classification.\n",
      "we experimented with a number of supervised classifiers on\n",
      "window sizes of 4, 8, and 12 seconds to discriminate positive\n",
      "(pages with a self-report = 32%) from negative (pages without a\n",
      "self-report) instances of mind wandering. the training data were\n",
      "downsampled to achieve a 50% base rate; testing data were\n",
      "unaltered. a leave-one-participant-out validation approach was\n",
      "adopted where models were built on data from n-1 participants\n",
      "and evaluated on the held-out participant. the process was\n",
      "repeated for all participants. model validation was conducted in a\n",
      "way to simulate a real-time system by analyzing data from every\n",
      "page. when classification was not possible due to a lack of valid\n",
      "gaze data and/or because participants did not spend enough time\n",
      "\n",
      "figure 1: gaze fixations during mind wandering (top)\n",
      "and normal reading (bottom)\n",
      "\n",
      "2.3 detector accuracy\n",
      "the best model was a support vector machine that used global\n",
      "features and operated on a window size of 8-seconds. the area\n",
      "under the roc curve (auc or auroc or a’) was .66, which\n",
      "exceeds the 0.5 chance threshold [17].\n",
      "we assigned each instance as mind wandering or not mind\n",
      "wandering based on whether the detector’s predicted likelihood\n",
      "of mind wandering (ranges from 0 to 1) was below or above 0.5\n",
      "we adopted the default 0.5 threshold as it led to a higher rate of\n",
      "true positives while maintaining a moderate rate of true negatives.\n",
      "this resulted in the following confusion matrix shown in table 1.\n",
      "the model had a weighted precision of 72.2% and a weighted\n",
      "recall of 67.4%, which we deemed to be sufficiently accurate for\n",
      "intervention.\n",
      "table 1: proportionalized confusion matrix for mind\n",
      "wandering detection\n",
      "predicted mind wandering (mw)\n",
      "actual mw\n",
      "\n",
      "yes\n",
      "\n",
      "no\n",
      "\n",
      "yes\n",
      "\n",
      "0.715 (hit)\n",
      "\n",
      "0.285 (miss)\n",
      "\n",
      "no\n",
      "\n",
      "0.346 (false positive)\n",
      "\n",
      "0.654 (correct rejection)\n",
      "\n",
      "3. intervention to address mind wandering\n",
      "our intervention approach is grounded in the basic idea that\n",
      "learning of conceptual information involves creating and\n",
      "maintaining an internal model (mental model) by integrating\n",
      "information from the text with prior knowledge from memory\n",
      "[25]. this integration process relies on attentional focus and\n",
      "breaks down during mind wandering because information from\n",
      "the external environment is no longer being integrated into the\n",
      "internal mental model. this results in an impaired model which\n",
      "leads to less effective suppression of off-task thoughts. this\n",
      "increase in mind wandering further impairs the mental model,\n",
      "\n",
      "\n",
      "\n",
      "10\n",
      "\n",
      "\f",
      "resulting in a vicious cycle. our intervention targets this vicious\n",
      "cycle by redirecting attention to the primary task and attempting\n",
      "to correct for comprehension deficits attributed to mind\n",
      "wandering. based on research demonstrating the effectiveness of\n",
      "interpolated testing [47], we propose that asking questions on\n",
      "pages where mind wandering is detected and encouraging rereading in response to incorrect responses will aid in re-directing\n",
      "attention to the text and correct knowledge deficits.\n",
      "\n",
      "page regardless of whether the second question was answered\n",
      "correctly, so as not to be overly burdensome.\n",
      "\n",
      "3.1 intervention implementation\n",
      "our initial intervention was implemented for the same text used\n",
      "to create the mind wandering detector (although it could be\n",
      "applied to any text). the text was integrated into the computer\n",
      "reading interface. mind wandering detection occurred when the\n",
      "learner navigated to the next page using the right arrow key. in\n",
      "order to address ambiguity in mind wandering detection, we used\n",
      "the detector’s mind wandering likelihood to probabilistically\n",
      "determine when to intervene. for example, if the mind wandering\n",
      "likelihood was 70%, then there was a 70% chance of intervention\n",
      "on any given page (all else being equal). we did not intervene for\n",
      "the first three pages in order to allow the learner to become\n",
      "familiar with the text and interface. to reduce disruption, there\n",
      "was a 50% reduced probability of intervening on adjacent pages,\n",
      "and the maximum number of interventions was capped at 1/3 ×\n",
      "the number of pages (19 for the present 57-page text). table 2\n",
      "presents pseudo code for when to launch an intervention.\n",
      "table 2: pseudo code for intervention strategy\n",
      "launch_intervention:\n",
      "if current_page >= waitpages\n",
      "and\n",
      "total_interventions < maxintrv)\n",
      "and\n",
      "gaze_likelihood > random(0,1)\n",
      "and\n",
      "(!has_intervened(previous_page)\n",
      "or 0.5 < random (0,1)):\n",
      "do_intervention()\n",
      "else:\n",
      "show_next_page()\n",
      "do_intervention:\n",
      "answer1 = show_question1()\n",
      "if answer1 is correct:\n",
      "show_positive_feedback()\n",
      "show_next_page()\n",
      "else:\n",
      "show_neg_feedback()\n",
      "suggest_rereading()\n",
      "if page advance detected:\n",
      "answer2 = show_question2();\n",
      "show_next_page()\n",
      "\n",
      "figure 2 presents an outline of the intervention strategy. the\n",
      "intervention itself relied on two multiple choice questions for\n",
      "each page (screen) of the text. when the system decided to\n",
      "intervene, one of the questions (randomly selected) was presented\n",
      "to the learner. if the learner answered this online question\n",
      "correctly, positive feedback was provided, and the learner could\n",
      "advance to the next page. if the learner answered incorrectly,\n",
      "negative feedback was provided, and the system encouraged the\n",
      "learner to re-read the page. the learner was then provided with a\n",
      "second (randomly selected) online question, which could either\n",
      "be the same or the alternate question for that page. feedback was\n",
      "not provided and the learner was allowed to advance to the next\n",
      "\n",
      "figure 2: outline of intervention strategy\n",
      "\n",
      "3.2 iterative refinement\n",
      "the technology was refined through multiple rounds of formative\n",
      "testing with 67 participants, recruited from the same institution\n",
      "used to build the detector. participants were observed while\n",
      "interacting with the technology, their responses were analyzed,\n",
      "and they were interviewed about their experience. we used the\n",
      "feedback gleaned from these tests to refine the intervention\n",
      "parameters (i.e., when to launch, how many interventions to\n",
      "launch, whether to launch interventions on subsequent pages),\n",
      "intervention questions themselves, and instructions on how to\n",
      "attend to the intervention. for example, earlier versions of the\n",
      "intervention used a fixed threshold (instead of the aforementioned\n",
      "probabilistic approach) to trigger an intervention. despite many\n",
      "attempts to set this threshold, the end result was that some\n",
      "participants received many interventions while others received\n",
      "almost no interventions. this issue was corrected by\n",
      "probabilistically rather than deterministically launching the\n",
      "intervention. additional testing/refinement of the comprehension\n",
      "questions used in the intervention was done using crowdsourcing\n",
      "platforms, specifically amazon’s mechanical turk (mturk).\n",
      "\n",
      "4. evaluation study\n",
      "we conducted a randomized controlled trial to evaluate the\n",
      "technology. the experiment had two conditions: an intervention\n",
      "condition and a yoked control condition (as described below). the\n",
      "yoked control was needed to verify that any learning benefits are\n",
      "attributed to the technology being sensitive to mind wandering\n",
      "and not merely to the added opportunities to answer online\n",
      "questions and re-read. this is because we know that interpolated\n",
      "testing itself has beneficial comprehension effects [47].\n",
      "\n",
      "4.1 method\n",
      "participants (n = 104) were a new set of undergraduate students\n",
      "who participated to fulfill research credit requirements. they\n",
      "were recruited from the same university used to build the mw\n",
      "detector and for the iterative testing and refinement cycles.\n",
      "we did not use a pretest because we expected participants to be\n",
      "unfamiliar with the topic. participants were not informed that the\n",
      "interface would be tracking their mind wandering (until the\n",
      "\n",
      "\n",
      "\n",
      "11\n",
      "\n",
      "\f",
      "debriefing at the end), instead, they were instructed as follows:\n",
      "“while reading the text, you will occasionally be asked some\n",
      "questions about the page you just read. depending on your\n",
      "answer, you will re-read the same page and you will be asked\n",
      "another question that may or may not be the same question.”\n",
      "participants in the intervention condition received the\n",
      "intervention as described above (i.e., based on detected mind\n",
      "wandering likelihoods). each participant in the yoked control\n",
      "condition was paired with a participant in the intervention\n",
      "condition. he or she received an intervention question on the\n",
      "same pages as their paired intervention participant regardless of\n",
      "mind wandering likelihood. for example, if participant a (i.e.,\n",
      "intervention condition) received questions on pages 5, 7, 10, and\n",
      "25, participant b (i.e., yoked control condition) would receive\n",
      "intervention questions on the same pages. however, if the yoked\n",
      "participant answered incorrectly, then (s)he had the opportunity\n",
      "to re-read and answer another question regardless of the outcome\n",
      "of their intervention-condition partner.\n",
      "after reading, participants completed a 38-item multiple choice\n",
      "comprehension assessment to measure learning. the questions\n",
      "were randomly selected from the 57 pages (one per page) with the\n",
      "exception that a higher selection priority was given to pages that\n",
      "were re-read on account of the intervention. participants in the\n",
      "yoked control condition received the same posttest questions as\n",
      "their intervention condition counterparts.\n",
      "\n",
      "4.2 results\n",
      "participants received an average of 16 (min of 7 and max of 19)\n",
      "interventions. they spent an average of 27.5 seconds on each\n",
      "screen prior to receiving an intervention. there was no significant\n",
      "difference across conditions (p = .998), suggesting that reading\n",
      "time was not a confound. in what follows, we compared each\n",
      "intervention participant to his/her yoked control with a two-tailed\n",
      "paired-samples t-test and a 0.05 criteria for statistical\n",
      "significance.\n",
      "mind wandering detection. the detector’s likelihood of mind\n",
      "wandering was slightly higher for participants in the yokedcontrol condition (m = .431; sd = .170) compared to the\n",
      "intervention condition (m = .404; sd = .112), but the difference\n",
      "was not statistically significant (p = .348). this was unsurprising\n",
      "as participants in both groups received the same interventions,\n",
      "which itself was expected to reduce mind wandering. importantly,\n",
      "mind wandering likelihoods were negatively correlated with\n",
      "performance on the online questions (r = -.296, p = .033) as well\n",
      "as on posttest questions (r = -.319, p = .021). this provides\n",
      "evidence for the validity of the mind wandering detector when\n",
      "applied to a new set of learners and under different conditions\n",
      "(i.e., reading interspersed with online questions compared to\n",
      "uninterrupted reading).\n",
      "comprehension assessment. there was some overlap between\n",
      "the online questions and the posttest questions. to obtain an\n",
      "unbiased estimate of learning, we only analyzed performance on\n",
      "previously unseen posttest questions. that is, questions that were\n",
      "used as part of the intervention were first removed before\n",
      "computing posttest scores.\n",
      "there were no significant condition differences on overall\n",
      "posttest scores (p = .846). the intervention condition answered\n",
      "57.6% (sd = .157) of the questions correctly while the yoked\n",
      "control condition answered 58.1% (sd = .129) correctly. this\n",
      "finding was not surprising as both conditions received the exact\n",
      "same treatment except that the interventions were triggered based\n",
      "\n",
      "on detected mind wandering in the intervention condition but not\n",
      "the control condition.\n",
      "next, we examined posttest performance as a function of mind\n",
      "wandering during reading. each page was designated as a low or\n",
      "high mind wandering page based on a median split of mind\n",
      "wandering likelihoods (medians = .35 and .36 on a 0 to 1 scale for\n",
      "intervention and control conditions, respectively). we then\n",
      "analyzed performance on posttest questions corresponding to\n",
      "pages with low vs. high likelihoods of mind wandering (during\n",
      "reading). the results are shown in table 3.\n",
      "we found no significant posttest differences on pages where both\n",
      "the intervention and control participants had low (p = .759) or\n",
      "high (p = .922) mind wandering likelihoods (first and last rows in\n",
      "table 3, respectively). there was also no significant posttest\n",
      "difference (p = .630) for pages where the intervention condition\n",
      "had high mind wandering likelihoods but the control condition\n",
      "had low mind wandering likelihoods (row 3). however, the\n",
      "intervention condition significantly (p = .003, d = .47 sigma)\n",
      "outperformed the control condition for pages where the\n",
      "intervention participants had low likelihoods of mind wandering\n",
      "but control participants had high mind wandering likelihoods\n",
      "(row 2). these last two finding suggests that the intervention had\n",
      "the intended effect of reducing comprehension deficits\n",
      "attributable to mind wandering because it led to equitable\n",
      "performance when mind wandering was high and improved\n",
      "performance when it was low.\n",
      "table 3: posttest performance (proportion of correct\n",
      "responses) as a function of mind wandering during reading.\n",
      "standard deviations in parenthesis.\n",
      "mind\n",
      "wandering\n",
      "\n",
      "posttest\n",
      "\n",
      "n\n",
      "\n",
      "int.\n",
      "\n",
      "cntrl.\n",
      "\n",
      "int.\n",
      "\n",
      "cntrl.\n",
      "\n",
      "43\n",
      "\n",
      "low\n",
      "\n",
      "low\n",
      "\n",
      ".604 (.288)\n",
      "\n",
      ".623 (.287)\n",
      "\n",
      "40\n",
      "\n",
      "low\n",
      "\n",
      "high\n",
      "\n",
      ".643 (.263)\n",
      "\n",
      ".489 (.298)\n",
      "\n",
      "43\n",
      "\n",
      "high\n",
      "\n",
      "low\n",
      "\n",
      ".535 (.295)\n",
      "\n",
      ".566 (.305)\n",
      "\n",
      "45\n",
      "\n",
      "high\n",
      "\n",
      "high\n",
      "\n",
      ".522 (.312)\n",
      "\n",
      ".515 (.291)\n",
      "\n",
      "scores\n",
      "\n",
      "note. int. = intervention. cntrl. = control. bolded cells represent a\n",
      "statistically significant difference. n = number of pairs (out of 52) in each\n",
      "analysis. it differs slightly across analyses as not all participants were\n",
      "assigned to each mind wandering group.\n",
      "\n",
      "after-task interview. we interviewed a subset of the participants\n",
      "in order to gauge their subjective experience with the\n",
      "intervention. a few key themes emerged. participants reported\n",
      "paying closer attention to the text after realizing they would be\n",
      "periodically answering multiple-choice questions. this was good.\n",
      "however, participants also reported that they adapted their\n",
      "reading strategies in one of two ways in response to the questions.\n",
      "since the questions targeted factual information (sometimes\n",
      "verbatim) from the text, some participants paid more attention to\n",
      "details and precise wordings instead of the broader concepts being\n",
      "discussed in the text. more discouragingly, some participants\n",
      "reported adopting a preemptive skimming strategy in that they\n",
      "would only look for keywords that they expected to appear in a\n",
      "subsequent question.\n",
      "participants were encouraged to re-read text when they answered\n",
      "incorrectly before receiving another question (or the same\n",
      "question in some cases). many participants reported simply\n",
      "scanning the text (when re-reading) to locate keywords from the\n",
      "question before moving on. since the scanning strategy was often\n",
      "\n",
      "\n",
      "\n",
      "12\n",
      "\n",
      "\f",
      "successful to answer the subsequent question, participants\n",
      "reported that the questions were too easy and it took relatively\n",
      "little effort to locate the correct answer compared to re-reading.\n",
      "they suggested that it may have been better if the questions had\n",
      "targeted key concepts rather than facts.\n",
      "finally, participants reported difficulties with re-engaging with\n",
      "the text after answering an online question because the text was\n",
      "cleared when an intervention question was displayed; an item that\n",
      "can be easily corrected in subsequent versions.\n",
      "\n",
      "5. discussion\n",
      "we developed the first educational technology capable of realtime mind wandering detection and dynamic intervention during\n",
      "computerized reading. in the remainder of this section, we discuss\n",
      "the significance of our main findings, limitations, and avenues for\n",
      "future work.\n",
      "\n",
      "5.1 significance of main findings\n",
      "we have three main findings. first, we demonstrated that a\n",
      "machine-learned mind wandering detector built in one context\n",
      "can be applied to a different (albeit related) interaction context.\n",
      "specifically, the detector was trained on a data set involving\n",
      "participants silently reading and self-reporting mind wandering,\n",
      "but was applied to an interactive context involving interpolated\n",
      "assessments, which engendered different reading strategies.\n",
      "further, self-reports of mind wandering were not collected in this\n",
      "interactive context, which might have influenced mind wandering\n",
      "rates in and of itself. despite these differences, we were able to\n",
      "demonstrate the predictive validity of the detector by showing\n",
      "that it negatively correlated with both online and offline\n",
      "comprehension scores when evaluated on new participants.\n",
      "second, we showed promising effects for our intervention\n",
      "approach despite a very conservative experimental design, which\n",
      "ensured that the intervention and control groups were equated\n",
      "along all respects, except that the intervention was triggered based\n",
      "on the mind wandering detector (key manipulation). further, we\n",
      "used a probabilistic approach to trigger an intervention, because\n",
      "the detector is inherently imperfect. as a result, participants could\n",
      "have received an intervention when they were not mind\n",
      "wandering and/or could have failed to receive one when they were\n",
      "mind wandering. therefore, it was essential to compare the two\n",
      "groups under conditions when the mind wandering levels\n",
      "differed. this more nuanced analysis revealed that although the\n",
      "intervention itself did not lead to a boost in overall comprehension\n",
      "(because it is remedial), it equated comprehension scores when\n",
      "mind wandering was high (i.e., scores for the intervention group\n",
      "were comparable when the control group was low on mind\n",
      "wandering). it also demonstrated the cost of not intervening\n",
      "during mind wandering (i.e., scores for the intervention group\n",
      "were greater when the control group was high on mind\n",
      "wandering). in other words, the intervention was successful in\n",
      "mitigating the negative effects of mind wandering.\n",
      "third, despite the advantages articulated above, the intervention\n",
      "itself was reactive and engendered several unintended (and\n",
      "presumably suboptimal) behaviors. in particular, students altered\n",
      "their reading strategies in response to the interpolated questions,\n",
      "which were a critical part of the intervention. in a sense, they\n",
      "attempted to “game the intervention” by attempting to proactively\n",
      "predict the types of questions they might receive and then\n",
      "adopting a complementary reading strategy consisting of\n",
      "skimming and/or focusing on factual information. this reliance\n",
      "on surface- rather than deeper-levels of processing was\n",
      "incongruent with our goal of promoting deep comprehension.\n",
      "\n",
      "5.2 limitations\n",
      "there are a number of methodological limitations with this work\n",
      "that go beyond limitations with the intervention (as discussed\n",
      "above). first, we focused on a single text that is perceived as\n",
      "being quite dull and consequently triggers rather high levels of\n",
      "mind wandering [26]. this raises the question of whether the\n",
      "detector will generalize to different texts. we expect some level\n",
      "of generalizability in terms of features used because the detector\n",
      "only used content- and position- (on the screen) free global gaze\n",
      "features. however, given that several supervised classifiers are\n",
      "very sensitive to differences in base rates, the detector might overor under- predict mind wandering when applied to texts that\n",
      "engender different rates of mind wandering. therefore, retraining\n",
      "the detector with a more diverse set of texts is warranted.\n",
      "another limitation is the scalability of our learning technology.\n",
      "the eye tracker we used was a cost-prohibitive tobii tx300 that\n",
      "will not scale beyond the laboratory. fortunately, commercialoff-the-shelf (cots) eye trackers, such as eye tribe and tobii\n",
      "eyex, can be used to surpass this limitation. it is an open question\n",
      "as to whether the mind wandering detector can operate with\n",
      "similar fidelity with these cots eye trackers. our use of global\n",
      "gaze features which do not require high-precision eye tracking\n",
      "holds considerable promise in this regard. nevertheless,\n",
      "replication with scalable eye trackers and/or scalable alternatives\n",
      "to eye tracking (e.g., facial-feature tracking [46] or monitoring\n",
      "reading patterns [27]) is an important next step (see section 5.3).\n",
      "our use of surface-level questions for both the intervention and\n",
      "the subsequent comprehension assessment is also a limitation as\n",
      "is the lack of a delayed comprehension assessment. it might be\n",
      "the case that the intervention effects manifest as richer encodings\n",
      "in long-term memory, a possibility that cannot be addressed in the\n",
      "current experiment that only assessed immediate learning.\n",
      "other limitations include a limited student sample (i.e.\n",
      "undergraduates from a private midwestern college) and a\n",
      "laboratory setup. it is possible that the results would not\n",
      "generalize to a more diverse student population or in more\n",
      "ecological environments (but see below for evidence of\n",
      "generalizability of the detector in classroom environments).\n",
      "replication with data from more diverse populations and\n",
      "environments would be a necessary next step to increase the\n",
      "ecological validity of this work.\n",
      "\n",
      "5.3 future work\n",
      "our future work is progressing along two main fronts. one is to\n",
      "address limitations in the intervention and design of the\n",
      "experimental evaluation as discussed above. accordingly, we are\n",
      "exploring alternative intervention strategies, such as: (a) tagging\n",
      "items for future re-study rather than interrupting participants\n",
      "during reading; (b) highlighting specific portions of the text as an\n",
      "overt cue to facilitate comprehension of critical information; (c)\n",
      "asking fewer intervention questions, but selecting inference\n",
      "questions that target deeper levels of comprehension and that span\n",
      "multiple pages of the text; and (d) asking learners to engage in\n",
      "reflection by providing written self-explanations of the textual\n",
      "content. we are currently evaluating one such redesigned\n",
      "intervention – open-ended questions targeting deeper levels of\n",
      "comprehension (item c). our revised experimental design taps\n",
      "both surface- and inference-level comprehension and assesses\n",
      "comprehension immediately after reading (to measure learning)\n",
      "and after a one-week delay (to measure retention).\n",
      "we are also developing attention-aware versions of more\n",
      "interactive interfaces, such as learning with an intelligent tutoring\n",
      "\n",
      "\n",
      "\n",
      "13\n",
      "\n",
      "\f",
      "system called gurututor [30]. this project also addresses some\n",
      "of the scalability concerns by replacing expensive research-grade\n",
      "eye tracking with cost-effective cots eye tracking (e.g., the eye\n",
      "tribe or tobii eyex) and provides evidence for real-world\n",
      "generalizability by collecting data in classrooms rather than the\n",
      "lab. we recently tested our implementation on 135 students (total)\n",
      "in a noisy computer-enabled high-school classroom where eyegaze of entire classes of students was collected during their\n",
      "normal class periods [20]. using a similar approach to the present\n",
      "work, we used the data to build and validate a studentindependent gaze-based mind wandering detector. the resultant\n",
      "mind wandering detection accuracy (f1 of 0.59) was substantially\n",
      "greater than chance (f1 of 0.24) and outperformed earlier work on\n",
      "the same domain [21]. the next step is to develop interventions\n",
      "that redirect attention and correct learning deficiencies\n",
      "attributable to mind wandering and to test the interventions in\n",
      "real-world environments. by doing so, we hope to advance our\n",
      "foundational vision of developing next-generation technologies\n",
      "that enhance the process and products of learning by “attending\n",
      "to attention.”\n",
      "\n",
      "[6]\n",
      "\n",
      "[7]\n",
      "\n",
      "[8]\n",
      "\n",
      "[9]\n",
      "\n",
      "[10]\n",
      "\n",
      "[11]\n",
      "\n",
      "[12]\n",
      "figure 3: guru tutor interface overlaid with eye-gaze\n",
      "obtained via the eyetribe\n",
      "\n",
      "[13]\n",
      "\n",
      "6. acknowledgements\n",
      "this research was supported by the national science foundation\n",
      "(nsf) (drl 1235958 and iis 1523091). the authors are grateful\n",
      "to kris kopp and jenny wu for their contributions to the study.\n",
      "any opinions, findings and conclusions, or recommendations\n",
      "expressed in this paper are those of the authors and do not\n",
      "necessarily reflect the views of nsf.\n",
      "\n",
      "[14]\n",
      "\n",
      "[15]\n",
      "\n",
      "7. references\n",
      "[1] anderson, j.r. 2002. spanning seven orders of magnitude:\n",
      "a challenge for cognitive modeling. cognitive science, 26\n",
      "(1), 85-112.\n",
      "[2] baird, b., smallwood, j., mrazek, m.d., kam, j.w.,\n",
      "franklin, m.s. and schooler, j.w. 2012. inspired by\n",
      "distraction mind wandering facilitates creative incubation.\n",
      "psychological science, 23 (10), 1117-1122.\n",
      "[3] bixler, r. and d'mello, s.k. 2016. automatic gaze-based\n",
      "user-independent detection of mind wandering during\n",
      "computerized reading. user modeling & user-adapted\n",
      "interaction, 26, 33-68.\n",
      "[4] boys, c.v. 1895. soap bubbles, their colours and the forces\n",
      "which mold them. society for promoting christian\n",
      "knowledge.\n",
      "[5] conati, c., aleven, v. and mitrovic, a. 2013. eye-tracking\n",
      "for student modelling in intelligent tutoring systems. in\n",
      "sottilare, r., graesser, a., hu, x. and holden, h. eds.\n",
      "design recommendations for intelligent tutoring systems -\n",
      "\n",
      "[16]\n",
      "\n",
      "[17]\n",
      "\n",
      "[18]\n",
      "\n",
      "[19]\n",
      "\n",
      "volume 1: learner modeling, army research laboratory,\n",
      "orlando, fl.\n",
      "conati, c. and merten, c. 2007. eye-tracking for user\n",
      "modeling in exploratory learning environments: an\n",
      "empirical evaluation. knowledge-based systems, 20 (6),\n",
      "557-574.\n",
      "d'mello, s., olney, a., williams, c. and hays, p. 2012.\n",
      "gaze tutor: a gaze-reactive intelligent tutoring system.\n",
      "international journal of human-computer studies, 70 (5),\n",
      "377-398.\n",
      "d'mello, s.k. 2016. giving eyesight to the blind: towards\n",
      "attention-aware aied. international journal of artificial\n",
      "intelligence in education, 26 (2), 645-659.\n",
      "d'mello, s.k., blanchard, n., baker, r., ocumpaugh, j. and\n",
      "brawner, k. 2014. i feel your pain: a selective review of\n",
      "affect-sensitive instructional strategies. in sottilare, r.,\n",
      "graesser, a., hu, x. and goldberg, b. eds. design\n",
      "recommendations for adaptive intelligent tutoring\n",
      "systems: adaptive instructional strategies (volume 2), us\n",
      "army research laboratory, orlando, fl.\n",
      "d'mello, s.k., kopp, k., bixler, r. and bosch, n. 2016.\n",
      "attending to attention: detecting and combating mind\n",
      "wandering during computerized reading in extended\n",
      "abstracts of the acm sigchi conference on human\n",
      "factors in computing systems (chi 2016), acm, new\n",
      "york.\n",
      "drummond, j. and litman, d. 2010. in the zone: towards\n",
      "detecting student zoning out using supervised machine\n",
      "learning. in aleven, v., kay, j. and mostow, j. eds.\n",
      "intelligent tutoring systems., springer-verlag, berlin /\n",
      "heidelberg.\n",
      "eastwood, j.d., frischen, a., fenske, m.j. and smilek, d.\n",
      "2012. the unengaged mind: defining boredom in terms of\n",
      "attention. perspectives on psychological science, 7 (5), 482495.\n",
      "faber, m., bixler, r. and d'mello, s.k. in press. an\n",
      "automated behavioral measure of mind wandering during\n",
      "computerized reading. behavior research methods.\n",
      "franklin, m.s., broadway, j.m., mrazek, m.d., smallwood,\n",
      "j. and schooler, j.w. 2013. window to the wandering mind:\n",
      "pupillometry of spontaneous thought while reading. the\n",
      "quarterly journal of experimental psychology, 66 (12),\n",
      "2289-2294.\n",
      "gluck, k.a., anderson, j.r. and douglass, s.a. 2000.\n",
      "broader bandwidth in student modeling: what if its were\n",
      "“eye” ts? in gauthier, c., frasson, c. and vanlehn, k. eds.\n",
      "proceedings of the 5th international conference on\n",
      "intelligent tutoring systems, springer, berlin.\n",
      "graesser, a., lu, s., olde, b., cooper-pye, e. and whitten,\n",
      "s. 2005. question asking and eye tracking during cognitive\n",
      "disequilibrium: comprehending illustrated texts on devices\n",
      "when the devices break down. memory and cognition, 33,\n",
      "1235-1247.\n",
      "hanley, j.a. and mcneil, b.j. 1982. the meaning and use\n",
      "of the area under a receiver operating characteristic (roc)\n",
      "curve. radiology, 143 (1), 29-36.\n",
      "harley, j.m., lajoie, s.p., frasson, c. and hall, n.c. in\n",
      "press. developing emotion-aware, advanced learning\n",
      "technologies: a taxonomy of approaches and features.\n",
      "international journal of artificial intelligence in education.\n",
      "hegarty, m. and just, m. 1993. constructing mental models\n",
      "of machines from text and diagrams. journal of memory and\n",
      "language, 32 (6), 717-742.\n",
      "\n",
      "\n",
      "\n",
      "14\n",
      "\n",
      "\f",
      "[20] hutt, s., mills, c., bosch, n., krasich, k., brockmole, j.r.\n",
      "and d'mello, s.k. in review. out of the fr-eye- ing pan:\n",
      "towards gaze-based models of attention during learning\n",
      "with technology in the classroom.\n",
      "[21] hutt, s., mills, c., white, s., donnelly, p.j. and d’mello,\n",
      "s.k. 2016. the eyes have it: gaze-based detection of mind\n",
      "wandering during learning with an intelligent tutoring\n",
      "system. in proceedings of the 9th international conference\n",
      "on educational data mining (edm 2016), international\n",
      "educational data mining society.\n",
      "[22] jaques, n., conati, c., harley, j.m. and azevedo, r. year.\n",
      "predicting affect from gaze data during interaction with an\n",
      "intelligent tutoring system. in intelligent tutoring systems,\n",
      "(2014), springer, 29-38.\n",
      "[23] kardan, s. and conati, c. 2012. exploring gaze data for\n",
      "determining user learning with an interactive simulation. in\n",
      "carberry, s., weibelzahl, s., micarelli, a. and semeraro, g.\n",
      "eds. proceedings of the 20th international conference on\n",
      "user modeling, adaptation, and personalization (umap\n",
      "2012), springer, berlin.\n",
      "[24] killingsworth, m.a. and gilbert, d.t. 2010. a wandering\n",
      "mind is an unhappy mind. science, 330 (6006), 932-932.\n",
      "[25] kintsch, w. 1998. comprehension: a paradigm for\n",
      "cognition. cambridge university press, new york.\n",
      "[26] kopp, k., d’mello, s. and mills, c. 2015. influencing the\n",
      "occurrence of mind wandering while reading. consciousness\n",
      "and cognition, 34 (1), 52-62.\n",
      "[27] mills, c. and d’mello, s.k. 2015. toward a real-time (day)\n",
      "dreamcatcher: detecting mind wandering episodes during\n",
      "online reading. in romero, c., pechenizkiy, m., boticario,\n",
      "j. and santos, o. eds. proceedings of the 8th international\n",
      "conference on educational data mining (edm 2015),\n",
      "international educational data mining society.\n",
      "[28] mooneyham, b.w. and schooler, j.w. 2013. the costs and\n",
      "benefits of mind-wandering: a review. canadian journal of\n",
      "experimental psychology/revue canadienne de psychologie\n",
      "expérimentale, 67 (1), 11.\n",
      "[29] muir, m. and conati, c. 2012. an analysis of attention to\n",
      "student–adaptive hints in an educational game. in cerri,\n",
      "s.a., clancey, w.j., papadourakis, g. and panourgia, k.\n",
      "eds. proceedings of the international conference on\n",
      "intelligent tutoring systems, springer, berlin.\n",
      "[30] olney, a., d'mello, a., person, n., cade, w., hays, p.,\n",
      "williams, c., lehman, b. and graesser, a. 2012. guru: a\n",
      "computer tutor that models expert human tutors. in cerri, s.,\n",
      "clancey, w., papadourakis, g. and panourgia, k. eds.\n",
      "proceedings of the 11th international conference on\n",
      "intelligent\n",
      "tutoring\n",
      "systems,\n",
      "springer-verlag,\n",
      "berlin/heidelberg.\n",
      "[31] olney, a., risko, e.f., d'mello, s.k. and graesser, a.c.\n",
      "2015. attention in educational contexts: the role of the\n",
      "learning task in guiding attention. in fawcett, j., risko, e.f.\n",
      "and kingstone, a. eds. the handbook of attention, mit\n",
      "press, cambridge, ma.\n",
      "[32] pham, p. and wang, j. 2016. adaptive review for mobile\n",
      "mooc learning via implicit physiological signal sensing.\n",
      "in proceedings of the 18th acm international conference\n",
      "on multimodal interaction (icmi 2016), acm, new york,\n",
      "ny.\n",
      "[33] pham, p. and wang, j. 2015. attentivelearner: improving\n",
      "mobile mooc learning via implicit heart rate tracking. in\n",
      "international conference on artificial intelligence in\n",
      "education, springer, berlin heidelberg.\n",
      "\n",
      "[34] randall, j.g., oswald, f.l. and beier, m.e. 2014. mindwandering, cognition, and performance: a theory-driven\n",
      "meta-analysis of attention regulation. psychological\n",
      "bulletin, 140 (6), 1411-1431.\n",
      "[35] rapp, d.n. 2006. the value of attention aware systems in\n",
      "educational settings. computers in human behavior, 22 (4),\n",
      "603-614.\n",
      "[36] rayner, k. 1998. eye movements in reading and information\n",
      "processing: 20 years of research. psychological bulletin, 124\n",
      "(3), 372-422.\n",
      "[37] reichle, e.d., reineberg, a.e. and schooler, j.w. 2010. eye\n",
      "movements during mindless reading. psychological science,\n",
      "21 (9), 1300.\n",
      "[38] risko, e.f., buchanan, d., medimorec, s. and kingstone, a.\n",
      "2013. everyday attention: mind wandering and computer\n",
      "use during lectures. computers & education, 68 (1), 275283.\n",
      "[39] roda, c. and thomas, j. 2006. attention aware systems:\n",
      "theories, applications, and research agenda. computers in\n",
      "human behavior, 22 (4), 557-587.\n",
      "[40] rowe, j., mott, b., mcquiggan, s., robison, j., lee, s. and\n",
      "lester, j. year. crystal island: a narrative-centered learning\n",
      "environment for eighth grade microbiology. in workshop on\n",
      "intelligent educational games at the 14th international\n",
      "conference on artificial intelligence in education,\n",
      "brighton, uk, (2009), 11-20.\n",
      "[41] shute, v.j., ventura, m., bauer, m. and zapata-rivera, d.\n",
      "2009. melding the power of serious games and embedded\n",
      "assessment to monitor and foster learning: flow and grow.\n",
      "in ritterfeld, u., cody, m. and vorderer, p. eds. serious\n",
      "games: mechanisms and effects, routledge, taylor and\n",
      "francis, mahwah, nj.\n",
      "[42] sibert, j.l., gokturk, m. and lavine, r.a. 2000. the reading\n",
      "assistant: eye gaze triggered auditory prompting for reading\n",
      "remediation. in proceedings of the 13th annual acm\n",
      "symposium on user interface software and technology,\n",
      "acm, new york, ny.\n",
      "[43] smallwood, j., davies, j.b., heim, d., finnigan, f.,\n",
      "sudberry, m., o'connor, r. and obonsawin, m. 2004.\n",
      "subjective experience and the attentional lapse: task\n",
      "engagement and disengagement during sustained attention.\n",
      "consciousness and cognition, 13 (4), 657-690.\n",
      "[44] smallwood, j., fishman, d.j. and schooler, j.w. 2007.\n",
      "counting the cost of an absent mind: mind wandering as an\n",
      "underrecognized influence on educational performance.\n",
      "psychonomic bulletin & review, 14 (2), 230-236.\n",
      "[45] smallwood, j. and schooler, j.w. 2015. the science of mind\n",
      "wandering: empirically navigating the stream of\n",
      "consciousness. annu. rev. psychol, 66, 487-518.\n",
      "[46] stewart, a., bosch, p., chen, h., donnelly, p.j. and\n",
      "d’mello, s.k. 2016. where's your mind at? video-based\n",
      "mind wandering detection during film viewing. in aroyo,\n",
      "l., d'mello, s., vassileva, j. and blustein, j. eds.\n",
      "proceedings of the 2016 acm on international conference\n",
      "on user modeling, adaptation, & personalization (acm\n",
      "umap 2016), acm, new york.\n",
      "[47] szpunar, k.k., khan, n.y. and schacter, d.l. 2013.\n",
      "interpolated memory tests reduce mind wandering and\n",
      "improve learning of online lectures. proceedings of the\n",
      "national academy of sciences, 110 (16), 6313-6317.\n",
      "[48] wang, h., chignell, m. and ishizuka, m. 2006. empathic\n",
      "tutoring software agents using real-time eye tracking. in\n",
      "proceedings of the 2006 symposium on eye tracking\n",
      "research &applications, acm, new york.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 27) we are going to work on the first paper to make sure that our \n",
    "# regex works. Just retrieve the text and assign it to a variable below\n",
    "fp = papers[0]\n",
    "print(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-23765cdb03d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtext_between\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"abstract\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"introduction\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "# 28) find the text between the words 'abstract' and \n",
    "# 'introduction' for the first paper using a regex\n",
    "# https://stackoverflow.com/questions/12736074/regex-matching-between-two-strings/12736203\n",
    "\n",
    "import re\n",
    "text_between = fp[fp.find(\"abstract\")+1:fp(\"introduction\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-117-5edd0397447e>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-117-5edd0397447e>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    re.findall('abstract(.*)introduction', string, re.DOTALL)\u001b[0m\n\u001b[1;37m                                                             \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "# 28) find the text between the words 'abstract' and \n",
    "# 'introduction' for the first paper using a regex\n",
    "# https://stackoverflow.com/questions/12736074/regex-matching-between-two-strings/12736203\n",
    "\n",
    "import re\n",
    "string = '''\n",
    "re.findall('abstract(.*)introduction', string, re.DOTALL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-8adbd2db0825>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtext_between\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"abstract\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"introduction\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m \u001b[1;33m(\u001b[0m \u001b[1;34m'<!--(.*?)-->'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMULTILINE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "# 28) find the text between the words 'abstract' and \n",
    "# 'introduction' for the first paper using a regex\n",
    "# https://stackoverflow.com/questions/12736074/regex-matching-between-two-strings/12736203\n",
    "\n",
    "import re\n",
    "text_between = fp[fp.find(\"abstract\")+1:fp(\"introduction\")]\n",
    "\n",
    "m = re.findall ( '<!--(.*?)-->', string, re.MULTILINE)\n",
    "m\n",
    "[' two -- -- ', ' three ']\n",
    "m = re.findall ( '<!--(.*?)-->', string, re.DOTALL)\n",
    "m\n",
    "[' one \\n', ' two -- -- ', ' three ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 28) find the text between the words 'abstract' and \n",
    "# 'introduction' for the first paper using a regex\n",
    "# https://stackoverflow.com/questions/12736074/regex-matching-between-two-strings/12736203\n",
    "\n",
    "import re\n",
    "text_between = fp[first_paper.find('abstract')+1:fp('introduction')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 28) find the text between the words 'abstract' and \n",
    "# 'introduction' for the first paper using a regex\n",
    "# https://stackoverflow.com/questions/12736074/regex-matching-between-two-strings/12736203\n",
    "abstract(?s)(.*)introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 29) find the text between the words 'abstract' and \n",
    "# 'introduction' for the first paper using the .index() function\n",
    "fp_list = fp.split() \n",
    "fp_list.index(\"abstract\")\n",
    "fp_list.index(\"introduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 30) add a new column namd \"abstract\" to the dataframe above \n",
    "# and initialize it with an empty string\n",
    "import pandas as pd\n",
    "fpd = pd.DataFrame(fp_list) \n",
    "fpd.head()\n",
    "fpd['abstract'] = 'empty'\n",
    "fpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# now add the abstracts to each row of the dataframe using either\n",
    "# of the two methods above\n",
    "# Hint: https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas\n",
    "\n",
    "for index, row in fpd.iterrows():\n",
    "    print row[\"c1\"], row[\"c2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now add the abstracts to each row of the dataframe using either\n",
    "# of the two methods above\n",
    "# Hint: https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas\n",
    "\n",
    "for row in fpd.itertuples(index=True, name='Pandas'):\n",
    "    print getattr(row, \"c1\"), getattr(row, \"c2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 31) print your abstracts (they should contain a lot of \\n = carriage return)\n",
    "print(df.loc['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 32) clean the abstract column using the \"apply\" function with a lambda\n",
    "# Hint: https://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.Series.apply.html\n",
    "\n",
    "def valuation_formula(x, y):\n",
    "    return x * y * 0.5\n",
    "\n",
    "fpd['abstract'] = fpd.apply(lambda row: valuation_formula(row['x'], row['y']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing documents using TF-IDF (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 33) now we are going to do something a little more advanced:'\n",
    "# we are going to compute the similarity between two texts\n",
    "# using a method called tf-idf (we'll talk more about it later)\n",
    "# Hint: https://stackoverflow.com/questions/43631533/similarity-between-two-text-documents-in-python\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34) What can you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 35) repeat the same procedure with the entire papers\n",
    "# Use the same logic as the previous cell, but use the text_list variable that we defined previously\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 36) What are two documents that seem to be very similar?\n",
    "# print their abstract: \n",
    "# print the first 1000 characters of each paper. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 37) what seems to be similar between them? \n",
    "\n",
    "# they both talk about analyzing questions and answers from students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free exploration (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- try to extract the names of the author\n",
    "- find a way to get the top words shared across two texts\n",
    "- use a regex (or any other method) to get the list of references"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
